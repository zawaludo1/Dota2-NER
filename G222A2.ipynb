{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "510138903_5046a2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "RFZSKcTxJWsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input embedding"
      ],
      "metadata": {
        "id": "ofhFAZu9gdV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Xu1fXeepI2pO",
        "outputId": "aeb6bb3d-7e06-4099-f5e8-1963254df87f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nwith open ('/content/drive/MyDrive/Colab Notebooks/5046a2/train.csv', 'rb') as f:\\n  train_data = pd.read_csv(f)\\nwith open ('/content/drive/MyDrive/Colab Notebooks/5046a2/val.csv', 'rb') as f:\\n  val_data = pd.read_csv(f)\\nwith open ('/content/drive/MyDrive/Colab Notebooks/5046a2/test_without_labels.csv', 'rb') as f:\\n  test_data = pd.read_csv(f)\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "!pip install -U -q PyDrive\n",
        "# ignore warning\n",
        "'''\n",
        "\n",
        "# load direction\n",
        "drive.mount('/content/drive/')\n",
        "'''\n",
        "# load 3 original csv: train, val, test dataset\n",
        "\n",
        "'''\n",
        "with open ('/content/drive/MyDrive/Colab Notebooks/5046a2/train.csv', 'rb') as f:\n",
        "  train_data = pd.read_csv(f)\n",
        "with open ('/content/drive/MyDrive/Colab Notebooks/5046a2/val.csv', 'rb') as f:\n",
        "  val_data = pd.read_csv(f)\n",
        "with open ('/content/drive/MyDrive/Colab Notebooks/5046a2/test_without_labels.csv', 'rb') as f:\n",
        "  test_data = pd.read_csv(f)\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import numpy as np\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1A29ZOhMVmc07SqmB0uC9WZ4YNRtCD3L4'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')\n",
        "train_data = pd.read_csv('train.csv')\n",
        "\n",
        "id = '1y-aON0QoQAVQheaV6WSQWXI-AuZeNpWx'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv')\n",
        "val_data = pd.read_csv('val.csv')\n",
        "\n",
        "id = '1OMftftj9IsmNobKKApFzeQ6nLUVK1E_R'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test_without_labels.csv')\n",
        "test_data = pd.read_csv('test_without_labels.csv')\n",
        "\n",
        "x_train = train_data['sents'].tolist()\n",
        "y_train = train_data['labels'].tolist()\n",
        "\n",
        "x_val = val_data['sents'].tolist()\n",
        "y_val = val_data['labels'].tolist()\n",
        "\n",
        "x_test = test_data['sents'].tolist()\n"
      ],
      "metadata": {
        "id": "dPcTqBHGMf5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_len_test_words = []\n",
        "for i in x_test:\n",
        "  for j in i.split():\n",
        "    total_len_test_words.append(j)\n",
        "len(total_len_test_words)"
      ],
      "metadata": {
        "id": "0HGWCqBj-_zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4c5246-d8ba-4ba2-b589-890147dfa2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2326"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train_len',len(train_data))\n",
        "print(x_train[0:2])\n",
        "print(y_train[0:2])\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "iiE6439bJZsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "f8d2baed-98f8-4c63-9fd7-56319c4232d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_len 26078\n",
            "['wow', 'WTF']\n",
            "['O', 'T']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sents labels\n",
              "0      wow      O\n",
              "1      WTF      T\n",
              "2  wpe wpe    O O\n",
              "3   hahaha      O\n",
              "4      wtf      T"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2adf6243-85cb-4b68-a78f-6b3914c3bb43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WTF</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wpe wpe</td>\n",
              "      <td>O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hahaha</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wtf</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2adf6243-85cb-4b68-a78f-6b3914c3bb43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2adf6243-85cb-4b68-a78f-6b3914c3bb43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2adf6243-85cb-4b68-a78f-6b3914c3bb43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('val_len',len(val_data))\n",
        "print(x_val[0:2])\n",
        "print(y_val[0:2])\n",
        "val_data.head()"
      ],
      "metadata": {
        "id": "St88hslVKZKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "5322a9b2-c450-4861-c889-abaeb5973efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val_len 8705\n",
            "['GG', 'gg']\n",
            "['S', 'S']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      sents        labels\n",
              "0                        GG             S\n",
              "1                        gg             S\n",
              "2  GG [SEPA] nice late game  S SEPA O O O\n",
              "3                       FUK             T\n",
              "4                        ;)             O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54678ac7-49b1-49b8-9805-c7bbd9cde62c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GG</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gg</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GG [SEPA] nice late game</td>\n",
              "      <td>S SEPA O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FUK</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>;)</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54678ac7-49b1-49b8-9805-c7bbd9cde62c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54678ac7-49b1-49b8-9805-c7bbd9cde62c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54678ac7-49b1-49b8-9805-c7bbd9cde62c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('test_len',len(test_data))\n",
        "print(x_test[0:2])\n",
        "test_data.head()"
      ],
      "metadata": {
        "id": "3Izir1CaLLea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "6541e32a-0786-414a-f954-14def7dc9d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_len 500\n",
            "['FUCKER', 'hahha']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       sents\n",
              "0     FUCKER\n",
              "1      hahha\n",
              "2      ggggg\n",
              "3  macropyre\n",
              "4       Boom"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-824b361f-8d23-4188-829e-833f737a011b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FUCKER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hahha</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ggggg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>macropyre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Boom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-824b361f-8d23-4188-829e-833f737a011b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-824b361f-8d23-4188-829e-833f737a011b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-824b361f-8d23-4188-829e-833f737a011b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H9xgCTc7PIRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Syntactic (pos+dep+ent)"
      ],
      "metadata": {
        "id": "broj8fblT6pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "from spacy.tokens import Doc\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "def token_same_num(sent):\n",
        "  tokenizer = Doc(nlp.vocab, sent.split())\n",
        "  return tokenizer\n",
        "nlp = en_core_web_sm.load()\n",
        "nlp.tokenizer = token_same_num\n",
        "\n",
        "def syn_inf(data):\n",
        "  pos = []\n",
        "  dependency = []\n",
        "  entity = []\n",
        "  \n",
        "  for i in range(len(data)):\n",
        "\n",
        "    data_temp = data[i]\n",
        "\n",
        "    pos_temp = []\n",
        "    dep_temp = []\n",
        "    ent_temp = []\n",
        "    \n",
        "    for j in nlp(data_temp):\n",
        "      \n",
        "      pos_temp.append(j.tag_)\n",
        "      dep_temp.append(j.dep_)\n",
        "      ent_temp.append(j.ent_type_)\n",
        "    \n",
        "    \n",
        "    pos.append(pos_temp)\n",
        "    dependency.append(dep_temp)\n",
        "    entity.append(ent_temp)\n",
        "      \n",
        "  return pos, dependency, entity"
      ],
      "metadata": {
        "id": "6NwK46EnP8DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "train_pos, train_dep, train_ent = syn_inf(x_train)\n",
        "val_pos, val_dep, val_ent = syn_inf(x_val)\n",
        "test_pos, test_dep, test_ent = syn_inf(x_test)\n",
        "'''"
      ],
      "metadata": {
        "id": "ciSIm2D-_PyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64011edd-d159-4bdf-8eaf-ea0347f65a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_pos, train_dep, train_ent = syn_inf(x_train)\\nval_pos, val_dep, val_ent = syn_inf(x_val)\\ntest_pos, test_dep, test_ent = syn_inf(x_test)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/syn/'\n",
        "file_name = ['train_pos.pkl', 'train_dep.pkl', 'train_ent.pkl',\n",
        "'val_pos.pkl', 'val_dep.pkl', 'val_ent.pkl',\n",
        "'test_pos.pkl', 'test_dep.pkl', 'test_ent.pkl']\n",
        "\n",
        "\n",
        "'''\n",
        "file = [train_pos, train_dep, train_ent,\n",
        "val_pos, val_dep, val_ent,\n",
        "test_pos, test_dep, test_ent]\n",
        "\n",
        "\n",
        "for i in range(len(file_name)):\n",
        "  \n",
        "  f = open(dir+file_name[i], 'wb')\n",
        "  pickle.dump(file[i], f)\n",
        "  f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(file_name)):\n",
        "  \n",
        "  f = open(dir+file_name[i], 'rb')\n",
        "  file[i] = f\n",
        "  f.close()\n",
        "'''"
      ],
      "metadata": {
        "id": "iykV32rUUP2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3f6f2bef-715d-46f6-ef8d-6518262a4225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfile = [train_pos, train_dep, train_ent,\\nval_pos, val_dep, val_ent,\\ntest_pos, test_dep, test_ent]\\n\\n\\nfor i in range(len(file_name)):\\n  \\n  f = open(dir+file_name[i], 'wb')\\n  pickle.dump(file[i], f)\\n  f.close()\\n\\n\\n\\n\\nfor i in range(len(file_name)):\\n  \\n  f = open(dir+file_name[i], 'rb')\\n  file[i] = f\\n  f.close()\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plist = [0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for i in range(9):\n",
        "  plist[i] = pickle.load(open(dir+file_name[i], 'rb'))\n",
        "\n",
        "train_pos, train_dep, train_ent, val_pos, val_dep, val_ent, test_pos, test_dep, test_ent = plist[0],plist[1],plist[2],plist[3],plist[4],plist[5],plist[6],plist[7],plist[8]"
      ],
      "metadata": {
        "id": "cHIHe3pyV8ZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(len(train_pos[i]) == len(x_train[i].split()))"
      ],
      "metadata": {
        "id": "q2pLHpR_up5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3004dcbf-7297-4b87-e703-0169176173c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {}\n",
        "for sentence in x_train+x_val+x_test:\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "for tags in y_train+y_val:\n",
        "    for tag in tags.split():\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)   "
      ],
      "metadata": {
        "id": "e3hrmJMAI2Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('num words:',len(word_to_ix))\n",
        "print(word_to_ix)\n",
        "print(word_list)\n",
        "print('-'*80)\n",
        "print('num tags:',len(tag_to_ix))\n",
        "print(tag_to_ix)"
      ],
      "metadata": {
        "id": "UT4e94tIWE8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bba95234-5861-4cc7-d500-0d2b7fb9946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num words: 14015\n",
            "{'wow': 0, 'WTF': 1, 'wpe': 2, 'hahaha': 3, 'wtf': 4, 'i': 5, 'cant': 6, '[SEPA]': 7, 'play': 8, 'with': 9, '4': 10, 'trash': 11, 'bg': 12, '#ERROR!': 13, 'gg': 14, 'report': 15, 'my': 16, 'team': 17, 'rat': 18, 'please': 19, 'ez': 20, 'mid': 21, 'hahah': 22, 'arrows': 23, 'always': 24, 'decent': 25, 'fuck': 26, 'u': 27, 'gh': 28, 'engage': 29, 'at': 30, 'bot': 31, 'lc': 32, 'takle': 33, 'then': 34, 'top': 35, 'cmon': 36, 'the': 37, 'comeback': 38, 'is': 39, 'real': 40, ':)': 41, 'him': 42, 'vs': 43, 'me': 44, 'just': 45, 'end': 46, 'wan': 47, 'nex': 48, 'game': 49, 'g': 50, 'he': 51, 'not': 52, 'losing': 53, 'Pls': 54, 'sb': 55, 'thanks': 56, 'omg': 57, 'ggwp': 58, 'WP': 59, 'cap': 60, 'lo': 61, 'lol': 62, 'fuyckjerfe': 63, 'noob': 64, 'invoker': 65, 'mean': 66, 'everyone': 67, 'on': 68, 'ur': 69, 'dumb': 70, 'enough': 71, 'to': 72, 'rot': 73, 'down': 74, '2': 75, 'hp': 76, '8': 77, 'it': 78, 'random': 79, ':/': 80, 'dead': 81, 'keeps': 82, 'charhing': 83, 'since': 84, 'spectre': 85, 'comited': 86, 'ult': 87, 'so': 88, 'did': 89, 'I': 90, ':D': 91, 'thought': 92, 'they': 93, 'will': 94, 'go': 95, 'for': 96, 'more': 97, 'blood': 98, 'but': 99, 'whatever': 100, 'too': 101, 'ty': 102, 'mmr': 103, 'you': 104, 'know': 105, 'can': 106, 'take': 107, 'mana': 108, 'thing': 109, 'out': 110, 'of': 111, 'boots': 112, 'gave': 113, 'free': 114, 'farm': 115, 'could': 116, 'kill': 117, '100': 118, 'times': 119, 'wp': 120, 'legoin': 121, 'm8': 122, 'nice': 123, 'many': 124, 'shit': 125, 'talk': 126, 'thx': 127, 'sea': 128, 'cancer': 129, 'talktalktalk': 130, 'SHIT': 131, 'talking': 132, 'boy': 133, 'alch': 134, 'TIME': 135, 'FOR': 136, 'A': 137, 'BIT': 138, 'OF': 139, 'RO': 140, 'SHAM': 141, 'BO': 142, 'COMEND': 143, 'DOOM': 144, 'IN': 145, 'LEGION': 146, 'greedy': 147, 'dont': 148, 'def': 149, 'isnt': 150, 'meant': 151, 'win': 152, 'lane': 153, 'SHITTT': 154, 'sad': 155, 'bs': 156, 'T': 157, 'QOP': 158, 'guys': 159, 'this': 160, 'fag': 161, 'went': 162, 'fucking': 163, 'bad': 164, 'Alche': 165, 'and': 166, 'lycan': 167, 'Rip': 168, 'singing': 169, 'siren': 170, 'dancing': 171, 'jugg': 172, 'meeporino': 173, 'feederino': 174, 'asshole': 175, 'Thats': 176, 'all': 177, 'gotta': 178, 'say': 179, 'Drow': 180, '5': 181, 'COMMEND': 182, 'lowskill': 183, 'shits': 184, 'have': 185, 'do': 186, 'dive': 187, 'endlessly': 188, 'cunt': 189, 'silencer': 190, 'invoekr': 191, 'let': 192, 'tnx': 193, 'russian': 194, 'obama': 195, 'least': 196, 'nuked': 197, 'putin': 198, 'wise': 199, 'ffs': 200, 'youi': 201, 'stop': 202, 'inviting': 203, 'strangers': 204, 'your': 205, 'grandmothers': 206, 'corpse': 207, 'heng': 208, 'never': 209, 'die': 210, 'We': 211, 'randomed': 212, 'golden': 213, 'medal': 214, 'GG': 215, 'lag': 216, 'HAHA': 217, 'btw': 218, 'AM': 219, 'blink': 220, 'into': 221, 'stun': 222, 'who': 223, 'care': 224, 'emergency': 225, 'plan': 226, 'sry': 227, 'want': 228, 'slardar': 229, 'getting': 230, 'strong': 231, 'ahahaha': 232, 'tho': 233, 'feeling': 234, 'bro': 235, 'whos': 236, 'daddy': 237, 'stunning': 238, 'man': 239, 'doto': 240, 'Sry': 241, 'feed': 242, 'dnt': 243, 'storm': 244, 'LOL': 245, 'be': 246, 'won': 247, 'weaver': 248, 'worry': 249, 'trone': 250, 'bm': 251, 'gj': 252, 'Ty': 253, 'hahahai': 254, 'blame': 255, 'us': 256, 'YEAAHHHHHHHHH': 257, 'GGGGGGGGGGGG': 258, 'EZ': 259, 'aw': 260, 'telling': 261, 'im': 262, 'much': 263, 'a': 264, 'solo': 265, 'player': 266, 'He': 267, 's': 268, 'picked': 269, 'in': 270, 'pubs': 271, 'only': 272, 'bracket': 273, 'has': 274, 'over': 275, 'rate': 276, 'very': 277, 'high': 278, 'skill': 279, 'asian': 280, 'servers': 281, 'So': 282, 'shut': 283, 'up': 284, 'pick': 285, 'something': 286, 'fun': 287, 'You': 288, 'cucks': 289, '2v5': 290, 'lmao': 291, 'captain': 292, 'obvious': 293, 'right': 294, ':DD': 295, 'better': 296, 'buy': 297, 'ticket': 298, 'was': 299, 'close': 300, 'furion': 301, 'kno': 302, 'necro': 303, 'book': 304, 'push': 305, 'think': 306, 'rage': 307, 'quit': 308, 'agad': 309, 'DONT': 310, 'PANIC': 311, 'GGW': 312, 'P': 313, 'see': 314, 'oh': 315, '13': 316, 'kills': 317, 'glad': 318, 'got': 319, 'suport': 320, 'gogo': 321, 'now': 322, 'leave': 323, 'five': 324, 'stack': 325, 'or': 326, 'put': 327, 'th': 328, '24': 329, 'come': 330, 'mama': 331, 'hhaha': 332, 'throws': 333, 'noobs': 334, 'Tol': 335, 'musta': 336, 'Text': 337, 'text': 338, 'nalang': 339, 'happens': 340, 'am': 341, 'waaa': 342, 'void': 343, 'dick': 344, 'head': 345, 't2': 346, 'rosh': 347, 'duza': 348, 'lose': 349, 'xaxaxa': 350, 'gee': 351, 'we': 352, '5x4': 353, '22': 354, 'min': 355, 'wheres': 356, 'facepalm': 357, 'emote': 358, 'when': 359, 'legion': 360, 'carry': 361, 'best': 362, 'time': 363, 'brew': 364, 'pls': 365, 'commend': 366, 'ofc': 367, 'its': 368, 'stupid': 369, 'no': 370, 'ward': 371, 'really': 372, 'family': 373, 'NOOB': 374, 'acc': 375, 'late': 376, 'obviusly': 377, 'pro': 378, 'snierp': 379, 'wihtout': 380, 'dust': 381, 'hey': 382, 'snieper': 383, 'basically': 384, 'mirana': 385, 'are': 386, 'wrong': 387, 'rep': 388, 'rt': 389, 'rubick': 390, 'O': 391, 'M': 392, 'F': 393, 'G': 394, 'FANI': 395, 'SUPHD': 396, 'brood': 397, 'REST': 398, 'IS': 399, 'Dude': 400, 'slow': 401, '180': 402, 'pure': 403, 'damage': 404, 'chance': 405, 'crit': 406, '6': 407, 'second': 408, 'cooldown': 409, '0': 410, 'Genuinely': 411, 'wait': 412, 'dota': 413, 'why': 414, 'don': 415, 'dare': 416, 'how': 417, 'long': 418, 'mor': 419, 'rofl': 420, 'indeed': 421, 'leader': 422, 'hi': 423, 'leong': 424, 'sir': 425, 'serenity': 426, 'TY': 427, 'alche': 428, 'needs': 429, 'BH': 430, 'still': 431, 'loses': 432, 'See': 433, 'next': 434, 'lion': 435, 'clock': 436, 'finish': 437, 'viper': 438, 'coz': 439, 'love': 440, 'wO': 441, 'AHAHAHA': 442, '1vs9090123': 443, 'reason': 444, 'help': 445, ';)': 446, 'w8': 447, 'plz': 448, 'eco': 449, 'mantan': 450, 'LUNA': 451, 'LVL': 452, 'HAHAHA': 453, 'need': 454, 'recon': 455, 'THANKS': 456, 'TO': 457, 'ME': 458, 'GUESS': 459, 'np': 460, 'bought': 461, 'account': 462, 'dc': 463, 'try': 464, 'hard': 465, 'nomas': 466, 'one': 467, 'hgahahah': 468, 'both': 469, 'yea': 470, 'feeding': 471, 'that': 472, 'carried': 473, 'haha': 474, 'Tired': 475, 'already': 476, 'Level': 477, 'Invo': 478, 'jungle': 479, 'Gank': 480, 'pumped': 481, 'load': 482, 'cum': 483, 'mums': 484, 'ass': 485, 'hole': 486, 'last': 487, 'night': 488, '1': 489, 'there': 490, 'came': 491, ':(': 492, 'bye': 493, 'nope': 494, 'today': 495, 'alc': 496, 'normal': 497, 'wont': 498, 'hit': 499, 'tht': 500, 'minute': 501, 'less': 502, 'unstable': 503, 'point': 504, 'WR': 505, 'suporting': 506, 'our': 507, 'asses': 508, 'tb': 509, 'veno': 510, 'competent': 511, 'ones': 512, 'wr': 513, 'maxed': 514, 'wind': 515, 'run': 516, 'first': 517, 'case': 518, 'were': 519, 'wondering': 520, 'easy': 521, 'btu': 522, 'wouldve': 523, 'if': 524, 'd': 525, 'idnt': 526, 'cm': 527, 'doom': 528, 'aso': 529, 'rl': 530, 'bleme': 531, 'gimme': 532, 'aids': 533, 'blem': 534, 'temA': 535, 'ten': 536, 'lich': 537, 'carrying': 538, 'tissue': 539, 'paper': 540, 'dsnt': 541, 'make': 542, 'diff': 543, 'fuckin': 544, 'dickhead': 545, 'Ge': 546, 'ge': 547, 'party': 548, 'YEAH': 549, 'DIDNT': 550, 'HAD': 551, 'THJE': 552, 'SLOT': 553, 'DUST': 554, 'ADN': 555, 'ALSO': 556, 'GYRO': 557, 'FFEDED': 558, 'LOT': 559, 'STILL': 560, 'WE': 561, 'TRIED': 562, 'does': 563, 'dazzle': 564, 'hero': 565, 'crys': 566, 'e': 567, 'pause': 568, '3': 569, 'ehehe': 570, 'problem': 571, 'ni': 572, 'mei': 573, 'great': 574, 'gane': 575, 'brobounty': 576, 'brounty': 577, 'GIGIL': 578, 'THE': 579, 'MAX': 580, 'Ez': 581, 'pudge': 582, 'hjaha': 583, '1000': 584, 'HAhaha': 585, 'entertain': 586, 'fingers': 587, 'defending': 588, 'ancient': 589, '4v5': 590, 'PROBLEMS': 591, 'PICK': 592, 'DAZLE': 593, 'ORACLE': 594, 'GAME': 595, 'FEED': 596, 'ONLY': 597, 'OPTION': 598, 'gyro': 599, 'earlyy': 600, 'socre': 601, 'MEEPO': 602, 'TNX': 603, 'lost': 604, 'wut': 605, 'One': 606, 'by': 607, 'Commend': 608, 'support': 609, 'HOW': 610, 'BOUT': 611, 'MID': 612, 'flying': 613, 'muy': 614, 'valve': 615, 'kkk': 616, 'bara': 617, 'charge': 618, 'well': 619, 'deinfinately': 620, 'reporting': 621, 'sf': 622, 'hundy': 623, 'ahahahahah': 624, 'EPIC': 625, 'goblok': 626, 'sniper': 627, 'FL': 628, 'ready': 629, 'get': 630, 'dumpstered': 631, 'legendary': 632, 'laught': 633, 'lel': 634, 'cause': 635, 'yo': 636, 'flare': 637, 'whats': 638, 'sk': 639, 'didnt': 640, 'realize': 641, 'seconds': 642, 'those': 643, 'tiger': 644, 'snake': 645, 'logo': 646, 'wo': 647, 'NO': 648, 'REASON': 649, 'CONTINUE': 650, 'glhf': 651, '4e': 652, 'tam': 653, 'zombie': 654, 'where': 655, '1v1': 656, 'COMEBACK': 657, ':#': 658, ':3': 659, 'ok': 660, 'wouldnt': 661, 'dp': 662, 'sorry': 663, 'couldnt': 664, 'resist': 665, 'quitters': 666, 'Hahaha': 667, 'Fucking': 668, 'hell': 669, 'SON': 670, 'GOD': 671, 'ALL': 672, 'FCKING': 673, 'JUNGLE': 674, 'ITS': 675, 'WARDED': 676, 'retard': 677, 'stalker': 678, '14': 679, '7': 680, 'bh': 681, 'ohhh': 682, 'IIIIIII': 683, 'NEED': 684, 'KNOW': 685, 'NOW': 686, 'CAN': 687, 'YOU': 688, 'LOVE': 689, 'AGAIN': 690, 'boys': 691, 'spend': 692, '10': 693, 'life': 694, 'mate': 695, 'SLARK': 696, 'mouse': 697, 'prob': 698, 'yet': 699, 'live': 700, 'b': 701, 'THIS': 702, '2K': 703, 'STORM': 704, 'OMG': 705, 'HAPPY': 706, 'NEW': 707, 'YEAR': 708, '1400': 709, 'Nice': 710, 'lsot': 711, 'junglers': 712, 'any': 713, 'worse': 714, 'gege': 715, 'noooo': 716, 'Gg': 717, 'rekt': 718, 'what': 719, 'playing': 720, 'invo': 721, 'an': 722, 'alright': 723, 'lineup': 724, 'things': 725, 'considered': 726, 'also': 727, 'lina': 728, 'didnr': 729, 'pos': 730, 'visage': 731, 'qop': 732, 'huskar': 733, 'Im': 734, 'fantastic': 735, 'Your': 736, 'autistic': 737, ':': 738, 'pugna': 739, 'funny': 740, '25': 741, 'ban': 742, 'like': 743, 'muted': 744, 'yellow': 745, 'dude': 746, 'crying': 747, 'stealing': 748, 'his': 749, 'dagon': 750, 'lick': 751, 'dildo': 752, 'straight': 753, 'reported': 754, 'fck': 755, 'ill': 756, 'greeves': 757, 'attaturk': 758, 'match': 759, 'excited': 760, 'idiot': 761, 'fail': 762, 'ah': 763, 'failed': 764, 'going': 765, 'rune': 766, 'HAha': 767, 'quelling': 768, 'OK': 769, 'ARE': 770, '6k': 771, 'Ok': 772, 'spec': 773, 'poor': 774, 'network': 775, 'U': 776, 'seen': 777, 'miracle': 778, '1k': 779, 'Freaking': 780, 'reportt': 781, 'axe': 782, 'happened': 783, 'before': 784, 'missclick': 785, 'pickphase': 786, 'fought': 787, 'bitch': 788, 'early': 789, 'cannot': 790, 'supp': 791, 'surivive': 792, 'continue': 793, 'yeah': 794, ':P': 795, 'But': 796, 'WHY': 797, 'SO': 798, 'GGwp': 799, 'hehe': 800, 'after': 801, 'being': 802, 'fed': 803, 'ds': 804, 'typical': 805, 'scared': 806, 'made': 807, 'from': 808, 'potato': 809, 'look': 810, 'these': 811, 'heroes': 812, 'anyone': 813, 'anymore': 814, 'WOOW': 815, 'happen': 816, 'pa': 817, 'okay': 818, 'killing': 819, 'liar': 820, 'DID': 821, 'WAIT': 822, 'AA': 823, 'tACTICAL': 824, 'AFK': 825, 'LMAO': 826, 'SUpport': 827, 'alchemiST': 828, 'AlchEMist': 829, 'BRO': 830, 'AlcheMIst': 831, 'Dont': 832, 'SHy': 833, 'Talk': 834, 'nc': 835, 'WTFF': 836, 'HAHAHAHAHA': 837, 'omggg': 838, 'sitll': 839, 'urge': 840, 'ember': 841, 'Bye': 842, 'easiest': 843, 'bate': 844, 'ALCHE': 845, 'uz': 846, 'works': 847, 'sparTA': 848, 'D': 849, 'yes': 850, 'hack': 851, 'ohoy': 852, 'worthit': 853, 'id': 854, 'tap': 855, 'astack': 856, 'DC': 857, 'mag': 858, 'good': 859, 'fucked': 860, 'sd': 861, 'said': 862, '4k': 863, 'cur': 864, 'miss': 865, 'anime': 866, 'loving': 867, 'gutta': 868, 'luv': 869, 'peru': 870, 'breezy': 871, 'suchtryhard': 872, 'HABLA': 873, 'BIEN': 874, 'BURRO': 875, 'threow': 876, 'jajaja': 877, 'oks': 878, 'c': 879, 'en': 880, '38': 881, 'sacas': 882, 'sky': 883, 'XD': 884, 'iy': 885, 'pl': 886, 'loooooooool': 887, 'wanted': 888, 'x': 889, 'le': 890, 'epig': 891, 'y': 892, '2k': 893, 'wk': 894, 'doesnt': 895, 'understand': 896, 'Sure': 897, 'riki': 898, 'Rtc': 899, 'ti': 900, 'hes': 901, '<3': 902, 'titty': 903, 'Crystal': 904, 'Maiden': 905, 'woodden': 906, 'cock': 907, 'use': 908, 'aggro': 909, 'hate': 910, 'assholes': 911, 'dual': 912, 'lanes': 913, 'jsut': 914, 'practice': 915, 'lest': 916, 'faggot': 917, 'tfw': 918, 'must': 919, 'punish': 920, 'mega': 921, 'cree': 922, 'goo': 923, 'Rofl': 924, 'suck': 925, 'killed': 926, 'agagin': 927, 'left': 928, 'them': 929, 'ghg': 930, 'almost': 931, 'couz': 932, 'watching': 933, 'holy': 934, 'unpaused': 935, 'ahha': 936, 'w': 937, '32': 938, 'rapier': 939, 'sec': 940, 'loL': 941, 'feel': 942, 'mk': 943, 'rip': 944, 'peppers': 945, 'NOB': 946, 'TEAM': 947, 'bash': 948, 'brown': 949, 'voker': 950, 'EZI': 951, 'ES': 952, 'pc': 953, 'freeze': 954, 'necor': 955, 'as': 956, 'hehehe': 957, 'Gs': 958, 'EVERYONE': 959, 'DESD': 960, 'swap': 961, 'bart': 962, 'WOW': 963, 'enigMa': 964, 'offlane': 965, 'AWWW': 966, 'whine': 967, 'S': 968, 'OpieOP': 969, 'wipe': 970, 'would': 971, 'surprising': 972, 'fb': 973, 'ta': 974, 'fking': 975, 'godd': 976, 'GGWP': 977, 'two': 978, 'gems': 979, 'Stop': 980, 'HEY': 981, 'OKAY': 982, 'WANT': 983, 'MORE': 984, 'gl': 985, 'endead': 986, 'sylla': 987, 'Ur': 988, 'moving': 989, 'paterns': 990, 'weird': 991, 'af': 992, 'scored': 993, 'build': 994, 'stuns': 995, 'Daun': 996, 'na': 997, 'weavere': 998, 'venge': 999, 'prosto': 1000, 'ebanutie': 1001, 'lsi': 1002, 'ebanie': 1003, 'little': 1004, 'What': 1005, 'calling': 1006, 'forced': 1007, 'fights': 1008, 'engagments': 1009, 'afk': 1010, 'had': 1011, 'mute': 1012, 'list': 1013, 'stuff': 1014, 'hahahaahah': 1015, 'lucky': 1016, 'bashes': 1017, 'unpause': 1018, 'fuq': 1019, 'tyu': 1020, 'omfg': 1021, '3k': 1022, '4k6': 1023, 'tele': 1024, 'Reportd': 1025, 'Noooob': 1026, 'trolls': 1027, 'la': 1028, 'smoke': 1029, 'price': 1030, 'increase': 1031, 'EXCUSE': 1032, 'HIM': 1033, 'ursa': 1034, 'WK': 1035, 'booya': 1036, 'fckin': 1037, 'antimage': 1038, 'xD': 1039, 'ROFL': 1040, 'rp': 1041, 'rim': 1042, 'starting': 1043, 'No': 1044, 'Today': 1045, 'mns': 1046, 'games': 1047, 'SEA': 1048, 'Oryou': 1049, 'home': 1050, 'father': 1051, 'some': 1052, 'FIGHT': 1053, 'PA': 1054, 'jajajaja': 1055, 'mlg': 1056, 'watch': 1057, 'watafak': 1058, '149': 1059, 'defend': 1060, 'counter': 1061, 'damn': 1062, 'told': 1063, 'mention': 1064, 'spoterd': 1065, 'spotted': 1066, 'thank': 1067, '2bad': 1068, 'TAKE': 1069, 'IT': 1070, 'LIAR': 1071, 'FRIENND': 1072, 'End': 1073, 'eat': 1074, 'jummy': 1075, 'BYE': 1076, 'gonna': 1077, 'safe': 1078, 'Team': 1079, 'maibe': 1080, 'RLY': 1081, 'scrubs': 1082, 'complain': 1083, 'nap': 1084, 'AND': 1085, 'HE': 1086, 'BAD': 1087, 'TA': 1088, 'rape': 1089, '58': 1090, 'mom': 1091, 'teach': 1092, '555': 1093, 'hahahahaa': 1094, 'return': 1095, '2012': 1096, 'LOLOLOL': 1097, 'USELESS': 1098, 'GO': 1099, 'ho': 1100, '68': 1101, 'having': 1102, 'cry': 1103, 'wasted': 1104, 'ulti': 1105, '<': 1106, 'died': 1107, 'inside': 1108, 'ago': 1109, 'cow': 1110, 'farmer': 1111, 'nightmares': 1112, 'SORRY': 1113, '30s': 1114, 'cd': 1115, 'true': 1116, 'items': 1117, 'nor': 1118, 'chat': 1119, 'reprot': 1120, '11': 1121, 'enigma': 1122, 'ftw': 1123, 'fight': 1124, 'PUDGE': 1125, 'If': 1126, 'fallout': 1127, 'here': 1128, 'dA': 1129, 'BB': 1130, 'GERAL': 1131, 'TEM': 1132, 'tnc': 1133, 'mineski': 1134, 'korea': 1135, 'ggggg': 1136, 'Weird': 1137, 'Dead': 1138, 'hyung': 1139, 'happening': 1140, 'mvp': 1141, 'hooking': 1142, 'mint': 1143, 'r': 1144, 'stupids': 1145, 'putting': 1146, 'es': 1147, 'ahahahah': 1148, 'lying': 1149, 'food': 1150, 'ye': 1151, 'mi': 1152, 'rampage': 1153, '=S': 1154, 'might': 1155, 'cleave': 1156, 'death': 1157, 'peneoise': 1158, 'listen': 1159, 'urself': 1160, 'LORc': 1161, 'LORD': 1162, 'SPECTRE': 1163, 'BLASPHEMY': 1164, 'alr': 1165, 'reconnecting': 1166, 'jajahaha': 1167, 'pub': 1168, 'safelane': 1169, 'bet': 1170, 'around': 1171, '30': 1172, 'guarantee': 1173, 'ive': 1174, 'commended': 1175, 'lesh': 1176, 'set': 1177, 'sentries': 1178, 'rather': 1179, 'than': 1180, 'mmrt': 1181, 'wagon': 1182, 'husk': 1183, 'From': 1184, 'PogChamp': 1185, 'alliance': 1186, 'back': 1187, 'ka': 1188, 'bu': 1189, 'tooooooooooooo': 1190, 'toxic': 1191, 'eggs': 1192, 'tsuyuyuy': 1193, 'tsokotomotoko': 1194, 'because': 1195, '10min': 1196, 'bush': 1197, '420': 1198, 'FF': 1199, 'lollllllllllllllllll': 1200, 'mother': 1201, 'snow': 1202, 'fine': 1203, 'friend': 1204, 'idk': 1205, 'WOWO': 1206, 'started': 1207, 'fighting': 1208, 'gods': 1209, 'kk': 1210, 'hahahahah': 1211, 'HAHAHAHAH': 1212, 'HAHAHAHHAHAHA': 1213, 'HAHAHAHAHAHAH': 1214, 'ya': 1215, 'od': 1216, 'panic': 1217, 'ADBOYS': 1218, 'slark': 1219, 'Farm': 1220, 'notthing': 1221, 'deal': 1222, 'fedeer': 1223, 'kay': 1224, 'nah': 1225, 'idont': 1226, 'thin': 1227, 'kso': 1228, 'eu': 1229, 'vi': 1230, 'tanto': 1231, 'q': 1232, 'deram': 1233, 'vai': 1234, 'se': 1235, 'fude': 1236, 'mlk': 1237, 'echo': 1238, 'err': 1239, 'FUCKING': 1240, 'item': 1241, 'HAHAHAHA': 1242, 'DDD': 1243, 'mostly': 1244, 'duel': 1245, 'caught': 1246, 'wisp': 1247, 'super': 1248, 'CHINESE': 1249, 'ebalo': 1250, 'shdi': 1251, 'davay': 1252, 'fast': 1253, 'para': 1254, 'les': 1255, 'toque': 1256, 'su': 1257, 'ranked': 1258, 'trying': 1259, 'laugh': 1260, 'working': 1261, 'pretty': 1262, 'comend': 1263, 'burn': 1264, 'speack': 1265, 'awkawkaw': 1266, 'ppl': 1267, 'shitty': 1268, 'pcs': 1269, 'IKR': 1270, 'idgaf': 1271, 'cuz': 1272, 'pinoy': 1273, 'block': 1274, 'probably': 1275, 'tholugh': 1276, 'eniggerma': 1277, 'smartass': 1278, 'radiant': 1279, 'wagger': 1280, 'mitches': 1281, 'haah': 1282, 'nyx': 1283, 'SOOOOOOOOOOOOOOOOBAD': 1284, 'CHAMP': 1285, 'abba': 1286, 'plsss': 1287, 'undying': 1288, 'using': 1289, 'tombstone': 1290, 'os': 1291, 'wins': 1292, 'legit': 1293, 'everything': 1294, 'uselsss': 1295, 'without': 1296, 'dmg': 1297, 'delay': 1298, ':DDDDDDDDDDD': 1299, 'nigga': 1300, '28': 1301, 'demage': 1302, 'kidding': 1303, 'LC': 1304, 'aahaha': 1305, 'monkjey': 1306, 'apologise': 1307, 'silence': 1308, 'sucker': 1309, 'Fuck': 1310, 'self': 1311, 'kids': 1312, 'Do': 1313, 'zz': 1314, 'english': 1315, 'arrow': 1316, 'tema': 1317, 'hola': 1318, 'ss': 1319, 'agree': 1320, 'trees': 1321, 'pushing': 1322, 'ooohhh': 1323, 'FUck': 1324, 'problems': 1325, 'her': 1326, 'bivaet': 1327, 'spamming': 1328, 'poormans': 1329, 'shield': 1330, 'stay': 1331, 'fucktrash': 1332, 'chill': 1333, 'relax': 1334, 'aggressive': 1335, '5200': 1336, '=': 1337, '5150': 1338, 'radiance': 1339, 'ikr': 1340, 'COMPRENDE': 1341, 'JUST': 1342, 'SAY': 1343, 'DADDY': 1344, 'stronk': 1345, 'idiots': 1346, 'entrense': 1347, 'burros': 1348, 'rc': 1349, 'recure': 1350, 'AMor': 1351, 'surely': 1352, '1st': 1353, 'goods': 1354, 'trad': 1355, 'Trade': 1356, 'hahaah': 1357, 'RETARD': 1358, 'reportr': 1359, 'nvm': 1360, 'full': 1361, 'wants': 1362, 'pad': 1363, 'KDAs': 1364, 'rly': 1365, 'ask': 1366, 'parents': 1367, 'CURIER': 1368, 'END': 1369, 'PLEASE': 1370, 'deep': 1371, 'wat': 1372, 'tri': 1373, 'each': 1374, 'day': 1375, 'suprised': 1376, 'omni': 1377, 'tell': 1378, 'pciks': 1379, 'moral': 1380, 'low': 1381, 'wards': 1382, 'k': 1383, 'teamwork': 1384, 'sure': 1385, 'saw': 1386, 'tech': 1387, 'BASTARD': 1388, 'REPORTED': 1389, 'TEH': 1390, 'cada': 1391, 'ves': 1392, 'tocan': 1393, 'mas': 1394, 'basuras': 1395, 'el': 1396, 'repoirt': 1397, 'FeelsBadMan': 1398, 'farming': 1399, 'fy': 1400, 'injoker': 1401, 'Yeah': 1402, 'Rektd': 1403, 'bout': 1404, 'w0w': 1405, 'magina': 1406, 'tekkies': 1407, 'TREANT': 1408, 'SOPRESA': 1409, ':v': 1410, 'throw': 1411, 'monkeys': 1412, 'YELLING': 1413, 'l': 1414, 'partyrock': 1415, 'lycab': 1416, 'scoreboard': 1417, 'blaming': 1418, 'atleast': 1419, 'doge': 1420, 'badtrri': 1421, 'ff': 1422, 'chmo': 1423, 'ebanoe': 1424, 'REPORT': 1425, 'TERROR': 1426, 'ops': 1427, 'welcome': 1428, 'talks': 1429, 'grave': 1430, 'predict': 1431, 'welll': 1432, 'begining': 1433, 'magic': 1434, 'aegis': 1435, 'bait': 1436, 'axaxaxa': 1437, 'FEEEEEED': 1438, 'MEEEEEEEE': 1439, 'mnmay': 1440, '1500': 1441, 'EZIEST': 1442, 'LIFE': 1443, 'dk': 1444, 'main': 1445, 'target': 1446, 'destroy': 1447, 'alttab': 1448, 'Report': 1449, 'ruining': 1450, 'attempted': 1451, 'desperate': 1452, 'winning': 1453, 'again': 1454, '20mins': 1455, 'mkb': 1456, 'pussy': 1457, 'happy': 1458, 'birthday': 1459, 'unfair': 1460, '9x': 1461, 'ebat': 1462, 'retards': 1463, 'Idgaf': 1464, 'intro': 1465, 'hahahahaah': 1466, 'Eveeeerrrrrrr': 1467, 'purges': 1468, 'shackles': 1469, 'missed': 1470, 'hook': 1471, 'black': 1472, 'ahahahahaha': 1473, 'called': 1474, 'p': 1475, 'hove': 1476, 'FAST': 1477, 'expect': 1478, 'ik': 1479, 'logic': 1480, 'bounty': 1481, ':p': 1482, 'yasha': 1483, '25mmr': 1484, 'ytou': 1485, 'sup': 1486, 'dun': 1487, 'techis': 1488, 'mood': 1489, 'thats': 1490, 'trench': 1491, 'gaming': 1492, 'aaahajahahahahhahahahahahaha': 1493, 'yuo': 1494, 'whingey': 1495, 'vodkahead': 1496, 'JAVRA': 1497, '1hr': 1498, 'bobo': 1499, 'acid': 1500, 'woulda': 1501, 'clash': 1502, 'feeders': 1503, 'bkbless': 1504, 'gryo': 1505, 'Yes': 1506, 'timber': 1507, 'dumbass': 1508, 'spelled': 1509, 'voting': 1510, 'Donald': 1511, 'Trump': 1512, '2016': 1513, 'For': 1514, 'wall': 1515, 'immigration': 1516, ':|': 1517, 'trow': 1518, 'teehee': 1519, 'emd': 1520, 'That': 1521, 'arlmet': 1522, 'LD': 1523, 'same': 1524, 'result': 1525, 'choice': 1526, 'sr': 1527, '3kscrub': 1528, 'way': 1529, 'wasnt': 1530, 'even': 1531, 'finally': 1532, 'The': 1533, 'monkey': 1534, 'pang': 1535, 'guinness': 1536, 'road': 1537, '5k': 1538, 'ooooooooooooooooooooooom': 1539, 'And': 1540, 'picker': 1541, 'every': 1542, 'RQ': 1543, 'luck': 1544, 'SAID': 1545, 'WANNA': 1546, 'EAT': 1547, 'DUDE': 1548, 'cute': 1549, 'red': 1550, 'john': 1551, 'irl': 1552, '44th': 1553, 'infantry': 1554, 'brigade': 1555, 'dagger': 1556, 'start': 1557, ';': 1558, 'Close': 1559, 'guess': 1560, '2min': 1561, '134': 1562, 'csw': 1563, 'Cs': 1564, 'hays': 1565, 'klng': 1566, 'po': 1567, 'ate': 1568, 'tY': 1569, 'mis': 1570, 'emer': 1571, 'money': 1572, 'io': 1573, 'tiny': 1574, 'wkwkw': 1575, 'until': 1576, 'ot': 1577, 'boga': 1578, 'kompor': 1579, 'bledos': 1580, 'gan': 1581, 'loosing': 1582, 'patience': 1583, 'FGOGOGOOGOG': 1584, 'jahahaha': 1585, 'enbd': 1586, 'invit': 1587, 'IDIOT': 1588, 'KONTOLAN': 1589, 'jug': 1590, 'pleasure': 1591, 'stream': 1592, 'reporta': 1593, 'ibama': 1594, 'fdp': 1595, 'sacrifica': 1596, 'animais': 1597, 'mates': 1598, 'bag': 1599, 'los': 1600, 'tienen': 1601, 'plata': 1602, 'queda': 1603, 'hablar': 1604, ':C': 1605, 'ayyyyy': 1606, 'she': 1607, 'stading': 1608, 'stree': 1609, 'AHAHAH': 1610, 'WAHAHGAh': 1611, 'Or': 1612, 'standing': 1613, 'front': 1614, 'others': 1615, 'YES': 1616, 'op': 1617, 'ugly': 1618, 'DK': 1619, 'XDXD': 1620, ':*': 1621, 'tusk': 1622, 'v': 1623, 'gank': 1624, 'yolo': 1625, '5v': 1626, 'familiars': 1627, 'wd': 1628, ':V': 1629, 'apparently': 1630, 'kiss': 1631, 'penis': 1632, 'hahahahahahahahaha': 1633, 'RADIC': 1634, 'MIN': 1635, '18': 1636, 'pheonix': 1637, 'puck': 1638, 'maybe': 1639, 'should': 1640, 'hug': 1641, 'ha': 1642, 'timing': 1643, 'rmk': 1644, 'Lol': 1645, 'ADADAS': 1646, 'Shut': 1647, 'LEL': 1648, 'ol': 1649, 'doing': 1650, 'rs': 1651, 'PAUSE': 1652, 'IM': 1653, 'SOO': 1654, 'LAG': 1655, 'HEREE': 1656, 'againts': 1657, 'Thank': 1658, 'coming': 1659, 'IDIOTS': 1660, 'gay': 1661, 'SVEN': 1662, 'boid': 1663, 'GLHF': 1664, 'work': 1665, 'net': 1666, 'scott': 1667, 'guts': 1668, 'against': 1669, 'BEST': 1670, 'BOOTS': 1671, 'MINS': 1672, 'enjoy': 1673, 'core': 1674, 'wicp': 1675, 'waahahaha': 1676, 'heheh': 1677, 'R': 1678, 'E': 1679, 'Ya': 1680, 'fucker': 1681, 'ouch': 1682, 'nasty': 1683, 'tide': 1684, 'In': 1685, 'picks': 1686, 'planned': 1687, 'EHEREE': 1688, 'WHEREE': 1689, 'buyback': 1690, 'possibly': 1691, 'FUCIK': 1692, 'FUCKA': 1693, 'TOYHPJ': 1694, 'wahts': 1695, 'FREE': 1696, 'LEAVE': 1697, 'wail': 1698, 'played': 1699, 'CENTAUR': 1700, 'NEVER': 1701, 'ULT': 1702, 'Dota': 1703, 'PL': 1704, 'added': 1705, 'disro': 1706, 'fu': 1707, 'tinker': 1708, 'Worst': 1709, 'ld': 1710, 'bashing': 1711, 'bommmm': 1712, 'wewe': 1713, 'jk': 1714, 'voer': 1715, 'retarded': 1716, 'once': 1717, 'HEALER': 1718, 'TOP': 1719, 'masturvbate': 1720, 'while': 1721, 'creeps': 1722, 'FUCK': 1723, 'KA': 1724, 'REALLY': 1725, 'gem': 1726, 'lie': 1727, 'sleep': 1728, 'child': 1729, 'BOT': 1730, 'worth': 1731, 'wb': 1732, '29': 1733, 'hows': 1734, 'soloing': 1735, 'hello': 1736, 'MMR': 1737, 'crashed': 1738, 'BKBS': 1739, 'walking': 1740, 'kotl': 1741, 'badly': 1742, 'ks': 1743, 'twice': 1744, 'aus': 1745, 'doita': 1746, 'quite': 1747, 'stuck': 1748, 'loading': 1749, 'screen': 1750, 'kid': 1751, 'creep': 1752, 'awarness': 1753, 'important': 1754, 'Cause': 1755, 'mad': 1756, 'luckman': 1757, 'wolrd': 1758, 'raped': 1759, 'letting': 1760, 'LOLOLOLOLOLO': 1761, 'waiting': 1762, 'chatting': 1763, 'outta': 1764, 'change': 1765, 'h': 1766, 'their': 1767, 'shiti': 1768, 'connection': 1769, 'brain': 1770, 'story': 1771, 'loser': 1772, 'sigh': 1773, 'Noob': 1774, 'SF': 1775, 'user': 1776, 'puto': 1777, 'RS': 1778, 'jz': 1779, 'df': 1780, 'worries': 1781, '5l': 1782, 'guy': 1783, 'Kappa': 1784, 'EVASIOOON': 1785, 'WHERE': 1786, 'DIVINA': 1787, 'RAPIRA': 1788, 'ptmr': 1789, 'ctmr': 1790, 'used': 1791, 'touching': 1792, 'reKT': 1793, 'doG': 1794, 'dad': 1795, 'taking': 1796, 'years': 1797, 'cigarettes': 1798, 'annus': 1799, 'commendation': 1800, 'ahhah': 1801, 'RUDE': 1802, 'WAITED': 1803, 'cyka': 1804, 'blyat': 1805, 'interwebs': 1806, 'BS': 1807, ':c': 1808, 'press': 1809, 'ogre': 1810, 'inveokr': 1811, 'draon': 1812, 'bottle': 1813, 'curier': 1814, 'PLS': 1815, 'Not': 1816, 'THINK': 1817, 'WAS': 1818, 'kjikl': 1819, 'GIGI': 1820, 'LOST': 1821, 'delete': 1822, 'purple': 1823, 'changed': 1824, 'mind': 1825, 'worst': 1826, 'cpt': 1827, 'ever': 1828, 'mine': 1829, 'HAND': 1830, 'NOOBS': 1831, 'Hehe': 1832, 'lmfao': 1833, '::D': 1834, 'gunna': 1835, 'rocket': 1836, 'league': 1837, 'INVOKER': 1838, 'Xd': 1839, 'ESSS': 1840, 'horse': 1841, 'recovered': 1842, 'bed': 1843, 'piece': 1844, 'uninstall': 1845, 'fuk': 1846, 'off': 1847, 'cumback': 1848, '9000': 1849, 'range': 1850, 'nothing': 1851, 'exams': 1852, 'jaja': 1853, 'daga': 1854, '20': 1855, 'actually': 1856, 'comment': 1857, '19': 1858, 'green': 1859, 'streaming': 1860, 'style': 1861, '5v3': 1862, 'someone': 1863, 'else': 1864, '2ez': 1865, 'ure': 1866, 'own': 1867, 'braindamaged': 1868, 'enemy': 1869, 'postion': 1870, 'Brb': 1871, 'ganking': 1872, 'ggw': 1873, 'tryhards': 1874, 'save': 1875, 'commened': 1876, 'commerd': 1877, 'lawl': 1878, 'onoob': 1879, 'suicide': 1880, 'Space': 1881, 'created': 1882, 'yoshi': 1883, 'missing': 1884, 'naga': 1885, 'aqop': 1886, 'tusker': 1887, 'bird': 1888, 'un': 1889, 'install': 1890, 'later': 1891, 'bane': 1892, 'ANO': 1893, 'BA': 1894, 'noobla': 1895, 'cuello': 1896, 'resume': 1897, 'deads': 1898, 'wew': 1899, 'tq': 1900, 'DMage': 1901, 'Duel': 1902, 'de': 1903, 'dark': 1904, 'daddys': 1905, 'bcuz': 1906, 'tards': 1907, 'waste': 1908, 'kontol': 1909, 'GWP': 1910, 'fuckign': 1911, 'boot': 1912, 'SAND': 1913, 'KING': 1914, 'been': 1915, 'though': 1916, 'funy': 1917, 'clowny': 1918, '3th': 1919, 'wqill': 1920, 'rpeort': 1921, 'semantics': 1922, 'aesthetics': 1923, 'word': 1924, 'looking': 1925, 'fin': 1926, 'hahaa': 1927, 'TANK': 1928, 'tryhard': 1929, 'known': 1930, 'vcs': 1931, 'sao': 1932, 'lixos': 1933, 'n': 1934, 'fode': 1935, 'acha': 1936, 'fez': 1937, 'algo': 1938, 'ainda': 1939, 'tirei': 1940, 'o': 1941, 'cara': 1942, 'sem': 1943, 'usa': 1944, 'vtnc': 1945, 'quiet': 1946, 'alchemist': 1947, 'raging': 1948, 'DP': 1949, 'revenge': 1950, 'avenge': 1951, 'courier': 1952, 'ruined': 1953, 'shakermon': 1954, 'huys': 1955, 'powershot': 1956, '71commends': 1957, 'thailand': 1958, 'yeah2': 1959, 'honorable': 1960, 'bb': 1961, 'niceu': 1962, 'lt': 1963, 'farmers': 1964, 'braindead': 1965, '12': 1966, 'old': 1967, ';/': 1968, 'bitches': 1969, 'wakaka': 1970, 'normalalc': 1971, 'ud': 1972, 'helic': 1973, 'mif': 1974, 'moan': 1975, 'starts': 1976, 'soon': 1977, 'CATH': 1978, 'LACSON': 1979, 'THAT': 1980, 'NOOOOO': 1981, 'roki': 1982, 'mmm': 1983, 'zzzzzzzzzzzzzzzzzzzz': 1984, '2hr': 1985, 'dota2': 1986, 'give': 1987, 'brah': 1988, 'Wag': 1989, 'mainis': 1990, 'ZZZ': 1991, 'yup': 1992, 'confused': 1993, 'ALLL': 1994, 'EU': 1995, 'DEUS': 1996, 'hahahaha': 1997, 'HAHAHAHAHAHHAAHAHAH': 1998, 't': 1999, 'below': 2000, 'invis': 2001, 'dunno': 2002, 'roams': 2003, 'El': 2004, 'adorno': 2005, 'mm': 2006, 'russians': 2007, 'Whats': 2008, 'rae': 2009, 'tp': 2010, 'armor': 2011, 'EAsy': 2012, 'izi': 2013, 'NICE': 2014, 'VISION': 2015, 'BLOCKED': 2016, 'VAC': 2017, 'words': 2018, 'bototm': 2019, 'lafe': 2020, 'yay': 2021, 'carries': 2022, 'TOOO': 2023, 'EZA': 2024, 'add': 2025, 'GGGGGGGGGGGGGGGGGGGG': 2026, 'genius': 2027, 'nood': 2028, 'lv': 2029, 'outlaned': 2030, 'non': 2031, 'steam': 2032, 'losers': 2033, 'GET': 2034, 'BFURY': 2035, 'FARM': 2036, 'HAS': 2037, 'MANTA': 2038, 'buyer': 2039, 'hw': 2040, 'eze': 2041, 'warlock': 2042, 'nerf': 2043, 'winter': 2044, 'wyvern': 2045, 'dies': 2046, 'LoL': 2047, 'harder': 2048, 'big': 2049, 'blue': 2050, 'looked': 2051, 'ggl': 2052, 'hims': 2053, '700': 2054, 'yaaaaaaaaaa': 2055, 'supports': 2056, 'new': 2057, 'LLOLOLOL': 2058, 'yr': 2059, 'xd': 2060, 'dendo': 2061, 'fel': 2062, 'mylife': 2063, 'drow': 2064, 'ragin': 2065, 'This': 2066, 'violent': 2067, 'peace': 2068, 'Just': 2069, 'Sf': 2070, 'serious': 2071, 'question': 2072, 'public': 2073, 'baited': 2074, 'DDUE': 2075, 'tried': 2076, 'aghanim': 2077, 'ls': 2078, 'cool': 2079, 'buyers': 2080, 'jesus': 2081, 'christ': 2082, 'At': 2083, 'lease': 2084, 'trashbag': 2085, 'sake': 2086, 'meepo': 2087, 'buff': 2088, 'THX': 2089, 'peruvians': 2090, 'loss': 2091, 'downs': 2092, 'culd': 2093, 'wrath': 2094, 'luna': 2095, 'stfu': 2096, 'botoom': 2097, 'Nah': 2098, 'Couldnt': 2099, 'handle': 2100, 'chuck': 2101, 'norris': 2102, 'BIRTH': 2103, 'DAY': 2104, 'ELDER': 2105, 'track': 2106, '3streak': 2107, 'aa': 2108, 'points': 2109, 'seeker': 2110, '400': 2111, 'jr': 2112, 'saving': 2113, 'spells': 2114, 'TOBBE': 2115, 'DUU': 2116, '115': 2117, 'guyz': 2118, 'supps': 2119, 'deserve': 2120, 'scary': 2121, 'youre': 2122, 'amte': 2123, 'TriHard': 2124, 'kappa': 2125, 'Comend': 2126, ':S': 2127, 'FAIL': 2128, 'dire': 2129, 'anyway': 2130, ';\\\\': 2131, 'learn': 2132, 'fk': 2133, '500gold': 2134, 'done': 2135, 'comendded': 2136, 'Ggwp': 2137, 'dumbfuck': 2138, 'american': 2139, 'elder': 2140, 'titan': 2141, 'spammed': 2142, 'freewin': 2143, 'sadboy': 2144, 'overkill': 2145, 'regardless': 2146, 'Can': 2147, 'Pseudo': 2148, 'total': 2149, 'uter': 2150, 'about': 2151, 'teamfight': 2152, 'Why': 2153, 'keep': 2154, 'leaving': 2155, 'offline': 2156, 'comback': 2157, 'snitch': 2158, 'bkbk': 2159, 'LET': 2160, 'sweet': 2161, 'dream': 2162, 'OUTTA': 2163, 'HERE': 2164, 'deaths': 2165, 'edad': 2166, 'slay': 2167, 'bastard': 2168, 'paused': 2169, 'shiet': 2170, 'nerds': 2171, 'havta': 2172, 'LMFAO': 2173, 'pz': 2174, 'magnus': 2175, 'brraiinnss': 2176, 'coo': 2177, ';!': 2178, 'angry': 2179, 'AUTIST': 2180, 'MEPPO': 2181, 'PLZ': 2182, 'LANAY': 2183, 'AHAHHA': 2184, 'BOOSTER': 2185, 'AHAHHAHAHA': 2186, 'BLIA': 2187, 'jugaer': 2188, 'phaton': 2189, 'IF': 2190, 'GIVEN': 2191, 'CHANCE': 2192, 'NOO': 2193, 'gigi': 2194, 'GETTING': 2195, 'GPM': 2196, 'tyou': 2197, 'p5': 2198, 'sven': 2199, 'priority': 2200, 'hohoho': 2201, 'lagging': 2202, 'dudes': 2203, 'god': 2204, 'falling': 2205, 'heavy': 2206, 'rare': 2207, 'reeport': 2208, 'rambo': 2209, 'paid': 2210, 'Lolll': 2211, 'sucking': 2212, 'ahaha': 2213, 'xDDD': 2214, 'cancerous': 2215, 'insane': 2216, 'invi': 2217, 'skillz': 2218, 'trol': 2219, 'luckiest': 2220, 'shackle': 2221, 'couple': 2222, 'beating': 2223, 'morning': 2224, 'HA': 2225, 'hold': 2226, 'secs': 2227, '500': 2228, 'ping': 2229, 'kl': 2230, 'bunch': 2231, 'climb': 2232, 'ore': 2233, 'defende': 2234, 'sai': 2235, 'daqui': 2236, 'Axe': 2237, 'nunca': 2238, 'tube': 2239, 'Done': 2240, 'rax': 2241, 'disruptor': 2242, 'gold': 2243, 'Hahah': 2244, 'SCARED': 2245, 'ahahha': 2246, 'tbh': 2247, 'literally': 2248, 'disconect': 2249, 'js': 2250, 'lal': 2251, 'careful': 2252, 'bite': 2253, 'rampagee': 2254, 'short': 2255, 'sali': 2256, 'sakin': 2257, 'con': 2258, 'estas': 2259, 'hay': 2260, 'fururo': 2261, 'clinkz': 2262, 'glglgl': 2263, 'wahaha': 2264, 'brotha': 2265, 'dot': 2266, 'lah': 2267, 'beh': 2268, 'BACK': 2269, '5K': 2270, 'OR': 2271, 'SLEEP': 2272, 'BAITED': 2273, 'taunt': 2274, 'morel': 2275, 'ike': 2276, 'Dc': 2277, 'BICTH': 2278, 'ggez': 2279, 'bobbbbbbbbb': 2280, 'conred': 2281, 'beef': 2282, 'gt': 2283, 'shirt': 2284, 'son': 2285, 'medusa': 2286, 'gayyy': 2287, 'Counterthrow': 2288, 'trilaning': 2289, 'XDDD': 2290, 'ahahhah': 2291, 'useless': 2292, 'jajaj': 2293, 'jedi': 2294, 'tricks': 2295, 'fake': 2296, 'Bg': 2297, 'rank': 2298, 'AW': 2299, 'wond': 2300, 'slaradar': 2301, 'WHOS': 2302, 'UR': 2303, 'nty': 2304, 'dotn': 2305, 'lady': 2306, 'relevant': 2307, 'thankfully': 2308, 'theres': 2309, 'another': 2310, 'sii': 2311, 'Me': 2312, 'toco': 2313, 'compatriotas': 2314, 'cos': 2315, 'skype': 2316, 'pauses': 2317, 'reading': 2318, 'mg': 2319, 'heuhue': 2320, 'coward': 2321, 'karma': 2322, 'ull': 2323, 'BARA': 2324, 'GOT': 2325, 'KILL': 2326, 'ultied': 2327, 'WHAT': 2328, 'YAY': 2329, 'NOLAG': 2330, 'newb': 2331, 'bomber': 2332, 'shaker': 2333, 'tider': 2334, 'wanna': 2335, 'HAVE': 2336, 'SUPP': 2337, 'BORING': 2338, 'COEM': 2339, 'SOME': 2340, 'quits': 2341, 'simple': 2342, 'indee3d': 2343, 'woobshe': 2344, 'base': 2345, 'flaming': 2346, 'fkn': 2347, 'joking': 2348, 'jumped': 2349, 'hex': 2350, 'name': 2351, 'PRO': 2352, 'YAYAYAYAA': 2353, 'LIL': 2354, 'PIMPO': 2355, 'FINISH': 2356, 'lh': 2357, 'PLEAS': 2358, '9': 2359, 'SPACE': 2360, 'players': 2361, 'naix': 2362, 'number': 2363, 'THATS': 2364, 'SUCKS': 2365, '50': 2366, 'Haha': 2367, 'OOOOOOOOOOOOOH': 2368, 'dirty': 2369, 'udid': 2370, 'twas': 2371, 'outside': 2372, 'lets': 2373, 'dragons': 2374, 'helloo': 2375, '4n4n': 2376, 'GAY': 2377, 'runes': 2378, 'sister': 2379, 'invoke': 2380, 'hope': 2381, 'techies': 2382, 'Rlly': 2383, 'volvo': 2384, 'INTRO': 2385, 'unbeliaveblay': 2386, 'lma': 2387, 'Easy': 2388, '27': 2389, 'Huh': 2390, '800': 2391, 'Fck': 2392, 'Dendi': 2393, 'rea': 2394, 'peruvian': 2395, 'Ask': 2396, 'pp': 2397, 'PRESENT': 2398, 'morph': 2399, 'youl': 2400, 'rares': 2401, 'yah': 2402, 'brave': 2403, 'GL': 2404, 'HF': 2405, 'matter': 2406, 'godlike': 2407, 'spree': 2408, 'STUPID': 2409, 'kotol': 2410, 'Always': 2411, 'ignore': 2412, 'JOKE': 2413, 'belong': 2414, 'mrrr': 2415, 'introgay': 2416, 'countless': 2417, 'send': 2418, 'hha': 2419, 'wy': 2420, 'compared': 2421, 'yours': 2422, 'score': 2423, 'pi': 2424, 'impact': 2425, 'othing': 2426, 'uys': 2427, 'hm': 2428, 'bit': 2429, ':saltY': 2430, 'ROAM': 2431, 'boom': 2432, 'daz': 2433, 'dced': 2434, 'porn': 2435, 'pornhub': 2436, 'com': 2437, 'atm': 2438, 'CREAP': 2439, 'imba': 2440, 'mmmm': 2441, '30sec': 2442, '5mins': 2443, 'lei': 2444, 'woops': 2445, 'EZPZ': 2446, 'browser': 2447, 'nort': 2448, 'harrass': 2449, 'pleaser': 2450, 'sereuse': 2451, 'shoulda': 2452, 'YTEPYEPYEPP': 2453, 'dr': 2454, 'uselees': 2455, 'repotr': 2456, 'Game': 2457, 'touched': 2458, 'sore': 2459, 'spot': 2460, 'HAHAHAAHHAHAHAAH': 2461, 'mango': 2462, 'coldsnap': 2463, 'W8': 2464, 'faith': 2465, 'prfile': 2466, 'alce': 2467, 'hf': 2468, 'facebook': 2469, 'feeder': 2470, 'making': 2471, 'sense': 2472, 'leak': 2473, 'nate': 2474, 'german': 2475, 'cares': 2476, 'ul': 2477, 'yep': 2478, 'pinoys': 2479, 'shortest': 2480, 'lfd': 2481, 'hfsdjsfd': 2482, 'tuskar': 2483, 'mins': 2484, 'laggs': 2485, 'agha': 2486, 'orchid': 2487, '46mins': 2488, 'call': 2489, 'drying': 2490, 'nail': 2491, 'paint': 2492, 'DIFFICULT': 2493, 'breed': 2494, 'hahahahahaha': 2495, 'wirth': 2496, 'LYCAN': 2497, 'GOOOO': 2498, '274': 2499, 'wala': 2500, 'nami': 2501, 'piso': 2502, 'drop': 2503, 'VEry': 2504, 'ms': 2505, 'manta': 2506, 'soloq': 2507, 'sitting': 2508, 'pukingina': 2509, 'kangkong': 2510, 'lancer': 2511, 'homophobic': 2512, '576': 2513, 'misss': 2514, 'javseen': 2515, 'ano': 2516, 'gtfo': 2517, 'gratz': 2518, 'ebola': 2519, 'jimmy': 2520, 'offensive': 2521, 'weh': 2522, 'divided': 2523, 'ARROW': 2524, 'MISS': 2525, 'faster': 2526, 'animation': 2527, 'eh': 2528, 'garbage': 2529, 'CANT': 2530, 'catch': 2531, 'spirit': 2532, 'tossed': 2533, 'offc': 2534, 'boosting': 2535, 'honestly': 2536, 'knows': 2537, 'Storm': 2538, 'sucked': 2539, 'wah': 2540, 'fam': 2541, 'Cant': 2542, 'minimap': 2543, '17': 2544, 'year': 2545, 'pliss': 2546, 'BUY': 2547, 'hardly': 2548, 'fat': 2549, 'liked': 2550, 'undy': 2551, 'ahahaa': 2552, 'decided': 2553, '80': 2554, 'againt': 2555, 'yeap': 2556, 'mby': 2557, 'pat': 2558, 'doeee': 2559, 'xddddddd': 2560, 'eng': 2561, 'deserved': 2562, 'loose': 2563, 'shout': 2564, 'SAd': 2565, 'gago': 2566, 'system': 2567, 'hahahah': 2568, 'L': 2569, 'trasktalker': 2570, 'btm': 2571, 'WAJA': 2572, 'AWAJ': 2573, 'SURPRISE': 2574, 'BLINK': 2575, 'bf': 2576, 'WOOOOW': 2577, 'SKILL': 2578, 'bristle': 2579, 'WHYYYYYYYYYYY': 2580, 'wowow': 2581, ':\\ue006': 2582, 'cores': 2583, 'average': 2584, 'act': 2585, 'haHA': 2586, 'pOOR': 2587, 'aM': 2588, 'FAT': 2589, 'INJOKER': 2590, 'tac': 2591, 'knew': 2592, 'srs': 2593, 'ddos': 2594, 'virgin': 2595, 'AHAHAHAHAHAHAHA': 2596, 'ky': 2597, 'ZIGA': 2598, 'lb': 2599, 'throwing': 2600, 'lolz': 2601, 'passed': 2602, 'gif': 2603, 'dogshit': 2604, '15': 2605, 'ON': 2606, 'TROLL': 2607, 'pay': 2608, 'rule': 2609, 'morphling': 2610, 'update': 2611, '2month': 2612, 'wishes': 2613, 'teammate': 2614, 'bottom': 2615, 'heart': 2616, 'MANA': 2617, 'VBEFORE': 2618, 'Be': 2619, 'diclk': 2620, 'reasons': 2621, 'soo': 2622, 'wtdf': 2623, 'ohh': 2624, 'w3w': 2625, 'LALALA': 2626, 'SNIPER': 2627, 'nature': 2628, 'prophet': 2629, 'mongoloi': 2630, 'abbadon': 2631, '600': 2632, 'sht': 2633, 'GEGEGEGEGEEGEEGEGEGEEG': 2634, 'create': 2635, 'lobby': 2636, 'believe': 2637, 'spike': 2638, 'during': 2639, 'Still': 2640, 'oo': 2641, 'OKEY': 2642, 'tps': 2643, 'YE': 2644, 'MATE': 2645, 'LES': 2646, 'Losers': 2647, 'knight': 2648, 'raporting': 2649, 'instead': 2650, 'menu': 2651, 'tango': 2652, 'trust': 2653, 'ea': 2654, 'girl': 2655, 'jap': 2656, 'iceblast': 2657, 'history': 2658, 'EZAOSO': 2659, 'rus': 2660, 'purpose': 2661, 'whyy': 2662, 'woow': 2663, 'nooo': 2664, '10120': 2665, 'RIP': 2666, 'PEACE': 2667, 'uh': 2668, 'How': 2669, 'Wait': 2670, 'MVP': 2671, 'makes': 2672, 'jugger': 2673, 'Russia': 2674, 'rub': 2675, 'harsh': 2676, 'failing': 2677, '16': 2678, '4800': 2679, 'delivers': 2680, 'throne': 2681, '1vs9': 2682, 'bow': 2683, 'king': 2684, 'touch': 2685, 'TQ': 2686, 'pudeg': 2687, 'meet': 2688, 'da': 2689, 'goin': 2690, 'amen': 2691, 'youjizz': 2692, 'respawn': 2693, 'tower': 2694, 'lesss': 2695, 'bless': 2696, 'communication': 2697, 'abuse': 2698, 'waht': 2699, 'DOESNT': 2700, 'YEEZYS': 2701, 'clement': 2702, 'ENDED': 2703, 'SERIOUS': 2704, 'klog': 2705, 'girls': 2706, 'dazz': 2707, 'days': 2708, 'Ye': 2709, 'backing': 2710, 'stacks': 2711, 'fq': 2712, 'PUDGA': 2713, ';3': 2714, 'spaz': 2715, 'KS': 2716, 'Any': 2717, 'EEEOOO': 2718, 'STICK': 2719, 'men': 2720, 'check': 2721, 'str8': 2722, 'mud': 2723, 'Ddiobnt': 2724, 'mbi': 2725, 'mge': 2726, 'yeup': 2727, '60000k': 2728, '4000': 2729, 'anyways': 2730, 'alone': 2731, 'autism': 2732, 'powerball': 2733, 'quickly': 2734, 'TAEWM': 2735, '34': 2736, 'forver': 2737, 'minutes': 2738, 'miles': 2739, 'tank': 2740, 'NOOV': 2741, 'nhice': 2742, 'yummy': 2743, 'flesh': 2744, 'heap': 2745, 'educated': 2746, 'person': 2747, 'moms': 2748, 'God': 2749, '890': 2750, 'rich': 2751, 'nono': 2752, 'hah': 2753, 'divine': 2754, 'maldito': 2755, 'oracle': 2756, 'bring': 2757, 'cumming': 2758, 'calm': 2759, 'double': 2760, 'wahahahah': 2761, ':`': 2762, 'waited': 2763, 'several': 2764, 'RART': 2765, 'DOTS': 2766, 'roflll': 2767, 'vroom': 2768, 'momment': 2769, 'babe': 2770, 'suoper': 2771, 'agreed': 2772, 'wil': 2773, 'ranger': 2774, 'ghost': 2775, 'ilu': 2776, 'stopped': 2777, '332': 2778, 'badluck': 2779, 'brian': 2780, 'ittttt': 2781, 'fuckig': 2782, 'sucks': 2783, 'chen': 2784, 'YF': 2785, 'CGHFIBDFTNCZ': 2786, '=)': 2787, 'venom': 2788, 'SAFELANE': 2789, 'AWFUL': 2790, 'dogshits': 2791, 'cunts': 2792, 'yuki': 2793, 'Sniper': 2794, 'peinose': 2795, 'anu': 2796, 'onngoys': 2797, 'Y': 2798, 'QUE': 2799, 'HAY': 2800, 'DE': 2801, 'LA': 2802, 'notlikethis': 2803, 'other': 2804, 'jizz': 2805, 'exited': 2806, 'THAN': 2807, 'FKCUNG': 2808, 'ACT': 2809, 'LIKE': 2810, 'kek': 2811, 'coulda': 2812, 'ruling': 2813, 'Send': 2814, 'z': 2815, 'gaben': 2816, 'sama': 2817, 'lfmao': 2818, 'PROseidon': 2819, 'WAwa': 2820, 'dces': 2821, 'orayt': 2822, 'hahahahaha': 2823, 'ruski': 2824, 'ragequit': 2825, 'aie': 2826, 'His': 2827, 'rally': 2828, 'dafuq': 2829, 'idot': 2830, 'considering': 2831, 'outcarry': 2832, 'razor': 2833, 'terrible': 2834, 'btr': 2835, 'east': 2836, 'fucktard': 2837, 'cj': 2838, 'which': 2839, 'pussi': 2840, ':m': 2841, 'THANK': 2842, 'eager': 2843, 'Dat': 2844, 'BOOM': 2845, '4v6': 2846, 'sorting': 2847, 'dw': 2848, 'zues': 2849, 'spy': 2850, 'pray': 2851, 'JARVA': 2852, 'jarva': 2853, 'nobss': 2854, 'SS': 2855, 'zeus': 2856, 'Back': 2857, 'usallt': 2858, 'goes': 2859, 'mf': 2860, 'HAAAAAAAAAAAAAAAA': 2861, 'thnx': 2862, 'trolling': 2863, 'takes': 2864, 'classic': 2865, 'yelloqw': 2866, 'FUCKIKN': 2867, 'TYPGIN': 2868, 'URT': 2869, 'succesds': 2870, 'rleady': 2871, 'pathing': 2872, '8k': 2873, 'SK': 2874, 'joke': 2875, 'liek': 2876, 'pee': 2877, 'diccks': 2878, '4TH': 2879, 'RUINED': 2880, 'BY': 2881, 'RETARDS': 2882, 'und': 2883, 'staying': 2884, 'near': 2885, 'smh': 2886, 'bother': 2887, 'supporting': 2888, 'tough': 2889, 'kit': 2890, 'kat': 2891, 'bkb': 2892, 'rapes': 2893, 'yung': 2894, 'namin': 2895, 'beyond': 2896, 'tanking': 2897, 'woo': 2898, 'gone': 2899, 'wasting': 2900, 'leaveee': 2901, 'trap': 2902, 'bear': 2903, 'Wew': 2904, 'pff': 2905, 'thaha': 2906, 'RAMPAGE': 2907, 'BOG': 2908, 'PROSTIT': 2909, 'weooh': 2910, 'kahh': 2911, 'arrivall': 2912, 'chi': 2913, 'dumbster': 2914, 'HAHAHHA': 2915, 'blademail': 2916, 'ggng': 2917, 'OP': 2918, 'heal': 2919, 'probs': 2920, 'dat': 2921, 'ahahahhaa': 2922, 'took': 2923, 'Ovision': 2924, 'abandoned': 2925, 'stats': 2926, 'recorded': 2927, 'Wp': 2928, 'boyz': 2929, 'reatrd': 2930, 'rq': 2931, 'Whuuuuuuut': 2932, 'Hahahaha': 2933, 'nigger': 2934, 'rdy': 2935, 'aga': 2936, '1v': 2937, '4d': 2938, 'amount': 2939, 'int': 2940, 'casters': 2941, 'plus': 2942, 'SMACK': 2943, 'MY': 2944, 'BUM': 2945, 'RUN': 2946, 'fvck': 2947, 'hooked': 2948, 'Lotte': 2949, 'cheese': 2950, 'lover': 2951, '52': 2952, 'transfer': 2953, 'TRANSFER': 2954, 'reborn': 2955, 'gpm': 2956, 'X': 2957, '=(': 2958, 'deti': 2959, 'govna': 2960, 'REKT': 2961, 'lul': 2962, 'xDDDDDDDDDD': 2963, 'odd': 2964, 'GUYS': 2965, 'DUSTTTTT': 2966, 'hans': 2967, 'dps': 2968, 'ccurious': 2969, 'freee': 2970, 'dusa': 2971, 'memba': 2972, 'says': 2973, 'GARAVCE': 2974, 'INA': 2975, 'WIN': 2976, '=3=': 2977, 'gigilmats': 2978, 'type': 2979, 'GGTY': 2980, 'FKING': 2981, 'peenoy': 2982, 'Mother': 2983, 'Fuckign': 2984, 'legolas': 2985, 'jojojo': 2986, 'anything': 2987, 'basdh': 2988, 'mepo': 2989, 'describe': 2990, 'greevees': 2991, 'reduction': 2992, 'hgahahaha': 2993, 'FU': 2994, 'woman': 2995, 'disturb': 2996, 'hmm': 2997, 'miran': 2998, 'XDDDDDDDDDDDD': 2999, 'smart': 3000, 'sahdow': 3001, 'Seattle': 3002, 'znaete': 3003, 'pered': 3004, 'tem': 3005, 'kriki': 3006, 'slil': 3007, 'napisal': 3008, 'ja': 3009, 'umeju': 3010, 'igratj': 3011, 'gemom': 3012, 'chtobi': 3013, 'ne': 3014, 'potreatj': 3015, 'ego': 3016, 'Ouch': 3017, 'doma': 3018, 'natures': 3019, 'WOo': 3020, 'zero': 3021, 'hastag': 3022, 'Puck': 3023, 'comes': 3024, 'HOOK': 3025, ':d': 3026, 'DAZZ': 3027, 'cour': 3028, 'pizza': 3029, 'scre': 3030, 'sydney': 3031, 'braaaaaaaaaaaa': 3032, 'slada': 3033, 'hihi': 3034, 'BELORUSSIAN': 3035, 'count': 3036, 'sum': 3037, 'mo': 3038, 'especially': 3039, 'shitness': 3040, 'OH': 3041, 'scrub': 3042, 'hiohi': 3043, 'focus': 3044, 'whiel': 3045, 'dis': 3046, 'tornado': 3047, 'bvlast': 3048, 'hc': 3049, 'safd': 3050, 'trawsh': 3051, 'STEAM': 3052, 'fuckj': 3053, 'thatsw': 3054, 'message': 3055, 'lessons': 3056, 'lot': 3057, 'wrond': 3058, 'no1': 3059, 'hits': 3060, 'longest': 3061, 'glimpse': 3062, 'coins': 3063, 'invok': 3064, 'fucks': 3065, 'writting': 3066, 'smht': 3067, 'BURN': 3068, 'huts': 3069, 'tf': 3070, 'heh': 3071, 'car': 3072, 'treeants': 3073, 'WORD': 3074, 'VS': 3075, 'apahal': 3076, 'srlsy': 3077, '63': 3078, 'computer': 3079, 'restart': 3080, '2others': 3081, 'creeeeeeeps': 3082, 'powerfull': 3083, 'laguhing': 3084, 'treatn': 3085, 'SLADAR': 3086, 'Qops': 3087, 'wu': 3088, 'turned': 3089, 'stone': 3090, 'unapuse': 3091, 'sladar': 3092, 'either': 3093, 'potomu': 3094, 'chto': 3095, 'tima': 3096, 'daunov': 3097, 'poetomu': 3098, 'proigrali': 3099, 'viva': 3100, 'csmr': 3101, 'noooooooo': 3102, 'CURSE': 3103, 'YOUR': 3104, 'SILENCE': 3105, 'ef': 3106, 'suka': 3107, 'syndrome': 3108, 'rules': 3109, 'Real': 3110, 'freak': 3111, 'value': 3112, 'Next': 3113, 'Oooooooor': 3114, 'laggggggggggggg': 3115, 'lagggggggg': 3116, 'RE': 3117, 'GOING': 3118, 'ROSH': 3119, '4v4': 3120, 'typing': 3121, 'pfft': 3122, 'sulod': 3123, 'mn': 3124, 'ILL': 3125, 'MOMO': 3126, 'ghrthj': 3127, 'Omg': 3128, 'alchi': 3129, 'nooob': 3130, 'Yawa': 3131, 'VOID': 3132, 'most': 3133, 'loozer': 3134, 'It': 3135, 'Ursa': 3136, 'HAHAH': 3137, '1on1': 3138, 'idea': 3139, 'WHAHAHA': 3140, 'ENEMY': 3141, 'whole': 3142, '4this': 3143, 'ic': 3144, 'ant': 3145, 'joker': 3146, 'outplayed': 3147, 'remnant': 3148, 'expire': 3149, 'haizzz': 3150, '6200': 3151, 'motherfuckers': 3152, 'deco': 3153, 'mong': 3154, 'children': 3155, 'wpwp': 3156, 'shitt': 3157, 'DODGE': 3158, 'find': 3159, 'BECAUSE': 3160, 'SUCK': 3161, 'SIR': 3162, 'BE': 3163, 'sabrura': 3164, 'tyy': 3165, 'FRIEND': 3166, 'WILL': 3167, 'BAKC': 3168, 'BITCCH': 3169, 'space': 3170, 'clue': 3171, 'Rq': 3172, 'NOT': 3173, 'COMING': 3174, 'LIAAAR': 3175, 'coin': 3176, 'attention': 3177, 'whore': 3178, 'ridiculous': 3179, 'iknow': 3180, 'EJEJEJEJ': 3181, 'ESE': 3182, 'CARRY': 3183, 'randoms': 3184, 'andrea': 3185, 'cavada': 3186, 'shame': 3187, 'THUSKAR': 3188, 'CANCER': 3189, 'NIGGERS': 3190, 'PUSSY': 3191, 'hopeless': 3192, 'ticklish': 3193, 'ar': 3194, 'NT': 3195, 'Aw': 3196, 'expected': 3197, 'line': 3198, 'feeds': 3199, 'goddddddddddddddddddddddddddddddd': 3200, 'buddy': 3201, 'slut': 3202, 'tard': 3203, 'gondar': 3204, 'spelling': 3205, 'buying': 3206, 'switch': 3207, 'VIVA': 3208, 'PERU': 3209, '2015': 3210, 'stable': 3211, 'AHAHA': 3212, 'agaisntt': 3213, 'unn': 3214, 'runnn': 3215, 'forest': 3216, 'move': 3217, 'WINDE': 3218, 'ShADOW': 3219, 'WINNER': 3220, 'JOJOJOJOJOJOJOJOJO': 3221, 'JOJOJOJOJOJO': 3222, 'JOJOJOJOJOJOJ': 3223, 'sick': 3224, 'hahahhahahha': 3225, 'beg': 3226, 'stomp': 3227, 'proud': 3228, 'lLlO': 3229, 'OLll': 3230, 'ooooooooooooo': 3231, 'PERUANETIRAR': 3232, 'frenchie': 3233, 'abandoning': 3234, 'quad': 3235, 'DEF': 3236, 'batya': 3237, 'urod': 3238, 'lonely': 3239, 'OUTPICK': 3240, 'calculate': 3241, 'thist': 3242, 'eam': 3243, 'roshan': 3244, 'spoil': 3245, 'tatctis': 3246, ':DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD': 3247, 'golbal': 3248, 'FTW': 3249, 'lvl': 3250, 'TOLD': 3251, 'bonus': 3252, 'preach': 3253, 'JOJOJOJOJ': 3254, 'scool': 3255, 'adn': 3256, 'treant': 3257, 'Pugna': 3258, '5x': 3259, 'Alg': 3260, 'John': 3261, 'Its': 3262, 'hood': 3263, 'commin': 3264, 'Snip': 3265, 'PING': 3266, 'hear': 3267, 'song': 3268, 'teamates': 3269, 'enemies': 3270, 'COOL': 3271, 'duo': 3272, 'pul': 3273, 'beastmaster': 3274, 'levels': 3275, 'away': 3276, '51': 3277, '300': 3278, 'speaks': 3279, 'abreak': 3280, 'Reconnecting': 3281, 'eating': 3282, 'popcorn': 3283, 'DUMB': 3284, 'WHOW': 3285, 'hhh': 3286, 'midas': 3287, 'odust': 3288, 'wrrou': 3289, '55': 3290, 'lelz': 3291, 'fuckers': 3292, 'lame': 3293, 'hAHA': 3294, 'health': 3295, 'ehp': 3296, '2V8': 3297, 'escape': 3298, 'doomed': 3299, '36': 3300, 'repport': 3301, 'slarder': 3302, 'stump': 3303, 'trump': 3304, 'whose': 3305, 'killsteals': 3306, 'staff': 3307, 'shud': 3308, 'tag': 3309, 'baby': 3310, 'urselves': 3311, 'favour': 3312, 'awful': 3313, 'ahahahaha': 3314, 'lmfaofmowemfoawemof': 3315, 'fool': 3316, 'stays': 3317, 'fare': 3318, 'pointless': 3319, 'beeeeeee': 3320, 'heaps': 3321, 'GHAHA': 3322, 'gf': 3323, 'sickening': 3324, '=D': 3325, 'Gl': 3326, 'Neah': 3327, 'Now': 3328, 'thsi': 3329, 'EHCO': 3330, 'REAL': 3331, 'sexy': 3332, 'enchant': 3333, 'boring': 3334, '4vs4': 3335, 'JOJOJOJO': 3336, 'itscool': 3337, 'WELL': 3338, 'PLAYED': 3339, 'GREAT': 3340, 'meduza': 3341, 'basura': 3342, 'mighty': 3343, 'reportenlo': 3344, 'nboob': 3345, 'dieback': 3346, 'scrim': 3347, 'walrus': 3348, 'punch': 3349, 'dog': 3350, 'DA': 3351, 'konek': 3352, 'pain': 3353, 'AMAZING': 3354, 'DOTO': 3355, 'tA': 3356, 'grieving': 3357, 'syr': 3358, 'fault': 3359, 'wiat': 3360, 'kunkka': 3361, 'smoked': 3362, 'gotten': 3363, 'reactively': 3364, 'similar': 3365, 'respect': 3366, 'earn': 3367, 'gets': 3368, 'direct': 3369, 'm': 3370, 'LAGGING': 3371, 'tree': 3372, 'yeahj': 3373, 'greaaaaaaat': 3374, 'ga': 3375, 'gfun': 3376, '89': 3377, 'Good': 3378, 'Slark': 3379, 'pounce': 3380, 'Then': 3381, 'DIE': 3382, 'HOLE': 3383, 'daun': 3384, 'juggeru': 3385, '1x': 3386, 'bby': 3387, 'grill': 3388, 'dotka': 3389, 'lad': 3390, 'ups': 3391, 'jdem': 3392, 'ggsf': 3393, 'shuld': 3394, 'agies': 3395, 'rubing': 3396, 'backwards': 3397, 'fcking': 3398, 'laughed': 3399, 'common': 3400, 'galet': 3401, '2v1': 3402, 'puj': 3403, 'spell': 3404, 'immunity': 3405, 'idaf': 3406, 'PLIS': 3407, 'sige': 3408, 'planing': 3409, 'gang': 3410, 'chase': 3411, 'repel': 3412, 'behind': 3413, 'people': 3414, 'sun': 3415, 'strike': 3416, 'lolll': 3417, 'STOP': 3418, 'Like': 3419, '5v4': 3420, 'zenokaia': 3421, 'artist': 3422, 'All': 3423, 'managed': 3424, 'silencio': 3425, 'supportado': 3426, 'asquerosa': 3427, 'rata': 3428, 'pulling': 3429, 'silver': 3430, 'edge': 3431, 'haiz': 3432, 'spa': 3433, 'ceba': 3434, 'pagaram': 3435, 'quanto': 3436, 'ele': 3437, 'PAPER': 3438, 'SHUT': 3439, 'UP': 3440, 'WIAT': 3441, 'tony': 3442, 'mongol': 3443, 'Ea': 3444, 'Srsly': 3445, 'donkey': 3446, 'cocks': 3447, 'probaly': 3448, 'sepctre': 3449, 'centaur': 3450, 'observe': 3451, 'backpack': 3452, 'fly': 3453, 'alt': 3454, 'tab': 3455, 'ts': 3456, 'post': 3457, 'ma': 3458, 'recommend': 3459, 'pleasE': 3460, 'accidental': 3461, 'WAHAHHAHA': 3462, 'noobnaut': 3463, 'notes': 3464, 'ezpz': 3465, 'Thk': 3466, 'OW': 3467, 'apa': 3468, 'OOPS': 3469, 'haters': 3470, 'qartveli': 3471, 'xart': 3472, 'vinme': 3473, 'vlve': 3474, 'givin': 3475, 'imbecle': 3476, 'loool': 3477, 'IZI': 3478, 'TINKER': 3479, 'Very': 3480, 'pry': 3481, 'key': 3482, 'keyboard': 3483, 'hihhiihi': 3484, 'disconnect': 3485, 'lies': 3486, 'liomn': 3487, 'HHEHE': 3488, 'raged': 3489, 'offalne': 3490, 'lasthitting': 3491, 'waves': 3492, 'glaives': 3493, 'Classic': 3494, 'STEAL': 3495, 'brakes': 3496, 'train': 3497, '26': 3498, 'ww': 3499, 'fckng': 3500, 'Brainless': 3501, 'SECXY': 3502, 'FROST': 3503, 'bloody': 3504, 'million': 3505, 'KEK': 3506, 'buys': 3507, 'MI': 3508, 'TODO': 3509, 'ANIMALES': 3510, 'MIERDA': 3511, 'cold': 3512, 'snap': 3513, 'SAD': 3514, 'twitch': 3515, 'business': 3516, 'mariks': 3517, 'Ahah': 3518, '60': 3519, 'yy': 3520, 'topo': 3521, 'eus': 3522, 'scepter': 3523, 'fishnet': 3524, 'COME': 3525, 'SHY': 3526, 'mr': 3527, 'homeboy': 3528, 'peenoise': 3529, 'ns': 3530, 'jakiro': 3531, 'epic': 3532, 'role': 3533, 'phah': 3534, 'lcvl': 3535, 'cose': 3536, 'BITCH': 3537, 'wannabve': 3538, 'wannabe': 3539, 'shh': 3540, 'kinda': 3541, 'Yo': 3542, 'pduge': 3543, 're': 3544, 'fucknig': 3545, 'BYEE': 3546, 'combo': 3547, 'tim': 3548, 'carri': 3549, 'Aa': 3550, 'WHAHAHAHAHa': 3551, 'TANGA': 3552, 'como': 3553, 'essa': 3554, 'templar': 3555, 'caga': 3556, 'mds': 3557, 'till': 3558, 'bk': 3559, 'THINGS': 3560, 'zzz': 3561, 'legal': 3562, 'cocky': 3563, 'just3kthinggs': 3564, '88': 3565, 'vlad': 3566, 'herself': 3567, 'tx': 3568, 'hid': 3569, 'measure': 3570, 'smash': 3571, 'aghs': 3572, 'em': 3573, 'sikerlerrrrrrrrrrrrrrrrrrrrrrrr': 3574, 'weak': 3575, 'remain': 3576, 'turn': 3577, 'ugh': 3578, 'holding': 3579, 'wooden': 3580, 'JOJOJOJOJOJ': 3581, 'cheers': 3582, 'opening': 3583, 'door': 3584, 'mrd': 3585, 'dayuuuuuuuuuuuuuuuuuuuuuuuuum': 3586, 'AHAHAHAHAHAHAHAH': 3587, 'countered': 3588, 'Crafty': 3589, 'vinter': 3590, 'curse': 3591, 'pass': 3592, 'butthurt': 3593, 'deso': 3594, 'f': 3595, 'above': 3596, 'CLINKZ': 3597, 'morons': 3598, 'Such': 3599, 'Clockwerk': 3600, '0v5': 3601, 'leh': 3602, 'vanguard': 3603, 'zones': 3604, 'combak': 3605, 'Woooooooo': 3606, '23': 3607, 'souls': 3608, 'requim': 3609, 'Na': 3610, 'Yup': 3611, 'spacecow': 3612, 'wehw': 3613, 'world': 3614, 'everyday': 3615, 'IMJUST': 3616, 'AROUND': 3617, 'RAKI': 3618, 'NE': 3619, 'DAYT': 3620, 'NA': 3621, 'blameee': 3622, 'FUN': 3623, 'ultra': 3624, 'STUN': 3625, 'lift': 3626, 'MERRY': 3627, 'CHRISTMAS': 3628, 'okey': 3629, 'cumbak': 3630, 'wrap': 3631, 'GOGOGO': 3632, 'She': 3633, 'Great': 3634, 'N': 3635, 'WAY': 3636, 'bl': 3637, 'olympics': 3638, 'sport': 3639, '2020': 3640, 'tired': 3641, 'kind': 3642, 'cc': 3643, 'hahhahha': 3644, 'hahahha': 3645, 'position': 3646, 'becoz': 3647, 'glfu': 3648, 'wood': 3649, 'alrite': 3650, 'ruiner': 3651, 'president': 3652, 'DR': 3653, 'GFG': 3654, 'cats': 3655, 'fire': 3656, 'badf': 3657, 'pusi': 3658, 'Qop': 3659, 'cheat': 3660, 'Doom': 3661, 'aware': 3662, 'MAP': 3663, 'WARD': 3664, 'focusings': 3665, 'draw': 3666, 'cabros': 3667, 'may': 3668, 'remind': 3669, 'unpauses': 3670, 'wahah': 3671, 'dneis': 3672, 'suppose': 3673, 'pusher': 3674, 'ajo': 3675, 'WIPE': 3676, 'joining': 3677, 'seems': 3678, 'risky': 3679, 'SUP': 3680, 'CM': 3681, 'doubt': 3682, 'Spit': 3683, 'peeps': 3684, 'bounce': 3685, 'DIED': 3686, 'BOUNCES': 3687, 'CREREPS': 3688, 'EWTD': 3689, 'Wtf': 3690, 'pussies': 3691, 'thus': 3692, 'alrady': 3693, 'fuckl': 3694, '5v5': 3695, 'pit': 3696, 'leggo': 3697, 'BOOOOM': 3698, 'counterpick': 3699, 'gusta': 3700, 'slarkino': 3701, 'Useless': 3702, 'useful': 3703, '3v7': 3704, 'learned': 3705, 'oyoyoy': 3706, 'yeahhh': 3707, 'ithought': 3708, 'fisure': 3709, 'tranquil': 3710, 'qw3kje': 3711, 'kowqnheui49jqwmke': 3712, 'yqakmsd': 3713, 'fvbr2uwieoakf8u49gjirufjnghyju3iuwjfmg': 3714, 'h4ijuwiksdfuyiMuyijamjy879ialnbyhabhgl': 3715, 'gnholb': 3716, 'fair': 3717, 'THROW': 3718, 'hte': 3719, 'majors': 3720, 'tomorrow': 3721, 'unknown': 3722, 'VG': 3723, 'ahh': 3724, 'jokes': 3725, '247': 3726, 'comdy': 3727, 'russia': 3728, 'spanish': 3729, 'botlane': 3730, 'cus': 3731, 'd2': 3732, 'crash': 3733, 'rngesus': 3734, 'kms': 3735, 'KITE': 3736, 'ocatarine': 3737, 'meta': 3738, 'contrita': 3739, 'probsn': 3740, 'delayed': 3741, 'inevtable': 3742, 'panics': 3743, 'ezz': 3744, 'okeyyy': 3745, 'yA': 3746, 'BCAUSE': 3747, 'NAME': 3748, 'row': 3749, 'grp': 3750, 'freind': 3751, 'CLOACK': 3752, 'B': 3753, 'aloone': 3754, 'spam': 3755, '4head': 3756, 'Hphhp': 3757, 'klool': 3758, 'gayish': 3759, '44455': 3760, 'NotLikeThis': 3761, 'clicked': 3762, 'f9': 3763, 'XDd': 3764, 'mider': 3765, 'fact': 3766, 'Wrekt': 3767, 'afks': 3768, 'slojno': 3769, 'KIND': 3770, 'MANY': 3771, 'Invok': 3772, 'realy': 3773, 'mumbarak': 3774, 'tryharding': 3775, 'hahhaha': 3776, 'sandstorming': 3777, 'Pro': 3778, 'FV': 3779, 'teaching': 3780, 'apperently': 3781, 'Epic': 3782, 'TF': 3783, 'THEY': 3784, 'CRY': 3785, 'wardinmg': 3786, 'job': 3787, 'choise': 3788, 'mall': 3789, '::)': 3790, 'ksing': 3791, 'abbandon': 3792, 'TB': 3793, 'aracana': 3794, 'b4': 3795, 'DO': 3796, 'CLOCK': 3797, 'crush': 3798, 'satan': 3799, 'following': 3800, 'fg': 3801, 'fountain': 3802, 'aways': 3803, 'murmuring': 3804, 'lord': 3805, 'Swan': 3806, 'Fuckyou': 3807, 'Fair': 3808, 'begging': 3809, 'OLEG': 3810, 'lolwut': 3811, 'OCMON': 3812, 'slutty': 3813, 'rock': 3814, 'server': 3815, 'Am': 3816, 'noisy': 3817, 'forgot': 3818, 'shoukld': 3819, 'Tping': 3820, 'KINKAA': 3821, 'gracias': 3822, 'ALREADY': 3823, 'SLARDAR': 3824, 'DOING': 3825, 'suppor': 3826, 'shorer': 3827, 'aba': 3828, 'illuminate': 3829, 'unplayabel': 3830, 'donnt': 3831, 'ply': 3832, 'gamne': 3833, 'trx': 3834, 'Told': 3835, 'iw': 3836, 'guna': 3837, 'klast': 3838, 'AWw': 3839, 'yourself': 3840, 'fuking': 3841, 'Dazzle': 3842, ':o': 3843, 'hahahaah': 3844, 'HAHAAH': 3845, 'fcj': 3846, 'bois': 3847, 'inv': 3848, 'KID': 3849, 'jajajajaja': 3850, 'NOPE': 3851, 'ending': 3852, 'fingered': 3853, ':>': 3854, 'tha': 3855, 'SEND': 3856, 'COURIER': 3857, 'commending': 3858, 'idc': 3859, 'shuit': 3860, 'tot': 3861, '==': 3862, 'aggresive': 3863, 'plays': 3864, 'd0': 3865, 'CUMING': 3866, 'wez': 3867, 'niggas': 3868, 'rn': 3869, 'rm': 3870, 'bcak': 3871, 'Ikr': 3872, 'REkt': 3873, 'uninstalld': 3874, 'ota': 3875, 'SEc': 3876, 'Srg': 3877, 'SUTRALIAN': 3878, 'ITNERNET': 3879, 'WOO': 3880, 'WHEN': 3881, 'STRONGER': 3882, 'HERO': 3883, 'MIRA': 3884, 'IMAGINE': 3885, 'PEOPLE': 3886, 'JOHN': 3887, 'LENNON': 3888, 'DOTA': 3889, 'ZEROS': 3890, 'Reported': 3891, 'vagina': 3892, 'butterfly': 3893, 'sided': 3894, 'jajajajaj': 3895, 'nobody': 3896, 'RAT': 3897, 'undiyng': 3898, 'druid': 3899, 'cai': 3900, 'dm': 3901, 'kinh': 3902, 'ak': 3903, 'whwere': 3904, 'frduikfaimcl': 3905, 'nigga1': 3906, 'stacked': 3907, ':DDDDDDDDDDDDDDDDDDDDDDDD': 3908, ':DDDDDDDDDDDDDDDDDDD': 3909, 'Running': 3910, 'WHO': 3911, 'Profile': 3912, 'private': 3913, 'heard': 3914, 'often': 3915, 'lool': 3916, 'eziest': 3917, 'PICKET': 3918, 'COTL': 3919, 'Gege': 3920, 'spammer': 3921, 'stole': 3922, 'wear': 3923, 'rapemid': 3924, 'incoming': 3925, 'Jessica': 3926, 'Feminazi': 3927, 'Eh': 3928, 'fell': 3929, 'ALCHEMIST': 3930, 'AUTO': 3931, 'spent': 3932, 'chasinbg': 3933, 'RAWR': 3934, 'JOIN': 3935, 'probleme': 3936, 'write': 3937, 'article': 3938, 'greatest': 3939, 'gtf': 3940, 'mess': 3941, 'GUYZ': 3942, 'snatch': 3943, 'israel': 3944, 'HOPPING': 3945, 'Help': 3946, 'daedalus': 3947, 'BUG': 3948, 'cheeky': 3949, 'Bat': 3950, 'bat': 3951, 'LIER': 3952, 'Jugg': 3953, 'MKB': 3954, 'surprised': 3955, 'walk': 3956, 'fuckingf': 3957, 'spastic': 3958, 'fug': 3959, 'defiance': 3960, 'glimmer': 3961, 'woww': 3962, 'TODAY': 3963, 'esa': 3964, 'bota': 3965, 'completa': 3966, 'appaK': 3967, 'realized': 3968, 'accountbuyer': 3969, 'rude': 3970, 'rest': 3971, 'forever': 3972, 'shadowfriend666': 3973, 'eternal': 3974, 'whatver': 3975, 'drunk': 3976, 'speaking': 3977, 'calms': 3978, 'tries': 3979, 'exe': 3980, 'definitely': 3981, 'FUCKIKGN': 3982, 'AWFUIL': 3983, 'ULTIS': 3984, 'PTS': 3985, 'zzzzz': 3986, 'goiod': 3987, 'face': 3988, 'roaming': 3989, 'misses': 3990, 'shambles': 3991, 'LO': 3992, 'ROLFH': 3993, 'Zzzzzzz': 3994, 'saying': 3995, 'ihihih': 3996, 'classes': 3997, 'interested': 3998, 'flarex': 3999, 'whereare': 4000, 'astart': 4001, 'stral': 4002, 'DECENT': 4003, 'STOODS': 4004, 'THERE': 4005, 'INVIS': 4006, 'blabla': 4007, 'ggwo': 4008, 'gaem': 4009, 'REMEMBER': 4010, 'KNIFE': 4011, 'TOILET': 4012, 'TEARS': 4013, 'roam': 4014, 'sniped': 4015, 'fukcing': 4016, 'necroo': 4017, 'biotch': 4018, 'WB': 4019, 'means': 4020, 'Rage': 4021, 'GeGe': 4022, 'skatin': 4023, 'ice': 4024, 'coast': 4025, 'ruin': 4026, 'positioning': 4027, 'bak': 4028, 'VOid': 4029, 'Thanks': 4030, 'place': 4031, 'trapping': 4032, 'warsd': 4033, 'WTf': 4034, 'siting': 4035, '54': 4036, 'snipe': 4037, 'iimmma': 4038, 'aim': 4039, 'couild': 4040, 't.': 4041, 'kamikaze': 4042, 'lock': 4043, 'waot': 4044, 'napkin': 4045, 'slayer': 4046, 'aight': 4047, 'PAUSING': 4048, 'lategame': 4049, 'few': 4050, 'months': 4051, 'dmkm': 4052, 'xpm': 4053, 'US': 4054, 'BTICH': 4055, 'gys': 4056, 'eye': 4057, 'comenden': 4058, 'laggg': 4059, 'jussssssssssssst': 4060, 'longer': 4061, 'wardz': 4062, 'ancients': 4063, 'obvius': 4064, 'phone': 4065, 'ing': 4066, 'thinsk': 4067, 'aye': 4068, 'hardlane': 4069, 'nno': 4070, ':DDDD': 4071, 'gv': 4072, 'BUYBACK': 4073, 'LIFESTEALER': 4074, 'bruh': 4075, 'steal': 4076, 'zail': 4077, 'UNDYING': 4078, 'somethings': 4079, 'SB': 4080, 'graphics': 4081, 'jus': 4082, 'useles': 4083, 'ULTI': 4084, 'teams': 4085, 'yoo': 4086, 'dooooom': 4087, 'giving': 4088, 'HOPE': 4089, 'XDDDDDDDDDDDDDDDDDDDDDDDD': 4090, '4vs5': 4091, 'AFKING': 4092, 'LANE': 4093, 'FUCKED': 4094, 'HARD': 4095, 'dogeee': 4096, 'ebashil': 4097, 'kak': 4098, 'mog': 4099, 'DEAD': 4100, 'denied': 4101, 'Probs': 4102, 'seriously': 4103, 'spoiling': 4104, 'kindly': 4105, 'heroess': 4106, 'alchim': 4107, 'Rc': 4108, 'HAHHA': 4109, 'extra': 4110, 'admire': 4111, 'friendsip': 4112, 'silencerrrr': 4113, 'Bad': 4114, 'Gem': 4115, 'stronger': 4116, 'wyverns': 4117, 'iguess': 4118, 'cya': 4119, 'bmw': 4120, 'schei': 4121, 'marke': 4122, 'cnosite': 4123, 'eto': 4124, '110': 4125, 'floatey': 4126, 'AHYAHAHA': 4127, 'encan': 4128, 'thoughts': 4129, 'wioth': 4130, 'writing': 4131, 'Fast': 4132, 'fnish': 4133, 'wish': 4134, 'ZERO': 4135, 'WOOOOOOOOOOOO': 4136, 'WALLLLS': 4137, 'To': 4138, 'wjahaha': 4139, 'creap': 4140, 'hh': 4141, 'skali': 4142, 'bulldog': 4143, 'auchhhh': 4144, 'global': 4145, 'boyS': 4146, 'Lolz': 4147, 'baka': 4148, 'kasi': 4149, 'tumaba': 4150, 'kayo': 4151, 'Glaubst': 4152, 'du': 4153, 'nicht': 4154, 'resumed': 4155, 'memememememem': 4156, ';_;': 4157, 'Fine': 4158, 'hetero': 4159, 'DOUBLE': 4160, 'PROPHETATION': 4161, 'haa': 4162, '2mins': 4163, 'LETS': 4164, 'SEE': 4165, 'WERE': 4166, 'HIDDING': 4167, 'sire': 4168, 'sange': 4169, 'shadow': 4170, 'aeguiis': 4171, 'horrible': 4172, 'yt': 4173, 'awit': 4174, 'congrats': 4175, 'WOOOOOOOOOOOOOOOOOO': 4176, 'online': 4177, 'ecks': 4178, 'dee': 4179, 'pickers': 4180, 'AHAAH': 4181, 'crystal': 4182, 'SOD': 4183, 'tyty': 4184, 'washroom': 4185, 'RUS': 4186, 'sumail': 4187, 'copy': 4188, '2FCKNG': 4189, 'basin': 4190, 'botbot': 4191, 'RIKI': 4192, 'ENXT': 4193, '=trash': 4194, 'craggy': 4195, 'ahah': 4196, 'Russian': 4197, 'log': 4198, 'creeepy': 4199, 'recording': 4200, 'WHERES': 4201, 'LION': 4202, 'AT': 4203, 'CUTE': 4204, 'MAGNUS': 4205, 'abondon': 4206, 'altest': 4207, 'maby': 4208, 'practis': 4209, 'missile': 4210, 'speed': 4211, 'balls': 4212, 'xDD': 4213, 'becuse': 4214, 'dumbuck': 4215, 'sok': 4216, 'jajajjaa': 4217, 'recorder': 4218, 'inches': 4219, 'Ezi': 4220, 'hahahhaha': 4221, 'DED': 4222, ':DDD': 4223, 'tells': 4224, 'tanga': 4225, 'genuinely': 4226, 'singsing': 4227, 'srsly': 4228, 'disgrace': 4229, 'LODA': 4230, 'pla': 4231, 'lags': 4232, 'brai': 4233, 'toxi': 4234, 'leguon': 4235, 'C': 4236, '===3': 4237, '23:59': 4238, 'LOOOL': 4239, 'actualy': 4240, 'among': 4241, 'fuckong': 4242, 'bying': 4243, 'pushes': 4244, 'forward': 4245, 'Lycan': 4246, 'wolf': 4247, 'hates': 4248, 'flames': 4249, 'tactical': 4250, 'LOSE': 4251, 'TEAMMATES': 4252, 'playeres': 4253, 'stealmid': 4254, 'mon': 4255, 'begin': 4256, 'cykaseeker': 4257, 'racist': 4258, 'theyre': 4259, 'juger': 4260, 'WHATTTTTTTTTTTTTTTTTTTTTTTTTTT': 4261, 'wnna': 4262, 'trolled': 4263, '3rd': 4264, 'Really': 4265, 'SOUND': 4266, 'ISSUES': 4267, 'max': 4268, 'totem': 4269, 'kick': 4270, 'duallane': 4271, 'ewait': 4272, 'fkng': 4273, 'pressure': 4274, 'fellas': 4275, 'jjaja': 4276, 'facts': 4277, 'EZZZZZZZZZZZZZZ': 4278, 'MUITO': 4279, 'FACIL': 4280, 'ruim': 4281, 'FAKE': 4282, 'WORLD': 4283, 'WONDERLAND': 4284, 'nearly': 4285, 'Troll': 4286, 'Get': 4287, 'rapira': 4288, 'chances': 4289, 'plss': 4290, 'rof': 4291, '9k': 4292, 'Def': 4293, 'Hell': 4294, 'pail': 4295, 'icant': 4296, 'hide': 4297, 'slanty': 4298, 'doh': 4299, 'reward': 4300, 'cockwork': 4301, 'combined': 4302, 'confirmed': 4303, 'perdedor': 4304, 'hurry': 4305, 'afraid': 4306, 'wc': 4307, 'ANY': 4308, 'QUESTION': 4309, 'Are': 4310, 'They': 4311, 'OUR': 4312, 'wag': 4313, 'rec': 4314, 'SWORD': 4315, 'EFFORT': 4316, 'ezy': 4317, 'Hahahah': 4318, 'manners': 4319, 'Pikachu': 4320, 'brings': 4321, 'ptsd': 4322, 'n1': 4323, 'Hes': 4324, 'busy': 4325, 'shittalking': 4326, 'Rubick': 4327, 'PUL': 4328, ':L': 4329, 'LOOOOOOOOOL': 4330, 'RECOMIENDENME': 4331, 'Wat': 4332, 'rpo': 4333, 'Windranger': 4334, 'KDA': 4335, 'tune': 4336, 'ooh': 4337, 'oppennenth': 4338, 'bn': 4339, 'OFF': 4340, 'electricity': 4341, 'wats': 4342, 'saddlebag': 4343, 'ou': 4344, 'master': 4345, 'hurts': 4346, 'beleive': 4347, 'LOW': 4348, 'QUALITY': 4349, 'MADE': 4350, 'CHINA': 4351, 'HC': 4352, 'ezt': 4353, 'tangos': 4354, 'Il': 4355, 'wae': 4356, 'Wave': 4357, 'sword': 4358, 'MAGINA': 4359, 'hahahahhahahahhahahahahhahahha': 4360, 'geg': 4361, 'rase': 4362, 'excellent': 4363, ':O': 4364, 'AHHASDA': 4365, 'BL': 4366, 'pidaras': 4367, 'jkes': 4368, 'chinese': 4369, 'bwersit': 4370, 'itgma': 4371, 'fickler': 4372, 'pugne': 4373, 'test': 4374, 'LEKT': 4375, 'CHECK': 4376, 'HAHGA': 4377, 'POGI': 4378, 'butu': 4379, 'wpould': 4380, 'ow': 4381, 'ARER': 4382, 'LUCKY': 4383, 'BYING': 4384, 'ACC': 4385, 'talkshits': 4386, 'omniknight': 4387, 'fixed': 4388, 'Reasons': 4389, 'GIVE': 4390, 'CARRIES': 4391, 'Guys': 4392, 'che': 4393, 'lz': 4394, 'icefrog': 4395, 'lars': 4396, 'ricken': 4397, 'ran': 4398, 'hurt': 4399, 'completely': 4400, '40': 4401, '2x8': 4402, 'dendiFace': 4403, 'W': 4404, 'fAIL': 4405, 'eVER': 4406, 'Nc': 4407, 'level': 4408, 'half': 4409, 'suports': 4410, ':DDDDD': 4411, 'LOSER': 4412, 'REF': 4413, 'FFS': 4414, ':OOO': 4415, 'taht': 4416, 'windows': 4417, 'tgx': 4418, 'LL': 4419, 'DEFEAT': 4420, 'CIS': 4421, 'SCUM': 4422, 'nid': 4423, 'tan': 4424, 'desesperado': 4425, 'AUSTRALIA': 4426, '118': 4427, '1188': 4428, 'looks': 4429, 'plis': 4430, 'vision': 4431, 'bset': 4432, 'matchup': 4433, 'meepwn': 4434, 'redemption': 4435, 'humilition': 4436, 'smack': 4437, 'homie': 4438, 'puge': 4439, 'maiden': 4440, 'pidori': 4441, 'emore': 4442, 'idiotd': 4443, 'towets': 4444, 'towers': 4445, ':DDDDDDDDDDDDD': 4446, 'jhahahaha': 4447, 'helps': 4448, 'Alliance': 4449, 'holes': 4450, 'broken': 4451, 'boyss': 4452, 'aint': 4453, 'ultis': 4454, 'gustav': 4455, 'pts': 4456, 'planting': 4457, 'mines': 4458, 'bullshit': 4459, 'nbice': 4460, 'niceeeeeeee': 4461, 'winner': 4462, 'wwe': 4463, 'champion': 4464, 'ded': 4465, 'EASY': 4466, 'tooeasy': 4467, '12mins': 4468, 'TEST': 4469, 'chuchamadre': 4470, 'gayest': 4471, 'bolas': 4472, 'guyss': 4473, 'rlly': 4474, 'srry': 4475, 'duzel': 4476, 'retaRD': 4477, 'BAstaRD': 4478, 'eport': 4479, 'dazel': 4480, 'abandon': 4481, 'alesso': 4482, 'klamamaa': 4483, '300mins': 4484, 'somalis': 4485, 'moneys': 4486, 'soz': 4487, 'stooping': 4488, 'introboy': 4489, 'vodka': 4490, 'balalaika': 4491, 'BUSH': 4492, 'luckymen': 4493, 'luckyman': 4494, 'anti': 4495, 'mah': 4496, 'kple': 4497, 'bulsshit': 4498, 'REKY': 4499, 'CUNTSS': 4500, 'Stfu': 4501, 'nest': 4502, 'lOL': 4503, 'buds': 4504, 'flamer': 4505, 'hve': 4506, 'chest': 4507, 'afff': 4508, 'definitelly': 4509, 'Enigma': 4510, 'spare': 4511, 'gaems': 4512, 'mucho': 4513, 'ahahahhahahah': 4514, 'TINY': 4515, 'alolololo': 4516, 'computers': 4517, 'kinse': 4518, 'casi': 4519, 'Jjajajaja': 4520, 'speak': 4521, 'allied': 4522, 'pinky': 4523, 'swear': 4524, 'Run': 4525, 'nooooooooooooooooooo': 4526, 'waifu': 4527, 'braidnead': 4528, 'LP': 4529, 'belongs': 4530, 'lian': 4531, 'farmed': 4532, 'ididnt': 4533, 'ulit': 4534, 'blamed': 4535, 'adjusted': 4536, 'wth': 4537, 'FK': 4538, 'TENGENE': 4539, 'SHACKLESHOT': 4540, 'CONNECT': 4541, 'ACTUAL': 4542, 'Literally': 4543, 'pausing': 4544, 'rad': 4545, 'PLAY': 4546, 'POR': 4547, 'FAVOR': 4548, 'built': 4549, 'gifts': 4550, 'vagi': 4551, 'motrher': 4552, 'wjore': 4553, 'side': 4554, 'Targeting': 4555, 'laid': 4556, 'christopher': 4557, 'leon': 4558, 'passive': 4559, 'BIG': 4560, 'DEFENCE': 4561, 'lots': 4562, 'K': 4563, 'DOWN': 4564, 'masochist': 4565, 'taste': 4566, 'spicy': 4567, 'thai': 4568, 'era': 4569, 'TROLLING': 4570, 'Phew': 4571, 'shackled': 4572, 'wdc': 4573, 'booo': 4574, 'ingame': 4575, 'cummin': 4576, 'TAU': 4577, 'KONTOOL': 4578, 'lkol': 4579, 'cumed': 4580, 'YA': 4581, 'PUDG': 4582, 'AXE': 4583, 'GMA': 4584, 'midtime': 4585, 'Sec': 4586, 'Last': 4587, 'Online': 4588, 'comew': 4589, 'friends': 4590, 'BETTER': 4591, 'STORY': 4592, 'helping': 4593, 'lopl': 4594, 'standin': 4595, 'troll': 4596, 'CMON': 4597, 'CREEPS': 4598, 'tilt': 4599, 'mode': 4600, 'engaged': 4601, 'cast': 4602, 'positive': 4603, 'Awww': 4604, 'restarting': 4605, 'goodbye': 4606, 'flame': 4607, 'aseeeeeee': 4608, 'jer': 4609, 'bank': 4610, 'chrono': 4611, 'Aaa': 4612, 'laptop': 4613, 'oyoyoyoyoyoyoy': 4614, 'wombo': 4615, 'Sweet': 4616, 'AHAYHAYHAY': 4617, 'ganked': 4618, 'noce': 4619, 'disr': 4620, 'doe': 4621, 'hours': 4622, 'wisdom': 4623, 'te': 4624, 'shu8t': 4625, 'mouth': 4626, 'tramp': 4627, 'kh': 4628, 'XXDDD': 4629, 'IO': 4630, 'THOUGH': 4631, 'RLZ': 4632, 'cena': 4633, 'undertaker': 4634, 'ajajajjaaj': 4635, 'ppor': 4636, 'HI': 4637, '4V4': 4638, 'HAAH': 4639, 'SJIT': 4640, 'Spec': 4641, 'thinks': 4642, 'nicveee': 4643, 'yeeeeeeeeeeeeeeeep': 4644, 'kunka': 4645, 'beast': 4646, 'oooh': 4647, 'jukes': 4648, 'tis': 4649, 'blaco': 4650, 'veryyy': 4651, 'needed': 4652, 'inb4': 4653, 'maphack': 4654, 'LAg': 4655, 'orge': 4656, 'farmt': 4657, 'mehr': 4658, 'als': 4659, 'jeder': 4660, 'bauer': 4661, 'criticism': 4662, 'pipe': 4663, 'such': 4664, 'wsTF': 4665, 'DOES': 4666, 'SHOOT': 4667, 'betulan': 4668, 'maap': 4669, 'tr': 4670, 'howdu': 4671, 'innocent': 4672, 'info': 4673, 'MADNESS': 4674, 'wa': 4675, 'thinking': 4676, 'yeh': 4677, 'orgies': 4678, 'sakai': 4679, 'huge': 4680, 'bonert': 4681, 'pano': 4682, 'confident': 4683, 'backfired': 4684, 'poo': 4685, 'wahahaha': 4686, '1min': 4687, 'bes': 4688, 'CHATING': 4689, 'sa': 4690, 'wakas': 4691, 'mga': 4692, 'ungas': 4693, 'WORST': 4694, 'BUILD': 4695, 'IVE': 4696, 'EVER': 4697, 'SEEN': 4698, 'alcehmist': 4699, 'reminant': 4700, 'warded': 4701, 'hHAHAHAHhAhahah': 4702, 'CORE': 4703, 'ROLES': 4704, 'TAKEN': 4705, 'BOYS': 4706, 'WOOOOO': 4707, 'scare': 4708, 'BF': 4709, 'Cm': 4710, 'mentality': 4711, ':EGKAYA': 4712, 'IE': 4713, 'VI': 4714, 'GDE': 4715, 'ggf': 4716, 'hunt': 4717, 'born': 4718, 'connectio': 4719, 'doin': 4720, 'NORM': 4721, '5K4': 4722, 'BOYZ': 4723, 'SAME': 4724, 'PARTY': 4725, 'metaplayer': 4726, 'DON': 4727, 'WAKE': 4728, 'FO': 4729, 'BOY': 4730, 'LOOK': 4731, 'MA': 4732, 'BOTTOM': 4733, 'EVEN': 4734, 'THEYRE': 4735, 'PRU': 4736, 'named': 4737, 'VERI': 4738, 'TAIRED': 4739, 'YO': 4740, 'goddamit': 4741, '10000': 4742, 'Doing': 4743, 'Oh': 4744, 'along': 4745, 'helpless': 4746, 'OCTA': 4747, 'CUMBACK': 4748, 'ALLIANCE': 4749, 'bla': 4750, 'TRADE': 4751, 'noobest': 4752, 'melee': 4753, 'extent': 4754, 'notification': 4755, 'Dire': 4756, 'spawns': 4757, 'remaining': 4758, 'Wak': 4759, 'wak': 4760, 'RUIN': 4761, 'abit': 4762, 'geam': 4763, 'ktukan': 4764, 'udh': 4765, 'hilang': 4766, 'cok': 4767, 'pink': 4768, 'dropped': 4769, 'patch': 4770, 'braker': 4771, 'thesee': 4772, ':[': 4773, 'Add': 4774, 'dzzle': 4775, 'dads': 4776, 'arsehole': 4777, 'STFU': 4778, 'reports': 4779, 'INVISIBLE': 4780, 'BROTHER': 4781, '33': 4782, 'tee': 4783, 'hee': 4784, 'issues': 4785, 'gagaga': 4786, 'welp': 4787, 'YAAH': 4788, 'rubic': 4789, 'greed': 4790, '9999': 4791, 'fue': 4792, 'megas': 4793, 'comp': 4794, 'monger': 4795, 'assasin': 4796, 'Same': 4797, 'Life': 4798, 'Strange': 4799, 'nuke': 4800, 'town': 4801, 'qquesiton': 4802, 'mever': 4803, 'agian': 4804, 'comfort': 4805, 'EMBER': 4806, 'balanced': 4807, 'awesome': 4808, '3mins': 4809, 'tE': 4810, 'HIZO': 4811, 'KKK': 4812, 'upports': 4813, 'WARDS': 4814, 'neverr': 4815, 'fak': 4816, 'ssory': 4817, 'nightmare': 4818, 'abilities': 4819, 'amirite': 4820, 'dreaming': 4821, 'madafaka': 4822, 'Lina': 4823, 'EAZY': 4824, 'NAO': 4825, 'FARMEI': 4826, 'pingas': 4827, 'MISSING': 4828, 'LAST': 4829, 'HITS': 4830, 'WITH': 4831, 'CHILLING': 4832, 'TOUCH': 4833, 'FINALLY': 4834, 'spelll': 4835, 'ckeckek': 4836, 'bkbs': 4837, 'SOMeBODY': 4838, 'TELL': 4839, 'USE': 4840, 'HIs': 4841, 'PASSIVE': 4842, 'blur': 4843, 'ComEbAcK': 4844, 'ALcheMISt': 4845, 'WHy': 4846, 'QuiET': 4847, 'singapour': 4848, 'tie': 4849, 'BROWN': 4850, 'CUNT': 4851, 'JUMPING': 4852, '10k': 4853, 'Well': 4854, 'thinke': 4855, 'PC': 4856, 'reconect': 4857, 'todl': 4858, 'uwhere': 4859, 'bullshitting': 4860, 'merry': 4861, 'SONG': 4862, 'decide': 4863, 'opn': 4864, 'whyyyyyyyyyyyyyyyyyyyyyyyy': 4865, 'exist': 4866, 'happend': 4867, 'ibrahimovich': 4868, 'WOAAAH': 4869, '1m': 4870, 'ahead': 4871, 'shy': 4872, 'bek': 4873, 'compo': 4874, 'mobo': 4875, 'BAM': 4876, 'BOM': 4877, 'BAm': 4878, 'losses': 4879, 'bF': 4880, 'XDDDD': 4881, '2MINS': 4882, 'DADY': 4883, 'puede': 4884, 'tocar': 4885, 'mierdas': 4886, 'laged': 4887, 'fuckerclink': 4888, 'kekke': 4889, 'DEFENDERE': 4890, 'Repord': 4891, 'pinke': 4892, 'loo': 4893, 'Invoker': 4894, 'fuken': 4895, 'om': 4896, 'arnt': 4897, 'wild': 4898, '5man': 4899, 'appears': 4900, 'tus': 4901, 'DS': 4902, 'u2': 4903, 'auto': 4904, 'BKB': 4905, 'gud': 4906, 'FUCKIN': 4907, 'HAH': 4908, 'tahts': 4909, 'impossible': 4910, 'KDDDDDDDDDDDDDD': 4911, 'SILENCER': 4912, 'Fortify': 4913, 'WTFG': 4914, 'Anything': 4915, 'quilspray': 4916, 'blinking': 4917, 'towards': 4918, 'KNEW': 4919, 'psl': 4920, 'tu': 4921, 'pouse': 4922, 'nub': 4923, 'tch': 4924, 'sda': 4925, 'ezwp': 4926, 'yrs': 4927, 'disconnecting': 4928, 'Therikavidalama': 4929, 'motherfuking': 4930, 'roofl': 4931, 'fuckhead': 4932, 'somehow': 4933, 'JUGER': 4934, '=\\\\': 4935, 'PEENOISE': 4936, 'teamchat': 4937, 'noone': 4938, 'WAT': 4939, 'HAPPEN': 4940, 'looy': 4941, 'pud': 4942, 'drag': 4943, 'beat': 4944, 'fow': 4945, 'show': 4946, '45': 4947, 'uhhh': 4948, 'takogo': 4949, 'slova': 4950, 'Serenity': 4951, 'boiz': 4952, 'hao': 4953, 'ACCOUNT': 4954, 'BUYER': 4955, 'scum': 4956, 'deserver': 4957, 'Our': 4958, 'owe': 4959, 'moments': 4960, 'OD': 4961, '4v': 4962, '5500': 4963, 'europe': 4964, 'matchmaking': 4965, 'ck': 4966, 'si': 4967, 'eaz': 4968, 'jimbo': 4969, 'pushte': 4970, 'otjimayu': 4971, 'voice': 4972, 'command': 4973, 'lm': 4974, 'pe': 4975, 'lika': 4976, 'ability': 4977, 'radience': 4978, 'fv': 4979, 'youtube': 4980, 'noice': 4981, 'hAHAHAHAHA': 4982, 'hAHAHAHAHAH': 4983, '5555': 4984, 'zeuiz': 4985, 'newbie': 4986, 'PREDICT': 4987, 'ANTI': 4988, 'PUSH': 4989, 'smar': 4990, 'diz': 4991, 'CLQ': 4992, 'counted': 4993, 'ITEMS': 4994, 'TARD': 4995, 'okayu': 4996, 'nobo': 4997, 'doctors': 4998, 'crazy': 4999, '1vs1': 5000, 'exp': 5001, 'likely': 5002, 'drain': 5003, 'wave': 5004, 'essez': 5005, 'wii': 5006, 'TINEKR': 5007, 'unstopdbl': 5008, 'XAxaxaxax': 5009, 'dying': 5010, 'doiung': 5011, 'noithign': 5012, 'idestroyed': 5013, 'XA': 5014, 'gotem': 5015, 'xhamster': 5016, 'Keep': 5017, 'doods': 5018, 'onlinE': 5019, '360': 5020, 'fgts': 5021, 'hooks': 5022, 'cal': 5023, 'dirt': 5024, 'bags': 5025, '1v5': 5026, 'EZE': 5027, 'Tho': 5028, 'hot': 5029, 'FURION': 5030, 'GOGO': 5031, 'clearly': 5032, 'katka': 5033, 'REportd': 5034, 'delte': 5035, 'fame': 5036, '41': 5037, 'SWEAR': 5038, 'Him': 5039, 'fog': 5040, 'gob': 5041, 'smacked': 5042, 'euls': 5043, '329': 5044, 'deny': 5045, 'stfuy': 5046, 'galwang': 5047, 'ninja': 5048, 'VOLVO': 5049, 'click': 5050, 'button': 5051, 'att': 5052, 'tj': 5053, 'ust': 5054, 'aoe': 5055, 'FUHRZEN': 5056, 'thrwos': 5057, 'ROLF': 5058, 'annoying': 5059, 'aahahhaa': 5060, 'denies': 5061, 'comeo': 5062, 'killer': 5063, 'shpould': 5064, 'iron': 5065, 'branch': 5066, '4min': 5067, 'KONTOL': 5068, 'ANJING': 5069, 'namaste': 5070, 'ji': 5071, 'ALCEHMIST': 5072, 'Tea': 5073, 'snowball': 5074, 'hayshit': 5075, 'gayshit': 5076, 'uheuhee': 5077, 'mints': 5078, 'habia': 5079, 'muerto': 5080, 'huevie': 5081, 'tecla': 5082, 'pm': 5083, 'calculated': 5084, 'lasted': 5085, 'huhhuhuhuhuh': 5086, 'yall': 5087, 'soft': 5088, 'hed': 5089, 'allies': 5090, 'PUASE': 5091, 'teliin': 5092, 'Okay': 5093, 'byebye': 5094, 'LOl': 5095, 'ganks': 5096, 'POOR': 5097, 'ZEus': 5098, 'salty': 5099, '200': 5100, 'leaderhsip': 5101, 'rewporetd': 5102, 'BAJCHS': 5103, 'THEN': 5104, 'FEEL': 5105, 'NC': 5106, 'blackout': 5107, ';(': 5108, 'giff': 5109, 'victory': 5110, 'Stupid': 5111, 'Lmao': 5112, 'recipe': 5113, 'destroyed': 5114, 'upgrade': 5115, 'Free': 5116, 'ASK': 5117, 'ALWAYS': 5118, 'MOST': 5119, 'WHOCARES': 5120, 'AUTOWIN': 5121, 'loa': 5122, 'deek': 5123, 'Bunch': 5124, 'kunts': 5125, 'candy': 5126, 'ramp': 5127, 'ehueheuheu': 5128, 'eTO': 5129, 'TI': 5130, 'TAK': 5131, 'NAMEKAEW': 5132, 'TOB': 5133, 'TEBYA': 5134, 'NAXYU': 5135, 'POSLAL': 5136, 'AAAA': 5137, 'ETO': 5138, 'NORMAL': 5139, 'MALENK': 5140, 'PIZDABO': 5141, 'YASNO': 5142, 'IDID': 5143, 'ZAEBAL': 5144, 'YJE': 5145, 'wrekt': 5146, 'lowprio': 5147, 'HEHHE': 5148, 'diebacks': 5149, '540': 5150, 'golds': 5151, 'Kramer': 5152, 'First': 5153, 'TREASUES': 5154, 'FASTR': 5155, 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz': 5156, 'kiddo': 5157, 'pushed': 5158, 'ghaha': 5159, 'iKR': 5160, 'dOG': 5161, 'BRAIN': 5162, 'det': 5163, 'emil': 5164, 'stabil': 5165, 'amazing': 5166, 'tidew': 5167, 'teammates': 5168, 'demoralize': 5169, 'HIS': 5170, 'CENAAAAAA': 5171, 'ezezeze': 5172, 'nnono': 5173, 'Earthsahker': 5174, 'sucka': 5175, 'deffing': 5176, 'rapiraa': 5177, 'hahahhahahahah': 5178, 'OHMEN': 5179, 'gettin': 5180, 'squeaker': 5181, 'alchie': 5182, 'minions': 5183, 'badabing': 5184, 'Gamers': 5185, 'ew': 5186, 'sents': 5187, 'leash': 5188, 'musa': 5189, 'noobis': 5190, 'nabs': 5191, 'Baited': 5192, 'cl': 5193, 'hands': 5194, 'SLOW': 5195, 'erroe': 5196, 'error': 5197, 'o0ne': 5198, 'motherducker': 5199, 'leslie': 5200, 'graphic': 5201, 'lower': 5202, 'ole': 5203, 'BABY': 5204, 'TIGHT': 5205, 'BLACK': 5206, 'COLOUR': 5207, 'Blind': 5208, 'phew': 5209, 'NOOO': 5210, 'tt': 5211, 'tron': 5212, 'comon': 5213, 'EEEEE': 5214, 'quickscoped': 5215, 'TRY': 5216, 'turk': 5217, 'fan': 5218, 'brother': 5219, 'whoops': 5220, 'unfortunately': 5221, 'fish': 5222, 'alien': 5223, 'CUZ': 5224, 'LEFT': 5225, 'BEFORE': 5226, 'MINUTES': 5227, 'MAG': 5228, 'ARISE': 5229, 'FEEDING': 5230, 'thief': 5231, 'lay': 5232, 'every1': 5233, 'asked': 5234, 'Atos': 5235, 'Abba': 5236, 'Err': 5237, '6v4': 5238, 'forget': 5239, 'prefere': 5240, 'actuially': 5241, 'ed': 5242, 'confidence': 5243, 'jump': 5244, 'fall': 5245, 'pip': 5246, 'mental': 5247, 'casual': 5248, 'niggumus': 5249, 'lil': 5250, 'boi': 5251, 'posion': 5252, 'cans': 5253, 'outplayd': 5254, 'ulol': 5255, 'skrub': 5256, 'Defend': 5257, 'internal': 5258, 'stacktrash': 5259, 'mat4es': 5260, 'disconnects': 5261, 'disconnected': 5262, 'brist': 5263, 'rekon': 5264, 'Wasfucking': 5265, 'eeeeeeeeeeeeeeez': 5266, 'meh': 5267, 'sielnecr': 5268, 'lotus': 5269, '47': 5270, 'eaxe': 5271, 'oging': 5272, 'natural': 5273, 'lowest': 5274, 'tier': 5275, 'kunt': 5276, 'BABILO': 5277, 'FUNNY': 5278, 'ulty': 5279, 'orryt': 5280, 'commedn': 5281, 'laning': 5282, 'cs': 5283, 'stage': 5284, '=raport': 5285, 'flaws': 5286, 'ezzz': 5287, 'DISCONNECT': 5288, 'ARBOL': 5289, 'WD': 5290, 'itch': 5291, 'bisaya': 5292, 'pisot': 5293, 'hgahhaha': 5294, 'bell': 5295, '=]': 5296, '2hp': 5297, 'soookaaa': 5298, 'reporten': 5299, 'critical': 5300, 'bog': 5301, 'manner': 5302, 'WOOOOOW': 5303, 'friendly': 5304, 'pickin': 5305, 'DAZZLE': 5306, 'SUCKMID': 5307, 'TOO': 5308, 'woah': 5309, 'der': 5310, 'isee': 5311, 'grey': 5312, 'packetloss': 5313, 'pwn': 5314, 'nubs': 5315, 'DAzl': 5316, 'ako': 5317, '7k': 5318, 'abited': 5319, 'eks': 5320, 'DD': 5321, 'ggg': 5322, 'JOJOJOJ': 5323, 'Sorry': 5324, 'walked': 5325, 'disgusting': 5326, 'wispo': 5327, 'guysreport': 5328, 'pill': 5329, 'themoreyouknow': 5330, 'republicans': 5331, 'ay': 5332, 'ylmao': 5333, 'mne': 5334, 'gus': 5335, 'yozu': 5336, '143': 5337, 'arms': 5338, 'shaking': 5339, 'jESUS': 5340, 'CRHIST': 5341, 'ignored': 5342, 'whant': 5343, 'hr': 5344, 'blackhole': 5345, 'titling': 5346, 'traash': 5347, 'connect': 5348, 'wtfast': 5349, 'connecting': 5350, 'Before': 5351, 'negative': 5352, 'psycho': 5353, 'ahahah': 5354, 'thebest': 5355, 'Crrrrunch': 5356, 'Sladar': 5357, 'tagal': 5358, 'WORTH': 5359, 'divers': 5360, 'maaaaadd': 5361, 'afford': 5362, 'gooo': 5363, '1cd': 5364, 'gggg': 5365, 'ABOUT': 5366, 'MJOLNIR': 5367, 'tit': 5368, 'cna': 5369, 'GRAVE': 5370, 'THOUGHT': 5371, 'CREEP': 5372, 'plant': 5373, 'trsah': 5374, 'milk': 5375, 'sclard': 5376, 'werth': 5377, '20sec': 5378, 'l2p': 5379, 'Liol': 5380, 'treants': 5381, 'linte': 5382, 'kamu': 5383, 'wsp': 5384, 'loda': 5385, 'gr8': 5386, 'b8': 5387, 'HAPPENING': 5388, 'morale': 5389, 'follow': 5390, 'dodge': 5391, '4ks': 5392, 'barking': 5393, 'gamme': 5394, 'week': 5395, 'drugs': 5396, 'nikolaiv': 5397, 'illu': 5398, 'haahhaah': 5399, 'Because': 5400, 'constantly': 5401, 'gtting': 5402, 'wollongong': 5403, 'south': 5404, 'dapto': 5405, 'maube': 5406, 'bully': 5407, 'Sexyness': 5408, '5min': 5409, 'LEARN': 5410, 'FCKTARD': 5411, 'easier': 5412, 'explain': 5413, 'bility': 5414, 'tjat': 5415, 'fayze': 5416, 'fireworks': 5417, 'Chase': 5418, 'suicede': 5419, 'Go': 5420, 'nmooob': 5421, 'DXXDXDXDXDXD': 5422, 'Mirana': 5423, 'usles': 5424, 'playes': 5425, 'Who': 5426, 'dooms': 5427, 'PUGNA': 5428, 'ShUT': 5429, 'FAQ': 5430, 'asfd': 5431, 'ojgba': 5432, 'lolo': 5433, 'tolko': 5434, 'imenno': 5435, 'izza': 5436, 'nego': 5437, 'eZ': 5438, 'nyxnynyxynxnyxnyxnyxny': 5439, 'healed': 5440, 'butterfl': 5441, 'alreadty': 5442, 'girlssss': 5443, 'Thx': 5444, 'Anyone': 5445, 'Suda': 5446, 'idite': 5447, 'Vseh': 5448, 'viebu': 5449, 'plx': 5450, 'babilo': 5451, 'hmmmm': 5452, 'atar': 5453, 'xaxaxaxaxaxaxaxax': 5454, 'dAT': 5455, 'optus': 5456, 'cake': 5457, 'tsunami': 5458, 'Rampage': 5459, '2nd': 5460, 'ory': 5461, 'oryt': 5462, 'OkAY': 5463, 'aLcheMIst': 5464, 'clcockwerk': 5465, 'lolllllllll': 5466, 'AAYY': 5467, 'notice': 5468, '350': 5469, 'Also': 5470, 'shiny': 5471, 'ezzzy': 5472, 'confsued': 5473, 'SPARE': 5474, 'mofo': 5475, '233': 5476, 'LAGH': 5477, 'plzz': 5478, 'stroking': 5479, 'SEARCH': 5480, 'FB': 5481, 'CEN': 5482, 'IZA': 5483, 'ruskies': 5484, 'west': 5485, 'brutos': 5486, 'clashing': 5487, 'wrote': 5488, 'xyilo': 5489, '2248': 5490, 'wpwpw': 5491, 'san': 5492, 'lupam': 5493, 'pairs': 5494, 'Low': 5495, 'gam': 5496, 'KIDS': 5497, 'streak': 5498, 'HAHAHAHAHHAAH': 5499, 'response': 5500, 'pot': 5501, 'XDDDDD': 5502, 'RIGHT': 5503, 'pizda': 5504, 'KEKEE': 5505, 'sound': 5506, 'sent': 5507, 'kaka': 5508, 'lang': 5509, 'KUNKKA': 5510, 'GEGE': 5511, 'BIGBADBIRD': 5512, 'easi': 5513, 'asking': 5514, 'JAMES': 5515, 'DEAN': 5516, 'paste': 5517, 'Atlas': 5518, 'tanginmao': 5519, '=.=': 5520, 'amiga': 5521, 'THATM': 5522, 'ISS': 5523, 'plantign': 5524, 'Alchemist': 5525, 'j': 5526, 'blyj': 5527, 'mushe': 5528, 'Stick': 5529, 'FACTS': 5530, 'rubish': 5531, 'OMg': 5532, 'reportd': 5533, 'Fail': 5534, 'rege': 5535, '1ult': 5536, '3die': 5537, '53': 5538, 'SRSLY': 5539, 'sisihan': 5540, 'BRING': 5541, 'CHEESE': 5542, 'sgh': 5543, 'shrapnel': 5544, 'craos': 5545, 'craps': 5546, 'spoils': 5547, 'robot': 5548, 'damo': 5549, 'LESSON': 5550, 'enter': 5551, 'fingering': 5552, 'begins': 5553, 'stains': 5554, 'shhht': 5555, 'alchee': 5556, 'astraling': 5557, 'rofmao': 5558, 'lovely': 5559, '8with': 5560, 'NP': 5561, 'clinkzz': 5562, 'LELS': 5563, 'checked': 5564, 'sat': 5565, 'PLAYERS': 5566, 'HALLO': 5567, 'ng': 5568, 'ROFLAJHJAKHDJAKLDNALKDN': 5569, 'um': 5570, 'haf': 5571, 'thjis': 5572, 'SPEC': 5573, 'bey': 5574, 'Coold': 5575, 'toilet': 5576, 'raku': 5577, 'o0o': 5578, 'ambulance': 5579, 'ahhaha': 5580, 'ezmid': 5581, 'AHHAH': 5582, 'glgl': 5583, 'fix': 5584, 'internet': 5585, 'SUMIAL': 5586, 'WANNABE': 5587, 'eva': 5588, 'ggwep': 5589, 'feeed': 5590, 'reasonable': 5591, 'DU': 5592, 'flashmob': 5593, 'tbd': 5594, 'frustrated': 5595, '38flesh': 5596, 'JUGG': 5597, 'V': 5598, 'MUTE': 5599, 'KSTATE': 5600, 'Miis': 5601, 'Follow': 5602, 'riiight': 5603, 'meanwhile': 5604, 'finding': 5605, 'Q': 5606, 'HAHHAA': 5607, 'HES': 5608, 'ONLINE': 5609, 'fist': 5610, 'HELLO': 5611, 'young': 5612, 'bulgarian': 5613, 'sausage': 5614, 'leki': 5615, 'xdxd': 5616, 'irony': 5617, 'usless': 5618, 'Say': 5619, 'NAXREN': 5620, 'mOM': 5621, 'basket': 5622, 'thrid': 5623, 'ALCH': 5624, 'SAYS': 5625, 'TEQ': 5626, 'between': 5627, 'SADBOIS': 5628, 'newbs': 5629, 'piNOY': 5630, 'glglgllglglglgl': 5631, 'CUTIE': 5632, 'hisssssssssssss': 5633, 'swpt': 5634, 'lolllllll': 5635, 'ajajajajaa': 5636, 'downies': 5637, 'orange': 5638, 'DICK': 5639, 'AS': 5640, 'LONG': 5641, 'WANTS': 5642, 'ASS': 5643, 'ranged': 5644, 'AHHAHA': 5645, 'idol': 5646, 'xaxa': 5647, 'missle': 5648, 'spiked': 5649, 'uselss': 5650, 'CHARGE': 5651, 'power': 5652, 'Sexy': 5653, 'cud': 5654, 'sunsfan': 5655, 'PREPARE': 5656, 'ANUS': 5657, 'wipping': 5658, 'SEXYYYY': 5659, 'goodnight': 5660, 'ZZ': 5661, 'rusk': 5662, 'BOMJI': 5663, '2100': 5664, 'XDDDDDDDDDDDDDDDDDDDDDDDDD': 5665, 'roflmao': 5666, 'itttt': 5667, '9(': 5668, 'HACKS': 5669, 'SCRIPER': 5670, ';;': 5671, 'INTO': 5672, 'GOOD': 5673, 'IDEA': 5674, 'havent': 5675, 'idots': 5676, 'POTANG': 5677, 'KAYO': 5678, 'BIGYAN': 5679, 'NIYO': 5680, 'NAMAN': 5681, 'AKO': 5682, 'NG': 5683, 'HALAGA': 5684, 'ling': 5685, 'hahyahahahe': 5686, 'maen': 5687, 'california': 5688, 'smooth': 5689, 'MAD': 5690, 'HAHAHAHHAA': 5691, 'DAEDALUs': 5692, 'GAMING': 5693, '66=65': 5694, 'sut': 5695, 'remember': 5696, 'sandstorm': 5697, 'Wow': 5698, 'Cumback': 5699, 'PUSHED': 5700, 'gass': 5701, 'apperantly': 5702, 'moved': 5703, 'assist': 5704, 'babay': 5705, 'ASSHIT': 5706, 'DEN': 5707, 'peruca': 5708, 'JAJA': 5709, 'oops': 5710, 'WRTF': 5711, 'Where': 5712, 'Ahaha': 5713, 'bounces': 5714, 'DAGON': 5715, 'stressed': 5716, 'cheeeers': 5717, 'gaaaame': 5718, 'navi': 5719, 'DEDZ': 5720, 'LOLS': 5721, 'DUEL': 5722, 'retardedrer': 5723, '=d': 5724, 'Recon': 5725, 'youll': 5726, 'pissed': 5727, 'nerd': 5728, 'department': 5729, 'invokers': 5730, 'NOOOOBEST': 5731, 'oblivion': 5732, 'aha': 5733, 'ryan': 5734, 'evening': 5735, 'tping': 5736, 'fear': 5737, 'footfalls': 5738, 'rolf': 5739, 'NEXT': 5740, 'GJ': 5741, 'gift': 5742, 'ROSHING': 5743, 'GOGOOGOGOGOGOGOGOGO': 5744, 'SUPPOSED': 5745, 'MUTED': 5746, 'Die': 5747, 'Hallo': 5748, 'pacan': 5749, 'midasom': 5750, 'centaurs': 5751, 'noooooooooo': 5752, 'erm': 5753, 'Please': 5754, 'month': 5755, 'dogggg': 5756, 'Hope': 5757, 'bucks': 5758, 'HIO': 5759, 'comke': 5760, 'cop': 5761, 'cent': 5762, 'skyrath': 5763, 'duels': 5764, 'absolutely': 5765, 'improves': 5766, 'HOUR': 5767, 'paly': 5768, 'shitties': 5769, 'haaha': 5770, 'tinekr': 5771, 'benn': 5772, 'worthy': 5773, 'RANDOM': 5774, 'ALCHI': 5775, 'UGLY': 5776, 'FUCk': 5777, 'rweport': 5778, 'fsuck': 5779, '3mretards': 5780, 'haha1': 5781, 'sunstrike': 5782, 'hand': 5783, 'depends': 5784, 'BWAHAHHA': 5785, 'm9': 5786, 'horrivel': 5787, 'amming': 5788, 'eys': 5789, 'cult': 5790, 'personality': 5791, 'punk': 5792, 'karl': 5793, 'queen': 5794, 'shold': 5795, 'finished': 5796, 'earlier': 5797, 'yee': 5798, 'break': 5799, 'dh': 5800, 'evahh': 5801, 'SAEC': 5802, 'unifi': 5803, 'issu': 5804, 'packet': 5805, 'cz': 5806, 'gamming': 5807, '=-=': 5808, 'sidruptor': 5809, 'enought': 5810, 'cb': 5811, 'oppenent': 5812, 'soght': 5813, 'NOZA': 5814, 'pants': 5815, 'LOOL': 5816, 'Wa': 5817, 'skilled': 5818, 'boyfriend': 5819, 'penetrated': 5820, 'fairplay': 5821, 'noore': 5822, 'initiation': 5823, 'cheekyness': 5824, 'chaeter': 5825, 'cloak': 5826, 'clickers': 5827, 'listo': 5828, 'fortify': 5829, 'disastah': 5830, 'Trash': 5831, 'ptm': 5832, 'nkow': 5833, 'discovered': 5834, 'America': 5835, 'OSfrog': 5836, 'LE': 5837, 'BALANCED': 5838, 'FEMALE': 5839, 'ROBIN': 5840, 'HOOD': 5841, 'featuring': 5842, 'phoenix': 5843, 'shtorm': 5844, 'mili': 5845, 'herto': 5846, 'school': 5847, '0o': 5848, 'client': 5849, 'defenive': 5850, 'retreath': 5851, 'JESUS': 5852, 'CHRIST': 5853, 'goodgame': 5854, 'gOODgAME': 5855, 'wELL': 5856, 'pLAYED': 5857, 'Fucker': 5858, 'makunat': 5859, 'r8': 5860, 'lived': 5861, 'akk': 5862, 'llove': 5863, 'bra': 5864, 'recomend': 5865, 'snip': 5866, 'googoo': 5867, 'gaga': 5868, 'some1': 5869, 'blade': 5870, 'MOFUCKER': 5871, 'sux': 5872, 'poetic': 5873, 'wwpwwpwpwp': 5874, 'mrs': 5875, 'mamu': 5876, 'jebem': 5877, 'trashtalking': 5878, 'kAPPA': 5879, 'ayy': 5880, 'WEw': 5881, 'debuff': 5882, 'aaha': 5883, 'Revenge': 5884, 'motherfucker': 5885, 'eZAASASAAS': 5886, 'festival': 5887, 'motherless': 5888, 'bots': 5889, 'opposite': 5890, 'photobooth': 5891, '11pm': 5892, 'affirmative': 5893, 'GE': 5894, 'eres': 5895, 'shet': 5896, 'Z': 5897, 'Logging': 5898, 'excuse': 5899, 'fone': 5900, 'isp': 5901, 'funnily': 5902, 'complains': 5903, 'Fking': 5904, 'moron': 5905, 'vpn': 5906, 'lmoa': 5907, 'vipper': 5908, 'Saba': 5909, 'thz': 5910, 'FCKNG': 5911, 'quick': 5912, 'anyday': 5913, 'il': 5914, 'rotating': 5915, 'gae': 5916, 'advantage': 5917, 'fucksticks': 5918, 'pic': 5919, 'wok': 5920, 'merchant': 5921, 'thiss': 5922, 'bbs': 5923, 'yun': 5924, 'cheaters': 5925, 'challenge': 5926, 'pug': 5927, 'gha': 5928, 'buybacks': 5929, 'armlet': 5930, '113': 5931, 'HEHE': 5932, 'Rude': 5933, 'reconnect': 5934, 'gaybin': 5935, 'treats': 5936, 'nicely': 5937, 'SEROIUSLY': 5938, 'prefered': 5939, 'Blink': 5940, 'talkin': 5941, 'boss': 5942, 'oi': 5943, 'miurana': 5944, 'mb': 5945, 'bringing': 5946, 'bastarrds': 5947, 'Step': 5948, 'Don': 5949, 'Fidel': 5950, 'taichi': 5951, 'occasionally': 5952, 'piss': 5953, 'MObile': 5954, 'Fatto': 5955, 'adik': 5956, 'fcup': 5957, '5:25': 5958, 'DREAM': 5959, '1:7': 5960, 'Braz1l': 5961, 'ratazaaaa': 5962, 'bitchery': 5963, 'slave': 5964, 'correct': 5965, 'platter': 5966, 'Phase': 5967, 'eazzzzzzzzzzz': 5968, 'ravage': 5969, 'youc': 5970, 'Hehehe': 5971, 'BAG': 5972, 'magi': 5973, 'lindo': 5974, 'PRAY': 5975, 'Relax': 5976, 'stick': 5977, 'CHICK': 5978, 'difference': 5979, 'fools': 5980, 'moore': 5981, 'coudlve': 5982, 'ended': 5983, 'Fu': 5984, 'achi': 5985, 'faka': 5986, ':\\\\': 5987, 'finaly': 5988, 'dint': 5989, 'celebrate': 5990, 'kpop': 5991, 'SE': 5992, 'nmE': 5993, 'tghrowers': 5994, 'gas': 5995, 'OL': 5996, 'EGGS': 5997, 'everyones': 5998, 'tonight': 5999, 'STAY': 6000, 'shaman': 6001, 'secret': 6002, 'weapon': 6003, 'twrs': 6004, 'mongoloids': 6005, 'sugar': 6006, 'pocket': 6007, 'sth': 6008, 'int1': 6009, 'trentooooo': 6010, 'ligghhter': 6011, 'helo': 6012, 'ADD': 6013, 'laah': 6014, 'puss': 6015, 'lanc': 6016, 'lan': 6017, 'Meppo': 6018, 'Win': 6019, 'http': 6020, 'www': 6021, 'dotabuff': 6022, '113924617': 6023, 'ABUSE': 6024, 'autist': 6025, 'Nevermind': 6026, 'unpausing': 6027, 'strat': 6028, 'HAHAHAH': 6029, '1v3': 6030, '000000': 6031, 'al': 6032, 'CHILLYOU': 6033, 'wqewi': 6034, 'ROSHAN': 6035, 'OURS': 6036, 'GEMS': 6037, 'whoever': 6038, 'due': 6039, 'manay': 6040, 'malaysian': 6041, 'tred': 6042, 'switched': 6043, 'ofmek': 6044, 'hence': 6045, 'fags': 6046, 'alway': 6047, 'ahaah': 6048, 'KappaRoss': 6049, 'cerape': 6050, 'oneee': 6051, '5k4': 6052, 'deward': 6053, 'timeing': 6054, 'h3h3h3': 6055, 'Delte': 6056, 'rush': 6057, 'wowowowow': 6058, 'fate': 6059, 'HOLY': 6060, 'perujvians': 6061, 'ben': 6062, 'relic': 6063, 'saboid': 6064, 'Bois': 6065, 'macd': 6066, 'sleeping': 6067, 'lel2': 6068, '59': 6069, 'twin': 6070, 'BLAME': 6071, 'lvls': 6072, 'hie': 6073, 'rteported': 6074, 'DAMIMIT': 6075, 'akakakakakaka': 6076, 'dafu': 6077, 'deff': 6078, 'aosdSDG': 6079, 'force': 6080, 'attack': 6081, 'agggg': 6082, 'recomiendo': 6083, 'reportean': 6084, 'hang': 6085, '1600': 6086, 'keybord': 6087, 'streaks': 6088, 'kthx': 6089, 'GUY': 6090, 'iS': 6091, 'HILARIOUS': 6092, 'SOMEBODY': 6093, 'WORKS': 6094, 'mes': 6095, 'gG': 6096, 'wiw': 6097, 'thisis': 6098, 'paiseh': 6099, 'phil': 6100, 'TRYHARDS': 6101, 'reatrds': 6102, 'YEH': 6103, 'SA': 6104, 'bp': 6105, 'mata': 6106, 'De': 6107, 'sclav': 6108, 'nob': 6109, '101': 6110, 'SPECTRA': 6111, 'BRAINDEAD': 6112, 'boner': 6113, 'house': 6114, 'hosue': 6115, 'wt': 6116, 'AHAHAHAHAH': 6117, 'REPROT': 6118, 'TRASH': 6119, 'youy': 6120, 'WHat': 6121, 'suffer': 6122, 'yamam': 6123, 'whatup': 6124, 'meme': 6125, 'JOB': 6126, 'DIRE': 6127, 'fps': 6128, 'niggers': 6129, 'RUBICK': 6130, 'WEAVER': 6131, 'PLease': 6132, 'awgmi13i12g': 6133, 'insulting': 6134, 'doo': 6135, 'MetWorth': 6136, 'bored': 6137, 'westeurope': 6138, '50point': 6139, 'ATLAST': 6140, 'chepo': 6141, 'shadowblade': 6142, 'PLAYING': 6143, 'BOTS': 6144, 'chilling': 6145, 'flamed': 6146, 'just2kthings': 6147, 'ABSOLUTE': 6148, 'backtrack': 6149, 'qq': 6150, '1:11': 6151, 'offlaner': 6152, 'DOTKA': 6153, 'okk': 6154, 'attacking': 6155, 'plain': 6156, 'tpying': 6157, 'gays': 6158, 'anw': 6159, 'heck': 6160, 'dress': 6161, 'ST': 6162, 'FUCKER': 6163, 'pussied': 6164, 'GEE': 6165, 'hardhomie': 6166, 'errro': 6167, 'Finally': 6168, 'Bark': 6169, 'ahora': 6170, 'kardel': 6171, 'finsh': 6172, 'sayang': 6173, 'imo': 6174, 'paningkamot': 6175, 'Noobs': 6176, 'hahhaa': 6177, 'hAHAHA': 6178, 'OUT': 6179, '22min': 6180, 'XDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD': 6181, 'PAJARRACO': 6182, 'CONCHETUMARE': 6183, 'Bitch': 6184, 'tntnt': 6185, 'ackt': 6186, 'shots': 6187, 'unreal': 6188, 'IDIOTA': 6189, 'INFIDELS': 6190, 'kda': 6191, 'BACOD': 6192, 'sacrifile': 6193, 'remake': 6194, 'NUKES': 6195, 'rz': 6196, 'laughs': 6197, 'mUT': 6198, 'LS': 6199, 'category': 6200, 'narco': 6201, 'AHahaha': 6202, 'anient': 6203, 'NOP': 6204, 'LOOOOOOOOOOOOOOLLLLLLLLL': 6205, 'Mokiproblems': 6206, 'nman': 6207, 'dunoe': 6208, 'instakill': 6209, 'invkoer': 6210, 'fokin': 6211, 'shitstain': 6212, 'gamer': 6213, 'BEG': 6214, 'naughty': 6215, 'DAT': 6216, 'Aganim': 6217, 'des': 6218, 'wardea': 6219, 'promise': 6220, 'camp': 6221, 'gogogo': 6222, 'hg': 6223, 'storng': 6224, 'vacum': 6225, 'AP': 6226, 'dpmne': 6227, 'CLASH': 6228, 'FUCKEDUPLIFE': 6229, 'REMEMBET': 6230, 'INDEED': 6231, 'WOWOWOOWOWW': 6232, 'dagg': 6233, 'mercy': 6234, 'excelelnt': 6235, 'hus': 6236, 'laggin': 6237, '179': 6238, 'goldi': 6239, 'slardara': 6240, 'freefarme': 6241, 'wet': 6242, 'noodle': 6243, 'mer': 6244, 'guiys': 6245, 'noiw': 6246, 'SPAM': 6247, 'MOM': 6248, 'liquid': 6249, 'arent': 6250, 'ulul': 6251, 'idiota': 6252, 'sps': 6253, 'swup': 6254, 'jking': 6255, 'GGness': 6256, 'xddddddddddddddddddddddddd': 6257, 'ahgahahahaha': 6258, 'toh': 6259, 'aswell': 6260, 'tables': 6261, 'ofl': 6262, 'nomnomlion': 6263, 'potm': 6264, 'distract': 6265, 'deed': 6266, 'yeaaa': 6267, 'truth': 6268, 'syrum': 6269, 'bitter': 6270, 'spawn': 6271, 'mai': 6272, 'junior': 6273, 'RELAX': 6274, 'bothered': 6275, 'ganging': 6276, 'SETTER': 6277, '1ST': 6278, 'INITIATE': 6279, 'CARRT': 6280, 'sory': 6281, 'bayu': 6282, 'slowing': 6283, 'Sb': 6284, 'cover': 6285, 'digusting': 6286, 'patheticness': 6287, 'cagada': 6288, 'legionn': 6289, 'assists': 6290, 'himn': 6291, 'hahahahahha': 6292, 'Es': 6293, 'goooo': 6294, 'XDD': 6295, 'panda': 6296, 'Most': 6297, 'whut': 6298, 'BROOD': 6299, 'wif': 6300, 'beeee': 6301, 'freezing': 6302, 'trilane': 6303, 'dam': 6304, 'miunte': 6305, 'ANIME': 6306, 'playa': 6307, 'proper': 6308, 'understands': 6309, 'probly': 6310, 'DotA': 6311, 'uses': 6312, 'ala': 6313, 'firme': 6314, 'pros': 6315, 'doign': 6316, 'embermon': 6317, 'nuh': 6318, 'ima': 6319, 'boat': 6320, 'gogogog': 6321, 'wuhahsduasd': 6322, 'ep': 6323, 'HERETICS': 6324, 'azzzz': 6325, 'nO': 6326, 'DEFEND': 6327, 'effort': 6328, 'sides': 6329, 'expecially': 6330, 'COMEBAK': 6331, 'eni': 6332, 'russki': 6333, 'noscope': 6334, 'mlgranger': 6335, 'WOHOOO': 6336, 'craggies': 6337, 'unluck': 6338, 'EAIUHEAIUHEAIUEAIUHEAEA': 6339, 'trade': 6340, 'diferent': 6341, 'THERES': 6342, 'hui': 6343, 'ahahahahahha': 6344, 'WHIRLPOOL': 6345, 'WATCH': 6346, 'SUNSET': 6347, 'DOENST': 6348, 'UNDERSTAND': 6349, 'COOLDOWNS': 6350, 'SPELLS': 6351, 'REC': 6352, 'HAHAIHAH': 6353, 'false': 6354, 'downtown': 6355, '515': 6356, 'rough': 6357, '4dr': 6358, 'jenau': 6359, 'cows': 6360, 'given': 6361, 'PASIIVE': 6362, 'MALEV': 6363, 'camped': 6364, 'ground': 6365, 'reportet': 6366, 'sfs': 6367, 'rapiers': 6368, 'coem': 6369, 'faggorts': 6370, 'aiyo': 6371, 'geegee': 6372, 'aSA': 6373, 'smth': 6374, 'homies': 6375, 'smile': 6376, 'tiene': 6377, 'carrys': 6378, 'regalen': 6379, 'uno': 6380, 'RADIANT': 6381, 'ASD': 6382, 'SADASDASDASD': 6383, 'dupp': 6384, 'WAAAH': 6385, 'COUTNERPICKED': 6386, 'faggots': 6387, 'acount': 6388, '322': 6389, 'bacl': 6390, 'naaaaameeee': 6391, 'iiiiiiiiis': 6392, 'JOOOOOOOOOOOOOOOOOOOOOHN': 6393, 'CEEEEEEEEEEEEEEEEEEEENA': 6394, 'tienes': 6395, 'que': 6396, 'darme': 6397, 'manos': 6398, 'through': 6399, 'snowangel': 6400, 'fuckwits': 6401, 'GIMME': 6402, 'DONDO': 6403, 'ALEREADY': 6404, 'easily': 6405, 'YUP': 6406, 'Sad': 6407, 'bug': 6408, 'yolol': 6409, 'o0ur': 6410, 'tyhrue': 6411, 'assault': 6412, 'sold': 6413, 'map': 6414, 'covered': 6415, 'sentrys': 6416, 'pleases': 6417, 'language': 6418, 'barrier': 6419, 'tutututututut': 6420, 'tutututut': 6421, 'rats': 6422, 'Shhh': 6423, 'plsssss': 6424, 'highground': 6425, 'pucked': 6426, 'refraction': 6427, 'pugnoo': 6428, 'armour': 6429, 'wbahahha': 6430, 'steamroll': 6431, 'classy': 6432, 'clapclap': 6433, 'raqequited': 6434, 'AHAHAHHA': 6435, 'dAMN': 6436, 'lee': 6437, 'accoutn': 6438, 'butters': 6439, 'lothar': 6440, 'EX': 6441, 'DEEE': 6442, 'WORTHIT': 6443, 'Retard': 6444, 'booooooooooooooom': 6445, 'PSUH': 6446, 'SOSI': 6447, 'SOBAKA': 6448, 'Hey': 6449, 'cuck': 6450, 'gfs': 6451, 'banged': 6452, 'different': 6453, 'BUT': 6454, 'XAXAXAXAXAXAXAX': 6455, 'OHWWWWWWWW': 6456, 'Rdy': 6457, 'satanic': 6458, 'lllol': 6459, 'bets': 6460, 'aww': 6461, 'midlane': 6462, 'reportwk': 6463, 'juijked': 6464, 'fixing': 6465, 'bathroom': 6466, 'woods': 6467, 'jupuk': 6468, 'ku': 6469, 'hahahh': 6470, 'agio': 6471, 'Lord': 6472, 'gagos': 6473, 'LINA': 6474, 'WTGF': 6475, 'HeyWk': 6476, 'mistakes': 6477, 'OUTA': 6478, 'yuuo': 6479, 'atlast': 6480, 'PROBKME': 6481, 'mario': 6482, 'lives': 6483, 'alrdy': 6484, 'dei': 6485, '1by': 6486, 'ryt': 6487, 'FACTAS': 6488, 'TERASH': 6489, 'dragged': 6490, 'Their': 6491, 'Offlane': 6492, 'spends': 6493, 'wholle': 6494, 'interrupt': 6495, 'OOOPPPS': 6496, 'crow': 6497, 'ebaty': 6498, 'aaa': 6499, 'SAMUEL': 6500, 'ROKET': 6501, 'introboys': 6502, 'fkcing': 6503, 'WINDRANNER': 6504, 'doint': 6505, 'third': 6506, 'juked': 6507, 'ent': 6508, 'hill': 6509, 'juguer': 6510, 'yuep': 6511, 'H': 6512, 'AH': 6513, 'ha2h2hh2h232h2ha': 6514, 'RYAN': 6515, 'GOULD': 6516, 'businessman': 6517, 'DEVIL': 6518, 'nug': 6519, 'DROW': 6520, 'jajajajja': 6521, '1v2': 6522, 'qweeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee': 6523, 'zzzzzzzzzzzzzzzzzzzzzzzz': 6524, 'slank': 6525, 'BALANAR': 6526, 'japan': 6527, 'nippon': 6528, 'french': 6529, 'beaner': 6530, 'ear': 6531, 'noooooooooooooooooooooooo': 6532, 'entertaining': 6533, 'ogh': 6534, 'broke': 6535, 'wpo': 6536, 'asingle': 6537, 'fihgt': 6538, 'dazle': 6539, 'wonder': 6540, 'ioahd': 6541, 'mmuted': 6542, 'aise': 6543, 'warding': 6544, 'muah': 6545, 'demolished': 6546, 'ivno': 6547, 'lkixo': 6548, 'SURE': 6549, 'ALMOST': 6550, 'WON': 6551, 'itS': 6552, 'COAL': 6553, 'yje': 6554, 'raslabone': 6555, '5:18': 6556, 'fuckyou': 6557, 'battlefield': 6558, 'rek': 6559, 'wsilencer': 6560, 'talo': 6561, 'talga': 6562, 'Bow': 6563, 'Hayo': 6564, 'lold': 6565, 'fvcking': 6566, 'cuirass': 6567, 'wazzup': 6568, 'Hi': 6569, 'Dumb': 6570, 'uy': 6571, 'seem': 6572, 'frist': 6573, 'CAUSE': 6574, 'BAT': 6575, 'shhh': 6576, '3v': 6577, 'cafe': 6578, 'possible': 6579, 'tactic': 6580, 'ultimate': 6581, 'join': 6582, 'purp': 6583, 'OKATY': 6584, '6100': 6585, 'tool': 6586, 'HAHAAHHA': 6587, 'oooooooo': 6588, 'PLAYER': 6589, 'ti6': 6590, 'headshots': 6591, 'cocksucker': 6592, 'alwkawkakw': 6593, 'EL': 6594, 'LISAJ': 6595, 'PARNI': 6596, 'META': 6597, 'NOOBEST': 6598, 'purely': 6599, 'placing': 6600, 'dumbs': 6601, 'trah': 6602, 'england': 6603, 'WOHOOOOOOOOOO': 6604, 'YEAHHHHHHHHHH': 6605, 'misklik': 6606, 'atras': 6607, 'abante': 6608, 'ampota': 6609, 'samuel': 6610, 'Fv': 6611, 'site': 6612, 'anothing': 6613, 'dropping': 6614, 'AXxaxa': 6615, 'XAxaxaxaxaxa': 6616, 'afkk': 6617, 'Learn': 6618, 'astral': 6619, 'BECIAE': 6620, 'FICKONG': 6621, 'RISSOANS': 6622, 'DESERVE': 6623, 'FUCJ': 6624, 'alive': 6625, 'dumpster': 6626, 'rdnt': 6627, 'shoehorn': 6628, 'sups': 6629, 'lixo': 6630, 'okl': 6631, '103': 6632, 'GAMe': 6633, 'hieroglyphics': 6634, 'Little': 6635, 'zzzzzzzzzz': 6636, 'arcane': 6637, 'breez': 6638, 'shape': 6639, 'golum': 6640, 'feeler': 6641, 'iT': 6642, 'hEHE': 6643, 'kiolll': 6644, 'droped': 6645, '2171': 6646, 'fuming': 6647, 'kee': 6648, 'avatar': 6649, 'bor': 6650, 'JUAS': 6651, 'fr': 6652, 'avicii': 6653, 'schwanz': 6654, 'fatfuck': 6655, 'FEEED': 6656, 'lololol': 6657, 'grand': 6658, 'justice': 6659, 'eheh': 6660, 'TRUE': 6661, 'RETARDED': 6662, 'BRAI': 6663, 'hs': 6664, 'dts': 6665, 'issue': 6666, 'gap': 6667, 'closers': 6668, 'kite': 6669, 'poison': 6670, 'questionable': 6671, 'afaik': 6672, 'shoes': 6673, 'haste': 6674, 'general': 6675, 'wowww': 6676, 'dager': 6677, 'phase': 6678, 'rawr': 6679, 'ALchEmiST': 6680, 'ArcAne': 6681, 'BooTS': 6682, 'PLAyer': 6683, '35': 6684, 'DEATH': 6685, 'extend': 6686, 'funniest': 6687, 'compliment': 6688, 'snipers': 6689, 'pRO': 6690, 'ASSASSINATE': 6691, 'KILLELD': 6692, 'gguys': 6693, 'quas': 6694, 'WIND': 6695, 'shiits': 6696, 'salo': 6697, 'cours': 6698, 'talong': 6699, 'wolfie': 6700, 'FUCL': 6701, 'PICKS': 6702, 'GAMES': 6703, 'Delete': 6704, 'dotta': 6705, 'TREE': 6706, 'ebnutii': 6707, 'pudg': 6708, 'coemd': 6709, 'sit': 6710, 'SRY': 6711, '2mid': 6712, 'qoup': 6713, 'noobick': 6714, 'rng': 6715, 'Ill': 6716, 'egm': 6717, 'Spare': 6718, 'LICH': 6719, 'COST': 6720, 'SUPORTS': 6721, 'desolator': 6722, 'GOLD': 6723, 'KREYGASM': 6724, 'HATE': 6725, 'ONE': 6726, '2KMMR': 6727, 'asdf': 6728, 'JAJAJ': 6729, 'YEA': 6730, 'bros': 6731, 'waow': 6732, 'Blya': 6733, 'biomusor': 6734, 'Butterfly': 6735, 'stoping': 6736, 'ibrb': 6737, 'IDIOTSZ': 6738, 'oooooon': 6739, 'wipi': 6740, 'hecho': 6741, 'laughing': 6742, 'JOPJOJOJOJOJ': 6743, 'winrate': 6744, 'racism': 6745, 'fockin': 6746, 'icked': 6747, 'TOIMBSTONE': 6748, 'INVO': 6749, 'copter': 6750, 'nahhhh': 6751, 'psh': 6752, 'outa': 6753, 'bomb': 6754, 'ebd': 6755, 'bhhot': 6756, 'competitive': 6757, 'mira': 6758, 'gamburger': 6759, 'costanza': 6760, 'FARMING': 6761, 'stages': 6762, 'kraken': 6763, 'shell': 6764, 'cross': 6765, 'osing': 6766, 'll': 6767, 'bai': 6768, 'babi': 6769, 'bothering': 6770, 'impressive': 6771, 'wun': 6772, 'brag': 6773, 'diffferent': 6774, 'nevermore': 6775, 'RATHER': 6776, 'smurf': 6777, 'based': 6778, 'unkillable': 6779, 'dorito': 6780, 'bulshit': 6781, 'LMOA': 6782, 'breeze': 6783, 'ro3': 6784, 'plsys': 6785, 'dump': 6786, 'zzzz': 6787, 'ooooh': 6788, 'babies': 6789, 'EXpress': 6790, 'CALL': 6791, 'het': 6792, 'fucken': 6793, 'hoping': 6794, 'lier': 6795, 'bam': 6796, 'CRYYY': 6797, 'allahu': 6798, 'akbar': 6799, 'DONe': 6800, 'randoming': 6801, 'Fasters': 6802, 'PLAYD': 6803, 'ONDE': 6804, 'AUSHDUASD': 6805, 'nabernaut': 6806, 'esasy': 6807, 'repor': 6808, 'tdat': 6809, 'fucekr': 6810, 'ccc': 6811, 'rason': 6812, 'EZY': 6813, 'exyz': 6814, 'oke': 6815, 'keepo': 6816, ':-': 6817, 'pidar': 6818, 'booste': 6819, 'Tiny': 6820, 'Salty': 6821, 'pokemon': 6822, 'hhahha': 6823, 'AHAHAHAH': 6824, 'naah': 6825, 'purchase': 6826, 'heathens': 6827, 'CHURCH': 6828, 'FIND': 6829, 'KILLL': 6830, 'gichiaan': 6831, 'otsukaresama': 6832, 'COMMENDED': 6833, 'moonshard': 6834, 'evasion': 6835, 'staks': 6836, 'FIRST': 6837, 'HIT': 6838, 'BASH': 6839, 'playdoh': 6840, 'prio': 6841, 'blinks': 6842, 'finger': 6843, 'eaisy': 6844, 'legio': 6845, 'slakrk': 6846, 'softly': 6847, 'swisp': 6848, 'denie': 6849, 'VOLVOOOOOOOOOOOOOOOOOOOOOOOOOOO': 6850, 'RUB': 6851, 'predicted': 6852, 'hopefully': 6853, 'able': 6854, 'BCOZ': 6855, 'ITEM': 6856, 'THRASHES': 6857, 'bel': 6858, 'divertito': 6859, 'WOOO': 6860, 'noty': 6861, 'mobile': 6862, 'phon': 6863, 'upset': 6864, 'hue': 6865, 'tang': 6866, 'ina': 6867, 'KKKKKKKKKKKKKKKK': 6868, 'KKKKKKKKKKKKKKKKKKKKK': 6869, 'RAXANDO': 6870, 'reaped': 6871, 'liao': 6872, 'talked': 6873, 'reprpot': 6874, 'emebr': 6875, 'disaster': 6876, 'FCK': 6877, 'atlest': 6878, 'bath': 6879, 'ulting': 6880, 'basher': 6881, 'Joke': 6882, 'creater': 6883, 'creator': 6884, 'mujm': 6885, 'noes': 6886, 'JAKIRO': 6887, 'quellin': 6888, 'gok': 6889, 'absolute': 6890, 'lvoe': 6891, 'yalnext': 6892, 'gtg': 6893, 'qp': 6894, 'ulties': 6895, 'Gay': 6896, 'wand': 6897, 'mark': 6898, 'illuminati': 6899, '727': 6900, 'rag': 6901, 'LLLLLLLLLLLLLL': 6902, 'JAJAJAJAA': 6903, 'tnks': 6904, 'war': 6905, 'doot': 6906, 'cumbag': 6907, 'Isnt': 6908, 'juggerw': 6909, 'rindo': 6910, 'moreee': 6911, 'incapable': 6912, 'woth': 6913, 'catches': 6914, 'suddenly': 6915, 'lifesteal': 6916, 'WHYS': 6917, 'OSEZA': 6918, 'huh': 6919, 'AoE': 6920, 'quik': 6921, 'wit': 6922, 'pleas': 6923, 'osama': 6924, 'binvoker': 6925, 'aiya': 6926, 'catapults': 6927, 'THEFEEDISREA': 6928, 'blames': 6929, 'sakes': 6930, 'currier': 6931, 'shop': 6932, 'waddafaaaak': 6933, 'Spiked': 6934, 'puish': 6935, 'ofawhore': 6936, 'ORAYT': 6937, 'carajo': 6938, 'magnuse': 6939, 'pfff': 6940, 'Try': 6941, 'hards': 6942, 'FACK': 6943, 'dsahdaslkdhwuroeyri32212': 6944, 'AHAHAHAHA': 6945, 'POTA': 6946, 'creamy': 6947, 'lads': 6948, 'bOmBaGhoStDotA': 6949, 'pitty': 6950, 'freefarm': 6951, 'NIGGA': 6952, 'sblade': 6953, 'per': 6954, 'ui': 6955, 'labas': 6956, 'RAPIER': 6957, 'agradecele': 6958, 'ohhhhhh': 6959, 'ahahahahahahhaha': 6960, '10x': 6961, 'kaya': 6962, 'naman': 6963, 'ee': 6964, 'w33': 6965, 'uxaxa': 6966, 'kuro': 6967, 'rtz': 6968, 'cyclone': 6969, '4V5': 6970, 'ebaniy': 6971, 'shas': 6972, 'bi': 6973, 'pati': 6974, 'mmchike': 6975, 'kontr': 6976, 'pikat': 6977, 'storma': 6978, 'sin': 6979, 'blyadi': 6980, 'bedzmozgliy': 6981, 'SAMUELLL': 6982, 'BITC': 6983, 'HRUN': 6984, 'damm': 6985, 'themetric': 6986, 'ree': 6987, 'XAXAXA': 6988, 'agme': 6989, 'sO': 6990, 'whered': 6991, 'reaching': 6992, 'rearm': 6993, 'Want': 6994, 'Com': 6995, 'shorter': 6996, 'ahhahaha': 6997, 'harm': 6998, 'stahp': 6999, 'worked': 7000, 'uderstood': 7001, 'OJOJOJO': 7002, 'sF': 7003, 'FICKS': 7004, '55min': 7005, 'AC': 7006, 'ESTA': 7007, 'scurred': 7008, 'anytime': 7009, 'outplay': 7010, 'appreciate': 7011, 'balanar': 7012, 'bestest': 7013, 'stayd': 7014, 'ahadd': 7015, 'corno': 7016, 'KEEP': 7017, 'umum': 7018, 'thot': 7019, 'board': 7020, 'tipical': 7021, 'contribution': 7022, 'complaining': 7023, 'wellplayed': 7024, 'glyphs': 7025, 'dispersion': 7026, 'musorka': 7027, 'slaty': 7028, 'feels': 7029, 'klnown': 7030, 'passives': 7031, 'PASSIVES': 7032, 'rustard': 7033, 'loko': 7034, 'bos': 7035, 'lo000iising': 7036, '3z': 7037, 'ayylmao': 7038, 'boost': 7039, 'Asdpoijasoidj': 7040, 'quickcast': 7041, 'slot': 7042, 'ale': 7043, 'dayn': 7044, 'battle': 7045, 'highest': 7046, 'mum': 7047, 'awefully': 7048, 'testing': 7049, 'reaction': 7050, 'GRATZ': 7051, 'SOLO': 7052, 'llamas': 7053, 'annoyin': 7054, 'str': 7055, 'WEW': 7056, 'memes': 7057, 'EM': 7058, 'tke': 7059, 'drink': 7060, 'commmmmmmmmmmmmmmmmed': 7061, 'meelee': 7062, 'itqrf': 7063, 'vfvrf': 7064, 'hfr': 7065, 'FAK': 7066, 'perfect': 7067, 'saf': 7068, 'BYe': 7069, 'AIM': 7070, 'frozen': 7071, 'AJAJAJAJA': 7072, 'fore': 7073, 'homeless': 7074, 'intencional': 7075, 'hitting': 7076, 'talent': 7077, 'xuan': 7078, 'dealing': 7079, 'cooking': 7080, 'suggust': 7081, 'mjollnir': 7082, 'tteam': 7083, 'Every': 7084, 'ahev': 7085, 'totaly': 7086, 'fullslotted': 7087, 'wiht': 7088, 'aghanims': 7089, 'gmae': 7090, 'odnt': 7091, 'zzzzzzzzzzzzzzz': 7092, 'May': 7093, 'tabbed': 7094, 'powful': 7095, 'aA': 7096, 'gET': 7097, 'twirling': 7098, 'YY': 7099, 'GTFO': 7100, 'INTERNET': 7101, 'CAFE': 7102, 'dodging': 7103, 'lai': 7104, 'knw': 7105, 'trademark': 7106, 'Wheres': 7107, 'wagaga': 7108, 'closest': 7109, '21': 7110, 'outpick': 7111, 'decay': 7112, 'myslef': 7113, 'discorvered': 7114, 'america': 7115, 'WENT': 7116, 'MIDAS': 7117, 'BUYING': 7118, 'SHITTY': 7119, 'WRONG': 7120, 'waiat': 7121, 'ruins': 7122, 'RANGER': 7123, 'expecting': 7124, 'xdd': 7125, 'Brist': 7126, 'removed': 7127, 'invokeer': 7128, 'skils': 7129, '56': 7130, 'wtrgf': 7131, 'UD': 7132, 'oct': 7133, 'open': 7134, 'wounds': 7135, 'morp': 7136, 'WONt': 7137, 'CARE': 7138, 'drinking': 7139, 'water': 7140, 'chemistry': 7141, 'martha': 7142, 'focker': 7143, 'TKS': 7144, 'Have': 7145, 'Ogre': 7146, 'cri': 7147, 'ENGLISH': 7148, 'PERUVIAN': 7149, 'AHHAHAHAHA': 7150, 'wTF': 7151, 'weather': 7152, 'onli': 7153, 'dup': 7154, 'Lel': 7155, 'PORFAVOR': 7156, 'drian': 7157, '85': 7158, 'thirst': 7159, 'XP': 7160, 'wkowkw': 7161, 'brraainnss': 7162, 'modem': 7163, 'NAMO': 7164, 'Plz': 7165, 'TIRAME': 7166, 'KAKA': 7167, 'NECRO': 7168, 'PUCK': 7169, 'PUEDE': 7170, 'TOCAR': 7171, 'gained': 7172, 'phenix': 7173, 'sm': 7174, 'mairo': 7175, 'wakle': 7176, 'quieres': 7177, 'pene': 7178, 'fcker': 7179, 'EleGiggle': 7180, 'SHOT': 7181, 'CRITS': 7182, 'nooooob': 7183, 'fucj': 7184, 'hahahhaa': 7185, 'reume': 7186, 'mecry': 7187, 'BLOOD': 7188, 'caryr': 7189, 'wods': 7190, 'gez': 7191, 'whiningf': 7192, 'DOG': 7193, 'TCHES': 7194, 'LOSS': 7195, '361': 7196, 'pogle': 7197, 'trax': 7198, 'SAIKIIII': 7199, 'cmnd': 7200, 'kwkwkw': 7201, 'nab': 7202, 'tuskker': 7203, 'Hahha': 7204, 'overwhelming': 7205, 'gaycumback': 7206, 'rent': 7207, 'lazy': 7208, 'reaper': 7209, 'malstrosm': 7210, 'nicea': 7211, 'WINS': 7212, 'ahahhaa': 7213, 'bruz': 7214, 'searing': 7215, 'chains': 7216, 'indifferent': 7217, 'injokeR': 7218, 'DONE': 7219, 'FROM': 7220, 'CAVE': 7221, 'Vs': 7222, 'ranga': 7223, 'grub': 7224, 'annoyed': 7225, 'allhis': 7226, 'unlres': 7227, 'scripts': 7228, 'League': 7229, 'Legends': 7230, 'instant': 7231, 'lp': 7232, 'buter': 7233, 'DAM': 7234, 'yaysayaay': 7235, 'laned': 7236, 'linkens': 7237, 'micro': 7238, '2010': 7239, '5700': 7240, 'unmanner': 7241, 'boob': 7242, ';_:': 7243, 'brb': 7244, 'shoping': 7245, 'aw2': 7246, 'BLOCK': 7247, 'danger': 7248, 'hahahaa': 7249, 'Throw': 7250, '000': 7251, 'camping': 7252, 'OOH': 7253, 'lucan': 7254, 'treads': 7255, '29HP': 7256, 'wepe': 7257, 'Hacker': 7258, 'Tequila': 7259, 'clowns': 7260, 'bj': 7261, 'reinicio': 7262, 'hmh': 7263, 'MASS': 7264, 'gnyt': 7265, 'resmue': 7266, '2e': 7267, 'Although': 7268, 'greece': 7269, 'kka': 7270, 'juke': 7271, 'esos': 7272, 'por': 7273, 'font': 7274, 'slipped': 7275, 'llater': 7276, 'haets': 7277, 'breaks': 7278, 'running': 7279, '3K': 7280, '200deward': 7281, 'hmmm': 7282, 'Meh': 7283, 'ehd': 7284, 'er': 7285, 'Wahaha': 7286, 'frend': 7287, 'minit': 7288, 'otw': 7289, 'morfin': 7290, 'lobster': 7291, 'crits': 7292, 'SUPPORT': 7293, 'bo': 7294, 'spiderman': 7295, 'lolol': 7296, 'whining': 7297, 'unbelivebale': 7298, 'nyc': 7299, 'wtslow': 7300, '1973': 7301, 'egypt': 7302, 'fatty': 7303, '1v9': 7304, '3ple': 7305, 'web': 7306, ':_': 7307, 'hoo': 7308, 'SOLD': 7309, 'download': 7310, 'FUCKINF': 7311, 'w9': 7312, 'trashtalk': 7313, 'yh': 7314, 'strikes': 7315, 'blowed': 7316, 'BOBO': 7317, 'MO': 7318, 'downer': 7319, 'WHURZEN': 7320, 'euro': 7321, 'country': 7322, 'surprise': 7323, 'HAahhaa': 7324, 'schackle': 7325, 'comunnication': 7326, 'scrun': 7327, 'shoulders': 7328, 'disonect': 7329, 'vietnam': 7330, 'putang': 7331, 'HEROES': 7332, 'AUTOEZGAMEW': 7333, 'childhood': 7334, 'baserace': 7335, 'yaya': 7336, 'deF': 7337, 'FOOL': 7338, 'PASUE': 7339, 'pAUSE': 7340, 'PIAST': 7341, 'ACCOUT': 7342, 'shes': 7343, 'favotire': 7344, 'rerport': 7345, 'AHAH': 7346, 'Rec': 7347, 'wuitters': 7348, 'Wt': 7349, 'dreamteam': 7350, 'End2': 7351, 'Too': 7352, 'draft': 7353, 'AAAAA': 7354, 'FASTER': 7355, 'asco': 7356, 'backd00r': 7357, 'rcing': 7358, 'ger': 7359, 'fkin': 7360, 'marahin': 7361, '.': 7362, 'Whatever': 7363, 'Fun': 7364, 'refuses': 7365, 'TP': 7366, 'trading': 7367, 'PMS': 7368, 'KappaPride': 7369, 'midases': 7370, 'aparet': 7371, 'ooops': 7372, 'ricky': 7373, '4K': 7374, 'octarine': 7375, 'rolls': 7376, 'none': 7377, 'BLINKED': 7378, 'HOOKL': 7379, 'dumber': 7380, 'smk': 7381, 'wrd': 7382, 'esports': 7383, 'idid': 7384, 'naxui': 7385, 'isukin': 7386, 'option': 7387, 'fng': 7388, 'ncie': 7389, 'Keepo': 7390, 'HAYS': 7391, 'SENTRY': 7392, 'FWAJHWFHBWFAHBAWFBHWFBHAWF': 7393, 'egege': 7394, 'ching': 7395, 'chang': 7396, 'chongs': 7397, 'Alch': 7398, 'practicalle': 7399, 'TIM': 7400, 'PIECE': 7401, 'KSER': 7402, 'majorino': 7403, 'Zzz': 7404, 'ttimes': 7405, 'againstt': 7406, 'shld': 7407, 'syka': 7408, 'unlucky': 7409, 'fuckingh': 7410, 'Nothin': 7411, 'Gotcha': 7412, 'xa': 7413, 'skdjbfksjdbfk': 7414, ':)0': 7415, '266': 7416, 'MS': 7417, 'REBORN': 7418, 'iomfg': 7419, 'OHHH': 7420, 'FUKENZIO': 7421, 'ripp': 7422, 'remmeber': 7423, 'movie': 7424, 'tracked': 7425, 'earth': 7426, 'Hard': 7427, 'diffusal': 7428, 'sworn': 7429, 'aaaa': 7430, 'hahhahah': 7431, 'pem': 7432, 'nivel': 7433, 'olaaa': 7434, 'lacueeeeek': 7435, '3V5': 7436, '75': 7437, 'skil': 7438, 'except': 7439, 'necrophos': 7440, 'BRUH': 7441, 'in5k': 7442, 'dendi': 7443, 'undiyinh': 7444, 'casting': 7445, 'larvas': 7446, 'sacan': 7447, 'profile': 7448, 'guse': 7449, 'OMFG': 7450, 'LOPL': 7451, 'fid': 7452, 'furry': 7453, 'recorn': 7454, 'AGHS': 7455, 'ANYONE': 7456, 'thy': 7457, 'RESPECT': 7458, 'atitude': 7459, 'Doesn': 7460, 'Weave': 7461, 'synergy': 7462, 'AMed': 7463, 'lolx': 7464, 'jumping': 7465, 'chair': 7466, 'oob': 7467, 'disraprot': 7468, 'NIce': 7469, 'misclick': 7470, 'hai': 7471, 'action': 7472, 'neba': 7473, 'gander': 7474, 'demons': 7475, 'wearing': 7476, 'clean': 7477, 'comunity': 7478, 'whisp': 7479, 'gawn': 7480, 'Neat': 7481, 'SENT': 7482, 'COURI': 7483, 'stong': 7484, 'Ayylotus': 7485, 'GIOVE': 7486, 'BREAK': 7487, 'TT': 7488, 'cimputer': 7489, 'crashing': 7490, 'daaamn': 7491, 'caucasian': 7492, 'representing': 7493, 'races': 7494, 'iditos': 7495, 'shocking': 7496, 'fcken': 7497, 'stewped': 7498, 'refresher': 7499, 'env': 7500, 'hospital': 7501, 'exactly': 7502, 'healing': 7503, 'goteem': 7504, 'wotah': 7505, 'crispy': 7506, 'bothers': 7507, 'GGG': 7508, 'Wasted': 7509, 'team8': 7510, 'Piece': 7511, 'bacan': 7512, 'ion': 7513, 'ENJOYING': 7514, 'HELL': 7515, 'HAHHAHA': 7516, 'loh': 7517, 'trashg': 7518, 'somewhere': 7519, 'HAHHAHAHA': 7520, 'pleease': 7521, 'single': 7522, 'magnius': 7523, 'bastards': 7524, 'unpoused': 7525, 'ment': 7526, 'FAGGOTS': 7527, 'SOLOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO': 7528, 'DUALLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL': 7529, '275': 7530, 'CK': 7531, 'tear': 7532, 'rolling': 7533, 'tears': 7534, 'MIND': 7535, 'Namaste': 7536, 'fucjk': 7537, 'shiva': 7538, 'mek': 7539, 'greaves': 7540, 'vlads': 7541, 'chanses': 7542, 'refresh': 7543, 'giv': 7544, '2500': 7545, 'mepoo': 7546, 'INTROBOYS': 7547, 'diam': 7548, 'bark': 7549, 'fre': 7550, 'dance': 7551, 'HAAHA': 7552, 'counters': 7553, 'OKY': 7554, 'bills': 7555, 'tress': 7556, 'fite': 7557, 'cepet2': 7558, 'di': 7559, 'makan': 7560, 'EALLY': 7561, 'PAKYU': 7562, 'lolk': 7563, 'GBAHA': 7564, 'tip': 7565, ':s': 7566, 'feedeen': 7567, 'nonsense': 7568, 'clueless': 7569, 'raptor': 7570, 'ady': 7571, 'rudee': 7572, 'rotation': 7573, 'orusp': 7574, 'cpcugu': 7575, 'FUCKNG': 7576, 'ZEUS': 7577, 'ahmed': 7578, 'arab': 7579, 'Cuz': 7580, 'commit': 7581, 'sudoku': 7582, 'vote': 7583, 'brutal': 7584, 'Feed': 7585, 'tv': 7586, 'laspelaps': 7587, 'implying': 7588, 'tracks': 7589, 'amulet': 7590, 'equally': 7591, 'conecting': 7592, 'reconnet': 7593, 'WEPE': 7594, 'favor': 7595, 'thrower': 7596, 'together': 7597, 'TALK': 7598, 'favorite': 7599, 'seer': 7600, 'leap': 7601, 'McDonald': 7602, 'fans': 7603, 'stpuid': 7604, 'sentry': 7605, 'plebs': 7606, 'SECPLS': 7607, 'LOLZ': 7608, 'glboys': 7609, 'Awwww': 7610, 'bothrunes': 7611, 'Sodium': 7612, 'Chloride': 7613, 'zoro': 7614, 'FYUCK': 7615, 'walamak': 7616, 'WJAT': 7617, 'bloodseeker': 7618, 'GEEGE': 7619, 'germany': 7620, 'comme': 7621, 'erz': 7622, 'hahha': 7623, 'WUT': 7624, 'sia': 7625, 'Mistake': 7626, 'noooooooooooooooo': 7627, 'HUSKAR': 7628, 'rekted': 7629, 'owned': 7630, 'Fuk': 7631, 'tits': 7632, 'AHGAHA': 7633, 'HZ': 7634, 'gyus': 7635, 'hhaa': 7636, '40min': 7637, '1:30': 7638, 'queue': 7639, 'Minglee': 7640, 'alrd': 7641, 'slar': 7642, '8wins': 7643, 'lyin': 7644, 'mmmmmmmmmmmmmmmmmmmmmmmmmmmohmygod': 7645, 'fukin': 7646, 'burns': 7647, 'EATH': 7648, 'DIVCK': 7649, 'jajajajajaaj': 7650, 'kogut': 7651, 'champ': 7652, 'bogo': 7653, 'ARMOURE': 7654, 'LESS': 7655, 'gorillas': 7656, 'sumwer': 7657, 'poa': 7658, 'WONT': 7659, 'Yolo': 7660, 'OVER': 7661, 'rating': 7662, 'elegiggle': 7663, 'Easiest': 7664, 'hechas': 7665, 'culpa': 7666, 'AGAGA': 7667, 'WW': 7668, 'sorr': 7669, 'Only': 7670, 'alrigfht': 7671, 'VIPER': 7672, 'THUGHT': 7673, 'jew': 7674, 'cw': 7675, 'POO': 7676, 'TIMBER': 7677, 'nmore': 7678, 'hmmmmmmm': 7679, '3min': 7680, 'quitting': 7681, 'suppp': 7682, 'Sshh': 7683, 'olo': 7684, 'haahahaha': 7685, 'ASSHOLES': 7686, 'kraaaaaay': 7687, 'hoenst': 7688, 'MEGA': 7689, 'MMRMRR': 7690, 'tilting': 7691, 'talaga': 7692, 'eyes': 7693, 'past': 7694, 'bull': 7695, 'messi': 7696, 'tahaha': 7697, 'date': 7698, 'bruhh': 7699, 'ald': 7700, 'amk': 7701, 'regard': 7702, 'jukt': 7703, 'hanged': 7704, 'PERRUUUUUUU': 7705, 'ffed': 7706, 'noT': 7707, 'WODDEN': 7708, '5minutes': 7709, 'bx': 7710, 'DW': 7711, 'CUT': 7712, 'PART': 7713, 'HHAHA': 7714, 'incompetent': 7715, 'nothin': 7716, 'HAAHAHAHA': 7717, 'hihg': 7718, 'stress': 7719, 'condom': 7720, 'dno': 7721, 'saatnic': 7722, 'feeDER': 7723, 'TOLOL': 7724, 'jut': 7725, 'ukltimate': 7726, 'ok2': 7727, 'FUICKING': 7728, 'NET': 7729, 'bye2x': 7730, 'wated': 7731, 'LOOOOOOOOOOOOOOOOOL': 7732, 'DAUNI': 7733, 'SUKA': 7734, 'yey': 7735, 'OYOYOYOYOY': 7736, 'recent': 7737, 'matches': 7738, 'COme': 7739, 'nao': 7740, 'dele': 7741, 'abbandons': 7742, 'admit': 7743, 'blamming': 7744, 'Gee': 7745, 'LEAP': 7746, 'MUTHAFACKA': 7747, 'logging': 7748, 'fellow': 7749, ':;': 7750, 'alsdasd': 7751, 'qweqwe': 7752, 'saved': 7753, 'lifes': 7754, 'SAVED': 7755, 'lapo': 7756, 'diwali': 7757, 'fakkkkkkkkk': 7758, 'cfg': 7759, 'activated': 7760, '43': 7761, 'defnd': 7762, 'uask': 7763, 'dEF': 7764, 'MOTHER': 7765, 'FUCKERS': 7766, 'putins': 7767, 'SUCH': 7768, 'WEIGH': 7769, 'MIRANA': 7770, 'TBH': 7771, 'RUSSIA': 7772, 'SERVER': 7773, 'SAKES': 7774, 'ddoss': 7775, 'ddosi': 7776, 'loves': 7777, 'suiciding': 7778, 'rite': 7779, 'ahhahaa': 7780, 'MEEEE': 7781, 'AJJAJAJ': 7782, 'SATANIC': 7783, 'SOY': 7784, 'COMO': 7785, 'AL': 7786, 'RETRASADO': 7787, 'ARCANA': 7788, 'EE': 7789, 'PLAYS': 7790, 'KAPPA': 7791, 'RUSS': 7792, 'DENDI': 7793, 'Brood': 7794, 'refill': 7795, 'Wrong': 7796, 'teamkilled': 7797, 'silancer': 7798, 'domestics': 7799, 'missclicked': 7800, 'CAME': 7801, 'necto': 7802, 'likens': 7803, 'asad': 7804, 'lioch': 7805, '30mins': 7806, 'river': 7807, 'leaveing': 7808, 'imagine': 7809, 'ims': 7810, 'erious': 7811, 'TALKING': 7812, 'RAPED': 7813, 'KKG': 7814, 'KANTOT': 7815, 'GIRL': 7816, 'yawn': 7817, 'JSUT': 7818, 'MATTER': 7819, 'MONEY': 7820, 'Dick': 7821, 'shto': 7822, 'GGGGGGGGGGGGGGG': 7823, 'melbourne': 7824, 'kfc': 7825, 'Awer': 7826, 'kw': 7827, 'agreee': 7828, 'QUED': 7829, 'PERFECTLY': 7830, 'TIMED': 7831, 'ROBOT': 7832, 'LGA': 7833, 'tru': 7834, 'cmere': 7835, 'ahahahahha': 7836, 'dfc': 7837, 'bvbr': 7838, 'yektdsq': 7839, 'hdtn': 7840, 'esse': 7841, 'figueiredo': 7842, 'filho': 7843, 'puta': 7844, 'POPAl': 7845, 'reporspec': 7846, 'gbarrel': 7847, 'swaggy': 7848, 'Luck': 7849, 'basted': 7850, 'easerion': 7851, 'firstbloodion': 7852, '1vs5': 7853, 'reach': 7854, 'Grammar': 7855, 'nazi': 7856, 'hail': 7857, 'cmd': 7858, 'WPWP': 7859, 'babes': 7860, 'shoppin': 7861, 'toss': 7862, 'st': 7863, 'omnislash': 7864, 'eaeaea': 7865, 'playin': 7866, 'slARK': 7867, 'rETK': 7868, 'WOAH': 7869, 'ahhaah': 7870, 'blank': 7871, 'claimed': 7872, 'lied': 7873, 'kabobobo': 7874, 'nyu': 7875, '4x': 7876, 'FVCK': 7877, 'fught': 7878, 'BEAST': 7879, 'MODE': 7880, 'trapp': 7881, 'accept': 7882, 'offering': 7883, 'FUK': 7884, 'gona': 7885, 'toos': 7886, 'tooos': 7887, 'PROFILE': 7888, 'sometimes': 7889, 'SD': 7890, 'lvl7': 7891, 'pudga': 7892, '30minutes': 7893, 'WUDLVE': 7894, 'WHILE': 7895, 'thatswhy': 7896, '938': 7897, 'attacks': 7898, 'plox': 7899, 'TOOK': 7900, 'UDY': 7901, 'MOTHERFUCKERS': 7902, 'SUCKERS': 7903, 'uilt': 7904, 'EnD': 7905, 'husker': 7906, 'battlefury': 7907, 'karam': 7908, 'sounds': 7909, 'animal': 7910, 'botz': 7911, 'spender': 7912, 'penetrate': 7913, 'wao': 7914, 'HURT': 7915, 'Save': 7916, 'summail': 7917, 'puc': 7918, 'wlwlwlwllww': 7919, 'torso': 7920, 'tipu': 7921, 'gua': 7922, 'Expects': 7923, 'ajajja': 7924, 'yum': 7925, 'wkwkwkwkw': 7926, 'playstlye': 7927, 'dollar': 7928, 'SORY': 7929, 'heuheu': 7930, 'hour': 7931, 'brains': 7932, 'photo': 7933, '10pm': 7934, 'vieja': 7935, 'ratas': 7936, 'wp2': 7937, 'gget': 7938, '6350': 7939, 'hwats': 7940, 'dogs': 7941, 'jokeing': 7942, 'unskilled': 7943, 'proved': 7944, 'africa': 7945, 'dotacinema': 7946, 'ONEEE': 7947, 'polaying': 7948, 'answer': 7949, 'bae': 7950, '0ward': 7951, 'sexally': 7952, 'HELP': 7953, 'INSTEAD': 7954, 'KILLING': 7955, 'mtoher': 7956, 'finsih': 7957, 'obvusly': 7958, 'actual': 7959, 'okej': 7960, 'breezzy': 7961, 'RECON': 7962, 'freely': 7963, 'througfh': 7964, 'entire': 7965, 'strategy': 7966, 'brought': 7967, 'aazazazazaza': 7968, 'EARLY': 7969, 'XDXDXD': 7970, 'chong': 7971, 'Gotta': 7972, 'gents': 7973, 'WEX': 7974, 'chiil': 7975, 'AAAAAA': 7976, 'Jungle': 7977, 'Never': 7978, 'nko': 7979, 'kinards': 7980, 'boshit': 7981, 'QA': 7982, 'Cum': 7983, 'katsamba': 7984, 'ramo': 7985, 'aslong': 7986, 'AKA': 7987, 'tellin': 7988, 'muna': 7989, 'ezflex': 7990, 'HONW': 7991, 'reset': 7992, 'ahaaha': 7993, 'krits': 7994, 'slovakia': 7995, 'krch': 7996, 'derma': 7997, 'zaruinil': 7998, 'THOSE': 7999, '959': 8000, 'CYKA': 8001, 'BLYUAT': 8002, 'Hah': 8003, 'xdddddddd': 8004, 'YAh': 8005, 'ngon': 8006, 'dammn': 8007, 'OO': 8008, 'IC': 8009, '242': 8010, 'lssing': 8011, 'dayyyuum': 8012, 'stron': 8013, 'ajajajja': 8014, 'prediction': 8015, 'DISASTAH': 8016, 'FED': 8017, 'lagged': 8018, \":'\": 8019, 'heros': 8020, 'Riki': 8021, 'ults': 8022, 'BRAT': 8023, 'thousand': 8024, 'qued': 8025, 'figured': 8026, 'EG': 8027, 'UNIVERSE': 8028, 'RTZ': 8029, 'SUMAIL': 8030, 'PPD': 8031, 'FEAR': 8032, 'EACH': 8033, 'CONTROL': 8034, 'LIMB': 8035, 'USING': 8036, 'HEAD': 8037, 'minets': 8038, 'ahve': 8039, 'delate': 8040, 'sm1': 8041, 'EARTH': 8042, 'SPIRIT': 8043, ':0': 8044, 'hahahahhaha': 8045, 'DIEBACK': 8046, 'ddint': 8047, 'alchje': 8048, 'betrayed': 8049, 'unpauser': 8050, 'TEVAS': 8051, 'CON': 8052, 'MIGO': 8053, 'affect': 8054, 'morality': 8055, 'ghots': 8056, 'Tony': 8057, 'Locket': 8058, '119': 8059, 'complex': 8060, 'getem': 8061, 'stlark': 8062, 'AHHHH': 8063, 'ihave': 8064, 'EXAM': 8065, 'GRAMMAR': 8066, 'Di': 8067, 'bagay': 8068, 'rikii': 8069, 'br': 8070, '8kmmr': 8071, 'midl': 8072, '00100': 8073, 'motherfucking': 8074, 'witch': 8075, 'wub': 8076, 'Lag': 8077, 'fuark': 8078, 'RULE': 8079, 'BLABLABLA': 8080, 'RULLER': 8081, 'FUE': 8082, 'GGGGGGGGGGGGGGGGGGGGGGG': 8083, 'pasue': 8084, 'ruinE': 8085, 'sonic': 8086, 'ahahahaah': 8087, 'Meme': 8088, 'abse': 8089, 'When': 8090, '2x3': 8091, 'alo': 8092, 'ebanat': 8093, 'mormo': 8094, 'felt': 8095, 'sek': 8096, 'pyzdec': 8097, 'ueless': 8098, 'waut': 8099, '49': 8100, '48': 8101, 'deleted': 8102, 'banned': 8103, 'ANTIGAY': 8104, 'xaaxx': 8105, 'sg': 8106, 'yuoyu': 8107, 'kidiing': 8108, 'bodyguard': 8109, 'small': 8110, 'KITER': 8111, 'AUTOLOSE': 8112, 'flaw': 8113, 'ang': 8114, 'beware': 8115, 'streka': 8116, 'handicap': 8117, 'hv': 8118, 'rong': 8119, 'etc': 8120, 'suffered': 8121, 'hahahahha': 8122, 'Kapaa': 8123, 'bahahahah': 8124, 'warddd': 8125, 'hagaga': 8126, 'windranger': 8127, 'wowowowo': 8128, 'mous': 8129, 'twq': 8130, 'soooooooooooooooo': 8131, 'sending': 8132, 'sms': 8133, 'owns': 8134, 'mage': 8135, 'dosnt': 8136, 'oyoy': 8137, 'overheated': 8138, 'lob': 8139, 'yeaaaah': 8140, '3x': 8141, 'jg': 8142, 'everywhere': 8143, 'idioto': 8144, 'Ta': 8145, ':slaty': 8146, 'standard': 8147, 'share': 8148, 'handing': 8149, 'behave': 8150, 'bluffing': 8151, 'hehje': 8152, 'oiut': 8153, 'lol7': 8154, 'huauha': 8155, 'leagueoflegends': 8156, 'register': 8157, 'filipinop': 8158, 'Come': 8159, '1vs': 8160, 'salita': 8161, 'BuyBAck': 8162, 'THanks': 8163, 'Mmr': 8164, 'tASTy': 8165, 'accbuyers': 8166, '1.': 8167, 'autoattack': 8168, 'PICKERS': 8169, 'aahhaha': 8170, 'blow': 8171, 'soup': 8172, 'deserv': 8173, 'inc': 8174, 'FLYING': 8175, 'uck': 8176, 'aahahhahahah': 8177, 'tetris': 8178, 'HIJOS': 8179, 'DEPUTA': 8180, 'seeing': 8181, 'comin': 8182, 'Batrider': 8183, 'CHE': 8184, 'KAK': 8185, 'TAM': 8186, 'ZOMBI': 8187, 'roamer': 8188, 'hellooooo': 8189, 'ooopss': 8190, 'terror': 8191, 'maidan': 8192, 'midd': 8193, 'Woah': 8194, 'noticed': 8195, '=gg': 8196, 'tbelieve': 8197, 'Wr': 8198, 'fegget': 8199, 'dcp': 8200, 'staralsya': 8201, 'haahahah': 8202, 'profesional': 8203, 'BITCHES': 8204, 'WOOOOP': 8205, 'JAHAHAHA': 8206, 'THat': 8207, 'mids': 8208, 'skills': 8209, 'ench': 8210, 'ehh': 8211, 'ULTRA': 8212, '213': 8213, 'craggt': 8214, ':@': 8215, 'thru': 8216, 'HUSKA': 8217, 'Gyro': 8218, 'Weirdest': 8219, 'PHOENIX': 8220, 'shameless': 8221, 'iidot': 8222, '2non': 8223, 'beforehand': 8224, 'focusing': 8225, 'arm': 8226, 'combackl': 8227, 'dove': 8228, 'Gang': 8229, 'bang': 8230, 'porblem': 8231, 'arryin': 8232, 'carryin': 8233, 'mexican': 8234, 'CHOP': 8235, 'HS': 8236, 'tini': 8237, 'awwwww': 8238, 'yourselves': 8239, 'tink': 8240, 'wole': 8241, 'Cocky': 8242, 'inboker': 8243, 'duneo': 8244, 'valcano': 8245, 'trend': 8246, 'dollars': 8247, 'palyed': 8248, 'murica': 8249, 'Intro': 8250, 'malay': 8251, 'sooo': 8252, 'wintendo': 8253, 'PICKING': 8254, 'RUGAL': 8255, 'totally': 8256, 'AWAY': 8257, 'major': 8258, 'scientist': 8259, 'figure': 8260, 'ignorant': 8261, 'ENJOY': 8262, 'TRASHCAN': 8263, 'PICKER': 8264, 'BOSY': 8265, 'pahaha': 8266, 'handling': 8267, 'diiot': 8268, 'mib': 8269, 'calls': 8270, 'distance': 8271, 'picking': 8272, 'reached': 8273, 'rerpot': 8274, 'fri': 8275, 'somthing': 8276, 'lack': 8277, 'education': 8278, 'irrelievant': 8279, 'dslmdlas': 8280, 'HYAHA': 8281, 'spoiler': 8282, 'PLESAE': 8283, 'unless': 8284, 'horn': 8285, 'chese': 8286, 'aprty': 8287, 'ggggggggggggggggggggggggggggg': 8288, 'swapping': 8289, 'GAIS': 8290, 'secure': 8291, 'yeahb': 8292, 'HAHAHAHAHAAHAHAHAHAHA': 8293, 'iyak': 8294, 'nxt': 8295, '8kg': 8296, 'germans': 8297, 'bleat': 8298, 'PAK': 8299, 'werent': 8300, 'DAAAZEHL': 8301, 'evne': 8302, 'causer': 8303, 'POWER': 8304, 'effigy': 8305, 'lanjiao': 8306, 'somevont': 8307, 'Techis': 8308, 'awtx': 8309, 'SCARE': 8310, 'fuckwit': 8311, 'daaaamn': 8312, 'provoking': 8313, 'sereiously': 8314, 'cmap': 8315, 'CHASE': 8316, 'knnow': 8317, 'smhall': 8318, 'Fuckin': 8319, 'hilariously': 8320, 'GODLIKE': 8321, 'yalll': 8322, 'una': 8323, 'misha': 8324, 'intence': 8325, 'eaaaaaaaaaaaaaaaaaasy': 8326, '3v1': 8327, 'AHAHAHAAHAHA': 8328, 'c0meback': 8329, 'noo': 8330, 'ilencer': 8331, 'fkboi': 8332, 'EERROOOOOY': 8333, 'toon': 8334, 'unpausers': 8335, 'mongoloid': 8336, 'Bs': 8337, 'nwx': 8338, 'leaved': 8339, '130cannot': 8340, 'geeeeeeeeeegeeeeeeeeeeeeeeeeee': 8341, '2008': 8342, 'payuse': 8343, 'chupadmela': 8344, 'JUMP': 8345, 'ltr': 8346, 'woaw': 8347, '1150': 8348, 'chorno': 8349, 'far': 8350, 'shhihtter': 8351, 'helped': 8352, 'alot': 8353, 'axaxax': 8354, 'HOPING': 8355, 'pobre': 8356, 'lloron': 8357, 'sadly': 8358, 'Better': 8359, 'NONONONONO': 8360, '4v1': 8361, 'GAYS': 8362, 'leT': 8363, 'waaahahahahaaha': 8364, 'neutrals': 8365, 'JST': 8366, 'search': 8367, 'recked': 8368, 'Afl': 8369, 'habit': 8370, 'commen': 8371, 'jay': 8372, 'feet': 8373, 'adadas': 8374, 'scouting': 8375, 'yelling': 8376, 'yeling': 8377, 'iten': 8378, 'thnqq': 8379, 'DEADS': 8380, 'yeha': 8381, 'foru': 8382, 'Fantatsic': 8383, 'alchesa': 8384, 'replay': 8385, 'jguger': 8386, 'glitch': 8387, 'lighning': 8388, 'ball': 8389, 'catcher': 8390, 'macro': 8391, 'EUUUUUUUUUUUUUUUROPPPPPPPPPEEEEEEEEEEEEEEEEEEEEEEEEEEEE': 8392, 'boyssssss': 8393, 'junkie': 8394, 'pudghe': 8395, 'meaning': 8396, 'SONS': 8397, 'gracefully': 8398, 'msged': 8399, 'hahahhahah': 8400, '2es4us': 8401, 'itshis': 8402, 'stunned': 8403, 'arrowed': 8404, 'abt': 8405, 'HOUSE': 8406, 'SHAREING': 8407, 'pussys': 8408, 'encouragement': 8409, '102': 8410, 'ghad': 8411, 'teamate': 8412, 'hat': 8413, 'banging': 8414, 'girlfriend': 8415, 'ALl': 8416, 'sbv': 8417, 'actualizacion': 8418, 'va': 8419, 'demorar': 8420, '352': 8421, 'gb': 8422, 'diga': 8423, 'creo': 8424, 'entre': 8425, 'rapido': 8426, 'Shutup': 8427, 'rEALLY': 8428, 'SHHH': 8429, 'illeagle': 8430, 'safely': 8431, 'bumhole': 8432, 'FLAME': 8433, '6mid': 8434, 'ABA': 8435, 'hehehehe': 8436, 'kil': 8437, 'huy': 8438, 'sosnesh': 8439, 'ants': 8440, 'pre': 8441, 'DENY': 8442, 'neutral': 8443, 'Ahhh': 8444, 'Btw': 8445, 'NONE': 8446, 'kpd': 8447, 'shakere': 8448, 'igraew': 8449, 'drug': 8450, 'briezi': 8451, 'DOTACINEMA': 8452, 'abusing': 8453, 'insulte': 8454, 'letz': 8455, 'ermm': 8456, 'Zzzzzzzzzzz': 8457, 'razes': 8458, 'dotaing': 8459, 'caryy': 8460, 'FRESH': 8461, 'MEAT': 8462, 'beside': 8463, 'necrophile': 8464, 'wahahahhahaa': 8465, 'NOOBSSSSS': 8466, 'PUB': 8467, 'GAMMER': 8468, 'comm': 8469, 'haahahahha': 8470, 'fae': 8471, 'das': 8472, 'estrelas': 8473, 'GLFHF': 8474, 'oghhh': 8475, 'Act': 8476, 'lmai': 8477, 'uiCK': 8478, 'cuh': 8479, 'gagagaga': 8480, 'WC': 8481, 'HelenaLive': 8482, 'LOVER': 8483, 'ary': 8484, 'nowaday': 8485, 'thoiught': 8486, 'wer': 8487, 'havnt': 8488, 'friendship': 8489, 'Hahhaha': 8490, 'spooky': 8491, 'INPLAY': 8492, 'STACK': 8493, 'HAAHAHHAA': 8494, '5vs4': 8495, 'GAYYYYYYYYY': 8496, 'wll': 8497, 'traxes': 8498, 'wi': 8499, 'couse': 8500, 'reinstall': 8501, 'refreshed': 8502, 'offlaners': 8503, '500h': 8504, 'YOu': 8505, 'soonTM': 8506, 'disease': 8507, 'comeon': 8508, 'sohuld': 8509, '8min': 8510, 'shake': 8511, 'geeeeeeeeeeeeeeeeeee': 8512, 'geeeeeeeeeeeeeeeeeeeeeeeee': 8513, 'jerk': 8514, 'store': 8515, 'spin': 8516, 'bottles': 8517, 'Mmm': 8518, 'Windrunner': 8519, 'pliz': 8520, 'refrac': 8521, 'ezist': 8522, 'sprout': 8523, 'tanky': 8524, 'platemail': 8525, 'BLAMEE': 8526, 'vepe': 8527, 'tinyyyy': 8528, 'cozuld': 8529, 'crited': 8530, 'intentional': 8531, 'SINGLE': 8532, 'ASTRAR': 8533, 'zica': 8534, 'ahhhhhhhh': 8535, 'nowadays': 8536, 'Arent': 8537, 'vahahaha': 8538, 'leat': 8539, 'THISGAME': 8540, 'roshing': 8541, 'aggresif': 8542, 'Watta': 8543, 'edn': 8544, 'unpaybale': 8545, 'any1': 8546, 'elad': 8547, 'ALAHU': 8548, 'AKBAR': 8549, 'halp': 8550, 'buback': 8551, 'hwo': 8552, 'liv': 8553, 'midle': 8554, 'afrer': 8555, 'MEMEK': 8556, 'shallwe': 8557, 'bahaha': 8558, 'FRE': 8559, 'ENJOUY': 8560, 'WINter': 8561, '4Head': 8562, 'PJSalt': 8563, 'punishes': 8564, 'beggining': 8565, 'EVERTIEM': 8566, 'My': 8567, 'yell': 8568, 'freidn': 8569, 'RAPIRAA': 8570, 'farm2': 8571, 'til': 8572, 'huehue': 8573, 'Rekt': 8574, 'cahging': 8575, 'gameplay': 8576, 'Crit': 8577, 'reddit': 8578, 'waw': 8579, 'coffee': 8580, 'hoiw': 8581, 'link': 8582, 'starving': 8583, 'waya': 8584, 'wud': 8585, 'doctor': 8586, 'wpgg': 8587, 'wbu': 8588, 'cactuses': 8589, 'KNOWING': 8590, 'WORSE': 8591, 'odin': 8592, 'ohuennee': 8593, 'drugogo': 8594, 'TRYING': 8595, 'Dedz': 8596, 'DAUN': 8597, 'course': 8598, 'leart': 8599, 'BULDOG': 8600, 'nekked': 8601, 'blowjob': 8602, 'basmati': 8603, 'rice': 8604, 'heaven': 8605, 'minglee': 8606, 'european': 8607, '2x': 8608, 'Ignore': 8609, 'kitten': 8610, 'agressive': 8611, 'cancers': 8612, 'carai': 8613, 'vc': 8614, 'soh': 8615, 'crita': 8616, 'jogar': 8617, 'nagga': 8618, 'ULOL': 8619, 'thoght': 8620, 'tenkz': 8621, ':Q': 8622, 'wivern': 8623, 'neck': 8624, 'myself': 8625, 'DAGGER': 8626, 'clicking': 8627, 'unclickable': 8628, 'accounts': 8629, 'verde': 8630, 'burdenb': 8631, 'moves': 8632, 'ethan': 8633, 'BFury': 8634, 'Silver': 8635, 'Edge': 8636, 'drgaon': 8637, 'soul': 8638, 'ring': 8639, 'runs': 8640, 'desease': 8641, 'coment': 8642, 't0': 8643, 'ahhh': 8644, 'okie': 8645, 'russtard': 8646, 'nbooob': 8647, 'ort': 8648, 'thigns': 8649, 'dumbest': 8650, 'broser': 8651, 'daaaaaaa': 8652, 'MOFOZ': 8653, 'combine': 8654, '42': 8655, 'uphill': 8656, 'LITERALLY': 8657, 'WARDING': 8658, 'HELPING': 8659, 'kawo': 8660, 'kaw': 8661, 'CHTO': 8662, 'mahhhhhhhhhhhhhhhhhhhhhhhh': 8663, 'reatd': 8664, 'ussles': 8665, '900': 8666, 'REPOR': 8667, 'proves': 8668, 'On': 8669, 'IQ': 8670, 'Hayz': 8671, 'silento': 8672, 'honest': 8673, 'emnd': 8674, 'mortred': 8675, 'CLIFF': 8676, 'CLIFFS': 8677, 'AF': 8678, 'COMBO': 8679, 'pakyu': 8680, 'selg': 8681, 'aoxaoxaoxaoao': 8682, 'tumbaron': 8683, 'todo': 8684, 'tsambahero': 8685, 'heee': 8686, 'hoy': 8687, 'HIGHHHHHH': 8688, 'pair': 8689, 'yeezys': 8690, 'talkinga': 8691, 'kyxy': 8692, 'KYXY': 8693, 'scratched': 8694, 'gary': 8695, 'clark': 8696, 'quiter': 8697, 'knos': 8698, 'nt': 8699, 'craptastic': 8700, 'akowokwakoawo': 8701, 'ault': 8702, 'ggnore': 8703, 'easyx': 8704, 'diving': 8705, 'Cac': 8706, 'co': 8707, 'thay': 8708, 'soi': 8709, 'dong': 8710, 'fEED': 8711, 'fuman': 8712, 'MOAR': 8713, 'keeper': 8714, 'wop': 8715, 'horns': 8716, 'therefore': 8717, 'BM': 8718, 'DRUM': 8719, 'UNPAUSING': 8720, 'wake': 8721, 'sos': 8722, 'SADEST': 8723, 'boyus': 8724, '3pl': 8725, 'pressing': 8726, 'Lyin': 8727, 'VENGE': 8728, 'chrnoo': 8729, 'hgrsoiuherjs': 8730, 'haahaha': 8731, 'cut': 8732, 'MOTHERFUCKER': 8733, 'Hahhahaha': 8734, 'aadu': 8735, 'Was': 8736, 'butuh': 8737, 'BAIA': 8738, 'douche': 8739, 'AKSDAKJDSJKASKDJA': 8740, 'speccccccc': 8741, 'alredy': 8742, 'greenm': 8743, 'FORGET': 8744, 'DAMN': 8745, 'meatballs': 8746, 'Shit': 8747, 'NOM': 8748, 'whenever': 8749, 'fairly': 8750, 'jhahaha': 8751, 'spectr': 8752, 'cancel': 8753, 'hehez': 8754, 'violado': 8755, 'porra': 8756, 'perdi': 8757, 'nessa': 8758, 'semana': 8759, 'kkkkkkkkk': 8760, 'whahahaha': 8761, 'Deluxe': 8762, 'Pony': 8763, 'mushi': 8764, 'gor': 8765, 'catchy': 8766, 'Tacos': 8767, 'wooho': 8768, 'edi': 8769, 'somali': 8770, 'robbing': 8771, 'SUPORT': 8772, 'tunnel': 8773, 'gayer': 8774, 'secrets': 8775, 'reference': 8776, 'PENIS': 8777, 'ufhm': 8778, 'ERAL': 8779, 'DASjklpfsegscg': 8780, 'FKINNNNNNNNN': 8781, 'MEDUSAAAAAA': 8782, 'fjuck': 8783, 'uuuuuu': 8784, 'Log': 8785, 'smg': 8786, 'scrublord': 8787, 'dela': 8788, 'boii': 8789, 'repoc': 8790, 'MORON': 8791, 'PHASE': 8792, 'BOOT': 8793, 'ghhahhaha': 8794, 'WPO': 8795, 'BADLY': 8796, 'DONEE': 8797, 'loooooolll': 8798, 'fcukin': 8799, 'retared': 8800, 'waaaaaaa': 8801, 'EFFOR': 8802, 'kingg': 8803, 'BAR': 8804, 'workin': 8805, 'OGRE': 8806, 'AAAAAAAAAAAAAAAAAA': 8807, 'DIIIICKKKK': 8808, 'isso': 8809, 'SHET': 8810, 'HAPPENED': 8811, 'EXPLAIN': 8812, 'nenado': 8813, 'HERRREEEE': 8814, 'EZZ': 8815, 'grandmother': 8816, 'rubbick': 8817, 'pasie': 8818, 'benjaz': 8819, 'undyingpicker': 8820, '999': 8821, 'RAPE': 8822, 'unp': 8823, 'THRONE': 8824, 'hei': 8825, 'believes': 8826, 'thgis': 8827, 'sadist': 8828, 'CD': 8829, 'lalalala': 8830, 'moment': 8831, 'vuz': 8832, 'cho': 8833, 'nhanh': 8834, 'yebok': 8835, 'wirht': 8836, 'ally': 8837, 'therer': 8838, 'bootcamping': 8839, 'nooooo': 8840, 'slvrdota': 8841, 'Finish': 8842, 'dear': 8843, 'yer': 8844, 'overplay': 8845, 'hahahhahahaha': 8846, 'unlimited': 8847, 'bombs': 8848, 'lewl': 8849, 'youknow': 8850, 'express': 8851, 'mysefl': 8852, 'disra': 8853, 'prior': 8854, 'recotnra': 8855, 'ese': 8856, 'pelase': 8857, 'mierda': 8858, 'century': 8859, 'ahahayeah': 8860, 'james': 8861, 'aHI': 8862, 'FUCVK': 8863, 'likes': 8864, 'brazzers': 8865, 'lifted': 8866, 'policy': 8867, 'EZZZZZZ': 8868, 'tame': 8869, 'JAJAJA': 8870, 'buld': 8871, 'mortal': 8872, 'kombat': 8873, 'mile': 8874, 'CLOKC': 8875, 'cape': 8876, 'grandpa': 8877, 'chicken': 8878, 'haduken': 8879, 'COLD': 8880, 'SNAP': 8881, 'screaming': 8882, 'mic': 8883, 'screw': 8884, 'runa': 8885, 'gente': 8886, '3miss': 8887, 'leeching': 8888, 'xp': 8889, 'patetic': 8890, 'HAI': 8891, 'CAO': 8892, 'NI': 8893, 'LAPSAP': 8894, 'funnik': 8895, '15y': 8896, 'elses': 8897, '5)': 8898, 'elvinskin': 8899, 'ut': 8900, 'ena': 8901, 'Frere': 8902, 'beaten': 8903, 'hacks': 8904, 'Plot': 8905, 'twist': 8906, 'Huskar': 8907, 'himself': 8908, 'alyway': 8909, 'jungles': 8910, 'Slam': 8911, 'dunk': 8912, 'GGWo': 8913, 'threw': 8914, 'GREEN': 8915, 'DORITO': 8916, 'HURTS': 8917, 'MUST': 8918, 'CLICK': 8919, 'pendejo': 8920, 'prepare': 8921, 'pussyh': 8922, '71': 8923, '2000': 8924, 'fagate': 8925, 'tin': 8926, 'poutsa': 8927, 'tryed': 8928, 'dombshit': 8929, 'detection': 8930, 'menya': 8931, 'iskal': 8932, 'xx': 8933, 'mfs': 8934, 'donger': 8935, 'okidoki': 8936, ':::::::::::::::::::::::::::)': 8937, 'teh': 8938, 'worrying': 8939, 'thanking': 8940, 'wot': 8941, 'special': 8942, 'uuseless': 8943, 'stopd': 8944, 'carrubick': 8945, 'DIFUSAL': 8946, 'goblack': 8947, 'BOSS': 8948, 'CALLS': 8949, 'ro': 8950, 'dedication': 8951, 'sjwsahashbas': 8952, 'HAAHHA': 8953, 'predick': 8954, 'DIe': 8955, 'surrender': 8956, 'nu': 8957, 'fcku': 8958, 'rewtar': 8959, 'cram': 8960, 'eg': 8961, 'settled': 8962, 'euw': 8963, 'white': 8964, 'meat': 8965, 'tasty': 8966, 'sooking': 8967, 'Sucker': 8968, 'ahhahahahaha': 8969, 'swimm': 8970, 'Cw': 8971, 'yeye': 8972, 'Sven': 8973, 'jaajja': 8974, 'carl': 8975, 'wtrf': 8976, 'sss': 8977, 'asquitos': 8978, 'Idiot': 8979, 'abadon': 8980, 'plahing': 8981, 'phonix': 8982, 'baboons': 8983, 'lsoe': 8984, 'PIDARAS': 8985, 'judge': 8986, 'hahahahahhahaa': 8987, 'uyes': 8988, 'lagggggggggggggggggggggggggggggggggggggggggggggggggg': 8989, '70': 8990, 'partY': 8991, 'conneccting': 8992, 'yyyyyyy': 8993, 'commends': 8994, 'MEET': 8995, 'LENCER': 8996, 'mages': 8997, 'MASAYOSHI': 8998, 'MIDDLE': 8999, 'GANK': 9000, 'uu': 9001, 'lkala': 9002, 'coco': 9003, 'brewmaster': 9004, 'light': 9005, 'fuckiig': 9006, 'cucumbertube': 9007, 'aLL': 9008, 'mnt': 9009, 'fatter': 9010, 'Legion': 9011, 'Kill': 9012, 'Plox': 9013, 'Nope': 9014, 'cheeckt': 9015, 'Ahahahah': 9016, 'zel': 9017, 'struggling': 9018, 'luchshii': 9019, 'THEM': 9020, 'NOTHING': 9021, 'EVERYTHING': 9022, 'chinks': 9023, 'toa': 9024, 'yeeha': 9025, 'biatch': 9026, 'au': 9027, 'batrider': 9028, 'designed': 9029, 'insult': 9030, 'TUSK': 9031, 'resuming': 9032, 'shup': 9033, 'anybody': 9034, 'suffering': 9035, 'gook': 9036, 'login': 9037, 'QoP': 9038, 'ajjaja': 9039, 'sod': 9040, 'eve': 9041, 'putangina': 9042, 'tae': 9043, 'rampege': 9044, 'noobbb': 9045, 'wipo': 9046, 'farmlane': 9047, 'hahhha': 9048, 'CLEMENT': 9049, 'fhm': 9050, 'photoshoot': 9051, 'achievement': 9052, 'neh': 9053, 'phandon': 9054, 'fiend': 9055, 'ba': 9056, 'ibig': 9057, 'sabihin': 9058, 'kampi': 9059, 'tahimik': 9060, 'UYDI': 9061, 'LAte': 9062, 'whattagame': 9063, 'uve': 9064, 'n0t': 9065, 'ayaw': 9066, 'lumabas': 9067, 'init': 9068, 'pushhhhhhh': 9069, 'alarm': 9070, 'EZZZZZZZZZZZZ': 9071, 'LOLOLOLOLL': 9072, 'hahahahhahaha': 9073, 'obviously': 9074, 'devil': 9075, 'TH': 9076, 'husky': 9077, 'sparkly': 9078, 'homo': 9079, 'fagnuts': 9080, 'alreayd': 9081, 'wings': 9082, 'mppb': 9083, 'Ppd': 9084, 'rotate': 9085, 'feeded': 9086, 'closes': 9087, 'kolakaoaw': 9088, 'doono': 9089, 'unbalanced': 9090, 'cooties': 9091, 'NOOOOOOOOOOOOOOOOOOOOOB': 9092, 'urn': 9093, 'keeping': 9094, 'AHAHAHAHAHAHAAH': 9095, 'salt': 9096, 'vinegar': 9097, 'leaves': 9098, 'Test': 9099, 'cRY': 9100, 'pinOYYYYYYYYY': 9101, 'aW': 9102, 'loST': 9103, '85st': 9104, 'jsagdhjkasgd': 9105, 'thye': 9106, 'techhies': 9107, 'huk': 9108, 'dende': 9109, 'HOHOHHO': 9110, 'impressed': 9111, 'shitttt': 9112, 'baggg': 9113, 'whaty': 9114, 'DAMAGE': 9115, '5mnt': 9116, 'saad': 9117, 'stryong': 9118, 'overexcited': 9119, 'HAHHAHAH': 9120, 'DREAMING': 9121, 'Ca': 9122, 'REPORTEN': 9123, 'ESA': 9124, 'PUGDE': 9125, 'comento': 9126, 'QUIEN': 9127, 'LOS': 9128, 'REPORTA': 9129, 'ngenge': 9130, 'jam': 9131, 'pfffttt': 9132, 'goodness': 9133, 'org': 9134, 'CW': 9135, 'M7': 9136, 'ENIGMA': 9137, 'MEK': 9138, 'beeing': 9139, 'feedy': 9140, 'rpoflmao': 9141, 'round': 9142, 'offer': 9143, 'meepos': 9144, 'heads': 9145, 'QUAZ': 9146, 'sodium': 9147, 'erdogan': 9148, 'canoot': 9149, '44': 9150, 'donno': 9151, 'suporte': 9152, 'ASDJSADUHHDAS': 9153, 'noooooooooooo': 9154, 'potM': 9155, 'blushes': 9156, 'FEEDER': 9157, 'mIRANA': 9158, 'locking': 9159, 'NYX': 9160, 'GEM': 9161, 'HUNT': 9162, 'plane': 9163, '10mins': 9164, '27MIN': 9165, 'BFYRT': 9166, 'HAA': 9167, 'burdens': 9168, 'burdeness': 9169, 'WAt': 9170, 'F9': 9171, 'STOLE': 9172, 'BIKE': 9173, 'nas': 9174, 'ewe': 9175, 'waite': 9176, 'sentence': 9177, 'noobz': 9178, 'iwas': 9179, 'pinging': 9180, 'SERVERS': 9181, 'CANNOT': 9182, 'TANGO': 9183, 'et': 9184, 'ags': 9185, 'ynf': 9186, 'sex': 9187, 'autis': 9188, 'lalalalal': 9189, 'AHHAAH': 9190, 'dUMB': 9191, 'YIYI': 9192, 'jajajaj': 9193, 'Beautiful': 9194, 'chasing': 9195, 'Nothing': 9196, 'msg': 9197, 'MISSIS': 9198, 'DOUBT': 9199, 'yurnero': 9200, 'MOUTH': 9201, 'ET': 9202, 'DEGANCIA': 9203, 'BLAT': 9204, 'DELETE': 9205, 'Necro': 9206, 'CHILL': 9207, 'isntenough': 9208, 'High': 9209, 'rollers': 9210, 'teneg': 9211, 'dir': 9212, 'TERROBLADE': 9213, 'TRAVEL': 9214, 'INvok': 9215, 'fura': 9216, 'enmy': 9217, 'Yoshi': 9218, 'Mario': 9219, 'court': 9220, 'room': 9221, 'balck': 9222, 'fuckng': 9223, 'skadi': 9224, 'dayum': 9225, '61': 9226, 'ghhaha': 9227, '=[': 9228, 'chink': 9229, 'boutt': 9230, 'autsist': 9231, 'ugay': 9232, 'idrk': 9233, 'inflated': 9234, 'disco': 9235, 'juggs': 9236, 'twat': 9237, 'raise': 9238, 'relaxxx': 9239, 'leg': 9240, 'Did': 9241, 'stand': 9242, 'uou': 9243, 'gos': 9244, 'BALA': 9245, 'Npn': 9246, 'infidel': 9247, 'HAHAHAHAHAHAAHAHAHA': 9248, 'wating': 9249, 'noting': 9250, 'DROWWWWWWW': 9251, 'untouchable': 9252, 'Zeus': 9253, 'terrorblade': 9254, 'pnkg': 9255, 'gme': 9256, 'Heehehehhe': 9257, 'ofcc': 9258, 'Deal': 9259, 'USED': 9260, 'somebody': 9261, 'pt': 9262, 'skewer': 9263, 'fir': 9264, 'obv': 9265, 'havenet': 9266, 'nh': 9267, 'Both': 9268, 'rethink': 9269, 'skyp': 9270, 'med': 9271, 'sloth': 9272, 'naationality': 9273, 'redtube': 9274, '881': 9275, 'Waow': 9276, 'remy': 9277, 'boyzz': 9278, 'Reort': 9279, 'peruasno': 9280, 'FOREST': 9281, 'shall': 9282, 'leav': 9283, 'biggest': 9284, 'turns': 9285, 'Morph': 9286, 'louy': 9287, 'pd': 9288, 'ebal': 9289, 'breathe': 9290, 'nose': 9291, 'vp': 9292, 'fuicken': 9293, 'sc': 9294, 'sook': 9295, 'voltis': 9296, 'zzzzzzz': 9297, 'rocks': 9298, 'mh': 9299, 'YORU': 9300, 'FUCKIGN': 9301, 'nasad': 9302, 'jud': 9303, 'mistake': 9304, 'hardest': 9305, 'pve': 9306, 'creaps': 9307, 'NERDS': 9308, 'M888': 9309, 'lamo': 9310, 'uR': 9311, 'DAN': 9312, 'PEENOTY': 9313, 'dadadqa': 9314, 'tped': 9315, 'feal': 9316, 'abanuti': 9317, 'pizdec': 9318, 'viweres': 9319, 'LIVe': 9320, 'tik': 9321, 'tok': 9322, 'provider': 9323, 'muere': 9324, 'callada': 9325, 'perra': 9326, 'duken': 9327, 'giusy': 9328, 'ggs': 9329, 'ookay': 9330, 'Tinny': 9331, 'deffs': 9332, 'leonidas': 9333, 'awj': 9334, 'img': 9335, 'etting': 9336, 'spikes': 9337, 'jhj': 9338, 'xddd': 9339, 'refract': 9340, 'eazzz': 9341, 'hhhhhhhhhhh': 9342, 'PISSFACE': 9343, 'MGA': 9344, '3kmmr': 9345, 'lasst': 9346, 'TAS': 9347, 'CNT': 9348, 'COMPETNENT': 9349, 'abanbdoned': 9350, 'Asdgfikom': 9351, 'Biper': 9352, 'Viper': 9353, 'honor': 9354, 'expensive': 9355, 'body': 9356, 'borderline': 9357, 'suicidal': 9358, 'spykes': 9359, 'poop': 9360, 'LEAR': 9361, 'TEAMMATE': 9362, 'MEANS': 9363, 'fianlly': 9364, 'okkkey': 9365, 'wkwkwkwkwk': 9366, 'pui': 9367, 'blodd': 9368, 'nvo': 9369, 'tow': 9370, 'watermelon': 9371, 'axxaxaxaaxaxax': 9372, 'clink': 9373, 'fyuuuhhh': 9374, 'MIC': 9375, 'obviosly': 9376, 'jurkoff': 9377, 'wht': 9378, 'mummys': 9379, 'nbedroom': 9380, 'sacrifice': 9381, 'imj': 9382, 'preety': 9383, 'RECORDED': 9384, 'siege': 9385, 'creepz': 9386, 'fucong': 9387, 'fukciong': 9388, 'reprt': 9389, 'runner': 9390, 'AHAHHAH': 9391, 'asissts': 9392, 'tat': 9393, 'omG': 9394, 'commendos': 9395, 'Sexo': 9396, 'butto': 9397, 'butt': 9398, 'under': 9399, 't1': 9400, 'misn': 9401, 'prove': 9402, 'agk': 9403, 'palky': 9404, 'kontool': 9405, 'Sup': 9406, 'zeyus': 9407, 'discussing': 9408, 't3': 9409, 'filthy': 9410, 'sand': 9411, 'Notlikethis': 9412, 'jpg': 9413, 'triple': 9414, 'Xuan': 9415, 'Mai': 9416, 'payback': 9417, 'toggle': 9418, 'tight': 9419, '2compos': 9420, 'CYAK': 9421, 'caca': 9422, 'sohai': 9423, 'OUUU': 9424, 'CH': 9425, 'loggin': 9426, 'Slardar': 9427, 'pertty': 9428, 'dame': 9429, 'Peru': 9430, 'bobby': 9431, 'bigger': 9432, 'ammirite': 9433, 'JAHAHHAA': 9434, 'lti': 9435, 'enig': 9436, 'ATRAS': 9437, 'RATAS': 9438, 'dewarding': 9439, 'Ofc': 9440, 'reportnite': 9441, 'etix': 9442, 'za': 9443, 'nityo': 9444, 'bst': 9445, 'WT': 9446, 'BOUGHT': 9447, 'COUR': 9448, 'TRYHARD': 9449, 'weee': 9450, 'whys': 9451, 'disconnnecting': 9452, 'encountered': 9453, 'LEADING': 9454, 'SKILLS': 9455, 'WUDUP': 9456, 'HEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEERES': 9457, 'feggets': 9458, 'sosator': 9459, 'sosater': 9460, 'ironic': 9461, 'dontg': 9462, 'wouldndt': 9463, 'NAHUJ': 9464, 'nigguh': 9465, 'ezez': 9466, 'graves': 9467, '50min': 9468, 'courriers': 9469, 'Shakel': 9470, 'TIMEE': 9471, 'whit': 9472, 'art': 9473, 'qwat': 9474, 'NOICE': 9475, 'JIJIJIJI': 9476, 'shadowfiend': 9477, 'footlocker': 9478, 'stonf': 9479, 'medicine': 9480, 'ASA': 9481, 'SI': 9482, 'BOBOB': 9483, 'satiesfied': 9484, 'JKAKAJAJAJAJAJ': 9485, 'supposed': 9486, 'happeend': 9487, 'drops': 9488, 'nuclear': 9489, 'Meracle': 9490, 'ahhahahaa': 9491, 'orospu': 9492, 'ocugu': 9493, 'CHIPPREL': 9494, 'NUTS': 9495, 'PATALO': 9496, '43232': 9497, 'sso': 9498, 'wrs': 9499, 'houses': 9500, 'sentires': 9501, 'sorta': 9502, 'SOMEHOW': 9503, 'ksd': 9504, 'WASTing': 9505, 'wkwkwk': 9506, 'wkwwk': 9507, 'deez': 9508, 'nutz': 9509, 'gryas': 9510, 'afucking': 9511, 'alchj': 9512, 'TOPO': 9513, 'starfall': 9514, 'SOMETHING': 9515, 'pikon': 9516, 'filipinos': 9517, 'WHYYYY': 9518, 'feder': 9519, 'warder': 9520, 'PUPPEY': 9521, 'ahghaha': 9522, 'frog': 9523, 'existing': 9524, 'GGp': 9525, 'UNPAUSE': 9526, 'ORE': 9527, 'tm': 9528, 'SHITTIES': 9529, 'nutshell': 9530, 'blrr': 9531, 'OA': 9532, 'fyi': 9533, 'vendetta': 9534, '2018': 9535, 'wbghat': 9536, 'eul': 9537, 'alyer': 9538, 'rizwan': 9539, 'GALSNDLASNDJ': 9540, 'OFC': 9541, 'buy1': 9542, 'fuckwad': 9543, 'selfish': 9544, 'suits': 9545, 'PH': 9546, 'outfarming': 9547, 'riky': 9548, 'katkaaa': 9549, 'igot': 9550, 'mormon': 9551, 'bnooob': 9552, 'As': 9553, 'inspect': 9554, 'read': 9555, 'gentelmen': 9556, '31': 9557, 'NABBED': 9558, 'HUA': 9559, 'urs': 9560, 'tapped': 9561, 'Jesus': 9562, 'found': 9563, '`': 9564, 'abd': 9565, 'Care': 9566, 'aaxax': 9567, 'allowed': 9568, 'bedroom': 9569, 'jakol': 9570, 'lesson': 9571, 'TWICE': 9572, 'meed': 9573, 'ggWp': 9574, ':DDDDDDDDDDDD': 9575, 'dn': 9576, 'couriers': 9577, 'strom': 9578, 'arguing': 9579, 'pLS': 9580, 'blog': 9581, 'stud': 9582, 'Hear': 9583, 'Were': 9584, 'argument': 9585, 'naw': 9586, 'askin': 9587, 'tactics': 9588, 'jokers': 9589, 'soda': 9590, 'FGUCK': 9591, 'fuxk': 9592, 'ahahahjajhajajajja': 9593, 'motherfuker': 9594, 'yeee': 9595, 'teamgame': 9596, 'LIVING': 9597, 'hje': 9598, 'WHIPE': 9599, '1year': 9600, 'tackle': 9601, 'NUB': 9602, 'rps': 9603, '1389461397419': 9604, 'wildkin': 9605, 'camps': 9606, 'ecvho': 9607, 'DL': 9608, 'rEPORT': 9609, 'TRYHARIDNG': 9610, 'stitch': 9611, 'planet': 9612, 'kept': 9613, 'DOUCHE': 9614, 'PICKED': 9615, 'While': 9616, 'afkd': 9617, 'baits': 9618, 'CLOSE': 9619, 'PUBLIC': 9620, 'URSA': 9621, 'jkajaja': 9622, 'DansGame': 9623, 'rspe': 9624, 'CONSECUTIVE': 9625, 'HAHAh': 9626, 'infinity': 9627, 'uze': 9628, 'ebqal': 9629, '2800': 9630, 'aiming': 9631, 'omkg': 9632, 'TUSKAR': 9633, 'TEACH': 9634, 'ASSHOLE': 9635, 'SHU': 9636, 'thinkg': 9637, 'causing': 9638, '15min': 9639, 'TEAMATE': 9640, '2vice': 9641, 'ajahhahahaa': 9642, 'regen': 9643, 'RAIJIN': 9644, 'Virgin': 9645, 'alert': 9646, 'gosu': 9647, 'REFPORT': 9648, 'DZZLE': 9649, 'gate': 9650, 'donde': 9651, 'ayubowan': 9652, 'dats': 9653, 'gree': 9654, 'PLEAE': 9655, 'ELECTRIC': 9656, 'downschild': 9657, 'hhqhqqhhq': 9658, 'HP': 9659, 'clarity': 9660, 'wrking': 9661, 'alchs': 9662, 'pleeeeeeeee': 9663, 'arcana': 9664, 'MOuise': 9665, 'silly': 9666, 'SUPPORTS': 9667, 'lMAO': 9668, 'dominator': 9669, 'successful': 9670, 'Dami': 9671, 'unbelievebale': 9672, 'wjhat': 9673, 'ursaz': 9674, 'produced': 9675, 'REALty': 9676, '15200': 9677, 'waaw': 9678, 'EVERY1': 9679, 'ION': 9680, 'BRACKET': 9681, 'everytime': 9682, 'bitchhhhhhh': 9683, 'mechanic': 9684, 'ULTO': 9685, 'HOYLFUCK': 9686, 'mq': 9687, 'dillon': 9688, 'harper': 9689, 'credit': 9690, 'faggets': 9691, 'survived': 9692, 'esteemed': 9693, 'mutelist': 9694, 'vooral': 9695, 'geen': 9696, 'stealed': 9697, 'businees': 9698, 'misstype': 9699, 'waiy': 9700, '24hrs': 9701, 'masturbating': 9702, 'Wasting': 9703, 'Hahaa': 9704, 'Hais': 9705, 'BUTT': 9706, 'HEART': 9707, '2EASY': 9708, 'englihs': 9709, '3300': 9710, 'Tabbed': 9711, 'KIDZ': 9712, 'TYPE': 9713, 'whooow': 9714, 'youve': 9715, 'organise': 9716, 'race': 9717, 'papi': 9718, 'paki': 9719, 'diarrea': 9720, 'eos': 9721, 'vas': 9722, 'medio': 9723, 'breaker': 9724, 'silenced': 9725, '40mins': 9726, 'lvl2': 9727, 'Ahhaah': 9728, 'PUNCH': 9729, 'CUNTS': 9730, 'Tipical': 9731, 'dnno': 9732, 'odn': 9733, 'Pudge': 9734, '100000': 9735, 'AHI': 9736, 'AXAXXA': 9737, 'Greed': 9738, 'indian': 9739, 'ook': 9740, 'imma': 9741, 'bagging': 9742, '2in': 9743, 'wwwwwwwwwwiiiiiiiiiiiiiiiiii': 9744, 'shhshhshshshnh': 9745, 'looser': 9746, 'whould': 9747, 'Got': 9748, 'mikes': 9749, 'converted': 9750, 'sadness': 9751, 'KOL9Y': 9752, 'blind': 9753, 'Girls': 9754, 'shot': 9755, 'eartshaker': 9756, 'trahs': 9757, 'cac': 9758, 'thanh': 9759, 'nien': 9760, 'awhile': 9761, 'mought': 9762, 'energy': 9763, 'omnbi': 9764, 'IDK': 9765, 'ahahaahah': 9766, 'hotkey': 9767, 'bone': 9768, 'chick': 9769, 'thooo': 9770, 'oj': 9771, 'blackput': 9772, 'wed': 9773, 'WArded': 9774, 'lone': 9775, 'ape': 9776, 'comnig': 9777, 'quicker': 9778, 'HAAAAAAAAAAAAAAAAAAAAAA': 9779, 'SEEMS': 9780, 'LIKELY': 9781, 'cocck': 9782, 'beer': 9783, 'HARDER': 9784, 'anymmore': 9785, 'TRYHARDING': 9786, 'root': 9787, 'WOA': 9788, 'mentally': 9789, 'WOOOO': 9790, 'MAXING': 9791, 'SENTRIES': 9792, 'OBS': 9793, 'UPGRADED': 9794, 'HCICKEN': 9795, 'SHITHEAD': 9796, 'DUSA': 9797, 'DYING': 9798, 'UNDER': 9799, 'BOOTY': 9800, 'SHITSTAINS': 9801, 'HAHHAHAHAHAHAHA': 9802, 'Peenoise': 9803, 'rprobems': 9804, 'GEGGE': 9805, 'WEP': 9806, 'EP': 9807, 'inish': 9808, 'ojala': 9809, 'vuelva': 9810, 'quiero': 9811, 'jugar': 9812, 'este': 9813, 'shitters': 9814, 'nevermoreland': 9815, 'GGGGG': 9816, 'gws': 9817, 'wifi': 9818, 'nmn': 9819, 'kau': 9820, 'AFk': 9821, 'iget': 9822, 'mir': 9823, 'teamwipe': 9824, 'dizaztah': 9825, ':salty': 9826, 'MIGHTY': 9827, 'grats': 9828, '748': 9829, 'bukake': 9830, 'quuuuuiiiiitEErasgx': 9831, 'premuted': 9832, 'pw': 9833, 'wreck': 9834, 'CHISTRIS': 9835, 'SPIELEEEEEN': 9836, 'svenb': 9837, 'Xdd': 9838, 'killsl': 9839, 'imd': 9840, 'Leave': 9841, 'pleae': 9842, 'Miran': 9843, 'WOLF': 9844, 'ad': 9845, 'hvnt': 9846, 'hardlaner': 9847, 'WARUM': 9848, 'EINFACH': 9849, 'xaxaxaxa': 9850, 'SWEET': 9851, 'DREAMS': 9852, 'aer': 9853, 'sutpid': 9854, 'POWEL': 9855, 'NAHYI': 9856, 'VIRODOK': 9857, 'crap': 9858, 'invuln': 9859, 'immune': 9860, 'physical': 9861, 'destoy': 9862, 'karo4e': 9863, 'HAHAHAA': 9864, 'wHOOOOOOOOOOOO': 9865, '5hp': 9866, 'loes': 9867, 'Twitter': 9868, 'resetin': 9869, 'graphh': 9870, 'ruskaya': 9871, 'svinya': 9872, 'divin': 9873, 'clap': 9874, 'STIL': 9875, 'HEAL': 9876, 'allah': 9877, 'tanginamo': 9878, 'Kriv': 9879, 'je': 9880, 'litaaaar': 9881, 'vinaaaaaaaaa': 9882, 'sexual': 9883, 'preference': 9884, 'acutaly': 9885, 'JUKES': 9886, 'profarmer': 9887, 'farmville': 9888, 'LALALLA': 9889, 'ahyhahha': 9890, 'Keeper': 9891, 'LIXO': 9892, 'DOCTO': 9893, 'FILHO': 9894, 'PUITA': 9895, 'yusss': 9896, 'circus': 9897, 'hiding': 9898, 'mhmm': 9899, 'sz': 9900, 'xaxaaxax': 9901, 'engines': 9902, 'KILLED': 9903, 'eruvians': 9904, 'Dun': 9905, 'yesterday': 9906, 'dos': 9907, 'duelos': 9908, 'FELANKOR': 9909, '1x1': 9910, 'caried': 9911, 'baban': 9912, 'sene': 9913, 'sickde': 9914, 'boobs': 9915, 'teamplay': 9916, 'FVCKING': 9917, 'nha': 9918, 'GWp': 9919, 'zoo': 9920, 'grammar': 9921, 'WHYYYYYYYYYYYYY': 9922, 'hash': 9923, 'middddddddddddddddddd': 9924, 'rect': 9925, 'ownit': 9926, 'doNT': 9927, 'sRY': 9928, 'pLZ': 9929, 'faGGOT': 9930, 'PELEAN': 9931, 'fuyck': 9932, 'HAWHWAHAW': 9933, 'agh': 9934, 'par': 9935, 'lar': 9936, 'defense': 9937, 'fury': 9938, 'learner': 9939, 'Sri': 9940, 'Lanka': 9941, 'tursk': 9942, 'DALLLI': 9943, 'Valar': 9944, 'Morghulis': 9945, 'Japan': 9946, '1mins': 9947, 'Ks': 9948, 'bay': 9949, 'FUCKTARD': 9950, 'Glhf': 9951, 'piost': 9952, 'stromn': 9953, 'silencing': 9954, 'Rly': 9955, 'talker': 9956, 'toxics': 9957, 'wars': 9958, 'lmaoooo': 9959, 'wutface': 9960, 'Dog': 9961, 'playert': 9962, 'mhm': 9963, 'stafcks': 9964, 'anus': 9965, 'pilaet': 9966, 'Mid': 9967, 'ckckck': 9968, 'BOYSSSSSSSSSSSSSSS': 9969, '2500ms': 9970, 'reuse': 9971, 'Woo': 9972, 'WOWOWO': 9973, 'surrneder': 9974, 'avrg': 9975, 'BURNING': 9976, 'soooooooooooooooooooo': 9977, 'Sut': 9978, 'pid': 9979, 'gives': 9980, 'stunrange': 9981, 'wehat': 9982, 'fits': 9983, 'MNY': 9984, 'THING': 9985, 'SLARKA': 9986, 'kekn': 9987, 'scrabbling': 9988, 'area': 9989, 'thankyouuu': 9990, 'gs': 9991, 'WAOW': 9992, 'REKITY': 9993, 'byebek': 9994, 'switggity': 9995, 'swooty': 9996, 'pesti': 9997, 'yawa': 9998, 'gia': 9999, 'tay': 10000, 'picki': 10001, 'tearing': 10002, 'johan': 10003, 'hav': 10004, 'banter': 10005, 'wkwk': 10006, 'alchemas': 10007, 'tambien': 10008, 'HAHAA': 10009, 'EleFuckingGiggle': 10010, 'nb': 10011, 'ritw': 10012, 'supercreeps': 10013, 'hhhahahah': 10014, 'babysat': 10015, 'Stone': 10016, 'SHIELD': 10017, '30min': 10018, 'TOUCHDOWN': 10019, 'mexico': 10020, 'dizazterr': 10021, 'statss': 10022, 'sooon': 10023, 'BOAT': 10024, 'unnistal': 10025, 'Ezzz': 10026, 'fiuck': 10027, 'midder': 10028, 'scream': 10029, '=/': 10030, 'bish': 10031, 'magno': 10032, 'pude': 10033, 'quiras': 10034, 'SMOKE': 10035, 'MAN': 10036, 'gL': 10037, 'FUCKS': 10038, 'nowdays': 10039, 'sjot': 10040, 'mutes': 10041, 'MT': 10042, 'CHERS': 10043, 'thejm': 10044, 'Commended': 10045, 'honey': 10046, 'noncontributory': 10047, 'warlok': 10048, 'hhahahahhahahaha': 10049, 'peri': 10050, 'hype': 10051, 'MOMMAS': 10052, 'BOOII': 10053, 'noobwd': 10054, 'rubbish': 10055, 'deffffff': 10056, 'tilted': 10057, 'sigue': 10058, 'ingles': 10059, 'medu': 10060, 'series': 10061, 'slarsadder': 10062, 'HEHEHE': 10063, 'muereeeeeeeeeeeee': 10064, 'guyzzz': 10065, 'leglas': 10066, 'Out': 10067, 'bas': 10068, 'Rsdfkpghsd': 10069, 'jhjosfh': 10070, 'poshel': 10071, 'urgent': 10072, 'salami': 10073, 'THEEE': 10074, 'slardars': 10075, 'vigilante': 10076, 'bandot': 10077, 'VERY': 10078, 'become': 10079, ':po': 10080, 'FUCKN': 10081, 'whereeee': 10082, 'heeeeeeeeeee': 10083, 'tc': 10084, 'cheecky': 10085, 'clever': 10086, 'gho': 10087, '211': 10088, 'hast': 10089, 'zzzzzzzzzzzz': 10090, 'gucci': 10091, 'dony': 10092, 'didt': 10093, 'Pa': 10094, 'lagg': 10095, 'IHhi': 10096, 'escort': 10097, 'LMAOOO': 10098, 'sp': 10099, 'zaebal': 10100, 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG': 10101, 'purge': 10102, 'kicked': 10103, 'dayna': 10104, 'walang': 10105, 'cuming': 10106, 'ruptured': 10107, 'eneemies': 10108, 'tornadio': 10109, 'waitcan': 10110, 'confirm': 10111, 'andwaitforhimself': 10112, 'ich': 10113, 'versteh': 10114, 'kein': 10115, 'wort': 10116, 'landing': 10117, 'DROP': 10118, 'whores': 10119, 'lonedruid': 10120, 'West': 10121, 'virginia': 10122, 'KKKKK': 10123, 'KKKKKKKKKKKKK': 10124, 'KKKKKKKKKKKKKKKKKK': 10125, 'VEJAM': 10126, 'WINTER': 10127, 'VALE': 10128, 'PENA': 10129, 'DAR': 10130, 'RIZADA': 10131, 'drums': 10132, 'Sunder': 10133, 'aclick': 10134, 'sedih': 10135, 'lagi': 10136, 'SHACLE': 10137, 'mangoes': 10138, 'Napakatanga': 10139, 'Smh': 10140, 'gret': 10141, 'wared': 10142, 'didn': 10143, 'befoire': 10144, 'botm': 10145, 'ar1se': 10146, 'polite': 10147, 'jib': 10148, 'watched': 10149, 'ainsley': 10150, 'harriott': 10151, 'cokking': 10152, 'duno': 10153, 'sickest': 10154, 'lucies': 10155, 'lkmao': 10156, 'bher': 10157, 'ownes': 10158, 'commned': 10159, 'mothercukeer': 10160, 'PREDICK': 10161, 'SKY': 10162, 'nowww': 10163, 'UMR': 10164, 'globl': 10165, 'globals': 10166, 'ropsh': 10167, 'lur': 10168, 'cuint': 10169, 'CUM': 10170, 'onilne': 10171, 'bum': 10172, 'SHUTUP': 10173, 'ARSE': 10174, 'CHICKEN': 10175, 'NOISY': 10176, 'abusive': 10177, 'tream': 10178, 'ths': 10179, 'bosting': 10180, 'Midlane': 10181, 'prefer': 10182, 'mao': 10183, 'moooooh': 10184, 'MLG': 10185, 'hon': 10186, 'tifa': 10187, 'RiP': 10188, 'RAVAGE': 10189, 'DUMBSHIT': 10190, 'brilliant': 10191, 'rotations': 10192, 'Unless': 10193, 'zez': 10194, 'machismo': 10195, 'noobi': 10196, 'setnry': 10197, 'romans': 10198, 'greeks': 10199, 'statues': 10200, 'naked': 10201, 'wrestling': 10202, 'dmid': 10203, 'matched': 10204, 'KAAAAAAAAMMMMMMMMMMEEEEEEEEEEEEEE': 10205, 'HAAAAAAAAAAAMMMMMMMMMMMMMEEEEEEEEEE': 10206, 'concernedstudent1950': 10207, '3v5': 10208, 'asap': 10209, 'huehuehuehue': 10210, 'pld': 10211, 'surpriseee': 10212, 'ru': 10213, 'kitty': 10214, 'spider': 10215, 'seg': 10216, 'immortal': 10217, 'everyon': 10218, 'atta': 10219, 'cyou': 10220, 'delet': 10221, 'oufhsjghsdg': 10222, 'invokeeeer': 10223, 'ours': 10224, 'noyt': 10225, 'slardera': 10226, 'Rape': 10227, 'hehhe': 10228, 'fucksake': 10229, 'hhhh': 10230, 'SPCE': 10231, 'alwys': 10232, 'cracked': 10233, 'SHORT': 10234, 'ezgame': 10235, 'tommorow': 10236, 'levi': 10237, 'Seconecto': 10238, 'Te': 10239, 'odiO': 10240, 'hpd': 10241, 'indonesia': 10242, 'wodota': 10243, 'george': 10244, 'brezzy': 10245, 'TONYH': 10246, 'TONY': 10247, 'Mangoes': 10248, 'TBD': 10249, 'ditch': 10250, 'whoop': 10251, 'domu': 10252, 'lagggggggggggg': 10253, 'xzxaaxaxaxaxaxaxa': 10254, 'gggwp': 10255, 'Jk': 10256, 'acalming': 10257, 'JK': 10258, 'ruskis': 10259, 'BARAT': 10260, 'neuts': 10261, '50:00': 10262, 'supoer': 10263, 'TIWALA': 10264, 'sneaky': 10265, 'kale': 10266, ':derp': 10267, 'screwing': 10268, 'yas': 10269, 'Double': 10270, 'yap': 10271, '=s': 10272, 'harras': 10273, 'eminem': 10274, 'doomn': 10275, 'drum': 10276, '340': 10277, 'dip': 10278, 'dcs': 10279, 'waits': 10280, 'rages': 10281, 'kod': 10282, 'hookshot': 10283, 'tiki': 10284, '4vs': 10285, 'youmadbro': 10286, 'movistar': 10287, 'step': 10288, 'Used': 10289, 'Make': 10290, 'idiiot': 10291, 'atay': 10292, 'optjer': 10293, 'concedes': 10294, 'baia': 10295, 'Is': 10296, 'wipeout': 10297, 'appeared': 10298, 'heang': 10299, 'prolem': 10300, 'address': 10301, 'jobs': 10302, 'fuzzy': 10303, 'wuzzy': 10304, 'zayehal': 10305, 'pahha': 10306, 'SWAP': 10307, 'tom': 10308, 'wrwrw': 10309, 'soooo': 10310, 'premute': 10311, 'Should': 10312, 'Didnt': 10313, 'fickijg': 10314, 'motehr': 10315, '25mins': 10316, 'QQ': 10317, 'yyy': 10318, 'silent': 10319, 'credits': 10320, 'ez4': 10321, 'commed': 10322, 'COMMNED': 10323, 'timbersaw': 10324, 'octine': 10325, 'inoker': 10326, 'flamming': 10327, 'wutever': 10328, 'duuude': 10329, 'mnay': 10330, 'woa': 10331, 'linch': 10332, 'commendable': 10333, 'motion': 10334, 'witing': 10335, 'thistime': 10336, 'Kek': 10337, 'Tusk': 10338, 'supprt': 10339, 'otvechay': 10340, 'pikaite': 10341, 'looooool': 10342, 'rooting': 10343, 'fucke': 10344, 'mahirap': 10345, 'zzzzzzzzz': 10346, 'torll': 10347, 'bithces': 10348, 'CMD': 10349, 'PT': 10350, 'SOS': 10351, 'UN': 10352, 'ASCO': 10353, 'TE': 10354, 'REPORTO': 10355, 'PODES': 10356, 'JUGAR': 10357, 'ASI': 10358, 'EN': 10359, 'RANKED': 10360, 'mjst': 10361, 'sureness': 10362, 'fo': 10363, 'rhim': 10364, 'chickens': 10365, 'omi': 10366, 'joob': 10367, 'poser': 10368, 'comming': 10369, 'gangsta': 10370, '84': 10371, 'LETAS': 10372, 'LULZ': 10373, 'ohmy': 10374, 'lelele': 10375, 'rubikc': 10376, 'lanning': 10377, 'basement': 10378, 'rme': 10379, 'ead': 10380, 'Muting': 10381, 'michael': 10382, 'phelps': 10383, 'randmon': 10384, 'Lesh': 10385, 'daynov': 10386, 'krome': 10387, 'wispa': 10388, 'malaysia': 10389, 'FKC': 10390, '330': 10391, 'AHhaah': 10392, 'deine': 10393, 'dag': 10394, 'attitude': 10395, 'PINOY': 10396, 'bobong': 10397, 'barbaric': 10398, 'ENOPJOUAY': 10399, 'tusks': 10400, 'waoit': 10401, 'CTM': 10402, 'mission': 10403, 'ohkay': 10404, 'predic': 10405, 'Straight': 10406, 'qward': 10407, 'recomiendane': 10408, 'qopa': 10409, 'dura': 10410, 'sobrala': 10411, 'yooohoo': 10412, 'unerstand': 10413, 'Hahahahahahah': 10414, 'HAHAHAHAHAHAHAHA': 10415, 'ALEG': 10416, 'AELG': 10417, 'roshd': 10418, 'wsip': 10419, '2moro': 10420, 'comps': 10421, 'jogo': 10422, 'muito': 10423, 'desisti': 10424, 'dessa': 10425, 'partida': 10426, '2300': 10427, 'lusting': 10428, 'qb': 10429, 'trilaned': 10430, 'VENOM': 10431, 'excuses': 10432, 'kok': 10433, 'lawannya': 10434, 'cupu': 10435, 'bgt': 10436, '96': 10437, 'nightr': 10438, 'katushka': 10439, 'dfsgahzwreas': 10440, 'patehtic': 10441, 'respawns': 10442, 'wai': 10443, 'shouldve': 10444, 'snickers': 10445, 'wrecking': 10446, 'itself': 10447, 'Davai2': 10448, 'bratan': 10449, 'accidentally': 10450, 'dualed': 10451, 'lov': 10452, 'shackels': 10453, 'group': 10454, 'vk': 10455, 'HAHAHAHAHAHA': 10456, 'watchin': 10457, 'replays': 10458, 'prt': 10459, 'NOBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB': 10460, 'topgame': 10461, 'europa': 10462, 'SWAN': 10463, 'mole': 10464, 'ox': 10465, 'dang': 10466, 'bravo': 10467, 'form': 10468, 'yan': 10469, 'frags': 10470, 'WAITING': 10471, 'hahg': 10472, '::@': 10473, 'PFF': 10474, 'LOX': 10475, 'nad': 10476, 'wrok': 10477, 'uncle': 10478, 'Benn': 10479, 'zl': 10480, 'greeting': 10481, 'decline': 10482, 'adoro': 10483, 'bater': 10484, 'quer': 10485, 'pagar': 10486, 'joga': 10487, 'kkkkk': 10488, 'Munic': 10489, 'peen': 10490, 'mrr': 10491, 'COMMING': 10492, 'EULS': 10493, 'WHICH': 10494, 'CAST': 10495, 'HOOKED': 10496, 'cruel': 10497, 'flash': 10498, 'deserves': 10499, 'wash': 10500, 'clothes': 10501, 'THESE': 10502, 'suffers': 10503, 'insta': 10504, 'wtv': 10505, 'ezMMR': 10506, 'size': 10507, 'flashy': 10508, 'LOLz': 10509, 'whhy': 10510, 'ezzzzzz': 10511, 'ALCHEEEEE': 10512, 'WATASHIWAA': 10513, 'HIGH': 10514, 'GROUND': 10515, 'HAHAHAHAHHA': 10516, 'NOOOO': 10517, 'galing': 10518, 'LUCKER': 10519, 'hilarious': 10520, 'trigger': 10521, 'split': 10522, 'nudes': 10523, 'Oo': 10524, 'BASURA': 10525, 'tudsun': 10526, 'JAJAHJAHAHA': 10527, 'alpha': 10528, 'chapstick': 10529, 'chavstick': 10530, 'shoot': 10531, 'GONNA': 10532, 'WAHAHAHA': 10533, 'wasteour': 10534, 'jajajajajaja': 10535, 'capt': 10536, 'PLSS': 10537, 'FULL': 10538, 'LUNATICS': 10539, 'ohard': 10540, 'tobias': 10541, 'helvete': 10542, 'UNTIL': 10543, 'laner': 10544, 'lapsap': 10545, 'ALLLLLL': 10546, 'BREW': 10547, 'Live': 10548, 'xarub': 10549, 'Awesome': 10550, 'essence': 10551, 'shift': 10552, 'Coinz': 10553, 'headshot': 10554, 'teamfights': 10555, 'blinked': 10556, 'jams': 10557, 'NERD': 10558, 'passion': 10559, 'RUNNER': 10560, 'absolutley': 10561, 'ahahahahahahahahha': 10562, 'HAHAHAHAHAHAHAHAH': 10563, 'haaaaaaaaaaaaaaaaaaaa': 10564, 'hakey': 10565, 'HER': 10566, 'dazl': 10567, 'crfat': 10568, 'wstyd': 10569, 'zaoszczedzony': 10570, 'panowie': 10571, 'crybabies': 10572, 'niga': 10573, 'mooooooh': 10574, 'briste': 10575, 'retribution': 10576, 'Boris': 10577, 'meka': 10578, 'reconncet': 10579, 'focken': 10580, 'unranked': 10581, 'TIDE': 10582, 'dauni': 10583, 'lesu': 10584, 'jugs': 10585, 'reportslark': 10586, 'JUGGER': 10587, 'volume': 10588, '::_': 10589, 'MEDUSA': 10590, 'Losing': 10591, 'Isntant': 10592, 'Somee1': 10593, 'RESTART': 10594, 'rematch': 10595, 'eyeballs': 10596, 'SUICIDE': 10597, 'syhit': 10598, 'cnacer': 10599, 'dist': 10600, 'ahhhhhhhhhhhhhh': 10601, 'AHA': 10602, 'previous': 10603, 'smaterz': 10604, 'Dk': 10605, 'stum': 10606, 'ooohoo': 10607, 'ezzzz': 10608, 'caya': 10609, 'cmtr': 10610, 'TAKDE': 10611, 'BGTAU': 10612, 'AWAL': 10613, 'opps': 10614, 'darling': 10615, 'frieenddd': 10616, 'intelligient': 10617, 'WOOOOOOOOOOOOOW': 10618, 'control': 10619, 'teamfighting': 10620, 'greek': 10621, 'Trable': 10622, 'SJ': 10623, 'spics': 10624, 'Rs': 10625, 'cristalis': 10626, 'bcos': 10627, 'terminen': 10628, 'STFUUU': 10629, 'holyshit': 10630, '2:11': 10631, 'areu': 10632, 'Spouky': 10633, 'owuld': 10634, 'ttrash': 10635, 'depression': 10636, 'ahgahhaa': 10637, 'discuss': 10638, 'situation': 10639, 'horoshiy': 10640, 'freeand': 10641, 'Yeha': 10642, '|': 10643, 'tampar': 10644, 'aku': 10645, 'pressence': 10646, 'receive': 10647, 'Lfdyj': 10648, 'gjhf': 10649, 'rthe': 10650, 'fuckboys': 10651, 'English': 10652, 'illiterate': 10653, 'JOJOJO': 10654, 'JOJOJOJOJOJOJO': 10655, 'oie': 10656, 'agnus': 10657, 'shouldnt': 10658, 'BRAVO': 10659, 'picknut': 10660, 'mmmmmmmmm': 10661, 'rnked': 10662, 'AR': 10663, 'HARDEST': 10664, 'OKE': 10665, 'STEALER': 10666, 'TCH': 10667, 'lyfe': 10668, 'wass': 10669, 'remotely': 10670, 'opinion': 10671, 'quote': 10672, 'SASGGGDDD': 10673, '69': 10674, 'bristleback': 10675, 'landed': 10676, 'plenty': 10677, 'paket': 10678, 'tengo': 10679, 'bummer': 10680, 'tuesday': 10681, 'repoted': 10682, 'cookkk': 10683, '34min': 10684, 'fest': 10685, 'trashlords': 10686, 'moly': 10687, 'ELSa': 10688, 'lolc': 10689, 'JOJOO': 10690, 'JIOJOJOJOJO': 10691, 'buhat': 10692, 'kingina': 10693, 'HAHHAH': 10694, 'WHORE': 10695, 'liched': 10696, 'embarrasing': 10697, 'multiplayer': 10698, 'videogame': 10699, 'enviroment': 10700, 'DISGUSTING': 10701, 'gaycunt': 10702, 'plans': 10703, 'Hello': 10704, 'sy': 10705, 'Fly': 10706, 'rak': 10707, 'moreplz': 10708, 'tyiny': 10709, 'haVBE': 10710, 'ISSUE': 10711, 'ABANDON': 10712, 'uit': 10713, 'messing': 10714, 'bitvh': 10715, 'leading': 10716, 'future': 10717, '2111': 10718, 'aggg': 10719, 'middle': 10720, 'hae': 10721, 'werk': 10722, 'wizard': 10723, 'DUel': 10724, 'acommend': 10725, 'HIII': 10726, 'havin': 10727, 'BIASA': 10728, 'pathetic': 10729, 'ahghahahah': 10730, 'idd': 10731, 'plater': 10732, 'EZZZ': 10733, 'chops': 10734, 'thankyou': 10735, 'serving': 10736, 'wisped': 10737, 'Io': 10738, 'rocked': 10739, '190': 10740, 'winnable': 10741, 'klikl': 10742, 'wtF': 10743, 'asdgsdgh': 10744, 'gabe': 10745, '1v4': 10746, 'thais': 10747, 'belive': 10748, 'jstbreak': 10749, 'Ns': 10750, 'papa': 10751, 'noooow': 10752, 'freezes': 10753, 'LOLOL': 10754, 'ghusk': 10755, 'TRAMP': 10756, 'eVA': 10757, 'hpta': 10758, 'effeect': 10759, 'blockers': 10760, 'hayne': 10761, 'doller': 10762, 'alienware': 10763, 'yuked': 10764, 'CARYY': 10765, 'BES': 10766, 'sipport': 10767, 'h3h3': 10768, 'templer': 10769, 'AHHAHAHAA': 10770, 'Tuskar': 10771, 'Bought': 10772, 'ZZZZ': 10773, 'Intense': 10774, 'Repport': 10775, 'transh': 10776, 'ennd': 10777, 'idioot': 10778, 'okj': 10779, 'thou': 10780, 'TOSSING': 10781, 'YOUVE': 10782, 'ANYWAY': 10783, 'fuckler': 10784, 'SU': 10785, 'vl': 10786, 'LOOOOOOOL': 10787, 'ocampo': 10788, 'WAHAHA': 10789, 'defim': 10790, 'piggy': 10791, 'ways': 10792, 'sevn': 10793, 'tanks': 10794, 'roll': 10795, 'sharpest': 10796, 'bulb': 10797, 'usap': 10798, 'tau': 10799, 'broadswor': 10800, 'Marvel': 10801, 'sitted': 10802, 'PUTIN': 10803, 'THEH': 10804, 'tonker': 10805, 'members': 10806, 'baby4': 10807, 'thursday': 10808, 'enjoying': 10809, 'thirsty': 10810, 'Catcher': 10811, 'saba': 10812, 'dira': 10813, 'sell': 10814, 'ampas': 10815, 'disconected': 10816, 'loved': 10817, 'Give': 10818, 'WPEE': 10819, 'dirge': 10820, 'WEEEE': 10821, 'arruine': 10822, 'showed': 10823, 'ehat': 10824, 'Hows': 10825, 'bz': 10826, 'sua': 10827, 'wana': 10828, 'pgg': 10829, 'Winning': 10830, 'TIZ': 10831, 'TRAP': 10832, 'Relocate': 10833, 'fountaion': 10834, 'Fountain': 10835, 'nexrt': 10836, 'kaapa': 10837, 'finn': 10838, 'asd': 10839, 'ogin': 10840, 'gto': 10841, 'MAgnus': 10842, 'finds': 10843, 'ultie': 10844, '830': 10845, 'claim': 10846, 'FUNNNY': 10847, 'HOHO': 10848, 'AEWFIOoiufbFON': 10849, 'fresh': 10850, 'Afk': 10851, 'ssentry': 10852, 'MONGOLOIDS': 10853, 'broi': 10854, 'tihnk': 10855, 'jerking': 10856, 'jst': 10857, 'bhai': 10858, 'khaana': 10859, 'kha': 10860, 'ke': 10861, 'aaya': 10862, 'jewish': 10863, 'glose': 10864, 'tks': 10865, 'rx': 10866, 'Le': 10867, 'redhead': 10868, 'NUMBER': 10869, 'HARASSING': 10870, 'purch': 10871, 'reaver': 10872, 'waiitng': 10873, '120s': 10874, 'regret': 10875, 'BNYAK': 10876, 'GAYA': 10877, 'KAU': 10878, 'ganr': 10879, 'Almost': 10880, 'BOOOO': 10881, 'commited': 10882, 'KAPPAROSS': 10883, 'backup': 10884, 'dro4it': 10885, 'masturbate': 10886, 'YEY': 10887, 'WAH': 10888, 'FVB': 10889, 'kurwo': 10890, 'https': 10891, 'rupees': 10892, 'MUAHAGAHAHAHAHAAH': 10893, 'LOOOOOOOOOOOOL': 10894, 'sme': 10895, 'hahaahaha': 10896, 'idolaku': 10897, 'stinked': 10898, 'nut': 10899, 'itchy': 10900, 'title': 10901, 'loto': 10902, 'pity': 10903, 'FUCKing': 10904, 'worthless': 10905, 'HAHAHHAHAA': 10906, 'ahhaa': 10907, 'writed': 10908, 'weave': 10909, 'sadfaceariono': 10910, 'sadfacearino': 10911, 'plags': 10912, 'nigsd': 10913, 'bitchh': 10914, 'dieee': 10915, 'lala': 10916, 'factor': 10917, 'transition': 10918, 'morreu': 10919, 'susto': 10920, 'univeirse': 10921, 'dem': 10922, 'DIFFUSAL': 10923, 'OMFg': 10924, 'fuckings': 10925, 'mens': 10926, 'eeeidiot': 10927, 'racks': 10928, '2many': 10929, 'strg': 10930, 'MIDD': 10931, 'definitly': 10932, 'Yay': 10933, 'tastes': 10934, 'mu': 10935, 'biasa': 10936, 'tussle': 10937, 'cago': 10938, 'plzi': 10939, 'JAJAJAJJA': 10940, 'SABE': 10941, 'GOLPEAR': 10942, 'bomji': 10943, 'hhtfu': 10944, 'sur': 10945, 'WKWK': 10946, 'yeajj': 10947, '=P': 10948, 'fked': 10949, 'blat': 10950, 'portal': 10951, 'scroll': 10952, 'nevermind': 10953, 'possess': 10954, 'Urn': 10955, 'unneeded': 10956, 'vby': 10957, 'cleavbe': 10958, 'dragon': 10959, 'ax': 10960, 'babeeeeeeeeeeee': 10961, '5000': 10962, 'alkemist': 10963, 'kalemn': 10964, 'traitor': 10965, 'neither': 10966, 'stopm': 10967, 'itms': 10968, 'wewerw': 10969, '490': 10970, 'Wins': 10971, 'Rat': 10972, 'lemon': 10973, 'sqeezy': 10974, 'tabla': 10975, 'land': 10976, 'WhERE': 10977, 'lmol': 10978, 'errrr': 10979, 'rediculous': 10980, 'ritardati': 10981, 'hoook': 10982, 'lols': 10983, 'Ahahaha': 10984, 'boyos': 10985, 'ROPFL': 10986, 'bending': 10987, 'Hence': 10988, 'penetration': 10989, ';-;': 10990, 'stpd': 10991, 'zbs': 10992, 'With': 10993, 'abysal': 10994, 'pull': 10995, 'outlevling': 10996, 'plys': 10997, 'awhi': 10998, 'thge': 10999, 'fycj': 11000, 'LOLOLOLOL': 11001, 'allways': 11002, 'STANDING': 11003, 'me2': 11004, 'usage': 11005, 'haahah': 11006, 'naab': 11007, 'WELCOME': 11008, 'shakled': 11009, 'telstra': 11010, 'ulted': 11011, 'arl': 11012, 'complete': 11013, '338': 11014, 'baara': 11015, 'playe': 11016, 'accont': 11017, 'TERRORBLADE': 11018, 'EZZZZ': 11019, 'nervous': 11020, 'exec': 11021, 'madcuzbad': 11022, 'ilidan': 11023, 'QO': 11024, 'mothers': 11025, 'fortune': 11026, 'omw': 11027, 'THNIS': 11028, 'SORRU': 11029, 'mmmmm': 11030, 'Venge': 11031, '3winstreak': 11032, 'passing': 11033, 'demon': 11034, 'sus': 11035, 'oki': 11036, 'espect': 11037, 'Shup': 11038, 'furi': 11039, 'undaut': 11040, 'cosplay': 11041, 'Clock': 11042, 'sign': 11043, 'memorandum': 11044, 'clinton': 11045, 'loomis': 11046, 'hahahahaahaha': 11047, 'difussalk': 11048, 'Culda': 11049, 'nyet': 11050, 'pieces': 11051, 'fu9ck': 11052, 'lami': 11053, 'perrra': 11054, 'HAHAHAHAHHAHAH': 11055, 'HHAHAHAHAHAHAHAHAHAHAHAA': 11056, 'KUNKA': 11057, 'awe': 11058, 'f4': 11059, '13mins': 11060, 'qwait': 11061, 'FML': 11062, 'WTFFF': 11063, 'Surprise': 11064, 'golem': 11065, 'pode': 11066, 'mail': 11067, 'clockwork': 11068, 'woop': 11069, 'deffiing': 11070, 'cryts': 11071, 'zaaaaaaaaaaaaaaaaaaaaaa': 11072, 'SPICCY': 11073, 'Zero': 11074, 'GLGL': 11075, 'mads': 11076, 'brahs': 11077, 'isin': 11078, 'tryahrds': 11079, 'kfucking': 11080, 'shity': 11081, 'rockhead': 11082, 'pride': 11083, 'NS': 11084, 'riperino': 11085, 'Np': 11086, 'ramge': 11087, 'Hook': 11088, 'Fat': 11089, 'edz': 11090, 'Throws': 11091, 'rcn': 11092, 'whiners': 11093, '5s': 11094, 'ooon': 11095, 'kakakak': 11096, 'tlaking': 11097, 'oyu': 11098, 'STALKING': 11099, 'SHOTS': 11100, 'FIRED': 11101, 'tentando': 11102, 'ensinar': 11103, 'meu': 11104, 'precisa': 11105, 'comprar': 11106, 'matar': 11107, '8K': 11108, 'Nooo': 11109, 'acted': 11110, 'dickheads': 11111, 'aff': 11112, 'ruinetr': 11113, 'chaos': 11114, 'acutalyl': 11115, 'STUNS': 11116, 'ttuskk': 11117, 'p0ta': 11118, 'fit': 11119, 'TROW': 11120, 'togehtr': 11121, 'umaru': 11122, 'yayaya': 11123, 'donate': 11124, 'nvoid': 11125, 'linking': 11126, 'links': 11127, 'wrg': 11128, 'hac': 11129, 'thatga': 11130, 'chupa': 11131, 'shitshaker': 11132, 'VOD': 11133, 'okairi': 11134, 'STAR': 11135, 'START': 11136, 'sooooooooooooooooooooooooooo': 11137, 'PROBLEM': 11138, 'NBEVER': 11139, 'galeng': 11140, 'pauzka': 11141, 'unpauzka': 11142, 'zakonjelas': 11143, 'igra': 11144, 'BABE': 11145, 'hilakay': 11146, 'bubulok': 11147, 'nito': 11148, 'p0tang': 11149, 'ywa': 11150, 'jembut': 11151, 'nganaaaaaa': 11152, 'yf': 11153, 'hfdifyt': 11154, 'doNE': 11155, 'ALREDY': 11156, 'nojeira': 11157, 'nothign': 11158, '35m': 11159, 'ins': 11160, 'Safelaen': 11161, 'mazing': 11162, 'ought': 11163, 'DELA': 11164, 'WEST': 11165, 'XO': 11166, 'supamida': 11167, 'blablabla': 11168, 'movespeed': 11169, 'midgame': 11170, 'perspective': 11171, 'UFCVK': 11172, 'Looks': 11173, 'whaaaaaaaaaaaat': 11174, 'bich': 11175, 'mide': 11176, 'Whos': 11177, 'tnker': 11178, 'rudeness': 11179, 'friendliness': 11180, '1by1': 11181, 'pleeaassse': 11182, 'ECUADOR': 11183, 'mi6kiiiiiiiiiiiiiii': 11184, 'Sick': 11185, 'Rep': 11186, 'RESUME': 11187, 'AHHA': 11188, 'Nc1': 11189, 'nus': 11190, 'cosmetic': 11191, 'winsgaes': 11192, 'kunkkar': 11193, 'beinga': 11194, 'chron': 11195, 'rampae': 11196, 'htings': 11197, 'sil': 11198, 'yuor': 11199, 'autos': 11200, 'microing': 11201, 'Carry': 11202, 'Blame': 11203, 'boosted': 11204, '524': 11205, 'Here': 11206, 'Take': 11207, 'nee': 11208, 'agamis': 11209, 'ZZZZZ': 11210, 'ISNT': 11211, 'MORPHLINGS': 11212, 'FAULT': 11213, 'topor': 11214, 'htat': 11215, 'snowballing': 11216, 'hacker': 11217, 'zeusss': 11218, 'ultiiiii': 11219, 'strats': 11220, 'Tipo': 11221, 'daj': 11222, 'ushel': 11223, 'iz': 11224, 'stuna': 11225, 'dued': 11226, 'compassion': 11227, 'uptime': 11228, 'age': 11229, 'wouldfk': 11230, 'cliff': 11231, 'thug': 11232, 'fuckkin': 11233, 'Lich': 11234, 'Scary': 11235, 'kapap': 11236, 'bitching': 11237, 'illusion': 11238, 'proofs': 11239, 'CURRIER': 11240, 'healtrain': 11241, 'leet': 11242, 'Yahh': 11243, 'Ahahahahah': 11244, 'AHahhaahahah': 11245, 'Hahahhaha': 11246, 'YEah': 11247, 'yaphets': 11248, 'rushing': 11249, 'diffu': 11250, 'Assholes': 11251, 'aretard': 11252, 'ebtter': 11253, 'umanner': 11254, 'DAMI': 11255, 'jennifer': 11256, 'aniston': 11257, 'bick': 11258, 'pone': 11259, 'plzzz': 11260, 'metapicker': 11261, 'atard': 11262, 'MARICA': 11263, 'desk': 11264, 'burning': 11265, 'byr': 11266, 'mostimpotant': 11267, 'Alceh': 11268, 'bengap': 11269, 'bouhgt': 11270, 'blamer': 11271, 'TMR': 11272, 'AGUANTA': 11273, 'PSS': 11274, 'CRTM': 11275, 'ggoing': 11276, 'aganim': 11277, 'HIGHLIGHT': 11278, 'kkkk': 11279, 'commment': 11280, 'ko': 11281, 'danh': 11282, 'thua': 11283, 'lau': 11284, 'roi': 11285, 'wha': 11286, 'pple': 11287, 'healers': 11288, 'jooked': 11289, 'Eul': 11290, 'wooo': 11291, 'rick': 11292, 'morty': 11293, 'annoucner': 11294, 'jigg': 11295, 'certainly': 11296, 'rain': 11297, 'hahahahahahaha': 11298, '900HP': 11299, 'poitns': 11300, 'iam': 11301, 'Perfect': 11302, '<<<<<': 11303, 'expressed': 11304, 'fead': 11305, 'phreshin': 11306, 'striggers': 11307, 'haist': 11308, 'Tgate': 11309, 'ilknjrhg': 11310, 'Bro': 11311, 'fuqn': 11312, 'RPs': 11313, 'Magnus': 11314, 'thusfar': 11315, 'Catch': 11316, 'STD': 11317, 'Awwh': 11318, 'accident': 11319, 'yessssssssssssssssss': 11320, 'mena': 11321, 'looool': 11322, 'human': 11323, 'sexi': 11324, 'wjo': 11325, 'wodden': 11326, 'nws': 11327, 'rought': 11328, 'imdeed': 11329, 'elfticle': 11330, 'restarted': 11331, 'LOOOOOOOOOOOOOOOOOOOL': 11332, 'Ded': 11333, 'GLIMMER': 11334, 'TAB': 11335, 'moneyyy': 11336, 'BEM': 11337, 'JOGADO': 11338, 'inchs': 11339, 'llife': 11340, 'BADS': 11341, 'STUPIDS': 11342, 'PINOYS': 11343, 'Hf': 11344, 'baaaaaag': 11345, 'mto': 11346, 'stab': 11347, 'mapxak': 11348, 'whata': 11349, 'SHOW': 11350, 'esx': 11351, 'duded': 11352, 'lolqop': 11353, 'quien': 11354, 'bruto': 11355, 'PETER': 11356, 'fIRST': 11357, 'kasrma': 11358, 'bithc': 11359, 'SMALL': 11360, 'AFTERALL': 11361, 'MICRO': 11362, 'mapa': 11363, 'Angry': 11364, 'buffalo': 11365, 'aroound': 11366, 'trist': 11367, 'WYWERN': 11368, 'etcetcetc': 11369, 'pedge': 11370, '228': 11371, 'furious': 11372, '040': 11373, 'bright': 11374, '185': 11375, 'ajaja': 11376, 'glim': 11377, 'therei': 11378, 'succes': 11379, 'thnk': 11380, 'specially': 11381, 'HAHAHHAHA': 11382, 'twot': 11383, 'LMFASO': 11384, ':FMAOP': 11385, 'Lf': 11386, 'vbl': 11387, 'yjhv': 11388, 'nfr': 11389, 'HOok': 11390, 'auawj': 11391, 'egofkl': 11392, 'PLAYE': 11393, 'ENOUGH': 11394, 'FFF': 11395, 'exz': 11396, 'campaign': 11397, 'tenks': 11398, 'exicte': 11399, 'ono': 11400, 'twr': 11401, '=M': 11402, 'bieng': 11403, 'emo': 11404, 'shittest': 11405, 'windrun': 11406, 'italy': 11407, 'GENOIUS': 11408, 'tricky': 11409, ':X': 11410, 'GARBAGE': 11411, 'fuycku': 11412, 'monney': 11413, 'doooo': 11414, 'eeeeeet': 11415, 'eeeeet': 11416, 'tranq': 11417, 'ai': 11418, 'aeg': 11419, 'aego': 11420, 'pissy': 11421, 'KWOWK': 11422, 'KWOKWOWK': 11423, 'fired': 11424, 'bitchas': 11425, 'ACTUALLY': 11426, 'motivation': 11427, 'rasta': 11428, 'motherfucekrew': 11429, 'Feeling': 11430, 'ful': 11431, 'chilled': 11432, 'brosky': 11433, 'noi': 11434, 'retads': 11435, 'FUCKSDF': 11436, 'SKILS': 11437, 'Winter': 11438, 'basics': 11439, 'GOLDEN': 11440, 'SHOVE': 11441, 'SKADI': 11442, 'BASHER': 11443, 'anjing': 11444, 'Lose': 11445, 'massively': 11446, 'regbnt': 11447, 'utv': 11448, 'rkbyrp': 11449, 'dfvb': 11450, 'hzjv': 11451, 'tuftn': 11452, 'UDAH': 11453, 'AEGIS': 11454, 'LU': 11455, 'BRAINLESS': 11456, 'HAHAHHAHHAHA': 11457, 'leddit': 11458, 'LOTAR': 11459, 'htfu': 11460, 'Vl': 11461, 'xanh': 11462, 'vy': 11463, 'expensice': 11464, 'danny': 11465, 'volteo': 11466, 'TECHIES': 11467, 'everywehere': 11468, 'unskill': 11469, 'scurbs': 11470, 'canyou': 11471, 'fuaskf': 11472, 'Bristle': 11473, 'jhave': 11474, 'GGgg': 11475, 'improve': 11476, 'properly': 11477, '400g': 11478, 'myh': 11479, 'REALL': 11480, 'jgug': 11481, 'machine': 11482, 'omgg': 11483, 'farrrrrrk': 11484, 'iodiot': 11485, 'horseman': 11486, 'chegamos': 11487, 'ao': 11488, 'heterosexual': 11489, 'brainly': 11490, 'akiro': 11491, 'HUH': 11492, 'submit': 11493, 'Crom': 11494, '13:8': 11495, 'CARRIED': 11496, 'dayuuuuuum': 11497, 'repot': 11498, 'hoe': 11499, '3vs5': 11500, 'Luna': 11501, 'loptop': 11502, 'Creep': 11503, 'ACID': 11504, 'SPRAY': 11505, 'RP': 11506, 'EBOLA': 11507, 'anyyhing': 11508, '250': 11509, 'mang': 11510, 'EPPI': 11511, 'AHHAHAHAH': 11512, 'army': 11513, 'pudsge': 11514, 'coommend': 11515, 'fukking': 11516, 'Worth': 11517, 'allow': 11518, 'jack': 11519, 'ie': 11520, 'papech': 11521, 'podrubil': 11522, 'seeu': 11523, 'launched': 11524, 'immop': 11525, 'bladmail': 11526, 'aime': 11527, 'Ahi': 11528, 'Ayyyy': 11529, 'Ezz': 11530, 'eiiii': 11531, 'calculator': 11532, 'Gk': 11533, 'rexxar': 11534, 'ALYANSOV': 11535, 'NASMOTRELIS': 11536, 'SOLYANOVO': 11537, 'alwayz': 11538, 'beffore': 11539, 'SUQOOA': 11540, 'famapage': 11541, 'ra': 11542, 'embarasing': 11543, 'ft': 11544, 'ASDIJANOSDAS': 11545, 'plyer': 11546, 'uyy': 11547, 'jag': 11548, 'thnak': 11549, 'ggwpp': 11550, 'WTB': 11551, 'SUN': 11552, 'STRIKE': 11553, 'kjkustu': 11554, 'disrupter': 11555, 'DEFF': 11556, 'culling': 11557, 'kuunka': 11558, 'gooddddddddddddd': 11559, 'Soup': 11560, 'Kitchen': 11561, 'fab': 11562, 'WAHAHHA': 11563, 'nop': 11564, 'umad': 11565, 'monogolian': 11566, 'ggo': 11567, 'ahaahaah': 11568, 'RUn': 11569, 'resdtart': 11570, 'LATE': 11571, 'siap': 11572, 'ACHE': 11573, 'WHATS': 11574, 'WRONGGGG': 11575, 'OUCH': 11576, 'KUTN': 11577, 'wAS': 11578, 'FUKING': 11579, 'ROUND': 11580, 'hlp': 11581, 'xboct': 11582, 'mther': 11583, 'GRET': 11584, 'everysingle': 11585, '1z1': 11586, 'juz': 11587, 'easyyyyyyyyyyyyyyyyyyy': 11588, 'freefarmed': 11589, 'timer': 11590, 'flag': 11591, 'stepd': 11592, 'xdddd': 11593, 'devoting': 11594, '0:00': 11595, 'CHALLENGE': 11596, 'ting': 11597, 'CRYSTAL': 11598, 'vete': 11599, 'xonshaotmare': 11600, 'neiter': 11601, 'ege': 11602, 'ultrakill': 11603, 'cf': 11604, 'saimung': 11605, 'ofline': 11606, 'sryt': 11607, 'morps': 11608, 'WINDOWS': 11609, 'UPDATE': 11610, 'a3': 11611, 'slivaetsya': 11612, 'alrighty': 11613, 'korean': 11614, 'mema': 11615, 'twitter': 11616, 'mech': 11617, 'v1': 11618, 'bicht': 11619, '60min': 11620, 'mythical': 11621, 'jojojojojo': 11622, 'wkwkwkkw': 11623, 'brushan': 11624, 'GANKS': 11625, 'TREASH': 11626, 'cary': 11627, 'Ow': 11628, 'shutting': 11629, 'PUnit': 11630, 'XAXA': 11631, 'BIATCH': 11632, 'h8': 11633, 'yiyi': 11634, 'mam': 11635, 'PORR': 11636, 'abaddon': 11637, 'jajjaa': 11638, 'ultimates': 11639, 'keper': 11640, 'jode': 11641, 'mrda': 11642, 'lowl': 11643, 'honesty': 11644, 'loan': 11645, 'nin': 11646, 'sanya': 11647, 'havn': 11648, 'winnign': 11649, 'COINS': 11650, 'Nobody': 11651, 'defence': 11652, 'guarding': 11653, 'siht': 11654, 'memeing': 11655, 'AHAHAAH': 11656, 'cooperate': 11657, 'dident': 11658, 'dide': 11659, 'nahuy': 11660, 'idi': 11661, 'goverment': 11662, 'hHAHAHA': 11663, 'wauiting': 11664, 'desperationj': 11665, 'REALY': 11666, 'sCARE': 11667, 'frens': 11668, 'wpee': 11669, 'inhouse': 11670, 'REPORTE': 11671, 'lucker': 11672, 'syllabear': 11673, 'legend': 11674, 'catapult': 11675, 'sooooo': 11676, 'ride': 11677, 'wreking': 11678, 'ahrd': 11679, 'zmuffinman': 11680, 'holu': 11681, 'shittttt': 11682, 'spark': 11683, 'OI': 11684, 'IDI': 11685, 'NYLEVOY': 11686, 'HAHAHAHAHAHAHAHAHAHAHAHAHAHA': 11687, 'HAHAHAHAHAHAHAHAHAHA': 11688, 'sinned': 11689, 'owh': 11690, '2kmmr': 11691, 'las': 11692, 'scorpion': 11693, 'Made': 11694, 'USA': 11695, 'Ultie': 11696, 'downside': 11697, 'enimga': 11698, 'matters': 11699, 'surgery': 11700, 'duble': 11701, 'wornggg': 11702, 'coiier': 11703, 'virgins': 11704, 'faggors': 11705, 'HURRY': 11706, 'dweller': 11707, 'looya': 11708, 'realise': 11709, 'breakes': 11710, 'shackleshot': 11711, 'dan': 11712, 'gib': 11713, 'LELELEL': 11714, 'fissure': 11715, 'suppoort': 11716, 'awaw': 11717, 'sed': 11718, 'cried': 11719, 'torture': 11720, 'JOke': 11721, 'couri': 11722, 'coaching': 11723, 'yesss': 11724, 'billing': 11725, 'wron': 11726, 'Feeding': 11727, 'blya': 11728, 'Empire': 11729, 'Liquid': 11730, 'HEHEHEHEHEEHEHEHEHEHEHEHEEHEHEHEHEHEHEHEHEHEEHEHEHEHEHEHEE': 11731, 'HUHUHUHUHUHUHHAHAAHAHAHAUAHUAHUAHAUHAUHAUHAUHUAHAUHAUAHUAHUAHAUAHUAHUHEHEUEHUHEUEHUEHUEHUE': 11732, 'HUEHUEUHUEHUEHUEHUEHUEHUEHUEHUE': 11733, 'konw': 11734, 'uf': 11735, 'simples': 11736, 'creazy': 11737, 'okeh': 11738, 'email': 11739, 'remove': 11740, 'science': 11741, 'Fuckingmmr': 11742, 'analed': 11743, 'MALES': 11744, 'buly': 11745, 'pease': 11746, 'intent': 11747, 'semblance': 11748, 'tqtq': 11749, 'teeny': 11750, '175': 11751, 'challange': 11752, 'tarzan': 11753, 'asssisst': 11754, 'Ti6': 11755, 'sreated': 11756, 'meppo': 11757, 'msgd': 11758, 'Abuser': 11759, 'GALACTIC': 11760, '1x5': 11761, 'LEave': 11762, 'tornade': 11763, 'hahaahahaha': 11764, 'oir': 11765, 'absurb': 11766, 'Silencer': 11767, 'mmrs': 11768, 'Takes': 11769, 'huska': 11770, 'Calm': 11771, 'ahs': 11772, 'parody': 11773, 'REpORT': 11774, 'XDX': 11775, 'ECHJO': 11776, 'FCUK': 11777, 'TESAM': 11778, 'linavs': 11779, 'basterds': 11780, 'meppen': 11781, 'code': 11782, '11mins': 11783, '22mins': 11784, 'minus': 11785, 'larth': 11786, 'dragging': 11787, 'drawing': 11788, 'sien': 11789, 'backdoor': 11790, 'HOOORRRRYYY': 11791, 'SHHIIITTT': 11792, 'recing': 11793, 'DJON': 11794, 'SINA': 11795, 'twatted': 11796, 'prick': 11797, 'jjust': 11798, '5555555555555': 11799, 'gahahhhhh': 11800, 'LEE': 11801, 'PAL': 11802, 'KR': 11803, 'becuase': 11804, '150': 11805, 'Love': 11806, 'active': 11807, 'WIT': 11808, 'THEIR': 11809, 'ROFLLLL': 11810, 'YALL': 11811, 'MATES': 11812, 'weaboo': 11813, 'kden': 11814, 'slown': 11815, 'Super': 11816, 'mael': 11817, 'teeam': 11818, 'heff': 11819, 'minded': 11820, 'PIRT': 11821, 'toewr': 11822, 'shallow': 11823, 'AXAXXAXA': 11824, 'Tanginamo': 11825, 'FUC': 11826, 'KNO': 11827, 'GANKED': 11828, 'atack': 11829, 'COMPEDIUM': 11830, 'weakest': 11831, '7u7': 11832, 'KRBEN': 11833, 'LEICHFANZ': 11834, 'TEMAMMATE': 11835, 'WAHT': 11836, 'steel': 11837, 'coureirs': 11838, 'eanwhile': 11839, 'shkel': 11840, 'fnatic': 11841, 'SLARKJ': 11842, 'wirdo': 11843, 'ASDFSADFASDFASDFASDFASFASDFASDFSAFASDFSDAFSADFASFADSFASDFASDFASFASDFASDFSADFSADFASDFASDFASDFADSFASDFSADFDASFDSAFDASFASDFASDFAS': 11844, 'proo': 11845, 'sdelayu': 11846, 'ru9n': 11847, 'fukboi': 11848, 'SAMUL': 11849, 'cumb': 11850, 'vf': 11851, '5th': 11852, 'seee': 11853, 'ac': 11854, 'overrated': 11855, 'insect': 11856, 'WITHOUT': 11857, 'POINT': 11858, 'compendium': 11859, 'bvoid': 11860, 'RUSSTARD': 11861, 'ler': 11862, 'bnro': 11863, 'awkward': 11864, 'fucku': 11865, 'unlike': 11866, 'maxing': 11867, 'sandking': 11868, 'jungling': 11869, 'refusing': 11870, 'afterwards': 11871, 'Ahahahha': 11872, 'nic2': 11873, 'more2': 11874, 'dde': 11875, 'WOULD': 11876, 'eaglesong': 11877, 'screenshoot': 11878, 'cli': 11879, 'Maybe': 11880, 'besides': 11881, 'leech': 11882, 'cung': 11883, 'qui': 11884, 'cangkeman': 11885, 'immature': 11886, 'slant': 11887, 'fxxk': 11888, 'goodboy': 11889, 'weve': 11890, 'knife': 11891, 'chode': 11892, 'baracks': 11893, 'Co': 11894, 'ooooooooooooooooo': 11895, 'tickect': 11896, 'GALAHD': 11897, 'ALUUKHAWAKBAR': 11898, 'uless': 11899, 'frank': 11900, 'BHITTER': 11901, 'MUCH': 11902, 'lencer': 11903, 'sauy': 11904, 'enuf': 11905, 'BET': 11906, 'exploded': 11907, 'TRI': 11908, 'PRETTY': 11909, 'nlob': 11910, 'vamatem': 11911, '=-': 11912, 'imposible': 11913, 'suuport': 11914, 'accepted': 11915, 'EleNiggle': 11916, 'msging': 11917, 'sthap': 11918, 'GONE': 11919, 'RADIANCE': 11920, 'SANDY': 11921, 'HTJGHN': 11922, 'GKP': 11923, 'CA': 11924, 'kristen': 11925, 'laste': 11926, 'ilike': 11927, 'tammates': 11928, 'smell': 11929, 'iceshards': 11930, 'shards': 11931, 'horny': 11932, 'polie': 11933, 'TJHAT': 11934, 'vbane': 11935, 'HAHAHAAHHAHAHHAAAAH': 11936, 'w8ing': 11937, 'inch': 11938, '30k': 11939, 'networth': 11940, 'mroe': 11941, '66mins': 11942, 'DOGE': 11943, 'fuknh': 11944, 'gtamne': 11945, 'dousnt': 11946, 'tryna': 11947, 'TRYNA': 11948, 'picE': 11949, 'CRAP': 11950, 'fiSH': 11951, 'didntt': 11952, 'imrpeganted': 11953, 'cuoi': 11954, 'lon': 11955, '1651': 11956, 'murdered': 11957, 'idioot22': 11958, 'EAYH': 11959, 'Taking': 11960, 'pinaka': 11961, 'buong': 11962, 'mundo': 11963, 'aylmao': 11964, 'rpeorten': 11965, 'entren': 11966, 'noma': 11967, 'pero': 11968, 'whrre': 11969, 'izz': 11970, 'emdio': 11971, 'dijo': 11972, 'llevaran': 11973, 'kupal': 11974, '12y': 11975, 'rembo': 11976, 'wacth': 11977, 'UEBISHE': 11978, 'pornsite': 11979, 'chased': 11980, 'kin': 11981, 'jippers': 11982, 'trippers': 11983, '2721': 11984, 'awtsu': 11985, 'spoted': 11986, 'goood': 11987, '1450': 11988, 'sladdar': 11989, 'welcum': 11990, 'forcestaff': 11991, 'analfisting': 11992, 'neva': 11993, 'meister': 11994, 'unpuase': 11995, 'UVE': 11996, 'GAURDIANS': 11997, 'Rata': 11998, 'PEENOYS': 11999, 'foodtrip': 12000, 'lell': 12001, 'WIPEOUT': 12002, 'sue': 12003, 'copyright': 12004, 'infringement': 12005, 'PDUGA': 12006, 'RAGE': 12007, 'alca': 12008, 'bitchass': 12009, 'awkawkakwkwa': 12010, 'lachi': 12011, 'retrad': 12012, 'square': 12013, 'est': 12014, 'silncer': 12015, 'SINGSING': 12016, 't4': 12017, 'serves': 12018, 'GGGGGGGGGGGGGGGGG': 12019, 'gamesr': 12020, 'Since': 12021, 'commead': 12022, '5v1': 12023, 'retk': 12024, 'bolder': 12025, 'anybodsy': 12026, 'elkse': 12027, 'masters': 12028, 'TAke': 12029, 'gahaha': 12030, 'ranfom': 12031, 'thd': 12032, 'godong': 12033, 'godthel': 12034, 'firstpickl': 12035, 'emotional': 12036, 'stinky': 12037, 'pucj': 12038, 'gyrohc': 12039, 'marko': 12040, 'Stun': 12041, 'pq': 12042, 'coel': 12043, 'masta': 12044, 'hating': 12045, 'rfc': 12046, 'BASE': 12047, 'onkly': 12048, 'sielencer': 12049, 'noobshit': 12050, 'DETECTED': 12051, 'loster': 12052, 'Ina': 12053, 'madness': 12054, 'service': 12055, 'spik': 12056, 'englis': 12057, 'OIHHH': 12058, 'taco': 12059, 'vaginitis': 12060, 'Early': 12061, 'loll': 12062, 'dotra': 12063, 'ngewes': 12064, 'infront': 12065, 'comr': 12066, 'WTFUCK': 12067, 'NIGGAS': 12068, 'goddamn': 12069, 'logi': 12070, 'reallyh': 12071, 'fucktards': 12072, 'thomas': 12073, 'cloack': 12074, 'plase': 12075, 'REPORTENME': 12076, 'commend2': 12077, 'fucktad': 12078, 'IMA': 12079, 'MAKE': 12080, 'y3a': 12081, 'performance': 12082, 'bakbuki': 12083, 'torando': 12084, 'lacky': 12085, 'pleasse': 12086, 'crimson': 12087, 'guardian': 12088, 'btf': 12089, 'QUIT': 12090, 'applaud': 12091, 'observer': 12092, 'hahahiz': 12093, 'uwon': 12094, 'rightr': 12095, 'ughh': 12096, 'gegege': 12097, 'foo': 12098, 'regrets': 12099, 'jung': 12100, 'gry': 12101, 'VENO': 12102, 'balnce': 12103, 'GRREDY': 12104, 'vd': 12105, 'bd': 12106, 'Zenokaiais': 12107, 'actualyl': 12108, 'THWN': 12109, 'ORAXCLE': 12110, 'WIM': 12111, 'NB': 12112, 'yoor': 12113, 'huhuh': 12114, 'record': 12115, 'puch': 12116, 'ACLHE': 12117, 'google': 12118, 'Neaaaaaaaar': 12119, 'huhuhu': 12120, 'ads': 12121, 'LMOFA': 12122, 'Yah': 12123, 'blakc': 12124, 'hol': 12125, 'HHSHSDHSD': 12126, 'ANIMAL': 12127, 'wh': 12128, 'Da': 12129, 'toaday': 12130, 'Push': 12131, 'FREAKING': 12132, 'KEYBOARD': 12133, 'WARRIOR': 12134, 'fku': 12135, 'uya': 12136, 'kayyyy': 12137, 'esss': 12138, 'Share': 12139, 'wadap': 12140, 'bc': 12141, 'ditto': 12142, 'yeyah': 12143, 'ezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz': 12144, 'reisen': 12145, 'itny': 12146, 'rperot': 12147, 'ama': 12148, 'treee': 12149, 'fro': 12150, 'mthat': 12151, 'JAJAJAJA': 12152, '4th': 12153, 'HJAHH': 12154, 'uguys': 12155, 'gogog': 12156, 'zhdu': 12157, 'forgive': 12158, 'dictates': 12159, 'SOOOO': 12160, 'NOOOB': 12161, 'SEC': 12162, 'Id': 12163, 'ont': 12164, 'QUITRR': 12165, 'fiesta': 12166, 'esta': 12167, 'lica': 12168, 'FIESTA': 12169, 'Dcm': 12170, 'ngay': 12171, 'PUssy': 12172, 'hahaahahahahaha': 12173, 'NOOOOOOOO': 12174, 'lows': 12175, 'qopp': 12176, 'MEAN': 12177, 'niet': 12178, 'quesiton': 12179, 'tops': 12180, 'buns': 12181, 'hasnt': 12182, '1rs': 12183, '1rst': 12184, 'RECION': 12185, 'kate': 12186, 'ness': 12187, 'GGGG': 12188, 'builddings': 12189, 'BOOOM': 12190, 'WHYY': 12191, 'WHYYY': 12192, 'prretty': 12193, 'Shet': 12194, 'struggled': 12195, 'LAN': 12196, 'brokenn': 12197, 'multiple': 12198, 'yeanhj': 12199, 'diurrrr': 12200, 'saiyan': 12201, 'laik': 12202, 'IMBA': 12203, 'Black': 12204, 'nnnnnnnnnnnnnnnn': 12205, 'gooooood': 12206, 'pepet': 12207, 'wpp': 12208, 'tinke': 12209, 'jungler': 12210, 'akf': 12211, 'HGhaha': 12212, 'b9': 12213, 'barely': 12214, 'UIFHIUWEHFOUIHWEF': 12215, 'twisted': 12216, 'VLADS': 12217, 'hung': 12218, 'maddest': 12219, 'lightr': 12220, 'float': 12221, 'rap': 12222, 'easir': 12223, 'yewa': 12224, 'pissing': 12225, 'gratification': 12226, 'aaaahaaajajaa': 12227, 'atos': 12228, '2ez4WR': 12229, 'Mexicans': 12230, 'exex': 12231, 'waved': 12232, 'BANE': 12233, 'JAJAJAAJAJAJA': 12234, 'againsty': 12235, '8ks': 12236, 'LIAT': 12237, 'BANGSAT': 12238, 'taxi': 12239, 'driver': 12240, '345': 12241, '00': 12242, 'rebooting': 12243, 'ECHO': 12244, 'ppls': 12245, '348': 12246, 'bruuuhh': 12247, 'agaw': 12248, 'naa': 12249, 'meeting': 12250, 'chatwheel': 12251, 'tinhker': 12252, 'qesseo': 12253, 'plaryer': 12254, 'spisn': 12255, 'mtued': 12256, 'wotn': 12257, 'UH': 12258, 'UHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH': 12259, 'Agies': 12260, 'SIDE': 12261, 'spectra': 12262, 'barracks': 12263, 'tanked': 12264, 'beginning': 12265, 'wanting': 12266, 'loseing': 12267, 'semi': 12268, 'braindeadm': 12269, 'onkey': 12270, 'bullshjit': 12271, 'lucu': 12272, 'lu': 12273, 'ezmode': 12274, 'smoking': 12275, 'fuckton': 12276, 'NOIOO': 12277, 'USCK': 12278, 'wastn': 12279, 'vsf': 12280, 'tn': 12281, 'chemical': 12282, 'component': 12283, 'recently': 12284, 'FEEDED': 12285, 'laggggggggggggggggggggggg': 12286, 'freaking': 12287, 'gahi': 12288, 'kaayo': 12289, 'haahh': 12290, 'pult': 12291, 'gameruining': 12292, 'moofta': 12293, 'salrk': 12294, 'relentless': 12295, 'chats': 12296, 'dooooooooom': 12297, 'DUUUUDe': 12298, 'Wish': 12299, 'Mate': 12300, 'bill': 12301, 'waldo': 12302, 'bitched': 12303, 'folks': 12304, 'lately': 12305, 'rid': 12306, 'Reporta': 12307, 'cheisnese': 12308, 'olso': 12309, 'present': 12310, 'Saw': 12311, '2dedos': 12312, 'Miracle': 12313, 'sgut': 12314, 'UNPY': 12315, 'crackwhores': 12316, 'router': 12317, 'AI': 12318, 'SIA': 12319, 'HAROMO': 12320, 'nagelfar': 12321, 'ojh': 12322, 'bugging': 12323, 'disappearing': 12324, 'incest': 12325, 'nicedoom': 12326, 'tamrae': 12327, 'wlangbawas': 12328, 'RATA': 12329, 'shapes': 12330, 'explane': 12331, 'famr': 12332, 'travel': 12333, 'ache': 12334, 'eulsed': 12335, 'MOOOOOOOH': 12336, 'FAGGOT': 12337, 'slaughtered': 12338, ':{': 12339, '06': 12340, 'ZE': 12341, 'taling': 12342, 'urejsut': 12343, 'homosexual': 12344, 'lolzzz': 12345, 'andu': 12346, 'youporn': 12347, 'humble': 12348, 'WORKING': 12349, 'INFILTRATING': 12350, 'xDDDDD': 12351, 'refused': 12352, 'rpg': 12353, 'FPS': 12354, 'ANYMORE': 12355, 'sayin': 12356, 'engalndski': 12357, 'lunatic': 12358, 'utterly': 12359, 'deranged': 12360, 'rpeorting': 12361, 'UPHILL': 12362, 'FIUCK': 12363, 'CNACNCELED': 12364, 'UWANT': 12365, 'GGGGGG': 12366, 'ssss': 12367, 'initiate': 12368, 'profeed': 12369, 'talento': 12370, 'GLOBAL': 12371, 'booster': 12372, 'warudo': 12373, 'brainless': 12374, 'TEL': 12375, 'FSSIISURE': 12376, 'DINT': 12377, 'GEt': 12378, 'HITTERS': 12379, 'nyakl': 12380, 'wits': 12381, 'tehn': 12382, 'highlight': 12383, 'prediccion': 12384, 'oooooo': 12385, 'ckise': 12386, 'mnvp': 12387, 'otherwise': 12388, 'spoill': 12389, 'excite': 12390, 'sny': 12391, 'dst': 12392, 'fkb': 12393, 'mmmr': 12394, 'nnt': 12395, 'Geegee': 12396, 'singlehandely': 12397, ':ddd': 12398, 'manfight': 12399, 'creapwave': 12400, '50th': 12401, 'pig': 12402, 'elo': 12403, '0coins': 12404, 'htink': 12405, 'shoiuld': 12406, 'askd': 12407, 'esteroids': 12408, 'cas': 12409, 'kunkaa': 12410, 'iria': 12411, 'direto': 12412, 'inteligente': 12413, 'powerful': 12414, 'reconsider': 12415, 'Loll': 12416, 'spawned': 12417, 'Smart': 12418, 'botbo9t': 12419, 'three': 12420, 'fiz': 12421, 'oq': 12422, 'nucna': 12423, 'cotnra': 12424, 'hardcore': 12425, 'mans': 12426, 'overly': 12427, 'dramatic': 12428, 'sinadya': 12429, 'lke': 12430, 'fututre': 12431, 'chicks': 12432, 'ehehehe': 12433, 'hikhik': 12434, 'OIIII': 12435, 'solar': 12436, 'lieslie': 12437, 'AHAHAHAHAHHA': 12438, 'sideeee': 12439, 'nice1': 12440, 'HAYOP': 12441, 'COULDNT': 12442, 'stars': 12443, 'clocks': 12444, 'T3': 12445, 'Wejiahbekjebqkjedbqkjd': 12446, 'cat': 12447, 'houise': 12448, 'tacnies': 12449, 'crEap': 12450, '2m': 12451, '3m': 12452, 'bnut': 12453, '30m': 12454, 'beastmode': 12455, 'rise': 12456, 'wwat': 12457, 'fw': 12458, 'met': 12459, 'PERRO': 12460, 'WtF': 12461, 'terussss': 12462, 'whoa': 12463, '201': 12464, 'surte': 12465, 'rez': 12466, 'SCRIPTER': 12467, 'SPELL': 12468, 'nyo': 12469, 'slota': 12470, '39': 12471, 'minut': 12472, 'ju': 12473, 'Wasn': 12474, 'unwinnable': 12475, 'sIark': 12476, 'mainly': 12477, 'NING': 12478, 'silenser': 12479, '2005': 12480, 'Slow': 12481, 'nto': 12482, 'comemnd': 12483, 'pricks': 12484, 'kritami': 12485, 'typoe': 12486, 'sozdanie': 12487, '8D': 12488, 'AHHAHAHA': 12489, 'nAH': 12490, '=6k': 12491, 'booty': 12492, 'nm': 12493, 'Ey': 12494, 'Suicide': 12495, 's4': 12496, 'zZz': 12497, 'toplane': 12498, 'waddup': 12499, 'cpu': 12500, 'harem': 12501, 'gameplan': 12502, 'HAEHAEHAE': 12503, 'Facke': 12504, 'discoonect': 12505, 'munny': 12506, 'gangerion': 12507, 'chickenon': 12508, 'TUSKY': 12509, 'shockingly': 12510, 'NvM': 12511, 'deni': 12512, 'SADUHHSAD': 12513, 'COININ': 12514, 'ASU': 12515, 'woooooooaw': 12516, 'Mr': 12517, 'katkovich': 12518, 'hayy': 12519, 'nevertheless': 12520, 'lolololol': 12521, 'shhhh': 12522, 'Shh': 12523, 'whaaaaaaat': 12524, 'GGGGGGGGGGGGGG': 12525, 'untol': 12526, 'ibundak': 12527, 'stoy': 12528, 'hetting': 12529, 'charger': 12530, 'aSShole': 12531, 'france': 12532, 'cuppa': 12533, 'marry': 12534, 'bucther': 12535, 'alrigh': 12536, 'Yep': 12537, 'dealer': 12538, 'LEGENDARY': 12539, 'apperenty': 12540, 'doestn': 12541, 'baitttttt': 12542, 'creepo': 12543, 'yEAH': 12544, 'coutnerpickers': 12545, 'JOKER': 12546, 'noovs': 12547, 'slarke': 12548, 'skulls': 12549, 'ggwomi': 12550, 'mich': 12551, 'auch': 12552, 'meca': 12553, 'Debuff': 12554, 'loudest': 12555, 'aaaaaaaaaaaaaaaaa': 12556, 'linken': 12557, 'park': 12558, ':laugh': 12559, ':Laugh': 12560, 'AYUDEN': 12561, 'GUSTARIA': 12562, 'TOQUE': 12563, 'ESAS': 12564, 'LACRAS': 12565, 'respawned': 12566, 'RARE': 12567, 'healthbar': 12568, 'Lmfao': 12569, 'BUGOK': 12570, 'farms': 12571, 'dkajwd': 12572, 'ladja': 12573, 'okeyy': 12574, 'ecchi': 12575, 'rusty': 12576, 'bitchez': 12577, 'fa': 12578, 'tiome': 12579, 'LOLL': 12580, 'Deward': 12581, 'yu': 12582, 'medium': 12583, 'jiji': 12584, 'realistic': 12585, 'shackel': 12586, 'BAGO': 12587, 'mastered': 12588, 'WEWEWEW': 12589, 'fuckimg': 12590, 'suppoprt': 12591, 'mekans': 12592, 'LOLOLOKOL': 12593, 'licj': 12594, 'tjhanks': 12595, 'JAAJAJAJAJJA': 12596, 'kawkawkawkwakaw': 12597, 'tyes': 12598, 'nahui': 12599, 'vsem': 12600, 'poxui': 12601, 'HAHAHAHHA': 12602, 'shodnt': 12603, 'shag': 12604, 'dl': 12605, 'HGHAHAHAHAAH': 12606, 'alachi': 12607, 'mayra': 12608, 'moutch': 12609, 'Shakermon': 12610, 'dandom': 12611, 'mantaed': 12612, 'sites': 12613, 'Warded': 12614, 'CHCUA': 12615, 'ABADON': 12616, 'TIENE': 12617, 'DIVINE': 12618, 'basic': 12619, 'noobie': 12620, 'mentioned': 12621, 'asia': 12622, 'capital': 12623, 'myanmar': 12624, 'restroom': 12625, 'wlel': 12626, 'onob': 12627, 'sak': 12628, 'Zz': 12629, 'overextending': 12630, 'fuckkk': 12631, 'DIRT': 12632, 'diddnt': 12633, 'hunter': 12634, 'ahhahha': 12635, 'LOSERS': 12636, 'squad': 12637, 'vwwgg': 12638, 'boobo': 12639, 'lowara': 12640, 'manga': 12641, 'xsend': 12642, 'mele': 12643, 'puting': 12644, 'unaware': 12645, 'whiny': 12646, '::DD': 12647, 'nowwww': 12648, 'Alright': 12649, 'EASI': 12650, 'ce4rf': 12651, 'eeezzz': 12652, 'neco': 12653, 'azaza': 12654, 'sacrifish': 12655, 'doooom': 12656, 'zone': 12657, 'mnuted': 12658, 'linas': 12659, 'wehn': 12660, 'snipa': 12661, 'becouse': 12662, 'bodied': 12663, 'coiuld': 12664, 'voided': 12665, 'sif': 12666, 'holys': 12667, 'fark': 12668, 'jiahou': 12669, 'Xu': 12670, 'mnow': 12671, 'sould': 12672, 'jejemon': 12673, 'nailed': 12674, 'cybercafe': 12675, 'theirselves': 12676, '3secs': 12677, 'settings': 12678, 'travels': 12679, 'unmuted': 12680, 'breathing': 12681, 'dribble': 12682, 'SCORE': 12683, 'thunderstorms': 12684, '4lyf': 12685, 'mustve': 12686, 'daamn': 12687, 'whahah': 12688, 'hhm': 12689, 'ata': 12690, 'timers': 12691, 'MINE': 12692, '4300': 12693, 'spared': 12694, 'bruv': 12695, 'nuthing': 12696, 'SPRO': 12697, 'fuckinearth': 12698, 'abuser': 12699, 'hen': 12700, 'negro': 12701, 'bfury': 12702, 'thinker': 12703, 'aahha': 12704, 'copo': 12705, 'njeng': 12706, 'Dominator': 12707, 'BLANCED': 12708, 'tehnku': 12709, 'woierjewkhfiwepojoiwehfijwer': 12710, 'phanter': 12711, 'whingeing': 12712, 'slack': 12713, 'lego': 12714, 'nyjno': 12715, 'chtobu': 12716, 'napusal': 12717, 'crono': 12718, 'CROM': 12719, 'FELIX': 12720, 'SECRETSHOP': 12721, 'Nvm': 12722, 'viebite': 12723, 'reportnu': 12724, 'ytolyu': 12725, 'There': 12726, 'KOTL': 12727, 'LOLK': 12728, 'kala': 12729, 'moha': 12730, 'THrow': 12731, 'penalty': 12732, 'decision': 12733, 'Extend': 12734, '4:10': 12735, 'complaning': 12736, 'HUskar': 12737, 'shinken': 12738, 'hakyouken': 12739, 'ehehehehee': 12740, 'mev': 12741, 'GAGLHWSLHW': 12742, 'HSLDHLWHWL': 12743, 'LHAWLGAL': 12744, 'AHAHGAH': 12745, '100HP': 12746, 'ULTY': 12747, 'SELL': 12748, 'muslim': 12749, 'poisin': 12750, 'pulled': 12751, '000000000000000': 12752, 'SPASIBO': 12753, 'chaserr': 12754, 'jALO': 12755, 'PISSING': 12756, 'PROMISE': 12757, 'CHANCES': 12758, 'bootcamp': 12759, '400ms': 12760, 'updates': 12761, 'fukn': 12762, 'CDEC': 12763, 'AGRESSIF': 12764, 'mestik': 12765, 'schoolboy': 12766, 'nickname': 12767, 'pohui': 12768, 'lomaite': 12769, 'Cse': 12770, 'stoyat': 12771, 'commemd': 12772, 'radik': 12773, 'dieddddd': 12774, 'baneeee': 12775, 'aliev': 12776, 'dumbcunt': 12777, 'Wahahhah': 12778, 'finis': 12779, 'hahahhahaa': 12780, 'maleware': 12781, 'thos': 12782, 'creatyre': 12783, 'nina': 12784, 'OWNITTT': 12785, 'j00ked': 12786, 'aiiiii': 12787, 'waaat': 12788, 'OFCI': 12789, 'weeb': 12790, 'geh': 12791, 'clinks': 12792, 'Ensd': 12793, 'nicee': 12794, '9999k': 12795, 'COMPARED': 12796, 'GRP': 12797, 'vajayjay': 12798, 'counterpicker': 12799, '1:23': 12800, 'okok': 12801, 'weeks': 12802, 'NAMIN': 12803, 'lele': 12804, 'COOOOOOOMEEEEND': 12805, 'aabut': 12806, 'vs1': 12807, 'WHYYYYYYYYYY': 12808, 'winte': 12809, 'fuckker': 12810, 'wrecked': 12811, 'passsion': 12812, 'website': 12813, 'slayers': 12814, 'finnaly': 12815, 'slarda': 12816, 'kycha': 12817, 'soboy': 12818, 'nosyat': 12819, 'require': 12820, 'relly': 12821, 'recomenden': 12822, 'mrdas': 12823, 'oO': 12824, 'GabeN': 12825, 'FAIR': 12826, 'part': 12827, 'btmm': 12828, 'null': 12829, 'cYKA': 12830, 'RUSSIAN': 12831, 'meld': 12832, 'foook': 12833, 'winrun': 12834, 'whom': 12835, '4500': 12836, 'ggpw': 12837, 'lichg': 12838, 'BTW': 12839, 'DISRUP': 12840, 'jungla': 12841, ':PP': 12842, 'howlonghave': 12843, 'terribles': 12844, 'pugde': 12845, 'maiy': 12846, 'phor': 12847, 'feggots': 12848, 'boludo': 12849, 'siente': 12850, 'gordito': 12851, 'pavo': 12852, 'HOOKS': 12853, ':DDDDDDDDDDDDDD': 12854, 'defance': 12855, 'td': 12856, 'RNG': 12857, 'kawawa': 12858, 'PRIORITY': 12859, 'dicks': 12860, 'mc': 12861, 'tusklar': 12862, 'lghf': 12863, 'lg': 12864, 'idonjt': 12865, 'canadians': 12866, 'dallae': 12867, 'Que': 12868, 'manyu': 12869, 'ddosser': 12870, 'dammit': 12871, 'rubrick': 12872, 'clear': 12873, 'charges': 12874, 'rubik': 12875, '5vs1': 12876, 'desable': 12877, 'pepe': 12878, 'AUTISM': 12879, '530': 12880, 'guesss': 12881, 'DUE': 12882, 'recfraction': 12883, 'stoP': 12884, 'madda': 12885, 'ogld': 12886, 'Gorrila': 12887, 'Dunk': 12888, 'ABBADONG': 12889, 'frankfurt': 12890, 'tricked': 12891, 'ganker': 12892, 'dunwan': 12893, 'sAD': 12894, 'Internet': 12895, 'xaxaxaxaxaxaxaxaxa': 12896, 'NIGGER': 12897, 'wadhawdujaw': 12898, 'bitach': 12899, 'WISP': 12900, 'licky': 12901, 'paus': 12902, 'akoy': 12903, 'GoD': 12904, 'Hahahahaha': 12905, 'deef': 12906, 'merica': 12907, '025': 12908, 'huesos': 12909, 'whyyyy': 12910, 'defeding': 12911, 'trk1j325rj123': 12912, 'AHAHHAA': 12913, 'Greedy': 12914, 'goof': 12915, 'Tide': 12916, 'agro': 12917, 'related': 12918, 'clown': 12919, 'mrrS': 12920, 'SCHOOLBOY': 12921, 'AAAHA': 12922, 'oooooooooooh': 12923, 'fuckiong': 12924, 'wahha': 12925, 'YOURE': 12926, 'urSA': 12927, 'SSS': 12928, 'mcdo': 12929, 'demand': 12930, 'mmy': 12931, 'squishy': 12932, 'sayo': 12933, 'gangbang': 12934, 'yoruself': 12935, 'produ': 12936, 'siraptor': 12937, 'MERCY': 12938, 'swing': 12939, 'air': 12940, 'hahaqha': 12941, 'NAPS': 12942, 'noise': 12943, 'damned': 12944, 'hhhhhhhhhhhhh': 12945, 'HIHI': 12946, 'amke': 12947, 'radi': 12948, 'ahahahh': 12949, 'AHAAHAHA': 12950, 'anough': 12951, 'kapa': 12952, 'sanking': 12953, 'caarry': 12954, 'perma': 12955, 'exort': 12956, 'pusyy': 12957, 'PUSSSSSYSYYYSYSYSYSYS': 12958, 'saki': 12959, 'bluff': 12960, 'fappy': 12961, 'tuesdays': 12962, 'higher': 12963, 'solos': 12964, 'annoy': 12965, 'RING': 12966, 'BASILUSS': 12967, 'USEFULL': 12968, '30seconds': 12969, 'usual': 12970, 'nica': 12971, 'woden': 12972, 'agaisnt': 12973, 'thuis': 12974, 'mummy': 12975, 'rubs': 12976, 'fortnight': 12977, 'kys': 12978, 'listening': 12979, 'comparing': 12980, 'DEBILI': 12981, 'ALEE': 12982, 'sosi': 12983, 'ze': 12984, 'vip': 12985, 'FOLLOWING': 12986, 'rainfall': 12987, 'tyrazor': 12988, 'bashed': 12989, 'sassy': 12990, 'nbever': 12991, 'stomped': 12992, 'poreso': 12993, 'unity': 12994, 'media': 12995, 'chronio': 12996, 'seriouslyt': 12997, 'SERIOUSLY': 12998, 'KYS': 12999, 'jgn': 13000, 'asik': 13001, 'anjign': 13002, 'grills': 13003, 'CENA': 13004, 'FALLEN': 13005, 'stall': 13006, 'dochu': 13007, 'fuckingg': 13008, 'ahv': 13009, 'etime': 13010, 'jacking': 13011, 'offfffff': 13012, 'Meow': 13013, 'AHAHH': 13014, 'BLUE': 13015, 'salisi': 13016, 'claims': 13017, 'closed': 13018, 'mere': 13019, 'greedisgood': 13020, 'Godot': 13021, 'aussie': 13022, 'Relt': 13023, 'boty': 13024, 'ORO': 13025, 'OMGGGGG': 13026, 'spooked': 13027, 'itde': 13028, 'soryr': 13029, '210': 13030, 'zoos': 13031, 'pausr': 13032, 'gntie': 13033, 'dank': 13034, 'dmge': 13035, 'BOBBY': 13036, 'BRACKINS': 13037, 'realx': 13038, '=W': 13039, 'slacko': 13040, 'commende': 13041, '=DD': 13042, 'pegde': 13043, 'pudgr': 13044, 'repoprt': 13045, 'Didn': 13046, 'Despite': 13047, 'perhapse': 13048, 'hsould': 13049, 'relt': 13050, 'motherf': 13051, 'PE': 13052, 'aquilla': 13053, 'CUNTKA': 13054, 'oxigeno': 13055, 'cerebro': 13056, 'porfavor': 13057, 'mnore': 13058, 'rto': 13059, 'directly': 13060, 'ir': 13061, 'reporn': 13062, 'PLIZ': 13063, 'sence': 13064, 'englioh': 13065, 'Rng': 13066, '4et': 13067, 'narutard': 13068, 'pool': 13069, 'MOOD': 13070, 'plaued': 13071, 'phantom': 13072, 'Shitstain': 13073, 'suitable': 13074, 'WADDUP': 13075, 'worsth': 13076, 'rtd': 13077, 'BAIT': 13078, 'HELLo': 13079, 'FROm': 13080, 'OTHER': 13081, '2hits': 13082, 'coordinator': 13083, 'JUKED': 13084, 'min3': 13085, 'bings': 13086, 'talino': 13087, 'jeniffer': 13088, 'lawrence': 13089, 'kissing': 13090, 'natalie': 13091, 'dormer': 13092, 'rager': 13093, 'SHIITS': 13094, 'Washington': 13095, 'proccesor': 13096, 'sakit': 13097, 'hati': 13098, 'TI5': 13099, 'blachhole': 13100, 'ALchEMist': 13101, 'reserve': 13102, 'jogaram': 13103, 'bem': 13104, 'setting': 13105, 'PNoy': 13106, 'amf': 13107, 'MURTAZAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA': 13108, 'professional': 13109, 'ahaahahahha': 13110, 'hahahhahahahhahahahhahaha': 13111, 'oy': 13112, 'katoska': 13113, 'hanging': 13114, 'SATAN': 13115, 'SITTING': 13116, 'TREEE': 13117, 'SHADES': 13118, 'GREY': 13119, 'Wooden': 13120, 'hacked': 13121, 'Laptop': 13122, 'owww': 13123, 'rarely': 13124, 'sharp': 13125, 'sakita': 13126, 'premade': 13127, 'gEASY': 13128, 'DAYN': 13129, 'difficuklt': 13130, 'xDDDD': 13131, 'mudda': 13132, 'labert': 13133, 'oky': 13134, 'coomend': 13135, 'UTMOST': 13136, 'CERTAINTY': 13137, 'arrogant': 13138, 'section': 13139, 'Secret': 13140, 'DDDDDD': 13141, 'barbie': 13142, 'OOO': 13143, 'ere': 13144, 'wewt': 13145, 'BG': 13146, 'firsts': 13147, 'assistrs': 13148, 'NATURE': 13149, 'especialy': 13150, 'USLES': 13151, 'Skype': 13152, 'Wont': 13153, 'HUGE': 13154, 'ec': 13155, 'neo': 13156, 'wanto': 13157, 'afasihon': 13158, 'vs5': 13159, 'Right': 13160, 'donp': 13161, 'giting': 13162, 'AJJAJAJA': 13163, 'Potuition': 13164, 'TOT': 13165, 'peeeeeee': 13166, 'peeeeeeeeeeeeeeeeeeeeee': 13167, 'rikki': 13168, 'pnoy': 13169, 'ALOWED': 13170, 'cocksuck': 13171, 'serv': 13172, 'jUGG': 13173, 'THO': 13174, 'usky': 13175, 'asks': 13176, 'bbopes': 13177, 'NOBOS': 13178, '833': 13179, 'sheck': 13180, 'SUPPLIES': 13181, 'huesosi': 13182, 'BRAINED': 13183, 'IMPACT': 13184, 'nooobs': 13185, 'period': 13186, 'TANGINA': 13187, 'Stack': 13188, 'HOUES': 13189, 'badddddddddddddddddddd': 13190, 'obsessed': 13191, 'NYA': 13192, 'NAKAAAAL': 13193, 'cCntt': 13194, 'KAMAZEEEE': 13195, 'itmorning': 13196, 'streamers': 13197, 'pogChamp': 13198, 'g3g3': 13199, 'phub': 13200, 'sounded': 13201, 'helkl': 13202, 'beack': 13203, 'counts': 13204, 'Gottes': 13205, 'willen': 13206, 'pols': 13207, 'Best': 13208, 'mangs': 13209, 'cumbacket': 13210, 'XAXAXAX': 13211, 'gahahfa': 13212, 'WORK': 13213, 'OFFLANE': 13214, 'freakin': 13215, 'hahhhahahhahah': 13216, 'blocked': 13217, 'acting': 13218, 'shjit': 13219, 'WOWOW': 13220, 'REMNANT': 13221, '2months': 13222, 'asdkljasdjklasdasd': 13223, 'DRAGON': 13224, 'KNGHT': 13225, 'PLLEASE': 13226, 'dota2smut': 13227, 'dd': 13228, 'voids': 13229, 'firs': 13230, 'gyri': 13231, 'mkm': 13232, 'final': 13233, 'nanashi': 13234, 'pablo': 13235, 'didjnt': 13236, 'intresting': 13237, 'moon': 13238, 'shard': 13239, 'dada': 13240, '<<': 13241, 'uni': 13242, 'Reconnet': 13243, 'grapic': 13244, '90': 13245, 'uis': 13246, 'cask': 13247, 'fing': 13248, 'suprise': 13249, 'BETRAYED': 13250, 'Stamos': 13251, 'evberywhere': 13252, 'clutch': 13253, 'pourri': 13254, 'club': 13255, 'JUG': 13256, 'ceci': 13257, 'tout': 13258, 'fait': 13259, 'dingue': 13260, 'POWERBALL': 13261, 'MIL': 13262, 'okay2': 13263, 'imagination': 13264, 'EUL': 13265, 'tng': 13266, 'queueing': 13267, 'requested': 13268, 'Value': 13269, 'ucnt': 13270, 'pop': 13271, 'aHAhahhAAHHA': 13272, 'epwoer': 13273, 'woohooooo': 13274, 'usually': 13275, 'thzis': 13276, 'YeSSSSSSSSSSSSSS': 13277, 'WFEPI': 13278, 'J': 13279, 'WPIJWPEIFG': 13280, 'qfhqiuhfouqehfoqwf': 13281, 'OUY': 13282, 'FGSIEF': 13283, 'jerw': 13284, 'ohfoui': 13285, 'hfoqho': 13286, 'OUFHEOUIHG': 13287, 'Wk': 13288, 'nthing': 13289, 'suki': 13290, '198': 13291, '3000': 13292, 'pinOY': 13293, 'bullied': 13294, 'ANOTHER': 13295, 'LOSING': 13296, 'VALVE': 13297, 'GABEN': 13298, 'DEEP': 13299, 'DELET': 13300, 'thta': 13301, 'barelya': 13302, 'matrix': 13303, 'vovlo': 13304, 'recons': 13305, 'plausible': 13306, 'HAVENT': 13307, 'Players': 13308, 'RUNING': 13309, 'uselses': 13310, 'Brother': 13311, 'bain': 13312, 'hmmmmmmmmmmmmmmm': 13313, 'TREDE': 13314, 'congratulations': 13315, 'rtop': 13316, 'NUKEPERU': 13317, 'relocate': 13318, 'hoes': 13319, 'mueren': 13320, 'theese': 13321, '3times': 13322, 'oui': 13323, 'vueki': 13324, 'abddon': 13325, 'MINUTE': 13326, 'burden': 13327, 'Commdnd': 13328, 'CALLATE': 13329, 'MRD': 13330, 'oso': 13331, 'ORLF': 13332, 'TMOHER': 13333, 'BUYERS': 13334, 'spiral': 13335, 'WPP': 13336, 'lile': 13337, 'ezi': 13338, 'katkas': 13339, 'ahahasha': 13340, 'defing': 13341, 'biscuit': 13342, 'vse': 13343, 'poocheredi': 13344, 'sam': 13345, 'dickriding': 13346, 'Idk': 13347, 'CAn': 13348, 'PISTE': 13349, 'frm': 13350, 'haahha': 13351, 'asmruf': 13352, 'CREATED': 13353, 'NI4EGO': 13354, 'PIWI': 13355, 'vacuume': 13356, 'AHAAHAHAHAH': 13357, 'Cunty': 13358, 'annoyance': 13359, 'OLOL': 13360, 'ougna': 13361, 'Ruh': 13362, 'roh': 13363, ':DDDDDDD': 13364, 'gun': 13365, 'Whthapnd': 13366, 'HIIII': 13367, 'qoq': 13368, 'Scare': 13369, 'lycane': 13370, 'Ward': 13371, 'kos': 13372, 'madara': 13373, 'SERINITY': 13374, 'pilde': 13375, 'raka': 13376, 'geez': 13377, 'pleb': 13378, 'LUSER': 13379, 'senk': 13380, 'snaiper': 13381, 'OT': 13382, 'MENYA': 13383, 'posla': 13384, '2gud': 13385, 'mobkey': 13386, 'HOME': 13387, 'COUNTRY': 13388, 'ROAD': 13389, 'RAZE': 13390, 'shite': 13391, 'ekkk': 13392, 'moonwalk': 13393, 'rustards': 13394, 'Asad': 13395, 'WERK': 13396, 'GOES': 13397, 'willing': 13398, 'sop': 13399, 'playign': 13400, 'anal': 13401, 'BLADEMAIL': 13402, 'hu': 13403, 'sickened': 13404, 'builds': 13405, 'randomer': 13406, 'messed': 13407, 'golems': 13408, 'dop': 13409, 'mini': 13410, 'misplayed': 13411, '21mins': 13412, 'nagbayag': 13413, 'mabisinakun': 13414, 'lancau': 13415, 'upon': 13416, 'dawn': 13417, 'owning': 13418, 'apes': 13419, 'sack': 13420, 'FRIENDS': 13421, 'oen': 13422, 'thas': 13423, 'TEAMM8': 13424, 'seexy': 13425, 'exprinece': 13426, 'betcha': 13427, 'moce': 13428, 'kukita': 13429, 'GOOOD': 13430, 'instagram': 13431, 'looooollll': 13432, 'idiotly': 13433, 'swin': 13434, ':=': 13435, 'clok': 13436, 'CAPS': 13437, 'LOCK': 13438, '4HEAD': 13439, 'lalalal': 13440, 'heeeeeeeeeeeeeeeee': 13441, 'HAHAHHAAH': 13442, 'AGHAHAHHAHA': 13443, 'spokesman': 13444, 'reci': 13445, 'Antifun': 13446, 'unfortunate': 13447, 'MMore': 13448, 'haaa': 13449, 'TAEM': 13450, 'IOS': 13451, 'SHTI': 13452, 'withj': 13453, 'tuiny': 13454, 'rpeott': 13455, 'ANAL': 13456, 'ditched': 13457, '8th': 13458, 'tomb': 13459, 'losting': 13460, 'HITTER': 13461, 'WEAK': 13462, 'WHAHAHHA': 13463, 'willw': 13464, 'ait': 13465, 'aura': 13466, 'bited': 13467, 'hahahahahahah': 13468, 'iq': 13469, 'morphg': 13470, 'fattttttttttttttttttttttttttttttt': 13471, 'initiating': 13472, 'wallhacks': 13473, 'Solo': 13474, 'ISI': 13475, 'Everyone': 13476, 'dooes': 13477, 'knowing': 13478, 'smurfs': 13479, 'TWF': 13480, 'polease': 13481, 'amchong': 13482, 'TANCHEEYUAN': 13483, '0162282307': 13484, 'fuckinng': 13485, 'russiinn': 13486, 'JUGGN': 13487, 'wuith': 13488, 'eagis': 13489, 'sone': 13490, 'hetp': 13491, 'ahwh': 13492, 'sthe': 13493, 'satisfaction': 13494, 'csing': 13495, 'ikkeh': 13496, 'yie': 13497, 'supported': 13498, 'pota': 13499, 'rmemeber': 13500, 'wewo': 13501, 'boohoo': 13502, 'ahiuhi': 13503, 'randomn': 13504, 'ey': 13505, 'somtiems': 13506, 'necrolyte': 13507, 'cookie': 13508, 'crumbles': 13509, 'cheaper': 13510, 'RANK': 13511, 'COmend': 13512, 'juas': 13513, 'HEATHENS': 13514, 'church': 13515, 'AKBAAAR': 13516, 'ctm': 13517, 'ex': 13518, 'TAKOE': 13519, 'REPORTADO': 13520, '12k': 13521, 'gunggong': 13522, 'foul': 13523, 'belond': 13524, 'Gahaha': 13525, 'ahhahahaha': 13526, 'invite': 13527, '65': 13528, 'WRECK': 13529, 'dogged': 13530, 'SAVE': 13531, 'Mineski': 13532, 'tides': 13533, 'cough': 13534, 'ctr': 13535, 'kited': 13536, 'rjyxtyfz': 13537, 'idfkm': 13538, 'nunal': 13539, 'fend': 13540, 'walao': 13541, 'misclickded': 13542, 'wc3': 13543, 'yxcv': 13544, 'Waht': 13545, 'shakle': 13546, 'Ctrl': 13547, 'YEa': 13548, 'Doesnt': 13549, 'AJAJAJAJAHAHAHAH': 13550, 'HSJJAHAHA': 13551, 'DCs': 13552, 'gna': 13553, 'hrs': 13554, 'COMEeeeee': 13555, 'mexicans': 13556, 'Atleast': 13557, 'nol': 13558, 'brat': 13559, 'su4ok': 13560, 'wrng': 13561, 'heeh': 13562, 'RAge': 13563, 'gfamer': 13564, 'Blade': 13565, 'xDDDDDDDDDDDDDDDDDD': 13566, 'inchoker': 13567, 'Blood': 13568, 'FA': 13569, 'KAMEN': 13570, 'paty': 13571, 'diversion': 13572, 'suckoff': 13573, 'dadadada': 13574, 'jahjahahajajaja': 13575, 'enchantress': 13576, 'DANCE': 13577, 'aganimas': 13578, 'rebooted': 13579, 'modafuka': 13580, 'howd': 13581, 'WOOHOO': 13582, 'solid': 13583, 'imprisonment': 13584, 'kser': 13585, 'hoi': 13586, 'original': 13587, 'VBS': 13588, 'teamed': 13589, 'math': 13590, 'hgahaha': 13591, 'ISIS': 13592, 'Funny': 13593, 'Tag': 13594, 'mike': 13595, 'kuma': 13596, 'FOOD': 13597, 'suchj': 13598, 'angle': 13599, 'DIS': 13600, 'soooooooo': 13601, 'disable': 13602, 'Sange': 13603, '7min': 13604, 'villain': 13605, 'commonwealth': 13606, 'raz': 13607, 'papanya': 13608, 'TRAXEX': 13609, 'BRUHHH': 13610, 'nag': 13611, 'ug': 13612, 'mightve': 13613, 'ohk': 13614, 'honour': 13615, 'wowowo': 13616, 'sh': 13617, 'rektkatka': 13618, '5kego': 13619, 'building': 13620, 'melt': 13621, 'enyway': 13622, 'FISURE': 13623, 'BLYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAT': 13624, 'tidner': 13625, 'farmou': 13626, 'inicio': 13627, 'kepp': 13628, 'norm': 13629, 'CENAAAAAAAAAAAAA': 13630, ';:D': 13631, 'doens': 13632, 'kidn': 13633, 'feeeder': 13634, '900gold': 13635, 'Realy': 13636, 'current': 13637, 'jks': 13638, 'MAKING': 13639, 'BHS': 13640, 'maxine': 13641, 'sall': 13642, 'hair': 13643, 'razing': 13644, 'proof': 13645, 'BibleThump': 13646, 'wkdopqwkdqwp': 13647, 'lvl4': 13648, '4chan': 13649, 'kidz': 13650, 'wife': 13651, 'rotated': 13652, 'opponents': 13653, 'pup': 13654, 'FIIIGHT': 13655, 'TPS': 13656, 'magn': 13657, 'asshoels': 13658, 'depot': 13659, 'calla': 13660, 'morf': 13661, 'ww3w': 13662, 'handedly': 13663, 'keping': 13664, 'realist': 13665, 'FRAPS': 13666, 'guesxzs': 13667, 'fuckload': 13668, 'whY': 13669, 'plsz': 13670, 'hush': 13671, 'faithless': 13672, 'ngiga': 13673, 'FICKING': 13674, 'shoutout': 13675, 'fegs': 13676, 'PUTA': 13677, 'negros': 13678, 'Smurfs': 13679, 'ceasepool': 13680, 'muting': 13681, 'Dynasty': 13682, 'amigos': 13683, 'Zzzzz': 13684, 'puases': 13685, ':^': 13686, 'stronmg': 13687, 'Fk': 13688, 'Does': 13689, 'tranqs': 13690, 'ahahhaah': 13691, 'wevaer': 13692, 'grrr': 13693, 'gotya': 13694, '37': 13695, 'slots': 13696, '1584': 13697, 'axaxa': 13698, 'dawg': 13699, 'hahahahahahahahahahahahahahahhahahahahaha': 13700, 'LUKCY': 13701, 'allov': 13702, 'thissf': 13703, 'iwasnt': 13704, 'ajajajajaja': 13705, '87mb': 13706, 'pack': 13707, 'hahaiz': 13708, 'humor': 13709, 'SaY': 13710, 'isreal': 13711, 'investing': 13712, 'sing': 13713, 'national': 13714, 'anthem': 13715, '30am': 13716, 'nneed': 13717, 'instaloss': 13718, 'kunkha': 13719, 'sleepZZZ': 13720, 'WOOOHOO': 13721, 'WINNING': 13722, 'suspen': 13723, 'damaged': 13724, 'chimp': 13725, '3kForLife': 13726, 'SG': 13727, 'haveen': 13728, 'mopl': 13729, 'geeett': 13730, 'reeeeekt': 13731, 'macropyre': 13732, 'Boom': 13733, 'masturbation': 13734, 'Shitpoo': 13735, 'ezs': 13736, 'shitface': 13737, 'ggggggggggggggggg': 13738, 'ggggggg': 13739, 'EZWP': 13740, 'EEZ': 13741, 'Ezeist': 13742, 'cM': 13743, 'Ezzzzzzzzzz': 13744, 'OMNI': 13745, 'mmrhunter': 13746, 'OMW': 13747, 'CHEN': 13748, 'kunkkaaaa': 13749, 'fff': 13750, 'faggerts': 13751, 'DDDD': 13752, 'AAAAAAAAAAAAAAA': 13753, 'hELP': 13754, 'Support': 13755, 'ALcheMist': 13756, 'Down': 13757, 'OFFLANER': 13758, 'rikik': 13759, 'STUPIUD': 13760, 'AGGRESSIVE': 13761, 'P0ta': 13762, 'slardasr': 13763, 'Kotl': 13764, 'Theres': 13765, 'gayteam': 13766, 'TOWER': 13767, 'EZSZZ': 13768, 'peruano': 13769, 'cochino': 13770, 'Wd': 13771, 'peruANOS': 13772, 'inutiles': 13773, 'YOURSELF': 13774, 'eez': 13775, 'RIky': 13776, 'niggaz': 13777, 'Shitty': 13778, 'Chill': 13779, 'HOES': 13780, 'EZZZZZZZZZZ': 13781, 'Fcuk': 13782, 'Dp': 13783, 'Bh': 13784, 'PTM': 13785, 'lanaya': 13786, 'CUMMING': 13787, 'alchem': 13788, 'COMN': 13789, 'CENT': 13790, 'Other': 13791, 'sluts': 13792, 'MOFO': 13793, 'juking': 13794, 'BUD': 13795, 'guysss': 13796, 'FOKKKEEEN': 13797, 'LOOOST': 13798, 'yaeh': 13799, 'juggernaut': 13800, 'trashcan': 13801, 'jeez': 13802, 'rroamer': 13803, 'METAAAAAAAAAAAAAAAAAAAAAAAA': 13804, 'BD': 13805, 'insted': 13806, 'NEGGER': 13807, 'SUch': 13808, 'lifer': 13809, 'Everything': 13810, 'bratans': 13811, 'guyzzzz': 13812, 'LITTLE': 13813, 'HIGHLIGHTS': 13814, 'MEKA': 13815, 'roshans': 13816, 'CS': 13817, 'MIDA': 13818, 'ROT': 13819, 'EBAL': 13820, 'SALO': 13821, 'ZAGLOD': 13822, 'EBANYYT': 13823, 'embers': 13824, 'slash': 13825, 'gqame': 13826, 'peruanos': 13827, 'dejen': 13828, 'servidor': 13829, 'illus': 13830, 'Welcome': 13831, 'Pinoy': 13832, 'plentiful': 13833, 'plurals': 13834, 'motomu': 13835, 'stupiud': 13836, 'hybrid': 13837, 'lothars': 13838, 'ROW': 13839, 'RUNS': 13840, 'WEN': 13841, 'YUOR': 13842, 'NUDE': 13843, 'pouncy': 13844, 'bested': 13845, 'epenis': 13846, 'fagets': 13847, 'FUCKEN': 13848, 'goi': 13849, 'WTG': 13850, 'aeghis': 13851, 'rube': 13852, 'MMr': 13853, 'ZUERS': 13854, 'mirna': 13855, 'Sexyyyyy': 13856, 'fancy': 13857, 'DENYYYYYYYYYYYY': 13858, 'sds': 13859, 'LIOn': 13860, 'PIT': 13861, 'jiungling': 13862, 'potms': 13863, 'cumwaste': 13864, 'disposal': 13865, 'abortion': 13866, 'clinic': 13867, 'SAW': 13868, 'meks': 13869, 'obs': 13870, 'crep': 13871, 'rylai': 13872, 'feelling': 13873, '527': 13874, 'INVOKE': 13875, '56min': 13876, 'sperm': 13877, 'Logic': 13878, 'sen': 13879, 'invkr': 13880, 'niggu': 13881, 'tenemos': 13882, 'livewwr': 13883, 'asscrack': 13884, 'lif': 13885, 'addtime': 13886, 'JAJAJAJAJAA': 13887, 'REZZZZZZZZZZZZZZZZZZZZZZZZZZZZ': 13888, 'JAJAJAA': 13889, 'skillshot': 13890, 'slards': 13891, 'bitcheeees': 13892, 'lelelelelel': 13893, 'kunnkka': 13894, 'junle': 13895, 'gankin': 13896, 'lou': 13897, 'botle': 13898, 'din': 13899, '11PM': 13900, 'Tell': 13901, 'PAUSES': 13902, 'secured': 13903, 'bieliebers': 13904, 'unite': 13905, 'slarky': 13906, 'musor': 13907, 'gggame': 13908, 'anyting': 13909, 'feeden': 13910, 'Earthshaker': 13911, 'shaked': 13912, 'beneath': 13913, 'MAIDEN': 13914, 'WAR': 13915, 'DEWARD': 13916, 'Terrorblade': 13917, 'abyss': 13918, 'OMGGGGGGGGGGGG': 13919, 'wtffff': 13920, 'happenign': 13921, 'madafucka': 13922, 'Focus': 13923, 'retardedw': 13924, 'EFFECT': 13925, 'CHEAT': 13926, 'hitbox': 13927, 'duration': 13928, 'blademaiol': 13929, 'everyting': 13930, '419': 13931, 'LESHRACK': 13932, 'oohh': 13933, 'rael': 13934, 'buyabakc': 13935, 'radidance': 13936, 'Death': 13937, 'XDLMfao': 13938, 'burrow': 13939, 'DAVAI': 13940, 'RUSKI': 13941, 'thc': 13942, 'noobies': 13943, 'sis': 13944, 'HAHAHAHAHAH': 13945, 'wz': 13946, 'OMMNI': 13947, 'Miss': 13948, 'GOOK': 13949, 'Idiots': 13950, 'fvking': 13951, 'begi': 13952, 'YASHA': 13953, 'DEON': 13954, 'FUCKNIG': 13955, 'blasts': 13956, 'Cocks': 13957, 'lIXO': 13958, 'FISSURE': 13959, 'THY': 13960, 'masakit': 13961, 'CRIT': 13962, 'creeep': 13963, 'damge': 13964, 'PICKD': 13965, 'Motherfuckers': 13966, 'picka': 13967, 'silncver': 13968, 'fuc': 13969, 'fuuck': 13970, 'agans': 13971, 'Account': 13972, 'kiting': 13973, 'STAHP': 13974, 'COURIERS': 13975, 'pickings': 13976, 'mams': 13977, 'spaghetti': 13978, 'slus': 13979, 'ave': 13980, 'sget': 13981, 'Void': 13982, 'backtracks': 13983, '4x5': 13984, 'maledict': 13985, 'TELLS': 13986, 'TALES': 13987, 'benla': 13988, 'tira': 13989, 'six': 13990, 'Illuminati': 13991, '1110': 13992, 'HAHAHAHAHAHAHA': 13993, 'HANDLE': 13994, 'nOOB': 13995, 'SNIPE': 13996, 'THEE': 13997, 'recall': 13998, 'slrk': 13999, 'fml': 14000, 'burrito': 14001, 'shitbag': 14002, 'ALGUIEN': 14003, 'PARA': 14004, 'USTEDES': 14005, 'TAMBIEN': 14006, 'ENTIENDAME': 14007, 'OTHERS': 14008, 'dieofcancer': 14009, 'hahahahh': 14010, 'wHY': 14011, 'fuckme': 14012, 'l0l': 14013, 'REALITY': 14014}\n",
            "['wow', 'WTF', 'wpe', 'hahaha', 'wtf', 'i', 'cant', '[SEPA]', 'play', 'with', '4', 'trash', 'bg', '#ERROR!', 'gg', 'report', 'my', 'team', 'rat', 'please', 'ez', 'mid', 'hahah', 'arrows', 'always', 'decent', 'fuck', 'u', 'gh', 'engage', 'at', 'bot', 'lc', 'takle', 'then', 'top', 'cmon', 'the', 'comeback', 'is', 'real', ':)', 'him', 'vs', 'me', 'just', 'end', 'wan', 'nex', 'game', 'g', 'he', 'not', 'losing', 'Pls', 'sb', 'thanks', 'omg', 'ggwp', 'WP', 'cap', 'lo', 'lol', 'fuyckjerfe', 'noob', 'invoker', 'mean', 'everyone', 'on', 'ur', 'dumb', 'enough', 'to', 'rot', 'down', '2', 'hp', '8', 'it', 'random', ':/', 'dead', 'keeps', 'charhing', 'since', 'spectre', 'comited', 'ult', 'so', 'did', 'I', ':D', 'thought', 'they', 'will', 'go', 'for', 'more', 'blood', 'but', 'whatever', 'too', 'ty', 'mmr', 'you', 'know', 'can', 'take', 'mana', 'thing', 'out', 'of', 'boots', 'gave', 'free', 'farm', 'could', 'kill', '100', 'times', 'wp', 'legoin', 'm8', 'nice', 'many', 'shit', 'talk', 'thx', 'sea', 'cancer', 'talktalktalk', 'SHIT', 'talking', 'boy', 'alch', 'TIME', 'FOR', 'A', 'BIT', 'OF', 'RO', 'SHAM', 'BO', 'COMEND', 'DOOM', 'IN', 'LEGION', 'greedy', 'dont', 'def', 'isnt', 'meant', 'win', 'lane', 'SHITTT', 'sad', 'bs', 'T', 'QOP', 'guys', 'this', 'fag', 'went', 'fucking', 'bad', 'Alche', 'and', 'lycan', 'Rip', 'singing', 'siren', 'dancing', 'jugg', 'meeporino', 'feederino', 'asshole', 'Thats', 'all', 'gotta', 'say', 'Drow', '5', 'COMMEND', 'lowskill', 'shits', 'have', 'do', 'dive', 'endlessly', 'cunt', 'silencer', 'invoekr', 'let', 'tnx', 'russian', 'obama', 'least', 'nuked', 'putin', 'wise', 'ffs', 'youi', 'stop', 'inviting', 'strangers', 'your', 'grandmothers', 'corpse', 'heng', 'never', 'die', 'We', 'randomed', 'golden', 'medal', 'GG', 'lag', 'HAHA', 'btw', 'AM', 'blink', 'into', 'stun', 'who', 'care', 'emergency', 'plan', 'sry', 'want', 'slardar', 'getting', 'strong', 'ahahaha', 'tho', 'feeling', 'bro', 'whos', 'daddy', 'stunning', 'man', 'doto', 'Sry', 'feed', 'dnt', 'storm', 'LOL', 'be', 'won', 'weaver', 'worry', 'trone', 'bm', 'gj', 'Ty', 'hahahai', 'blame', 'us', 'YEAAHHHHHHHHH', 'GGGGGGGGGGGG', 'EZ', 'aw', 'telling', 'im', 'much', 'a', 'solo', 'player', 'He', 's', 'picked', 'in', 'pubs', 'only', 'bracket', 'has', 'over', 'rate', 'very', 'high', 'skill', 'asian', 'servers', 'So', 'shut', 'up', 'pick', 'something', 'fun', 'You', 'cucks', '2v5', 'lmao', 'captain', 'obvious', 'right', ':DD', 'better', 'buy', 'ticket', 'was', 'close', 'furion', 'kno', 'necro', 'book', 'push', 'think', 'rage', 'quit', 'agad', 'DONT', 'PANIC', 'GGW', 'P', 'see', 'oh', '13', 'kills', 'glad', 'got', 'suport', 'gogo', 'now', 'leave', 'five', 'stack', 'or', 'put', 'th', '24', 'come', 'mama', 'hhaha', 'throws', 'noobs', 'Tol', 'musta', 'Text', 'text', 'nalang', 'happens', 'am', 'waaa', 'void', 'dick', 'head', 't2', 'rosh', 'duza', 'lose', 'xaxaxa', 'gee', 'we', '5x4', '22', 'min', 'wheres', 'facepalm', 'emote', 'when', 'legion', 'carry', 'best', 'time', 'brew', 'pls', 'commend', 'ofc', 'its', 'stupid', 'no', 'ward', 'really', 'family', 'NOOB', 'acc', 'late', 'obviusly', 'pro', 'snierp', 'wihtout', 'dust', 'hey', 'snieper', 'basically', 'mirana', 'are', 'wrong', 'rep', 'rt', 'rubick', 'O', 'M', 'F', 'G', 'FANI', 'SUPHD', 'brood', 'REST', 'IS', 'Dude', 'slow', '180', 'pure', 'damage', 'chance', 'crit', '6', 'second', 'cooldown', '0', 'Genuinely', 'wait', 'dota', 'why', 'don', 'dare', 'how', 'long', 'mor', 'rofl', 'indeed', 'leader', 'hi', 'leong', 'sir', 'serenity', 'TY', 'alche', 'needs', 'BH', 'still', 'loses', 'See', 'next', 'lion', 'clock', 'finish', 'viper', 'coz', 'love', 'wO', 'AHAHAHA', '1vs9090123', 'reason', 'help', ';)', 'w8', 'plz', 'eco', 'mantan', 'LUNA', 'LVL', 'HAHAHA', 'need', 'recon', 'THANKS', 'TO', 'ME', 'GUESS', 'np', 'bought', 'account', 'dc', 'try', 'hard', 'nomas', 'one', 'hgahahah', 'both', 'yea', 'feeding', 'that', 'carried', 'haha', 'Tired', 'already', 'Level', 'Invo', 'jungle', 'Gank', 'pumped', 'load', 'cum', 'mums', 'ass', 'hole', 'last', 'night', '1', 'there', 'came', ':(', 'bye', 'nope', 'today', 'alc', 'normal', 'wont', 'hit', 'tht', 'minute', 'less', 'unstable', 'point', 'WR', 'suporting', 'our', 'asses', 'tb', 'veno', 'competent', 'ones', 'wr', 'maxed', 'wind', 'run', 'first', 'case', 'were', 'wondering', 'easy', 'btu', 'wouldve', 'if', 'd', 'idnt', 'cm', 'doom', 'aso', 'rl', 'bleme', 'gimme', 'aids', 'blem', 'temA', 'ten', 'lich', 'carrying', 'tissue', 'paper', 'dsnt', 'make', 'diff', 'fuckin', 'dickhead', 'Ge', 'ge', 'party', 'YEAH', 'DIDNT', 'HAD', 'THJE', 'SLOT', 'DUST', 'ADN', 'ALSO', 'GYRO', 'FFEDED', 'LOT', 'STILL', 'WE', 'TRIED', 'does', 'dazzle', 'hero', 'crys', 'e', 'pause', '3', 'ehehe', 'problem', 'ni', 'mei', 'great', 'gane', 'brobounty', 'brounty', 'GIGIL', 'THE', 'MAX', 'Ez', 'pudge', 'hjaha', '1000', 'HAhaha', 'entertain', 'fingers', 'defending', 'ancient', '4v5', 'PROBLEMS', 'PICK', 'DAZLE', 'ORACLE', 'GAME', 'FEED', 'ONLY', 'OPTION', 'gyro', 'earlyy', 'socre', 'MEEPO', 'TNX', 'lost', 'wut', 'One', 'by', 'Commend', 'support', 'HOW', 'BOUT', 'MID', 'flying', 'muy', 'valve', 'kkk', 'bara', 'charge', 'well', 'deinfinately', 'reporting', 'sf', 'hundy', 'ahahahahah', 'EPIC', 'goblok', 'sniper', 'FL', 'ready', 'get', 'dumpstered', 'legendary', 'laught', 'lel', 'cause', 'yo', 'flare', 'whats', 'sk', 'didnt', 'realize', 'seconds', 'those', 'tiger', 'snake', 'logo', 'wo', 'NO', 'REASON', 'CONTINUE', 'glhf', '4e', 'tam', 'zombie', 'where', '1v1', 'COMEBACK', ':#', ':3', 'ok', 'wouldnt', 'dp', 'sorry', 'couldnt', 'resist', 'quitters', 'Hahaha', 'Fucking', 'hell', 'SON', 'GOD', 'ALL', 'FCKING', 'JUNGLE', 'ITS', 'WARDED', 'retard', 'stalker', '14', '7', 'bh', 'ohhh', 'IIIIIII', 'NEED', 'KNOW', 'NOW', 'CAN', 'YOU', 'LOVE', 'AGAIN', 'boys', 'spend', '10', 'life', 'mate', 'SLARK', 'mouse', 'prob', 'yet', 'live', 'b', 'THIS', '2K', 'STORM', 'OMG', 'HAPPY', 'NEW', 'YEAR', '1400', 'Nice', 'lsot', 'junglers', 'any', 'worse', 'gege', 'noooo', 'Gg', 'rekt', 'what', 'playing', 'invo', 'an', 'alright', 'lineup', 'things', 'considered', 'also', 'lina', 'didnr', 'pos', 'visage', 'qop', 'huskar', 'Im', 'fantastic', 'Your', 'autistic', ':', 'pugna', 'funny', '25', 'ban', 'like', 'muted', 'yellow', 'dude', 'crying', 'stealing', 'his', 'dagon', 'lick', 'dildo', 'straight', 'reported', 'fck', 'ill', 'greeves', 'attaturk', 'match', 'excited', 'idiot', 'fail', 'ah', 'failed', 'going', 'rune', 'HAha', 'quelling', 'OK', 'ARE', '6k', 'Ok', 'spec', 'poor', 'network', 'U', 'seen', 'miracle', '1k', 'Freaking', 'reportt', 'axe', 'happened', 'before', 'missclick', 'pickphase', 'fought', 'bitch', 'early', 'cannot', 'supp', 'surivive', 'continue', 'yeah', ':P', 'But', 'WHY', 'SO', 'GGwp', 'hehe', 'after', 'being', 'fed', 'ds', 'typical', 'scared', 'made', 'from', 'potato', 'look', 'these', 'heroes', 'anyone', 'anymore', 'WOOW', 'happen', 'pa', 'okay', 'killing', 'liar', 'DID', 'WAIT', 'AA', 'tACTICAL', 'AFK', 'LMAO', 'SUpport', 'alchemiST', 'AlchEMist', 'BRO', 'AlcheMIst', 'Dont', 'SHy', 'Talk', 'nc', 'WTFF', 'HAHAHAHAHA', 'omggg', 'sitll', 'urge', 'ember', 'Bye', 'easiest', 'bate', 'ALCHE', 'uz', 'works', 'sparTA', 'D', 'yes', 'hack', 'ohoy', 'worthit', 'id', 'tap', 'astack', 'DC', 'mag', 'good', 'fucked', 'sd', 'said', '4k', 'cur', 'miss', 'anime', 'loving', 'gutta', 'luv', 'peru', 'breezy', 'suchtryhard', 'HABLA', 'BIEN', 'BURRO', 'threow', 'jajaja', 'oks', 'c', 'en', '38', 'sacas', 'sky', 'XD', 'iy', 'pl', 'loooooooool', 'wanted', 'x', 'le', 'epig', 'y', '2k', 'wk', 'doesnt', 'understand', 'Sure', 'riki', 'Rtc', 'ti', 'hes', '<3', 'titty', 'Crystal', 'Maiden', 'woodden', 'cock', 'use', 'aggro', 'hate', 'assholes', 'dual', 'lanes', 'jsut', 'practice', 'lest', 'faggot', 'tfw', 'must', 'punish', 'mega', 'cree', 'goo', 'Rofl', 'suck', 'killed', 'agagin', 'left', 'them', 'ghg', 'almost', 'couz', 'watching', 'holy', 'unpaused', 'ahha', 'w', '32', 'rapier', 'sec', 'loL', 'feel', 'mk', 'rip', 'peppers', 'NOB', 'TEAM', 'bash', 'brown', 'voker', 'EZI', 'ES', 'pc', 'freeze', 'necor', 'as', 'hehehe', 'Gs', 'EVERYONE', 'DESD', 'swap', 'bart', 'WOW', 'enigMa', 'offlane', 'AWWW', 'whine', 'S', 'OpieOP', 'wipe', 'would', 'surprising', 'fb', 'ta', 'fking', 'godd', 'GGWP', 'two', 'gems', 'Stop', 'HEY', 'OKAY', 'WANT', 'MORE', 'gl', 'endead', 'sylla', 'Ur', 'moving', 'paterns', 'weird', 'af', 'scored', 'build', 'stuns', 'Daun', 'na', 'weavere', 'venge', 'prosto', 'ebanutie', 'lsi', 'ebanie', 'little', 'What', 'calling', 'forced', 'fights', 'engagments', 'afk', 'had', 'mute', 'list', 'stuff', 'hahahaahah', 'lucky', 'bashes', 'unpause', 'fuq', 'tyu', 'omfg', '3k', '4k6', 'tele', 'Reportd', 'Noooob', 'trolls', 'la', 'smoke', 'price', 'increase', 'EXCUSE', 'HIM', 'ursa', 'WK', 'booya', 'fckin', 'antimage', 'xD', 'ROFL', 'rp', 'rim', 'starting', 'No', 'Today', 'mns', 'games', 'SEA', 'Oryou', 'home', 'father', 'some', 'FIGHT', 'PA', 'jajajaja', 'mlg', 'watch', 'watafak', '149', 'defend', 'counter', 'damn', 'told', 'mention', 'spoterd', 'spotted', 'thank', '2bad', 'TAKE', 'IT', 'LIAR', 'FRIENND', 'End', 'eat', 'jummy', 'BYE', 'gonna', 'safe', 'Team', 'maibe', 'RLY', 'scrubs', 'complain', 'nap', 'AND', 'HE', 'BAD', 'TA', 'rape', '58', 'mom', 'teach', '555', 'hahahahaa', 'return', '2012', 'LOLOLOL', 'USELESS', 'GO', 'ho', '68', 'having', 'cry', 'wasted', 'ulti', '<', 'died', 'inside', 'ago', 'cow', 'farmer', 'nightmares', 'SORRY', '30s', 'cd', 'true', 'items', 'nor', 'chat', 'reprot', '11', 'enigma', 'ftw', 'fight', 'PUDGE', 'If', 'fallout', 'here', 'dA', 'BB', 'GERAL', 'TEM', 'tnc', 'mineski', 'korea', 'ggggg', 'Weird', 'Dead', 'hyung', 'happening', 'mvp', 'hooking', 'mint', 'r', 'stupids', 'putting', 'es', 'ahahahah', 'lying', 'food', 'ye', 'mi', 'rampage', '=S', 'might', 'cleave', 'death', 'peneoise', 'listen', 'urself', 'LORc', 'LORD', 'SPECTRE', 'BLASPHEMY', 'alr', 'reconnecting', 'jajahaha', 'pub', 'safelane', 'bet', 'around', '30', 'guarantee', 'ive', 'commended', 'lesh', 'set', 'sentries', 'rather', 'than', 'mmrt', 'wagon', 'husk', 'From', 'PogChamp', 'alliance', 'back', 'ka', 'bu', 'tooooooooooooo', 'toxic', 'eggs', 'tsuyuyuy', 'tsokotomotoko', 'because', '10min', 'bush', '420', 'FF', 'lollllllllllllllllll', 'mother', 'snow', 'fine', 'friend', 'idk', 'WOWO', 'started', 'fighting', 'gods', 'kk', 'hahahahah', 'HAHAHAHAH', 'HAHAHAHHAHAHA', 'HAHAHAHAHAHAH', 'ya', 'od', 'panic', 'ADBOYS', 'slark', 'Farm', 'notthing', 'deal', 'fedeer', 'kay', 'nah', 'idont', 'thin', 'kso', 'eu', 'vi', 'tanto', 'q', 'deram', 'vai', 'se', 'fude', 'mlk', 'echo', 'err', 'FUCKING', 'item', 'HAHAHAHA', 'DDD', 'mostly', 'duel', 'caught', 'wisp', 'super', 'CHINESE', 'ebalo', 'shdi', 'davay', 'fast', 'para', 'les', 'toque', 'su', 'ranked', 'trying', 'laugh', 'working', 'pretty', 'comend', 'burn', 'speack', 'awkawkaw', 'ppl', 'shitty', 'pcs', 'IKR', 'idgaf', 'cuz', 'pinoy', 'block', 'probably', 'tholugh', 'eniggerma', 'smartass', 'radiant', 'wagger', 'mitches', 'haah', 'nyx', 'SOOOOOOOOOOOOOOOOBAD', 'CHAMP', 'abba', 'plsss', 'undying', 'using', 'tombstone', 'os', 'wins', 'legit', 'everything', 'uselsss', 'without', 'dmg', 'delay', ':DDDDDDDDDDD', 'nigga', '28', 'demage', 'kidding', 'LC', 'aahaha', 'monkjey', 'apologise', 'silence', 'sucker', 'Fuck', 'self', 'kids', 'Do', 'zz', 'english', 'arrow', 'tema', 'hola', 'ss', 'agree', 'trees', 'pushing', 'ooohhh', 'FUck', 'problems', 'her', 'bivaet', 'spamming', 'poormans', 'shield', 'stay', 'fucktrash', 'chill', 'relax', 'aggressive', '5200', '=', '5150', 'radiance', 'ikr', 'COMPRENDE', 'JUST', 'SAY', 'DADDY', 'stronk', 'idiots', 'entrense', 'burros', 'rc', 'recure', 'AMor', 'surely', '1st', 'goods', 'trad', 'Trade', 'hahaah', 'RETARD', 'reportr', 'nvm', 'full', 'wants', 'pad', 'KDAs', 'rly', 'ask', 'parents', 'CURIER', 'END', 'PLEASE', 'deep', 'wat', 'tri', 'each', 'day', 'suprised', 'omni', 'tell', 'pciks', 'moral', 'low', 'wards', 'k', 'teamwork', 'sure', 'saw', 'tech', 'BASTARD', 'REPORTED', 'TEH', 'cada', 'ves', 'tocan', 'mas', 'basuras', 'el', 'repoirt', 'FeelsBadMan', 'farming', 'fy', 'injoker', 'Yeah', 'Rektd', 'bout', 'w0w', 'magina', 'tekkies', 'TREANT', 'SOPRESA', ':v', 'throw', 'monkeys', 'YELLING', 'l', 'partyrock', 'lycab', 'scoreboard', 'blaming', 'atleast', 'doge', 'badtrri', 'ff', 'chmo', 'ebanoe', 'REPORT', 'TERROR', 'ops', 'welcome', 'talks', 'grave', 'predict', 'welll', 'begining', 'magic', 'aegis', 'bait', 'axaxaxa', 'FEEEEEED', 'MEEEEEEEE', 'mnmay', '1500', 'EZIEST', 'LIFE', 'dk', 'main', 'target', 'destroy', 'alttab', 'Report', 'ruining', 'attempted', 'desperate', 'winning', 'again', '20mins', 'mkb', 'pussy', 'happy', 'birthday', 'unfair', '9x', 'ebat', 'retards', 'Idgaf', 'intro', 'hahahahaah', 'Eveeeerrrrrrr', 'purges', 'shackles', 'missed', 'hook', 'black', 'ahahahahaha', 'called', 'p', 'hove', 'FAST', 'expect', 'ik', 'logic', 'bounty', ':p', 'yasha', '25mmr', 'ytou', 'sup', 'dun', 'techis', 'mood', 'thats', 'trench', 'gaming', 'aaahajahahahahhahahahahahaha', 'yuo', 'whingey', 'vodkahead', 'JAVRA', '1hr', 'bobo', 'acid', 'woulda', 'clash', 'feeders', 'bkbless', 'gryo', 'Yes', 'timber', 'dumbass', 'spelled', 'voting', 'Donald', 'Trump', '2016', 'For', 'wall', 'immigration', ':|', 'trow', 'teehee', 'emd', 'That', 'arlmet', 'LD', 'same', 'result', 'choice', 'sr', '3kscrub', 'way', 'wasnt', 'even', 'finally', 'The', 'monkey', 'pang', 'guinness', 'road', '5k', 'ooooooooooooooooooooooom', 'And', 'picker', 'every', 'RQ', 'luck', 'SAID', 'WANNA', 'EAT', 'DUDE', 'cute', 'red', 'john', 'irl', '44th', 'infantry', 'brigade', 'dagger', 'start', ';', 'Close', 'guess', '2min', '134', 'csw', 'Cs', 'hays', 'klng', 'po', 'ate', 'tY', 'mis', 'emer', 'money', 'io', 'tiny', 'wkwkw', 'until', 'ot', 'boga', 'kompor', 'bledos', 'gan', 'loosing', 'patience', 'FGOGOGOOGOG', 'jahahaha', 'enbd', 'invit', 'IDIOT', 'KONTOLAN', 'jug', 'pleasure', 'stream', 'reporta', 'ibama', 'fdp', 'sacrifica', 'animais', 'mates', 'bag', 'los', 'tienen', 'plata', 'queda', 'hablar', ':C', 'ayyyyy', 'she', 'stading', 'stree', 'AHAHAH', 'WAHAHGAh', 'Or', 'standing', 'front', 'others', 'YES', 'op', 'ugly', 'DK', 'XDXD', ':*', 'tusk', 'v', 'gank', 'yolo', '5v', 'familiars', 'wd', ':V', 'apparently', 'kiss', 'penis', 'hahahahahahahahaha', 'RADIC', 'MIN', '18', 'pheonix', 'puck', 'maybe', 'should', 'hug', 'ha', 'timing', 'rmk', 'Lol', 'ADADAS', 'Shut', 'LEL', 'ol', 'doing', 'rs', 'PAUSE', 'IM', 'SOO', 'LAG', 'HEREE', 'againts', 'Thank', 'coming', 'IDIOTS', 'gay', 'SVEN', 'boid', 'GLHF', 'work', 'net', 'scott', 'guts', 'against', 'BEST', 'BOOTS', 'MINS', 'enjoy', 'core', 'wicp', 'waahahaha', 'heheh', 'R', 'E', 'Ya', 'fucker', 'ouch', 'nasty', 'tide', 'In', 'picks', 'planned', 'EHEREE', 'WHEREE', 'buyback', 'possibly', 'FUCIK', 'FUCKA', 'TOYHPJ', 'wahts', 'FREE', 'LEAVE', 'wail', 'played', 'CENTAUR', 'NEVER', 'ULT', 'Dota', 'PL', 'added', 'disro', 'fu', 'tinker', 'Worst', 'ld', 'bashing', 'bommmm', 'wewe', 'jk', 'voer', 'retarded', 'once', 'HEALER', 'TOP', 'masturvbate', 'while', 'creeps', 'FUCK', 'KA', 'REALLY', 'gem', 'lie', 'sleep', 'child', 'BOT', 'worth', 'wb', '29', 'hows', 'soloing', 'hello', 'MMR', 'crashed', 'BKBS', 'walking', 'kotl', 'badly', 'ks', 'twice', 'aus', 'doita', 'quite', 'stuck', 'loading', 'screen', 'kid', 'creep', 'awarness', 'important', 'Cause', 'mad', 'luckman', 'wolrd', 'raped', 'letting', 'LOLOLOLOLOLO', 'waiting', 'chatting', 'outta', 'change', 'h', 'their', 'shiti', 'connection', 'brain', 'story', 'loser', 'sigh', 'Noob', 'SF', 'user', 'puto', 'RS', 'jz', 'df', 'worries', '5l', 'guy', 'Kappa', 'EVASIOOON', 'WHERE', 'DIVINA', 'RAPIRA', 'ptmr', 'ctmr', 'used', 'touching', 'reKT', 'doG', 'dad', 'taking', 'years', 'cigarettes', 'annus', 'commendation', 'ahhah', 'RUDE', 'WAITED', 'cyka', 'blyat', 'interwebs', 'BS', ':c', 'press', 'ogre', 'inveokr', 'draon', 'bottle', 'curier', 'PLS', 'Not', 'THINK', 'WAS', 'kjikl', 'GIGI', 'LOST', 'delete', 'purple', 'changed', 'mind', 'worst', 'cpt', 'ever', 'mine', 'HAND', 'NOOBS', 'Hehe', 'lmfao', '::D', 'gunna', 'rocket', 'league', 'INVOKER', 'Xd', 'ESSS', 'horse', 'recovered', 'bed', 'piece', 'uninstall', 'fuk', 'off', 'cumback', '9000', 'range', 'nothing', 'exams', 'jaja', 'daga', '20', 'actually', 'comment', '19', 'green', 'streaming', 'style', '5v3', 'someone', 'else', '2ez', 'ure', 'own', 'braindamaged', 'enemy', 'postion', 'Brb', 'ganking', 'ggw', 'tryhards', 'save', 'commened', 'commerd', 'lawl', 'onoob', 'suicide', 'Space', 'created', 'yoshi', 'missing', 'naga', 'aqop', 'tusker', 'bird', 'un', 'install', 'later', 'bane', 'ANO', 'BA', 'noobla', 'cuello', 'resume', 'deads', 'wew', 'tq', 'DMage', 'Duel', 'de', 'dark', 'daddys', 'bcuz', 'tards', 'waste', 'kontol', 'GWP', 'fuckign', 'boot', 'SAND', 'KING', 'been', 'though', 'funy', 'clowny', '3th', 'wqill', 'rpeort', 'semantics', 'aesthetics', 'word', 'looking', 'fin', 'hahaa', 'TANK', 'tryhard', 'known', 'vcs', 'sao', 'lixos', 'n', 'fode', 'acha', 'fez', 'algo', 'ainda', 'tirei', 'o', 'cara', 'sem', 'usa', 'vtnc', 'quiet', 'alchemist', 'raging', 'DP', 'revenge', 'avenge', 'courier', 'ruined', 'shakermon', 'huys', 'powershot', '71commends', 'thailand', 'yeah2', 'honorable', 'bb', 'niceu', 'lt', 'farmers', 'braindead', '12', 'old', ';/', 'bitches', 'wakaka', 'normalalc', 'ud', 'helic', 'mif', 'moan', 'starts', 'soon', 'CATH', 'LACSON', 'THAT', 'NOOOOO', 'roki', 'mmm', 'zzzzzzzzzzzzzzzzzzzz', '2hr', 'dota2', 'give', 'brah', 'Wag', 'mainis', 'ZZZ', 'yup', 'confused', 'ALLL', 'EU', 'DEUS', 'hahahaha', 'HAHAHAHAHAHHAAHAHAH', 't', 'below', 'invis', 'dunno', 'roams', 'El', 'adorno', 'mm', 'russians', 'Whats', 'rae', 'tp', 'armor', 'EAsy', 'izi', 'NICE', 'VISION', 'BLOCKED', 'VAC', 'words', 'bototm', 'lafe', 'yay', 'carries', 'TOOO', 'EZA', 'add', 'GGGGGGGGGGGGGGGGGGGG', 'genius', 'nood', 'lv', 'outlaned', 'non', 'steam', 'losers', 'GET', 'BFURY', 'FARM', 'HAS', 'MANTA', 'buyer', 'hw', 'eze', 'warlock', 'nerf', 'winter', 'wyvern', 'dies', 'LoL', 'harder', 'big', 'blue', 'looked', 'ggl', 'hims', '700', 'yaaaaaaaaaa', 'supports', 'new', 'LLOLOLOL', 'yr', 'xd', 'dendo', 'fel', 'mylife', 'drow', 'ragin', 'This', 'violent', 'peace', 'Just', 'Sf', 'serious', 'question', 'public', 'baited', 'DDUE', 'tried', 'aghanim', 'ls', 'cool', 'buyers', 'jesus', 'christ', 'At', 'lease', 'trashbag', 'sake', 'meepo', 'buff', 'THX', 'peruvians', 'loss', 'downs', 'culd', 'wrath', 'luna', 'stfu', 'botoom', 'Nah', 'Couldnt', 'handle', 'chuck', 'norris', 'BIRTH', 'DAY', 'ELDER', 'track', '3streak', 'aa', 'points', 'seeker', '400', 'jr', 'saving', 'spells', 'TOBBE', 'DUU', '115', 'guyz', 'supps', 'deserve', 'scary', 'youre', 'amte', 'TriHard', 'kappa', 'Comend', ':S', 'FAIL', 'dire', 'anyway', ';\\\\', 'learn', 'fk', '500gold', 'done', 'comendded', 'Ggwp', 'dumbfuck', 'american', 'elder', 'titan', 'spammed', 'freewin', 'sadboy', 'overkill', 'regardless', 'Can', 'Pseudo', 'total', 'uter', 'about', 'teamfight', 'Why', 'keep', 'leaving', 'offline', 'comback', 'snitch', 'bkbk', 'LET', 'sweet', 'dream', 'OUTTA', 'HERE', 'deaths', 'edad', 'slay', 'bastard', 'paused', 'shiet', 'nerds', 'havta', 'LMFAO', 'pz', 'magnus', 'brraiinnss', 'coo', ';!', 'angry', 'AUTIST', 'MEPPO', 'PLZ', 'LANAY', 'AHAHHA', 'BOOSTER', 'AHAHHAHAHA', 'BLIA', 'jugaer', 'phaton', 'IF', 'GIVEN', 'CHANCE', 'NOO', 'gigi', 'GETTING', 'GPM', 'tyou', 'p5', 'sven', 'priority', 'hohoho', 'lagging', 'dudes', 'god', 'falling', 'heavy', 'rare', 'reeport', 'rambo', 'paid', 'Lolll', 'sucking', 'ahaha', 'xDDD', 'cancerous', 'insane', 'invi', 'skillz', 'trol', 'luckiest', 'shackle', 'couple', 'beating', 'morning', 'HA', 'hold', 'secs', '500', 'ping', 'kl', 'bunch', 'climb', 'ore', 'defende', 'sai', 'daqui', 'Axe', 'nunca', 'tube', 'Done', 'rax', 'disruptor', 'gold', 'Hahah', 'SCARED', 'ahahha', 'tbh', 'literally', 'disconect', 'js', 'lal', 'careful', 'bite', 'rampagee', 'short', 'sali', 'sakin', 'con', 'estas', 'hay', 'fururo', 'clinkz', 'glglgl', 'wahaha', 'brotha', 'dot', 'lah', 'beh', 'BACK', '5K', 'OR', 'SLEEP', 'BAITED', 'taunt', 'morel', 'ike', 'Dc', 'BICTH', 'ggez', 'bobbbbbbbbb', 'conred', 'beef', 'gt', 'shirt', 'son', 'medusa', 'gayyy', 'Counterthrow', 'trilaning', 'XDDD', 'ahahhah', 'useless', 'jajaj', 'jedi', 'tricks', 'fake', 'Bg', 'rank', 'AW', 'wond', 'slaradar', 'WHOS', 'UR', 'nty', 'dotn', 'lady', 'relevant', 'thankfully', 'theres', 'another', 'sii', 'Me', 'toco', 'compatriotas', 'cos', 'skype', 'pauses', 'reading', 'mg', 'heuhue', 'coward', 'karma', 'ull', 'BARA', 'GOT', 'KILL', 'ultied', 'WHAT', 'YAY', 'NOLAG', 'newb', 'bomber', 'shaker', 'tider', 'wanna', 'HAVE', 'SUPP', 'BORING', 'COEM', 'SOME', 'quits', 'simple', 'indee3d', 'woobshe', 'base', 'flaming', 'fkn', 'joking', 'jumped', 'hex', 'name', 'PRO', 'YAYAYAYAA', 'LIL', 'PIMPO', 'FINISH', 'lh', 'PLEAS', '9', 'SPACE', 'players', 'naix', 'number', 'THATS', 'SUCKS', '50', 'Haha', 'OOOOOOOOOOOOOH', 'dirty', 'udid', 'twas', 'outside', 'lets', 'dragons', 'helloo', '4n4n', 'GAY', 'runes', 'sister', 'invoke', 'hope', 'techies', 'Rlly', 'volvo', 'INTRO', 'unbeliaveblay', 'lma', 'Easy', '27', 'Huh', '800', 'Fck', 'Dendi', 'rea', 'peruvian', 'Ask', 'pp', 'PRESENT', 'morph', 'youl', 'rares', 'yah', 'brave', 'GL', 'HF', 'matter', 'godlike', 'spree', 'STUPID', 'kotol', 'Always', 'ignore', 'JOKE', 'belong', 'mrrr', 'introgay', 'countless', 'send', 'hha', 'wy', 'compared', 'yours', 'score', 'pi', 'impact', 'othing', 'uys', 'hm', 'bit', ':saltY', 'ROAM', 'boom', 'daz', 'dced', 'porn', 'pornhub', 'com', 'atm', 'CREAP', 'imba', 'mmmm', '30sec', '5mins', 'lei', 'woops', 'EZPZ', 'browser', 'nort', 'harrass', 'pleaser', 'sereuse', 'shoulda', 'YTEPYEPYEPP', 'dr', 'uselees', 'repotr', 'Game', 'touched', 'sore', 'spot', 'HAHAHAAHHAHAHAAH', 'mango', 'coldsnap', 'W8', 'faith', 'prfile', 'alce', 'hf', 'facebook', 'feeder', 'making', 'sense', 'leak', 'nate', 'german', 'cares', 'ul', 'yep', 'pinoys', 'shortest', 'lfd', 'hfsdjsfd', 'tuskar', 'mins', 'laggs', 'agha', 'orchid', '46mins', 'call', 'drying', 'nail', 'paint', 'DIFFICULT', 'breed', 'hahahahahaha', 'wirth', 'LYCAN', 'GOOOO', '274', 'wala', 'nami', 'piso', 'drop', 'VEry', 'ms', 'manta', 'soloq', 'sitting', 'pukingina', 'kangkong', 'lancer', 'homophobic', '576', 'misss', 'javseen', 'ano', 'gtfo', 'gratz', 'ebola', 'jimmy', 'offensive', 'weh', 'divided', 'ARROW', 'MISS', 'faster', 'animation', 'eh', 'garbage', 'CANT', 'catch', 'spirit', 'tossed', 'offc', 'boosting', 'honestly', 'knows', 'Storm', 'sucked', 'wah', 'fam', 'Cant', 'minimap', '17', 'year', 'pliss', 'BUY', 'hardly', 'fat', 'liked', 'undy', 'ahahaa', 'decided', '80', 'againt', 'yeap', 'mby', 'pat', 'doeee', 'xddddddd', 'eng', 'deserved', 'loose', 'shout', 'SAd', 'gago', 'system', 'hahahah', 'L', 'trasktalker', 'btm', 'WAJA', 'AWAJ', 'SURPRISE', 'BLINK', 'bf', 'WOOOOW', 'SKILL', 'bristle', 'WHYYYYYYYYYYY', 'wowow', ':\\ue006', 'cores', 'average', 'act', 'haHA', 'pOOR', 'aM', 'FAT', 'INJOKER', 'tac', 'knew', 'srs', 'ddos', 'virgin', 'AHAHAHAHAHAHAHA', 'ky', 'ZIGA', 'lb', 'throwing', 'lolz', 'passed', 'gif', 'dogshit', '15', 'ON', 'TROLL', 'pay', 'rule', 'morphling', 'update', '2month', 'wishes', 'teammate', 'bottom', 'heart', 'MANA', 'VBEFORE', 'Be', 'diclk', 'reasons', 'soo', 'wtdf', 'ohh', 'w3w', 'LALALA', 'SNIPER', 'nature', 'prophet', 'mongoloi', 'abbadon', '600', 'sht', 'GEGEGEGEGEEGEEGEGEGEEG', 'create', 'lobby', 'believe', 'spike', 'during', 'Still', 'oo', 'OKEY', 'tps', 'YE', 'MATE', 'LES', 'Losers', 'knight', 'raporting', 'instead', 'menu', 'tango', 'trust', 'ea', 'girl', 'jap', 'iceblast', 'history', 'EZAOSO', 'rus', 'purpose', 'whyy', 'woow', 'nooo', '10120', 'RIP', 'PEACE', 'uh', 'How', 'Wait', 'MVP', 'makes', 'jugger', 'Russia', 'rub', 'harsh', 'failing', '16', '4800', 'delivers', 'throne', '1vs9', 'bow', 'king', 'touch', 'TQ', 'pudeg', 'meet', 'da', 'goin', 'amen', 'youjizz', 'respawn', 'tower', 'lesss', 'bless', 'communication', 'abuse', 'waht', 'DOESNT', 'YEEZYS', 'clement', 'ENDED', 'SERIOUS', 'klog', 'girls', 'dazz', 'days', 'Ye', 'backing', 'stacks', 'fq', 'PUDGA', ';3', 'spaz', 'KS', 'Any', 'EEEOOO', 'STICK', 'men', 'check', 'str8', 'mud', 'Ddiobnt', 'mbi', 'mge', 'yeup', '60000k', '4000', 'anyways', 'alone', 'autism', 'powerball', 'quickly', 'TAEWM', '34', 'forver', 'minutes', 'miles', 'tank', 'NOOV', 'nhice', 'yummy', 'flesh', 'heap', 'educated', 'person', 'moms', 'God', '890', 'rich', 'nono', 'hah', 'divine', 'maldito', 'oracle', 'bring', 'cumming', 'calm', 'double', 'wahahahah', ':`', 'waited', 'several', 'RART', 'DOTS', 'roflll', 'vroom', 'momment', 'babe', 'suoper', 'agreed', 'wil', 'ranger', 'ghost', 'ilu', 'stopped', '332', 'badluck', 'brian', 'ittttt', 'fuckig', 'sucks', 'chen', 'YF', 'CGHFIBDFTNCZ', '=)', 'venom', 'SAFELANE', 'AWFUL', 'dogshits', 'cunts', 'yuki', 'Sniper', 'peinose', 'anu', 'onngoys', 'Y', 'QUE', 'HAY', 'DE', 'LA', 'notlikethis', 'other', 'jizz', 'exited', 'THAN', 'FKCUNG', 'ACT', 'LIKE', 'kek', 'coulda', 'ruling', 'Send', 'z', 'gaben', 'sama', 'lfmao', 'PROseidon', 'WAwa', 'dces', 'orayt', 'hahahahaha', 'ruski', 'ragequit', 'aie', 'His', 'rally', 'dafuq', 'idot', 'considering', 'outcarry', 'razor', 'terrible', 'btr', 'east', 'fucktard', 'cj', 'which', 'pussi', ':m', 'THANK', 'eager', 'Dat', 'BOOM', '4v6', 'sorting', 'dw', 'zues', 'spy', 'pray', 'JARVA', 'jarva', 'nobss', 'SS', 'zeus', 'Back', 'usallt', 'goes', 'mf', 'HAAAAAAAAAAAAAAAA', 'thnx', 'trolling', 'takes', 'classic', 'yelloqw', 'FUCKIKN', 'TYPGIN', 'URT', 'succesds', 'rleady', 'pathing', '8k', 'SK', 'joke', 'liek', 'pee', 'diccks', '4TH', 'RUINED', 'BY', 'RETARDS', 'und', 'staying', 'near', 'smh', 'bother', 'supporting', 'tough', 'kit', 'kat', 'bkb', 'rapes', 'yung', 'namin', 'beyond', 'tanking', 'woo', 'gone', 'wasting', 'leaveee', 'trap', 'bear', 'Wew', 'pff', 'thaha', 'RAMPAGE', 'BOG', 'PROSTIT', 'weooh', 'kahh', 'arrivall', 'chi', 'dumbster', 'HAHAHHA', 'blademail', 'ggng', 'OP', 'heal', 'probs', 'dat', 'ahahahhaa', 'took', 'Ovision', 'abandoned', 'stats', 'recorded', 'Wp', 'boyz', 'reatrd', 'rq', 'Whuuuuuuut', 'Hahahaha', 'nigger', 'rdy', 'aga', '1v', '4d', 'amount', 'int', 'casters', 'plus', 'SMACK', 'MY', 'BUM', 'RUN', 'fvck', 'hooked', 'Lotte', 'cheese', 'lover', '52', 'transfer', 'TRANSFER', 'reborn', 'gpm', 'X', '=(', 'deti', 'govna', 'REKT', 'lul', 'xDDDDDDDDDD', 'odd', 'GUYS', 'DUSTTTTT', 'hans', 'dps', 'ccurious', 'freee', 'dusa', 'memba', 'says', 'GARAVCE', 'INA', 'WIN', '=3=', 'gigilmats', 'type', 'GGTY', 'FKING', 'peenoy', 'Mother', 'Fuckign', 'legolas', 'jojojo', 'anything', 'basdh', 'mepo', 'describe', 'greevees', 'reduction', 'hgahahaha', 'FU', 'woman', 'disturb', 'hmm', 'miran', 'XDDDDDDDDDDDD', 'smart', 'sahdow', 'Seattle', 'znaete', 'pered', 'tem', 'kriki', 'slil', 'napisal', 'ja', 'umeju', 'igratj', 'gemom', 'chtobi', 'ne', 'potreatj', 'ego', 'Ouch', 'doma', 'natures', 'WOo', 'zero', 'hastag', 'Puck', 'comes', 'HOOK', ':d', 'DAZZ', 'cour', 'pizza', 'scre', 'sydney', 'braaaaaaaaaaaa', 'slada', 'hihi', 'BELORUSSIAN', 'count', 'sum', 'mo', 'especially', 'shitness', 'OH', 'scrub', 'hiohi', 'focus', 'whiel', 'dis', 'tornado', 'bvlast', 'hc', 'safd', 'trawsh', 'STEAM', 'fuckj', 'thatsw', 'message', 'lessons', 'lot', 'wrond', 'no1', 'hits', 'longest', 'glimpse', 'coins', 'invok', 'fucks', 'writting', 'smht', 'BURN', 'huts', 'tf', 'heh', 'car', 'treeants', 'WORD', 'VS', 'apahal', 'srlsy', '63', 'computer', 'restart', '2others', 'creeeeeeeps', 'powerfull', 'laguhing', 'treatn', 'SLADAR', 'Qops', 'wu', 'turned', 'stone', 'unapuse', 'sladar', 'either', 'potomu', 'chto', 'tima', 'daunov', 'poetomu', 'proigrali', 'viva', 'csmr', 'noooooooo', 'CURSE', 'YOUR', 'SILENCE', 'ef', 'suka', 'syndrome', 'rules', 'Real', 'freak', 'value', 'Next', 'Oooooooor', 'laggggggggggggg', 'lagggggggg', 'RE', 'GOING', 'ROSH', '4v4', 'typing', 'pfft', 'sulod', 'mn', 'ILL', 'MOMO', 'ghrthj', 'Omg', 'alchi', 'nooob', 'Yawa', 'VOID', 'most', 'loozer', 'It', 'Ursa', 'HAHAH', '1on1', 'idea', 'WHAHAHA', 'ENEMY', 'whole', '4this', 'ic', 'ant', 'joker', 'outplayed', 'remnant', 'expire', 'haizzz', '6200', 'motherfuckers', 'deco', 'mong', 'children', 'wpwp', 'shitt', 'DODGE', 'find', 'BECAUSE', 'SUCK', 'SIR', 'BE', 'sabrura', 'tyy', 'FRIEND', 'WILL', 'BAKC', 'BITCCH', 'space', 'clue', 'Rq', 'NOT', 'COMING', 'LIAAAR', 'coin', 'attention', 'whore', 'ridiculous', 'iknow', 'EJEJEJEJ', 'ESE', 'CARRY', 'randoms', 'andrea', 'cavada', 'shame', 'THUSKAR', 'CANCER', 'NIGGERS', 'PUSSY', 'hopeless', 'ticklish', 'ar', 'NT', 'Aw', 'expected', 'line', 'feeds', 'goddddddddddddddddddddddddddddddd', 'buddy', 'slut', 'tard', 'gondar', 'spelling', 'buying', 'switch', 'VIVA', 'PERU', '2015', 'stable', 'AHAHA', 'agaisntt', 'unn', 'runnn', 'forest', 'move', 'WINDE', 'ShADOW', 'WINNER', 'JOJOJOJOJOJOJOJOJO', 'JOJOJOJOJOJO', 'JOJOJOJOJOJOJ', 'sick', 'hahahhahahha', 'beg', 'stomp', 'proud', 'lLlO', 'OLll', 'ooooooooooooo', 'PERUANETIRAR', 'frenchie', 'abandoning', 'quad', 'DEF', 'batya', 'urod', 'lonely', 'OUTPICK', 'calculate', 'thist', 'eam', 'roshan', 'spoil', 'tatctis', ':DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD', 'golbal', 'FTW', 'lvl', 'TOLD', 'bonus', 'preach', 'JOJOJOJOJ', 'scool', 'adn', 'treant', 'Pugna', '5x', 'Alg', 'John', 'Its', 'hood', 'commin', 'Snip', 'PING', 'hear', 'song', 'teamates', 'enemies', 'COOL', 'duo', 'pul', 'beastmaster', 'levels', 'away', '51', '300', 'speaks', 'abreak', 'Reconnecting', 'eating', 'popcorn', 'DUMB', 'WHOW', 'hhh', 'midas', 'odust', 'wrrou', '55', 'lelz', 'fuckers', 'lame', 'hAHA', 'health', 'ehp', '2V8', 'escape', 'doomed', '36', 'repport', 'slarder', 'stump', 'trump', 'whose', 'killsteals', 'staff', 'shud', 'tag', 'baby', 'urselves', 'favour', 'awful', 'ahahahaha', 'lmfaofmowemfoawemof', 'fool', 'stays', 'fare', 'pointless', 'beeeeeee', 'heaps', 'GHAHA', 'gf', 'sickening', '=D', 'Gl', 'Neah', 'Now', 'thsi', 'EHCO', 'REAL', 'sexy', 'enchant', 'boring', '4vs4', 'JOJOJOJO', 'itscool', 'WELL', 'PLAYED', 'GREAT', 'meduza', 'basura', 'mighty', 'reportenlo', 'nboob', 'dieback', 'scrim', 'walrus', 'punch', 'dog', 'DA', 'konek', 'pain', 'AMAZING', 'DOTO', 'tA', 'grieving', 'syr', 'fault', 'wiat', 'kunkka', 'smoked', 'gotten', 'reactively', 'similar', 'respect', 'earn', 'gets', 'direct', 'm', 'LAGGING', 'tree', 'yeahj', 'greaaaaaaat', 'ga', 'gfun', '89', 'Good', 'Slark', 'pounce', 'Then', 'DIE', 'HOLE', 'daun', 'juggeru', '1x', 'bby', 'grill', 'dotka', 'lad', 'ups', 'jdem', 'ggsf', 'shuld', 'agies', 'rubing', 'backwards', 'fcking', 'laughed', 'common', 'galet', '2v1', 'puj', 'spell', 'immunity', 'idaf', 'PLIS', 'sige', 'planing', 'gang', 'chase', 'repel', 'behind', 'people', 'sun', 'strike', 'lolll', 'STOP', 'Like', '5v4', 'zenokaia', 'artist', 'All', 'managed', 'silencio', 'supportado', 'asquerosa', 'rata', 'pulling', 'silver', 'edge', 'haiz', 'spa', 'ceba', 'pagaram', 'quanto', 'ele', 'PAPER', 'SHUT', 'UP', 'WIAT', 'tony', 'mongol', 'Ea', 'Srsly', 'donkey', 'cocks', 'probaly', 'sepctre', 'centaur', 'observe', 'backpack', 'fly', 'alt', 'tab', 'ts', 'post', 'ma', 'recommend', 'pleasE', 'accidental', 'WAHAHHAHA', 'noobnaut', 'notes', 'ezpz', 'Thk', 'OW', 'apa', 'OOPS', 'haters', 'qartveli', 'xart', 'vinme', 'vlve', 'givin', 'imbecle', 'loool', 'IZI', 'TINKER', 'Very', 'pry', 'key', 'keyboard', 'hihhiihi', 'disconnect', 'lies', 'liomn', 'HHEHE', 'raged', 'offalne', 'lasthitting', 'waves', 'glaives', 'Classic', 'STEAL', 'brakes', 'train', '26', 'ww', 'fckng', 'Brainless', 'SECXY', 'FROST', 'bloody', 'million', 'KEK', 'buys', 'MI', 'TODO', 'ANIMALES', 'MIERDA', 'cold', 'snap', 'SAD', 'twitch', 'business', 'mariks', 'Ahah', '60', 'yy', 'topo', 'eus', 'scepter', 'fishnet', 'COME', 'SHY', 'mr', 'homeboy', 'peenoise', 'ns', 'jakiro', 'epic', 'role', 'phah', 'lcvl', 'cose', 'BITCH', 'wannabve', 'wannabe', 'shh', 'kinda', 'Yo', 'pduge', 're', 'fucknig', 'BYEE', 'combo', 'tim', 'carri', 'Aa', 'WHAHAHAHAHa', 'TANGA', 'como', 'essa', 'templar', 'caga', 'mds', 'till', 'bk', 'THINGS', 'zzz', 'legal', 'cocky', 'just3kthinggs', '88', 'vlad', 'herself', 'tx', 'hid', 'measure', 'smash', 'aghs', 'em', 'sikerlerrrrrrrrrrrrrrrrrrrrrrrr', 'weak', 'remain', 'turn', 'ugh', 'holding', 'wooden', 'JOJOJOJOJOJ', 'cheers', 'opening', 'door', 'mrd', 'dayuuuuuuuuuuuuuuuuuuuuuuuuum', 'AHAHAHAHAHAHAHAH', 'countered', 'Crafty', 'vinter', 'curse', 'pass', 'butthurt', 'deso', 'f', 'above', 'CLINKZ', 'morons', 'Such', 'Clockwerk', '0v5', 'leh', 'vanguard', 'zones', 'combak', 'Woooooooo', '23', 'souls', 'requim', 'Na', 'Yup', 'spacecow', 'wehw', 'world', 'everyday', 'IMJUST', 'AROUND', 'RAKI', 'NE', 'DAYT', 'NA', 'blameee', 'FUN', 'ultra', 'STUN', 'lift', 'MERRY', 'CHRISTMAS', 'okey', 'cumbak', 'wrap', 'GOGOGO', 'She', 'Great', 'N', 'WAY', 'bl', 'olympics', 'sport', '2020', 'tired', 'kind', 'cc', 'hahhahha', 'hahahha', 'position', 'becoz', 'glfu', 'wood', 'alrite', 'ruiner', 'president', 'DR', 'GFG', 'cats', 'fire', 'badf', 'pusi', 'Qop', 'cheat', 'Doom', 'aware', 'MAP', 'WARD', 'focusings', 'draw', 'cabros', 'may', 'remind', 'unpauses', 'wahah', 'dneis', 'suppose', 'pusher', 'ajo', 'WIPE', 'joining', 'seems', 'risky', 'SUP', 'CM', 'doubt', 'Spit', 'peeps', 'bounce', 'DIED', 'BOUNCES', 'CREREPS', 'EWTD', 'Wtf', 'pussies', 'thus', 'alrady', 'fuckl', '5v5', 'pit', 'leggo', 'BOOOOM', 'counterpick', 'gusta', 'slarkino', 'Useless', 'useful', '3v7', 'learned', 'oyoyoy', 'yeahhh', 'ithought', 'fisure', 'tranquil', 'qw3kje', 'kowqnheui49jqwmke', 'yqakmsd', 'fvbr2uwieoakf8u49gjirufjnghyju3iuwjfmg', 'h4ijuwiksdfuyiMuyijamjy879ialnbyhabhgl', 'gnholb', 'fair', 'THROW', 'hte', 'majors', 'tomorrow', 'unknown', 'VG', 'ahh', 'jokes', '247', 'comdy', 'russia', 'spanish', 'botlane', 'cus', 'd2', 'crash', 'rngesus', 'kms', 'KITE', 'ocatarine', 'meta', 'contrita', 'probsn', 'delayed', 'inevtable', 'panics', 'ezz', 'okeyyy', 'yA', 'BCAUSE', 'NAME', 'row', 'grp', 'freind', 'CLOACK', 'B', 'aloone', 'spam', '4head', 'Hphhp', 'klool', 'gayish', '44455', 'NotLikeThis', 'clicked', 'f9', 'XDd', 'mider', 'fact', 'Wrekt', 'afks', 'slojno', 'KIND', 'MANY', 'Invok', 'realy', 'mumbarak', 'tryharding', 'hahhaha', 'sandstorming', 'Pro', 'FV', 'teaching', 'apperently', 'Epic', 'TF', 'THEY', 'CRY', 'wardinmg', 'job', 'choise', 'mall', '::)', 'ksing', 'abbandon', 'TB', 'aracana', 'b4', 'DO', 'CLOCK', 'crush', 'satan', 'following', 'fg', 'fountain', 'aways', 'murmuring', 'lord', 'Swan', 'Fuckyou', 'Fair', 'begging', 'OLEG', 'lolwut', 'OCMON', 'slutty', 'rock', 'server', 'Am', 'noisy', 'forgot', 'shoukld', 'Tping', 'KINKAA', 'gracias', 'ALREADY', 'SLARDAR', 'DOING', 'suppor', 'shorer', 'aba', 'illuminate', 'unplayabel', 'donnt', 'ply', 'gamne', 'trx', 'Told', 'iw', 'guna', 'klast', 'AWw', 'yourself', 'fuking', 'Dazzle', ':o', 'hahahaah', 'HAHAAH', 'fcj', 'bois', 'inv', 'KID', 'jajajajaja', 'NOPE', 'ending', 'fingered', ':>', 'tha', 'SEND', 'COURIER', 'commending', 'idc', 'shuit', 'tot', '==', 'aggresive', 'plays', 'd0', 'CUMING', 'wez', 'niggas', 'rn', 'rm', 'bcak', 'Ikr', 'REkt', 'uninstalld', 'ota', 'SEc', 'Srg', 'SUTRALIAN', 'ITNERNET', 'WOO', 'WHEN', 'STRONGER', 'HERO', 'MIRA', 'IMAGINE', 'PEOPLE', 'JOHN', 'LENNON', 'DOTA', 'ZEROS', 'Reported', 'vagina', 'butterfly', 'sided', 'jajajajaj', 'nobody', 'RAT', 'undiyng', 'druid', 'cai', 'dm', 'kinh', 'ak', 'whwere', 'frduikfaimcl', 'nigga1', 'stacked', ':DDDDDDDDDDDDDDDDDDDDDDDD', ':DDDDDDDDDDDDDDDDDDD', 'Running', 'WHO', 'Profile', 'private', 'heard', 'often', 'lool', 'eziest', 'PICKET', 'COTL', 'Gege', 'spammer', 'stole', 'wear', 'rapemid', 'incoming', 'Jessica', 'Feminazi', 'Eh', 'fell', 'ALCHEMIST', 'AUTO', 'spent', 'chasinbg', 'RAWR', 'JOIN', 'probleme', 'write', 'article', 'greatest', 'gtf', 'mess', 'GUYZ', 'snatch', 'israel', 'HOPPING', 'Help', 'daedalus', 'BUG', 'cheeky', 'Bat', 'bat', 'LIER', 'Jugg', 'MKB', 'surprised', 'walk', 'fuckingf', 'spastic', 'fug', 'defiance', 'glimmer', 'woww', 'TODAY', 'esa', 'bota', 'completa', 'appaK', 'realized', 'accountbuyer', 'rude', 'rest', 'forever', 'shadowfriend666', 'eternal', 'whatver', 'drunk', 'speaking', 'calms', 'tries', 'exe', 'definitely', 'FUCKIKGN', 'AWFUIL', 'ULTIS', 'PTS', 'zzzzz', 'goiod', 'face', 'roaming', 'misses', 'shambles', 'LO', 'ROLFH', 'Zzzzzzz', 'saying', 'ihihih', 'classes', 'interested', 'flarex', 'whereare', 'astart', 'stral', 'DECENT', 'STOODS', 'THERE', 'INVIS', 'blabla', 'ggwo', 'gaem', 'REMEMBER', 'KNIFE', 'TOILET', 'TEARS', 'roam', 'sniped', 'fukcing', 'necroo', 'biotch', 'WB', 'means', 'Rage', 'GeGe', 'skatin', 'ice', 'coast', 'ruin', 'positioning', 'bak', 'VOid', 'Thanks', 'place', 'trapping', 'warsd', 'WTf', 'siting', '54', 'snipe', 'iimmma', 'aim', 'couild', 't.', 'kamikaze', 'lock', 'waot', 'napkin', 'slayer', 'aight', 'PAUSING', 'lategame', 'few', 'months', 'dmkm', 'xpm', 'US', 'BTICH', 'gys', 'eye', 'comenden', 'laggg', 'jussssssssssssst', 'longer', 'wardz', 'ancients', 'obvius', 'phone', 'ing', 'thinsk', 'aye', 'hardlane', 'nno', ':DDDD', 'gv', 'BUYBACK', 'LIFESTEALER', 'bruh', 'steal', 'zail', 'UNDYING', 'somethings', 'SB', 'graphics', 'jus', 'useles', 'ULTI', 'teams', 'yoo', 'dooooom', 'giving', 'HOPE', 'XDDDDDDDDDDDDDDDDDDDDDDDD', '4vs5', 'AFKING', 'LANE', 'FUCKED', 'HARD', 'dogeee', 'ebashil', 'kak', 'mog', 'DEAD', 'denied', 'Probs', 'seriously', 'spoiling', 'kindly', 'heroess', 'alchim', 'Rc', 'HAHHA', 'extra', 'admire', 'friendsip', 'silencerrrr', 'Bad', 'Gem', 'stronger', 'wyverns', 'iguess', 'cya', 'bmw', 'schei', 'marke', 'cnosite', 'eto', '110', 'floatey', 'AHYAHAHA', 'encan', 'thoughts', 'wioth', 'writing', 'Fast', 'fnish', 'wish', 'ZERO', 'WOOOOOOOOOOOO', 'WALLLLS', 'To', 'wjahaha', 'creap', 'hh', 'skali', 'bulldog', 'auchhhh', 'global', 'boyS', 'Lolz', 'baka', 'kasi', 'tumaba', 'kayo', 'Glaubst', 'du', 'nicht', 'resumed', 'memememememem', ';_;', 'Fine', 'hetero', 'DOUBLE', 'PROPHETATION', 'haa', '2mins', 'LETS', 'SEE', 'WERE', 'HIDDING', 'sire', 'sange', 'shadow', 'aeguiis', 'horrible', 'yt', 'awit', 'congrats', 'WOOOOOOOOOOOOOOOOOO', 'online', 'ecks', 'dee', 'pickers', 'AHAAH', 'crystal', 'SOD', 'tyty', 'washroom', 'RUS', 'sumail', 'copy', '2FCKNG', 'basin', 'botbot', 'RIKI', 'ENXT', '=trash', 'craggy', 'ahah', 'Russian', 'log', 'creeepy', 'recording', 'WHERES', 'LION', 'AT', 'CUTE', 'MAGNUS', 'abondon', 'altest', 'maby', 'practis', 'missile', 'speed', 'balls', 'xDD', 'becuse', 'dumbuck', 'sok', 'jajajjaa', 'recorder', 'inches', 'Ezi', 'hahahhaha', 'DED', ':DDD', 'tells', 'tanga', 'genuinely', 'singsing', 'srsly', 'disgrace', 'LODA', 'pla', 'lags', 'brai', 'toxi', 'leguon', 'C', '===3', '23:59', 'LOOOL', 'actualy', 'among', 'fuckong', 'bying', 'pushes', 'forward', 'Lycan', 'wolf', 'hates', 'flames', 'tactical', 'LOSE', 'TEAMMATES', 'playeres', 'stealmid', 'mon', 'begin', 'cykaseeker', 'racist', 'theyre', 'juger', 'WHATTTTTTTTTTTTTTTTTTTTTTTTTTT', 'wnna', 'trolled', '3rd', 'Really', 'SOUND', 'ISSUES', 'max', 'totem', 'kick', 'duallane', 'ewait', 'fkng', 'pressure', 'fellas', 'jjaja', 'facts', 'EZZZZZZZZZZZZZZ', 'MUITO', 'FACIL', 'ruim', 'FAKE', 'WORLD', 'WONDERLAND', 'nearly', 'Troll', 'Get', 'rapira', 'chances', 'plss', 'rof', '9k', 'Def', 'Hell', 'pail', 'icant', 'hide', 'slanty', 'doh', 'reward', 'cockwork', 'combined', 'confirmed', 'perdedor', 'hurry', 'afraid', 'wc', 'ANY', 'QUESTION', 'Are', 'They', 'OUR', 'wag', 'rec', 'SWORD', 'EFFORT', 'ezy', 'Hahahah', 'manners', 'Pikachu', 'brings', 'ptsd', 'n1', 'Hes', 'busy', 'shittalking', 'Rubick', 'PUL', ':L', 'LOOOOOOOOOL', 'RECOMIENDENME', 'Wat', 'rpo', 'Windranger', 'KDA', 'tune', 'ooh', 'oppennenth', 'bn', 'OFF', 'electricity', 'wats', 'saddlebag', 'ou', 'master', 'hurts', 'beleive', 'LOW', 'QUALITY', 'MADE', 'CHINA', 'HC', 'ezt', 'tangos', 'Il', 'wae', 'Wave', 'sword', 'MAGINA', 'hahahahhahahahhahahahahhahahha', 'geg', 'rase', 'excellent', ':O', 'AHHASDA', 'BL', 'pidaras', 'jkes', 'chinese', 'bwersit', 'itgma', 'fickler', 'pugne', 'test', 'LEKT', 'CHECK', 'HAHGA', 'POGI', 'butu', 'wpould', 'ow', 'ARER', 'LUCKY', 'BYING', 'ACC', 'talkshits', 'omniknight', 'fixed', 'Reasons', 'GIVE', 'CARRIES', 'Guys', 'che', 'lz', 'icefrog', 'lars', 'ricken', 'ran', 'hurt', 'completely', '40', '2x8', 'dendiFace', 'W', 'fAIL', 'eVER', 'Nc', 'level', 'half', 'suports', ':DDDDD', 'LOSER', 'REF', 'FFS', ':OOO', 'taht', 'windows', 'tgx', 'LL', 'DEFEAT', 'CIS', 'SCUM', 'nid', 'tan', 'desesperado', 'AUSTRALIA', '118', '1188', 'looks', 'plis', 'vision', 'bset', 'matchup', 'meepwn', 'redemption', 'humilition', 'smack', 'homie', 'puge', 'maiden', 'pidori', 'emore', 'idiotd', 'towets', 'towers', ':DDDDDDDDDDDDD', 'jhahahaha', 'helps', 'Alliance', 'holes', 'broken', 'boyss', 'aint', 'ultis', 'gustav', 'pts', 'planting', 'mines', 'bullshit', 'nbice', 'niceeeeeeee', 'winner', 'wwe', 'champion', 'ded', 'EASY', 'tooeasy', '12mins', 'TEST', 'chuchamadre', 'gayest', 'bolas', 'guyss', 'rlly', 'srry', 'duzel', 'retaRD', 'BAstaRD', 'eport', 'dazel', 'abandon', 'alesso', 'klamamaa', '300mins', 'somalis', 'moneys', 'soz', 'stooping', 'introboy', 'vodka', 'balalaika', 'BUSH', 'luckymen', 'luckyman', 'anti', 'mah', 'kple', 'bulsshit', 'REKY', 'CUNTSS', 'Stfu', 'nest', 'lOL', 'buds', 'flamer', 'hve', 'chest', 'afff', 'definitelly', 'Enigma', 'spare', 'gaems', 'mucho', 'ahahahhahahah', 'TINY', 'alolololo', 'computers', 'kinse', 'casi', 'Jjajajaja', 'speak', 'allied', 'pinky', 'swear', 'Run', 'nooooooooooooooooooo', 'waifu', 'braidnead', 'LP', 'belongs', 'lian', 'farmed', 'ididnt', 'ulit', 'blamed', 'adjusted', 'wth', 'FK', 'TENGENE', 'SHACKLESHOT', 'CONNECT', 'ACTUAL', 'Literally', 'pausing', 'rad', 'PLAY', 'POR', 'FAVOR', 'built', 'gifts', 'vagi', 'motrher', 'wjore', 'side', 'Targeting', 'laid', 'christopher', 'leon', 'passive', 'BIG', 'DEFENCE', 'lots', 'K', 'DOWN', 'masochist', 'taste', 'spicy', 'thai', 'era', 'TROLLING', 'Phew', 'shackled', 'wdc', 'booo', 'ingame', 'cummin', 'TAU', 'KONTOOL', 'lkol', 'cumed', 'YA', 'PUDG', 'AXE', 'GMA', 'midtime', 'Sec', 'Last', 'Online', 'comew', 'friends', 'BETTER', 'STORY', 'helping', 'lopl', 'standin', 'troll', 'CMON', 'CREEPS', 'tilt', 'mode', 'engaged', 'cast', 'positive', 'Awww', 'restarting', 'goodbye', 'flame', 'aseeeeeee', 'jer', 'bank', 'chrono', 'Aaa', 'laptop', 'oyoyoyoyoyoyoy', 'wombo', 'Sweet', 'AHAYHAYHAY', 'ganked', 'noce', 'disr', 'doe', 'hours', 'wisdom', 'te', 'shu8t', 'mouth', 'tramp', 'kh', 'XXDDD', 'IO', 'THOUGH', 'RLZ', 'cena', 'undertaker', 'ajajajjaaj', 'ppor', 'HI', '4V4', 'HAAH', 'SJIT', 'Spec', 'thinks', 'nicveee', 'yeeeeeeeeeeeeeeeep', 'kunka', 'beast', 'oooh', 'jukes', 'tis', 'blaco', 'veryyy', 'needed', 'inb4', 'maphack', 'LAg', 'orge', 'farmt', 'mehr', 'als', 'jeder', 'bauer', 'criticism', 'pipe', 'such', 'wsTF', 'DOES', 'SHOOT', 'betulan', 'maap', 'tr', 'howdu', 'innocent', 'info', 'MADNESS', 'wa', 'thinking', 'yeh', 'orgies', 'sakai', 'huge', 'bonert', 'pano', 'confident', 'backfired', 'poo', 'wahahaha', '1min', 'bes', 'CHATING', 'sa', 'wakas', 'mga', 'ungas', 'WORST', 'BUILD', 'IVE', 'EVER', 'SEEN', 'alcehmist', 'reminant', 'warded', 'hHAHAHAHhAhahah', 'CORE', 'ROLES', 'TAKEN', 'BOYS', 'WOOOOO', 'scare', 'BF', 'Cm', 'mentality', ':EGKAYA', 'IE', 'VI', 'GDE', 'ggf', 'hunt', 'born', 'connectio', 'doin', 'NORM', '5K4', 'BOYZ', 'SAME', 'PARTY', 'metaplayer', 'DON', 'WAKE', 'FO', 'BOY', 'LOOK', 'MA', 'BOTTOM', 'EVEN', 'THEYRE', 'PRU', 'named', 'VERI', 'TAIRED', 'YO', 'goddamit', '10000', 'Doing', 'Oh', 'along', 'helpless', 'OCTA', 'CUMBACK', 'ALLIANCE', 'bla', 'TRADE', 'noobest', 'melee', 'extent', 'notification', 'Dire', 'spawns', 'remaining', 'Wak', 'wak', 'RUIN', 'abit', 'geam', 'ktukan', 'udh', 'hilang', 'cok', 'pink', 'dropped', 'patch', 'braker', 'thesee', ':[', 'Add', 'dzzle', 'dads', 'arsehole', 'STFU', 'reports', 'INVISIBLE', 'BROTHER', '33', 'tee', 'hee', 'issues', 'gagaga', 'welp', 'YAAH', 'rubic', 'greed', '9999', 'fue', 'megas', 'comp', 'monger', 'assasin', 'Same', 'Life', 'Strange', 'nuke', 'town', 'qquesiton', 'mever', 'agian', 'comfort', 'EMBER', 'balanced', 'awesome', '3mins', 'tE', 'HIZO', 'KKK', 'upports', 'WARDS', 'neverr', 'fak', 'ssory', 'nightmare', 'abilities', 'amirite', 'dreaming', 'madafaka', 'Lina', 'EAZY', 'NAO', 'FARMEI', 'pingas', 'MISSING', 'LAST', 'HITS', 'WITH', 'CHILLING', 'TOUCH', 'FINALLY', 'spelll', 'ckeckek', 'bkbs', 'SOMeBODY', 'TELL', 'USE', 'HIs', 'PASSIVE', 'blur', 'ComEbAcK', 'ALcheMISt', 'WHy', 'QuiET', 'singapour', 'tie', 'BROWN', 'CUNT', 'JUMPING', '10k', 'Well', 'thinke', 'PC', 'reconect', 'todl', 'uwhere', 'bullshitting', 'merry', 'SONG', 'decide', 'opn', 'whyyyyyyyyyyyyyyyyyyyyyyyy', 'exist', 'happend', 'ibrahimovich', 'WOAAAH', '1m', 'ahead', 'shy', 'bek', 'compo', 'mobo', 'BAM', 'BOM', 'BAm', 'losses', 'bF', 'XDDDD', '2MINS', 'DADY', 'puede', 'tocar', 'mierdas', 'laged', 'fuckerclink', 'kekke', 'DEFENDERE', 'Repord', 'pinke', 'loo', 'Invoker', 'fuken', 'om', 'arnt', 'wild', '5man', 'appears', 'tus', 'DS', 'u2', 'auto', 'BKB', 'gud', 'FUCKIN', 'HAH', 'tahts', 'impossible', 'KDDDDDDDDDDDDDD', 'SILENCER', 'Fortify', 'WTFG', 'Anything', 'quilspray', 'blinking', 'towards', 'KNEW', 'psl', 'tu', 'pouse', 'nub', 'tch', 'sda', 'ezwp', 'yrs', 'disconnecting', 'Therikavidalama', 'motherfuking', 'roofl', 'fuckhead', 'somehow', 'JUGER', '=\\\\', 'PEENOISE', 'teamchat', 'noone', 'WAT', 'HAPPEN', 'looy', 'pud', 'drag', 'beat', 'fow', 'show', '45', 'uhhh', 'takogo', 'slova', 'Serenity', 'boiz', 'hao', 'ACCOUNT', 'BUYER', 'scum', 'deserver', 'Our', 'owe', 'moments', 'OD', '4v', '5500', 'europe', 'matchmaking', 'ck', 'si', 'eaz', 'jimbo', 'pushte', 'otjimayu', 'voice', 'command', 'lm', 'pe', 'lika', 'ability', 'radience', 'fv', 'youtube', 'noice', 'hAHAHAHAHA', 'hAHAHAHAHAH', '5555', 'zeuiz', 'newbie', 'PREDICT', 'ANTI', 'PUSH', 'smar', 'diz', 'CLQ', 'counted', 'ITEMS', 'TARD', 'okayu', 'nobo', 'doctors', 'crazy', '1vs1', 'exp', 'likely', 'drain', 'wave', 'essez', 'wii', 'TINEKR', 'unstopdbl', 'XAxaxaxax', 'dying', 'doiung', 'noithign', 'idestroyed', 'XA', 'gotem', 'xhamster', 'Keep', 'doods', 'onlinE', '360', 'fgts', 'hooks', 'cal', 'dirt', 'bags', '1v5', 'EZE', 'Tho', 'hot', 'FURION', 'GOGO', 'clearly', 'katka', 'REportd', 'delte', 'fame', '41', 'SWEAR', 'Him', 'fog', 'gob', 'smacked', 'euls', '329', 'deny', 'stfuy', 'galwang', 'ninja', 'VOLVO', 'click', 'button', 'att', 'tj', 'ust', 'aoe', 'FUHRZEN', 'thrwos', 'ROLF', 'annoying', 'aahahhaa', 'denies', 'comeo', 'killer', 'shpould', 'iron', 'branch', '4min', 'KONTOL', 'ANJING', 'namaste', 'ji', 'ALCEHMIST', 'Tea', 'snowball', 'hayshit', 'gayshit', 'uheuhee', 'mints', 'habia', 'muerto', 'huevie', 'tecla', 'pm', 'calculated', 'lasted', 'huhhuhuhuhuh', 'yall', 'soft', 'hed', 'allies', 'PUASE', 'teliin', 'Okay', 'byebye', 'LOl', 'ganks', 'POOR', 'ZEus', 'salty', '200', 'leaderhsip', 'rewporetd', 'BAJCHS', 'THEN', 'FEEL', 'NC', 'blackout', ';(', 'giff', 'victory', 'Stupid', 'Lmao', 'recipe', 'destroyed', 'upgrade', 'Free', 'ASK', 'ALWAYS', 'MOST', 'WHOCARES', 'AUTOWIN', 'loa', 'deek', 'Bunch', 'kunts', 'candy', 'ramp', 'ehueheuheu', 'eTO', 'TI', 'TAK', 'NAMEKAEW', 'TOB', 'TEBYA', 'NAXYU', 'POSLAL', 'AAAA', 'ETO', 'NORMAL', 'MALENK', 'PIZDABO', 'YASNO', 'IDID', 'ZAEBAL', 'YJE', 'wrekt', 'lowprio', 'HEHHE', 'diebacks', '540', 'golds', 'Kramer', 'First', 'TREASUES', 'FASTR', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'kiddo', 'pushed', 'ghaha', 'iKR', 'dOG', 'BRAIN', 'det', 'emil', 'stabil', 'amazing', 'tidew', 'teammates', 'demoralize', 'HIS', 'CENAAAAAA', 'ezezeze', 'nnono', 'Earthsahker', 'sucka', 'deffing', 'rapiraa', 'hahahhahahahah', 'OHMEN', 'gettin', 'squeaker', 'alchie', 'minions', 'badabing', 'Gamers', 'ew', 'sents', 'leash', 'musa', 'noobis', 'nabs', 'Baited', 'cl', 'hands', 'SLOW', 'erroe', 'error', 'o0ne', 'motherducker', 'leslie', 'graphic', 'lower', 'ole', 'BABY', 'TIGHT', 'BLACK', 'COLOUR', 'Blind', 'phew', 'NOOO', 'tt', 'tron', 'comon', 'EEEEE', 'quickscoped', 'TRY', 'turk', 'fan', 'brother', 'whoops', 'unfortunately', 'fish', 'alien', 'CUZ', 'LEFT', 'BEFORE', 'MINUTES', 'MAG', 'ARISE', 'FEEDING', 'thief', 'lay', 'every1', 'asked', 'Atos', 'Abba', 'Err', '6v4', 'forget', 'prefere', 'actuially', 'ed', 'confidence', 'jump', 'fall', 'pip', 'mental', 'casual', 'niggumus', 'lil', 'boi', 'posion', 'cans', 'outplayd', 'ulol', 'skrub', 'Defend', 'internal', 'stacktrash', 'mat4es', 'disconnects', 'disconnected', 'brist', 'rekon', 'Wasfucking', 'eeeeeeeeeeeeeeez', 'meh', 'sielnecr', 'lotus', '47', 'eaxe', 'oging', 'natural', 'lowest', 'tier', 'kunt', 'BABILO', 'FUNNY', 'ulty', 'orryt', 'commedn', 'laning', 'cs', 'stage', '=raport', 'flaws', 'ezzz', 'DISCONNECT', 'ARBOL', 'WD', 'itch', 'bisaya', 'pisot', 'hgahhaha', 'bell', '=]', '2hp', 'soookaaa', 'reporten', 'critical', 'bog', 'manner', 'WOOOOOW', 'friendly', 'pickin', 'DAZZLE', 'SUCKMID', 'TOO', 'woah', 'der', 'isee', 'grey', 'packetloss', 'pwn', 'nubs', 'DAzl', 'ako', '7k', 'abited', 'eks', 'DD', 'ggg', 'JOJOJOJ', 'Sorry', 'walked', 'disgusting', 'wispo', 'guysreport', 'pill', 'themoreyouknow', 'republicans', 'ay', 'ylmao', 'mne', 'gus', 'yozu', '143', 'arms', 'shaking', 'jESUS', 'CRHIST', 'ignored', 'whant', 'hr', 'blackhole', 'titling', 'traash', 'connect', 'wtfast', 'connecting', 'Before', 'negative', 'psycho', 'ahahah', 'thebest', 'Crrrrunch', 'Sladar', 'tagal', 'WORTH', 'divers', 'maaaaadd', 'afford', 'gooo', '1cd', 'gggg', 'ABOUT', 'MJOLNIR', 'tit', 'cna', 'GRAVE', 'THOUGHT', 'CREEP', 'plant', 'trsah', 'milk', 'sclard', 'werth', '20sec', 'l2p', 'Liol', 'treants', 'linte', 'kamu', 'wsp', 'loda', 'gr8', 'b8', 'HAPPENING', 'morale', 'follow', 'dodge', '4ks', 'barking', 'gamme', 'week', 'drugs', 'nikolaiv', 'illu', 'haahhaah', 'Because', 'constantly', 'gtting', 'wollongong', 'south', 'dapto', 'maube', 'bully', 'Sexyness', '5min', 'LEARN', 'FCKTARD', 'easier', 'explain', 'bility', 'tjat', 'fayze', 'fireworks', 'Chase', 'suicede', 'Go', 'nmooob', 'DXXDXDXDXDXD', 'Mirana', 'usles', 'playes', 'Who', 'dooms', 'PUGNA', 'ShUT', 'FAQ', 'asfd', 'ojgba', 'lolo', 'tolko', 'imenno', 'izza', 'nego', 'eZ', 'nyxnynyxynxnyxnyxnyxny', 'healed', 'butterfl', 'alreadty', 'girlssss', 'Thx', 'Anyone', 'Suda', 'idite', 'Vseh', 'viebu', 'plx', 'babilo', 'hmmmm', 'atar', 'xaxaxaxaxaxaxaxax', 'dAT', 'optus', 'cake', 'tsunami', 'Rampage', '2nd', 'ory', 'oryt', 'OkAY', 'aLcheMIst', 'clcockwerk', 'lolllllllll', 'AAYY', 'notice', '350', 'Also', 'shiny', 'ezzzy', 'confsued', 'SPARE', 'mofo', '233', 'LAGH', 'plzz', 'stroking', 'SEARCH', 'FB', 'CEN', 'IZA', 'ruskies', 'west', 'brutos', 'clashing', 'wrote', 'xyilo', '2248', 'wpwpw', 'san', 'lupam', 'pairs', 'Low', 'gam', 'KIDS', 'streak', 'HAHAHAHAHHAAH', 'response', 'pot', 'XDDDDD', 'RIGHT', 'pizda', 'KEKEE', 'sound', 'sent', 'kaka', 'lang', 'KUNKKA', 'GEGE', 'BIGBADBIRD', 'easi', 'asking', 'JAMES', 'DEAN', 'paste', 'Atlas', 'tanginmao', '=.=', 'amiga', 'THATM', 'ISS', 'plantign', 'Alchemist', 'j', 'blyj', 'mushe', 'Stick', 'FACTS', 'rubish', 'OMg', 'reportd', 'Fail', 'rege', '1ult', '3die', '53', 'SRSLY', 'sisihan', 'BRING', 'CHEESE', 'sgh', 'shrapnel', 'craos', 'craps', 'spoils', 'robot', 'damo', 'LESSON', 'enter', 'fingering', 'begins', 'stains', 'shhht', 'alchee', 'astraling', 'rofmao', 'lovely', '8with', 'NP', 'clinkzz', 'LELS', 'checked', 'sat', 'PLAYERS', 'HALLO', 'ng', 'ROFLAJHJAKHDJAKLDNALKDN', 'um', 'haf', 'thjis', 'SPEC', 'bey', 'Coold', 'toilet', 'raku', 'o0o', 'ambulance', 'ahhaha', 'ezmid', 'AHHAH', 'glgl', 'fix', 'internet', 'SUMIAL', 'WANNABE', 'eva', 'ggwep', 'feeed', 'reasonable', 'DU', 'flashmob', 'tbd', 'frustrated', '38flesh', 'JUGG', 'V', 'MUTE', 'KSTATE', 'Miis', 'Follow', 'riiight', 'meanwhile', 'finding', 'Q', 'HAHHAA', 'HES', 'ONLINE', 'fist', 'HELLO', 'young', 'bulgarian', 'sausage', 'leki', 'xdxd', 'irony', 'usless', 'Say', 'NAXREN', 'mOM', 'basket', 'thrid', 'ALCH', 'SAYS', 'TEQ', 'between', 'SADBOIS', 'newbs', 'piNOY', 'glglgllglglglgl', 'CUTIE', 'hisssssssssssss', 'swpt', 'lolllllll', 'ajajajajaa', 'downies', 'orange', 'DICK', 'AS', 'LONG', 'WANTS', 'ASS', 'ranged', 'AHHAHA', 'idol', 'xaxa', 'missle', 'spiked', 'uselss', 'CHARGE', 'power', 'Sexy', 'cud', 'sunsfan', 'PREPARE', 'ANUS', 'wipping', 'SEXYYYY', 'goodnight', 'ZZ', 'rusk', 'BOMJI', '2100', 'XDDDDDDDDDDDDDDDDDDDDDDDDD', 'roflmao', 'itttt', '9(', 'HACKS', 'SCRIPER', ';;', 'INTO', 'GOOD', 'IDEA', 'havent', 'idots', 'POTANG', 'KAYO', 'BIGYAN', 'NIYO', 'NAMAN', 'AKO', 'NG', 'HALAGA', 'ling', 'hahyahahahe', 'maen', 'california', 'smooth', 'MAD', 'HAHAHAHHAA', 'DAEDALUs', 'GAMING', '66=65', 'sut', 'remember', 'sandstorm', 'Wow', 'Cumback', 'PUSHED', 'gass', 'apperantly', 'moved', 'assist', 'babay', 'ASSHIT', 'DEN', 'peruca', 'JAJA', 'oops', 'WRTF', 'Where', 'Ahaha', 'bounces', 'DAGON', 'stressed', 'cheeeers', 'gaaaame', 'navi', 'DEDZ', 'LOLS', 'DUEL', 'retardedrer', '=d', 'Recon', 'youll', 'pissed', 'nerd', 'department', 'invokers', 'NOOOOBEST', 'oblivion', 'aha', 'ryan', 'evening', 'tping', 'fear', 'footfalls', 'rolf', 'NEXT', 'GJ', 'gift', 'ROSHING', 'GOGOOGOGOGOGOGOGOGO', 'SUPPOSED', 'MUTED', 'Die', 'Hallo', 'pacan', 'midasom', 'centaurs', 'noooooooooo', 'erm', 'Please', 'month', 'dogggg', 'Hope', 'bucks', 'HIO', 'comke', 'cop', 'cent', 'skyrath', 'duels', 'absolutely', 'improves', 'HOUR', 'paly', 'shitties', 'haaha', 'tinekr', 'benn', 'worthy', 'RANDOM', 'ALCHI', 'UGLY', 'FUCk', 'rweport', 'fsuck', '3mretards', 'haha1', 'sunstrike', 'hand', 'depends', 'BWAHAHHA', 'm9', 'horrivel', 'amming', 'eys', 'cult', 'personality', 'punk', 'karl', 'queen', 'shold', 'finished', 'earlier', 'yee', 'break', 'dh', 'evahh', 'SAEC', 'unifi', 'issu', 'packet', 'cz', 'gamming', '=-=', 'sidruptor', 'enought', 'cb', 'oppenent', 'soght', 'NOZA', 'pants', 'LOOL', 'Wa', 'skilled', 'boyfriend', 'penetrated', 'fairplay', 'noore', 'initiation', 'cheekyness', 'chaeter', 'cloak', 'clickers', 'listo', 'fortify', 'disastah', 'Trash', 'ptm', 'nkow', 'discovered', 'America', 'OSfrog', 'LE', 'BALANCED', 'FEMALE', 'ROBIN', 'HOOD', 'featuring', 'phoenix', 'shtorm', 'mili', 'herto', 'school', '0o', 'client', 'defenive', 'retreath', 'JESUS', 'CHRIST', 'goodgame', 'gOODgAME', 'wELL', 'pLAYED', 'Fucker', 'makunat', 'r8', 'lived', 'akk', 'llove', 'bra', 'recomend', 'snip', 'googoo', 'gaga', 'some1', 'blade', 'MOFUCKER', 'sux', 'poetic', 'wwpwwpwpwp', 'mrs', 'mamu', 'jebem', 'trashtalking', 'kAPPA', 'ayy', 'WEw', 'debuff', 'aaha', 'Revenge', 'motherfucker', 'eZAASASAAS', 'festival', 'motherless', 'bots', 'opposite', 'photobooth', '11pm', 'affirmative', 'GE', 'eres', 'shet', 'Z', 'Logging', 'excuse', 'fone', 'isp', 'funnily', 'complains', 'Fking', 'moron', 'vpn', 'lmoa', 'vipper', 'Saba', 'thz', 'FCKNG', 'quick', 'anyday', 'il', 'rotating', 'gae', 'advantage', 'fucksticks', 'pic', 'wok', 'merchant', 'thiss', 'bbs', 'yun', 'cheaters', 'challenge', 'pug', 'gha', 'buybacks', 'armlet', '113', 'HEHE', 'Rude', 'reconnect', 'gaybin', 'treats', 'nicely', 'SEROIUSLY', 'prefered', 'Blink', 'talkin', 'boss', 'oi', 'miurana', 'mb', 'bringing', 'bastarrds', 'Step', 'Don', 'Fidel', 'taichi', 'occasionally', 'piss', 'MObile', 'Fatto', 'adik', 'fcup', '5:25', 'DREAM', '1:7', 'Braz1l', 'ratazaaaa', 'bitchery', 'slave', 'correct', 'platter', 'Phase', 'eazzzzzzzzzzz', 'ravage', 'youc', 'Hehehe', 'BAG', 'magi', 'lindo', 'PRAY', 'Relax', 'stick', 'CHICK', 'difference', 'fools', 'moore', 'coudlve', 'ended', 'Fu', 'achi', 'faka', ':\\\\', 'finaly', 'dint', 'celebrate', 'kpop', 'SE', 'nmE', 'tghrowers', 'gas', 'OL', 'EGGS', 'everyones', 'tonight', 'STAY', 'shaman', 'secret', 'weapon', 'twrs', 'mongoloids', 'sugar', 'pocket', 'sth', 'int1', 'trentooooo', 'ligghhter', 'helo', 'ADD', 'laah', 'puss', 'lanc', 'lan', 'Meppo', 'Win', 'http', 'www', 'dotabuff', '113924617', 'ABUSE', 'autist', 'Nevermind', 'unpausing', 'strat', 'HAHAHAH', '1v3', '000000', 'al', 'CHILLYOU', 'wqewi', 'ROSHAN', 'OURS', 'GEMS', 'whoever', 'due', 'manay', 'malaysian', 'tred', 'switched', 'ofmek', 'hence', 'fags', 'alway', 'ahaah', 'KappaRoss', 'cerape', 'oneee', '5k4', 'deward', 'timeing', 'h3h3h3', 'Delte', 'rush', 'wowowowow', 'fate', 'HOLY', 'perujvians', 'ben', 'relic', 'saboid', 'Bois', 'macd', 'sleeping', 'lel2', '59', 'twin', 'BLAME', 'lvls', 'hie', 'rteported', 'DAMIMIT', 'akakakakakaka', 'dafu', 'deff', 'aosdSDG', 'force', 'attack', 'agggg', 'recomiendo', 'reportean', 'hang', '1600', 'keybord', 'streaks', 'kthx', 'GUY', 'iS', 'HILARIOUS', 'SOMEBODY', 'WORKS', 'mes', 'gG', 'wiw', 'thisis', 'paiseh', 'phil', 'TRYHARDS', 'reatrds', 'YEH', 'SA', 'bp', 'mata', 'De', 'sclav', 'nob', '101', 'SPECTRA', 'BRAINDEAD', 'boner', 'house', 'hosue', 'wt', 'AHAHAHAHAH', 'REPROT', 'TRASH', 'youy', 'WHat', 'suffer', 'yamam', 'whatup', 'meme', 'JOB', 'DIRE', 'fps', 'niggers', 'RUBICK', 'WEAVER', 'PLease', 'awgmi13i12g', 'insulting', 'doo', 'MetWorth', 'bored', 'westeurope', '50point', 'ATLAST', 'chepo', 'shadowblade', 'PLAYING', 'BOTS', 'chilling', 'flamed', 'just2kthings', 'ABSOLUTE', 'backtrack', 'qq', '1:11', 'offlaner', 'DOTKA', 'okk', 'attacking', 'plain', 'tpying', 'gays', 'anw', 'heck', 'dress', 'ST', 'FUCKER', 'pussied', 'GEE', 'hardhomie', 'errro', 'Finally', 'Bark', 'ahora', 'kardel', 'finsh', 'sayang', 'imo', 'paningkamot', 'Noobs', 'hahhaa', 'hAHAHA', 'OUT', '22min', 'XDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD', 'PAJARRACO', 'CONCHETUMARE', 'Bitch', 'tntnt', 'ackt', 'shots', 'unreal', 'IDIOTA', 'INFIDELS', 'kda', 'BACOD', 'sacrifile', 'remake', 'NUKES', 'rz', 'laughs', 'mUT', 'LS', 'category', 'narco', 'AHahaha', 'anient', 'NOP', 'LOOOOOOOOOOOOOOLLLLLLLLL', 'Mokiproblems', 'nman', 'dunoe', 'instakill', 'invkoer', 'fokin', 'shitstain', 'gamer', 'BEG', 'naughty', 'DAT', 'Aganim', 'des', 'wardea', 'promise', 'camp', 'gogogo', 'hg', 'storng', 'vacum', 'AP', 'dpmne', 'CLASH', 'FUCKEDUPLIFE', 'REMEMBET', 'INDEED', 'WOWOWOOWOWW', 'dagg', 'mercy', 'excelelnt', 'hus', 'laggin', '179', 'goldi', 'slardara', 'freefarme', 'wet', 'noodle', 'mer', 'guiys', 'noiw', 'SPAM', 'MOM', 'liquid', 'arent', 'ulul', 'idiota', 'sps', 'swup', 'jking', 'GGness', 'xddddddddddddddddddddddddd', 'ahgahahahaha', 'toh', 'aswell', 'tables', 'ofl', 'nomnomlion', 'potm', 'distract', 'deed', 'yeaaa', 'truth', 'syrum', 'bitter', 'spawn', 'mai', 'junior', 'RELAX', 'bothered', 'ganging', 'SETTER', '1ST', 'INITIATE', 'CARRT', 'sory', 'bayu', 'slowing', 'Sb', 'cover', 'digusting', 'patheticness', 'cagada', 'legionn', 'assists', 'himn', 'hahahahahha', 'Es', 'goooo', 'XDD', 'panda', 'Most', 'whut', 'BROOD', 'wif', 'beeee', 'freezing', 'trilane', 'dam', 'miunte', 'ANIME', 'playa', 'proper', 'understands', 'probly', 'DotA', 'uses', 'ala', 'firme', 'pros', 'doign', 'embermon', 'nuh', 'ima', 'boat', 'gogogog', 'wuhahsduasd', 'ep', 'HERETICS', 'azzzz', 'nO', 'DEFEND', 'effort', 'sides', 'expecially', 'COMEBAK', 'eni', 'russki', 'noscope', 'mlgranger', 'WOHOOO', 'craggies', 'unluck', 'EAIUHEAIUHEAIUEAIUHEAEA', 'trade', 'diferent', 'THERES', 'hui', 'ahahahahahha', 'WHIRLPOOL', 'WATCH', 'SUNSET', 'DOENST', 'UNDERSTAND', 'COOLDOWNS', 'SPELLS', 'REC', 'HAHAIHAH', 'false', 'downtown', '515', 'rough', '4dr', 'jenau', 'cows', 'given', 'PASIIVE', 'MALEV', 'camped', 'ground', 'reportet', 'sfs', 'rapiers', 'coem', 'faggorts', 'aiyo', 'geegee', 'aSA', 'smth', 'homies', 'smile', 'tiene', 'carrys', 'regalen', 'uno', 'RADIANT', 'ASD', 'SADASDASDASD', 'dupp', 'WAAAH', 'COUTNERPICKED', 'faggots', 'acount', '322', 'bacl', 'naaaaameeee', 'iiiiiiiiis', 'JOOOOOOOOOOOOOOOOOOOOOHN', 'CEEEEEEEEEEEEEEEEEEEENA', 'tienes', 'que', 'darme', 'manos', 'through', 'snowangel', 'fuckwits', 'GIMME', 'DONDO', 'ALEREADY', 'easily', 'YUP', 'Sad', 'bug', 'yolol', 'o0ur', 'tyhrue', 'assault', 'sold', 'map', 'covered', 'sentrys', 'pleases', 'language', 'barrier', 'tutututututut', 'tutututut', 'rats', 'Shhh', 'plsssss', 'highground', 'pucked', 'refraction', 'pugnoo', 'armour', 'wbahahha', 'steamroll', 'classy', 'clapclap', 'raqequited', 'AHAHAHHA', 'dAMN', 'lee', 'accoutn', 'butters', 'lothar', 'EX', 'DEEE', 'WORTHIT', 'Retard', 'booooooooooooooom', 'PSUH', 'SOSI', 'SOBAKA', 'Hey', 'cuck', 'gfs', 'banged', 'different', 'BUT', 'XAXAXAXAXAXAXAX', 'OHWWWWWWWW', 'Rdy', 'satanic', 'lllol', 'bets', 'aww', 'midlane', 'reportwk', 'juijked', 'fixing', 'bathroom', 'woods', 'jupuk', 'ku', 'hahahh', 'agio', 'Lord', 'gagos', 'LINA', 'WTGF', 'HeyWk', 'mistakes', 'OUTA', 'yuuo', 'atlast', 'PROBKME', 'mario', 'lives', 'alrdy', 'dei', '1by', 'ryt', 'FACTAS', 'TERASH', 'dragged', 'Their', 'Offlane', 'spends', 'wholle', 'interrupt', 'OOOPPPS', 'crow', 'ebaty', 'aaa', 'SAMUEL', 'ROKET', 'introboys', 'fkcing', 'WINDRANNER', 'doint', 'third', 'juked', 'ent', 'hill', 'juguer', 'yuep', 'H', 'AH', 'ha2h2hh2h232h2ha', 'RYAN', 'GOULD', 'businessman', 'DEVIL', 'nug', 'DROW', 'jajajajja', '1v2', 'qweeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee', 'zzzzzzzzzzzzzzzzzzzzzzzz', 'slank', 'BALANAR', 'japan', 'nippon', 'french', 'beaner', 'ear', 'noooooooooooooooooooooooo', 'entertaining', 'ogh', 'broke', 'wpo', 'asingle', 'fihgt', 'dazle', 'wonder', 'ioahd', 'mmuted', 'aise', 'warding', 'muah', 'demolished', 'ivno', 'lkixo', 'SURE', 'ALMOST', 'WON', 'itS', 'COAL', 'yje', 'raslabone', '5:18', 'fuckyou', 'battlefield', 'rek', 'wsilencer', 'talo', 'talga', 'Bow', 'Hayo', 'lold', 'fvcking', 'cuirass', 'wazzup', 'Hi', 'Dumb', 'uy', 'seem', 'frist', 'CAUSE', 'BAT', 'shhh', '3v', 'cafe', 'possible', 'tactic', 'ultimate', 'join', 'purp', 'OKATY', '6100', 'tool', 'HAHAAHHA', 'oooooooo', 'PLAYER', 'ti6', 'headshots', 'cocksucker', 'alwkawkakw', 'EL', 'LISAJ', 'PARNI', 'META', 'NOOBEST', 'purely', 'placing', 'dumbs', 'trah', 'england', 'WOHOOOOOOOOOO', 'YEAHHHHHHHHHH', 'misklik', 'atras', 'abante', 'ampota', 'samuel', 'Fv', 'site', 'anothing', 'dropping', 'AXxaxa', 'XAxaxaxaxaxa', 'afkk', 'Learn', 'astral', 'BECIAE', 'FICKONG', 'RISSOANS', 'DESERVE', 'FUCJ', 'alive', 'dumpster', 'rdnt', 'shoehorn', 'sups', 'lixo', 'okl', '103', 'GAMe', 'hieroglyphics', 'Little', 'zzzzzzzzzz', 'arcane', 'breez', 'shape', 'golum', 'feeler', 'iT', 'hEHE', 'kiolll', 'droped', '2171', 'fuming', 'kee', 'avatar', 'bor', 'JUAS', 'fr', 'avicii', 'schwanz', 'fatfuck', 'FEEED', 'lololol', 'grand', 'justice', 'eheh', 'TRUE', 'RETARDED', 'BRAI', 'hs', 'dts', 'issue', 'gap', 'closers', 'kite', 'poison', 'questionable', 'afaik', 'shoes', 'haste', 'general', 'wowww', 'dager', 'phase', 'rawr', 'ALchEmiST', 'ArcAne', 'BooTS', 'PLAyer', '35', 'DEATH', 'extend', 'funniest', 'compliment', 'snipers', 'pRO', 'ASSASSINATE', 'KILLELD', 'gguys', 'quas', 'WIND', 'shiits', 'salo', 'cours', 'talong', 'wolfie', 'FUCL', 'PICKS', 'GAMES', 'Delete', 'dotta', 'TREE', 'ebnutii', 'pudg', 'coemd', 'sit', 'SRY', '2mid', 'qoup', 'noobick', 'rng', 'Ill', 'egm', 'Spare', 'LICH', 'COST', 'SUPORTS', 'desolator', 'GOLD', 'KREYGASM', 'HATE', 'ONE', '2KMMR', 'asdf', 'JAJAJ', 'YEA', 'bros', 'waow', 'Blya', 'biomusor', 'Butterfly', 'stoping', 'ibrb', 'IDIOTSZ', 'oooooon', 'wipi', 'hecho', 'laughing', 'JOPJOJOJOJOJ', 'winrate', 'racism', 'fockin', 'icked', 'TOIMBSTONE', 'INVO', 'copter', 'nahhhh', 'psh', 'outa', 'bomb', 'ebd', 'bhhot', 'competitive', 'mira', 'gamburger', 'costanza', 'FARMING', 'stages', 'kraken', 'shell', 'cross', 'osing', 'll', 'bai', 'babi', 'bothering', 'impressive', 'wun', 'brag', 'diffferent', 'nevermore', 'RATHER', 'smurf', 'based', 'unkillable', 'dorito', 'bulshit', 'LMOA', 'breeze', 'ro3', 'plsys', 'dump', 'zzzz', 'ooooh', 'babies', 'EXpress', 'CALL', 'het', 'fucken', 'hoping', 'lier', 'bam', 'CRYYY', 'allahu', 'akbar', 'DONe', 'randoming', 'Fasters', 'PLAYD', 'ONDE', 'AUSHDUASD', 'nabernaut', 'esasy', 'repor', 'tdat', 'fucekr', 'ccc', 'rason', 'EZY', 'exyz', 'oke', 'keepo', ':-', 'pidar', 'booste', 'Tiny', 'Salty', 'pokemon', 'hhahha', 'AHAHAHAH', 'naah', 'purchase', 'heathens', 'CHURCH', 'FIND', 'KILLL', 'gichiaan', 'otsukaresama', 'COMMENDED', 'moonshard', 'evasion', 'staks', 'FIRST', 'HIT', 'BASH', 'playdoh', 'prio', 'blinks', 'finger', 'eaisy', 'legio', 'slakrk', 'softly', 'swisp', 'denie', 'VOLVOOOOOOOOOOOOOOOOOOOOOOOOOOO', 'RUB', 'predicted', 'hopefully', 'able', 'BCOZ', 'ITEM', 'THRASHES', 'bel', 'divertito', 'WOOO', 'noty', 'mobile', 'phon', 'upset', 'hue', 'tang', 'ina', 'KKKKKKKKKKKKKKKK', 'KKKKKKKKKKKKKKKKKKKKK', 'RAXANDO', 'reaped', 'liao', 'talked', 'reprpot', 'emebr', 'disaster', 'FCK', 'atlest', 'bath', 'ulting', 'basher', 'Joke', 'creater', 'creator', 'mujm', 'noes', 'JAKIRO', 'quellin', 'gok', 'absolute', 'lvoe', 'yalnext', 'gtg', 'qp', 'ulties', 'Gay', 'wand', 'mark', 'illuminati', '727', 'rag', 'LLLLLLLLLLLLLL', 'JAJAJAJAA', 'tnks', 'war', 'doot', 'cumbag', 'Isnt', 'juggerw', 'rindo', 'moreee', 'incapable', 'woth', 'catches', 'suddenly', 'lifesteal', 'WHYS', 'OSEZA', 'huh', 'AoE', 'quik', 'wit', 'pleas', 'osama', 'binvoker', 'aiya', 'catapults', 'THEFEEDISREA', 'blames', 'sakes', 'currier', 'shop', 'waddafaaaak', 'Spiked', 'puish', 'ofawhore', 'ORAYT', 'carajo', 'magnuse', 'pfff', 'Try', 'hards', 'FACK', 'dsahdaslkdhwuroeyri32212', 'AHAHAHAHA', 'POTA', 'creamy', 'lads', 'bOmBaGhoStDotA', 'pitty', 'freefarm', 'NIGGA', 'sblade', 'per', 'ui', 'labas', 'RAPIER', 'agradecele', 'ohhhhhh', 'ahahahahahahhaha', '10x', 'kaya', 'naman', 'ee', 'w33', 'uxaxa', 'kuro', 'rtz', 'cyclone', '4V5', 'ebaniy', 'shas', 'bi', 'pati', 'mmchike', 'kontr', 'pikat', 'storma', 'sin', 'blyadi', 'bedzmozgliy', 'SAMUELLL', 'BITC', 'HRUN', 'damm', 'themetric', 'ree', 'XAXAXA', 'agme', 'sO', 'whered', 'reaching', 'rearm', 'Want', 'Com', 'shorter', 'ahhahaha', 'harm', 'stahp', 'worked', 'uderstood', 'OJOJOJO', 'sF', 'FICKS', '55min', 'AC', 'ESTA', 'scurred', 'anytime', 'outplay', 'appreciate', 'balanar', 'bestest', 'stayd', 'ahadd', 'corno', 'KEEP', 'umum', 'thot', 'board', 'tipical', 'contribution', 'complaining', 'wellplayed', 'glyphs', 'dispersion', 'musorka', 'slaty', 'feels', 'klnown', 'passives', 'PASSIVES', 'rustard', 'loko', 'bos', 'lo000iising', '3z', 'ayylmao', 'boost', 'Asdpoijasoidj', 'quickcast', 'slot', 'ale', 'dayn', 'battle', 'highest', 'mum', 'awefully', 'testing', 'reaction', 'GRATZ', 'SOLO', 'llamas', 'annoyin', 'str', 'WEW', 'memes', 'EM', 'tke', 'drink', 'commmmmmmmmmmmmmmmmed', 'meelee', 'itqrf', 'vfvrf', 'hfr', 'FAK', 'perfect', 'saf', 'BYe', 'AIM', 'frozen', 'AJAJAJAJA', 'fore', 'homeless', 'intencional', 'hitting', 'talent', 'xuan', 'dealing', 'cooking', 'suggust', 'mjollnir', 'tteam', 'Every', 'ahev', 'totaly', 'fullslotted', 'wiht', 'aghanims', 'gmae', 'odnt', 'zzzzzzzzzzzzzzz', 'May', 'tabbed', 'powful', 'aA', 'gET', 'twirling', 'YY', 'GTFO', 'INTERNET', 'CAFE', 'dodging', 'lai', 'knw', 'trademark', 'Wheres', 'wagaga', 'closest', '21', 'outpick', 'decay', 'myslef', 'discorvered', 'america', 'WENT', 'MIDAS', 'BUYING', 'SHITTY', 'WRONG', 'waiat', 'ruins', 'RANGER', 'expecting', 'xdd', 'Brist', 'removed', 'invokeer', 'skils', '56', 'wtrgf', 'UD', 'oct', 'open', 'wounds', 'morp', 'WONt', 'CARE', 'drinking', 'water', 'chemistry', 'martha', 'focker', 'TKS', 'Have', 'Ogre', 'cri', 'ENGLISH', 'PERUVIAN', 'AHHAHAHAHA', 'wTF', 'weather', 'onli', 'dup', 'Lel', 'PORFAVOR', 'drian', '85', 'thirst', 'XP', 'wkowkw', 'brraainnss', 'modem', 'NAMO', 'Plz', 'TIRAME', 'KAKA', 'NECRO', 'PUCK', 'PUEDE', 'TOCAR', 'gained', 'phenix', 'sm', 'mairo', 'wakle', 'quieres', 'pene', 'fcker', 'EleGiggle', 'SHOT', 'CRITS', 'nooooob', 'fucj', 'hahahhaa', 'reume', 'mecry', 'BLOOD', 'caryr', 'wods', 'gez', 'whiningf', 'DOG', 'TCHES', 'LOSS', '361', 'pogle', 'trax', 'SAIKIIII', 'cmnd', 'kwkwkw', 'nab', 'tuskker', 'Hahha', 'overwhelming', 'gaycumback', 'rent', 'lazy', 'reaper', 'malstrosm', 'nicea', 'WINS', 'ahahhaa', 'bruz', 'searing', 'chains', 'indifferent', 'injokeR', 'DONE', 'FROM', 'CAVE', 'Vs', 'ranga', 'grub', 'annoyed', 'allhis', 'unlres', 'scripts', 'League', 'Legends', 'instant', 'lp', 'buter', 'DAM', 'yaysayaay', 'laned', 'linkens', 'micro', '2010', '5700', 'unmanner', 'boob', ';_:', 'brb', 'shoping', 'aw2', 'BLOCK', 'danger', 'hahahaa', 'Throw', '000', 'camping', 'OOH', 'lucan', 'treads', '29HP', 'wepe', 'Hacker', 'Tequila', 'clowns', 'bj', 'reinicio', 'hmh', 'MASS', 'gnyt', 'resmue', '2e', 'Although', 'greece', 'kka', 'juke', 'esos', 'por', 'font', 'slipped', 'llater', 'haets', 'breaks', 'running', '3K', '200deward', 'hmmm', 'Meh', 'ehd', 'er', 'Wahaha', 'frend', 'minit', 'otw', 'morfin', 'lobster', 'crits', 'SUPPORT', 'bo', 'spiderman', 'lolol', 'whining', 'unbelivebale', 'nyc', 'wtslow', '1973', 'egypt', 'fatty', '1v9', '3ple', 'web', ':_', 'hoo', 'SOLD', 'download', 'FUCKINF', 'w9', 'trashtalk', 'yh', 'strikes', 'blowed', 'BOBO', 'MO', 'downer', 'WHURZEN', 'euro', 'country', 'surprise', 'HAahhaa', 'schackle', 'comunnication', 'scrun', 'shoulders', 'disonect', 'vietnam', 'putang', 'HEROES', 'AUTOEZGAMEW', 'childhood', 'baserace', 'yaya', 'deF', 'FOOL', 'PASUE', 'pAUSE', 'PIAST', 'ACCOUT', 'shes', 'favotire', 'rerport', 'AHAH', 'Rec', 'wuitters', 'Wt', 'dreamteam', 'End2', 'Too', 'draft', 'AAAAA', 'FASTER', 'asco', 'backd00r', 'rcing', 'ger', 'fkin', 'marahin', '.', 'Whatever', 'Fun', 'refuses', 'TP', 'trading', 'PMS', 'KappaPride', 'midases', 'aparet', 'ooops', 'ricky', '4K', 'octarine', 'rolls', 'none', 'BLINKED', 'HOOKL', 'dumber', 'smk', 'wrd', 'esports', 'idid', 'naxui', 'isukin', 'option', 'fng', 'ncie', 'Keepo', 'HAYS', 'SENTRY', 'FWAJHWFHBWFAHBAWFBHWFBHAWF', 'egege', 'ching', 'chang', 'chongs', 'Alch', 'practicalle', 'TIM', 'PIECE', 'KSER', 'majorino', 'Zzz', 'ttimes', 'againstt', 'shld', 'syka', 'unlucky', 'fuckingh', 'Nothin', 'Gotcha', 'xa', 'skdjbfksjdbfk', ':)0', '266', 'MS', 'REBORN', 'iomfg', 'OHHH', 'FUKENZIO', 'ripp', 'remmeber', 'movie', 'tracked', 'earth', 'Hard', 'diffusal', 'sworn', 'aaaa', 'hahhahah', 'pem', 'nivel', 'olaaa', 'lacueeeeek', '3V5', '75', 'skil', 'except', 'necrophos', 'BRUH', 'in5k', 'dendi', 'undiyinh', 'casting', 'larvas', 'sacan', 'profile', 'guse', 'OMFG', 'LOPL', 'fid', 'furry', 'recorn', 'AGHS', 'ANYONE', 'thy', 'RESPECT', 'atitude', 'Doesn', 'Weave', 'synergy', 'AMed', 'lolx', 'jumping', 'chair', 'oob', 'disraprot', 'NIce', 'misclick', 'hai', 'action', 'neba', 'gander', 'demons', 'wearing', 'clean', 'comunity', 'whisp', 'gawn', 'Neat', 'SENT', 'COURI', 'stong', 'Ayylotus', 'GIOVE', 'BREAK', 'TT', 'cimputer', 'crashing', 'daaamn', 'caucasian', 'representing', 'races', 'iditos', 'shocking', 'fcken', 'stewped', 'refresher', 'env', 'hospital', 'exactly', 'healing', 'goteem', 'wotah', 'crispy', 'bothers', 'GGG', 'Wasted', 'team8', 'Piece', 'bacan', 'ion', 'ENJOYING', 'HELL', 'HAHHAHA', 'loh', 'trashg', 'somewhere', 'HAHHAHAHA', 'pleease', 'single', 'magnius', 'bastards', 'unpoused', 'ment', 'FAGGOTS', 'SOLOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO', 'DUALLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLLL', '275', 'CK', 'tear', 'rolling', 'tears', 'MIND', 'Namaste', 'fucjk', 'shiva', 'mek', 'greaves', 'vlads', 'chanses', 'refresh', 'giv', '2500', 'mepoo', 'INTROBOYS', 'diam', 'bark', 'fre', 'dance', 'HAAHA', 'counters', 'OKY', 'bills', 'tress', 'fite', 'cepet2', 'di', 'makan', 'EALLY', 'PAKYU', 'lolk', 'GBAHA', 'tip', ':s', 'feedeen', 'nonsense', 'clueless', 'raptor', 'ady', 'rudee', 'rotation', 'orusp', 'cpcugu', 'FUCKNG', 'ZEUS', 'ahmed', 'arab', 'Cuz', 'commit', 'sudoku', 'vote', 'brutal', 'Feed', 'tv', 'laspelaps', 'implying', 'tracks', 'amulet', 'equally', 'conecting', 'reconnet', 'WEPE', 'favor', 'thrower', 'together', 'TALK', 'favorite', 'seer', 'leap', 'McDonald', 'fans', 'stpuid', 'sentry', 'plebs', 'SECPLS', 'LOLZ', 'glboys', 'Awwww', 'bothrunes', 'Sodium', 'Chloride', 'zoro', 'FYUCK', 'walamak', 'WJAT', 'bloodseeker', 'GEEGE', 'germany', 'comme', 'erz', 'hahha', 'WUT', 'sia', 'Mistake', 'noooooooooooooooo', 'HUSKAR', 'rekted', 'owned', 'Fuk', 'tits', 'AHGAHA', 'HZ', 'gyus', 'hhaa', '40min', '1:30', 'queue', 'Minglee', 'alrd', 'slar', '8wins', 'lyin', 'mmmmmmmmmmmmmmmmmmmmmmmmmmmohmygod', 'fukin', 'burns', 'EATH', 'DIVCK', 'jajajajajaaj', 'kogut', 'champ', 'bogo', 'ARMOURE', 'LESS', 'gorillas', 'sumwer', 'poa', 'WONT', 'Yolo', 'OVER', 'rating', 'elegiggle', 'Easiest', 'hechas', 'culpa', 'AGAGA', 'WW', 'sorr', 'Only', 'alrigfht', 'VIPER', 'THUGHT', 'jew', 'cw', 'POO', 'TIMBER', 'nmore', 'hmmmmmmm', '3min', 'quitting', 'suppp', 'Sshh', 'olo', 'haahahaha', 'ASSHOLES', 'kraaaaaay', 'hoenst', 'MEGA', 'MMRMRR', 'tilting', 'talaga', 'eyes', 'past', 'bull', 'messi', 'tahaha', 'date', 'bruhh', 'ald', 'amk', 'regard', 'jukt', 'hanged', 'PERRUUUUUUU', 'ffed', 'noT', 'WODDEN', '5minutes', 'bx', 'DW', 'CUT', 'PART', 'HHAHA', 'incompetent', 'nothin', 'HAAHAHAHA', 'hihg', 'stress', 'condom', 'dno', 'saatnic', 'feeDER', 'TOLOL', 'jut', 'ukltimate', 'ok2', 'FUICKING', 'NET', 'bye2x', 'wated', 'LOOOOOOOOOOOOOOOOOL', 'DAUNI', 'SUKA', 'yey', 'OYOYOYOYOY', 'recent', 'matches', 'COme', 'nao', 'dele', 'abbandons', 'admit', 'blamming', 'Gee', 'LEAP', 'MUTHAFACKA', 'logging', 'fellow', ':;', 'alsdasd', 'qweqwe', 'saved', 'lifes', 'SAVED', 'lapo', 'diwali', 'fakkkkkkkkk', 'cfg', 'activated', '43', 'defnd', 'uask', 'dEF', 'MOTHER', 'FUCKERS', 'putins', 'SUCH', 'WEIGH', 'MIRANA', 'TBH', 'RUSSIA', 'SERVER', 'SAKES', 'ddoss', 'ddosi', 'loves', 'suiciding', 'rite', 'ahhahaa', 'MEEEE', 'AJJAJAJ', 'SATANIC', 'SOY', 'COMO', 'AL', 'RETRASADO', 'ARCANA', 'EE', 'PLAYS', 'KAPPA', 'RUSS', 'DENDI', 'Brood', 'refill', 'Wrong', 'teamkilled', 'silancer', 'domestics', 'missclicked', 'CAME', 'necto', 'likens', 'asad', 'lioch', '30mins', 'river', 'leaveing', 'imagine', 'ims', 'erious', 'TALKING', 'RAPED', 'KKG', 'KANTOT', 'GIRL', 'yawn', 'JSUT', 'MATTER', 'MONEY', 'Dick', 'shto', 'GGGGGGGGGGGGGGG', 'melbourne', 'kfc', 'Awer', 'kw', 'agreee', 'QUED', 'PERFECTLY', 'TIMED', 'ROBOT', 'LGA', 'tru', 'cmere', 'ahahahahha', 'dfc', 'bvbr', 'yektdsq', 'hdtn', 'esse', 'figueiredo', 'filho', 'puta', 'POPAl', 'reporspec', 'gbarrel', 'swaggy', 'Luck', 'basted', 'easerion', 'firstbloodion', '1vs5', 'reach', 'Grammar', 'nazi', 'hail', 'cmd', 'WPWP', 'babes', 'shoppin', 'toss', 'st', 'omnislash', 'eaeaea', 'playin', 'slARK', 'rETK', 'WOAH', 'ahhaah', 'blank', 'claimed', 'lied', 'kabobobo', 'nyu', '4x', 'FVCK', 'fught', 'BEAST', 'MODE', 'trapp', 'accept', 'offering', 'FUK', 'gona', 'toos', 'tooos', 'PROFILE', 'sometimes', 'SD', 'lvl7', 'pudga', '30minutes', 'WUDLVE', 'WHILE', 'thatswhy', '938', 'attacks', 'plox', 'TOOK', 'UDY', 'MOTHERFUCKERS', 'SUCKERS', 'uilt', 'EnD', 'husker', 'battlefury', 'karam', 'sounds', 'animal', 'botz', 'spender', 'penetrate', 'wao', 'HURT', 'Save', 'summail', 'puc', 'wlwlwlwllww', 'torso', 'tipu', 'gua', 'Expects', 'ajajja', 'yum', 'wkwkwkwkw', 'playstlye', 'dollar', 'SORY', 'heuheu', 'hour', 'brains', 'photo', '10pm', 'vieja', 'ratas', 'wp2', 'gget', '6350', 'hwats', 'dogs', 'jokeing', 'unskilled', 'proved', 'africa', 'dotacinema', 'ONEEE', 'polaying', 'answer', 'bae', '0ward', 'sexally', 'HELP', 'INSTEAD', 'KILLING', 'mtoher', 'finsih', 'obvusly', 'actual', 'okej', 'breezzy', 'RECON', 'freely', 'througfh', 'entire', 'strategy', 'brought', 'aazazazazaza', 'EARLY', 'XDXDXD', 'chong', 'Gotta', 'gents', 'WEX', 'chiil', 'AAAAAA', 'Jungle', 'Never', 'nko', 'kinards', 'boshit', 'QA', 'Cum', 'katsamba', 'ramo', 'aslong', 'AKA', 'tellin', 'muna', 'ezflex', 'HONW', 'reset', 'ahaaha', 'krits', 'slovakia', 'krch', 'derma', 'zaruinil', 'THOSE', '959', 'CYKA', 'BLYUAT', 'Hah', 'xdddddddd', 'YAh', 'ngon', 'dammn', 'OO', 'IC', '242', 'lssing', 'dayyyuum', 'stron', 'ajajajja', 'prediction', 'DISASTAH', 'FED', 'lagged', \":'\", 'heros', 'Riki', 'ults', 'BRAT', 'thousand', 'qued', 'figured', 'EG', 'UNIVERSE', 'RTZ', 'SUMAIL', 'PPD', 'FEAR', 'EACH', 'CONTROL', 'LIMB', 'USING', 'HEAD', 'minets', 'ahve', 'delate', 'sm1', 'EARTH', 'SPIRIT', ':0', 'hahahahhaha', 'DIEBACK', 'ddint', 'alchje', 'betrayed', 'unpauser', 'TEVAS', 'CON', 'MIGO', 'affect', 'morality', 'ghots', 'Tony', 'Locket', '119', 'complex', 'getem', 'stlark', 'AHHHH', 'ihave', 'EXAM', 'GRAMMAR', 'Di', 'bagay', 'rikii', 'br', '8kmmr', 'midl', '00100', 'motherfucking', 'witch', 'wub', 'Lag', 'fuark', 'RULE', 'BLABLABLA', 'RULLER', 'FUE', 'GGGGGGGGGGGGGGGGGGGGGGG', 'pasue', 'ruinE', 'sonic', 'ahahahaah', 'Meme', 'abse', 'When', '2x3', 'alo', 'ebanat', 'mormo', 'felt', 'sek', 'pyzdec', 'ueless', 'waut', '49', '48', 'deleted', 'banned', 'ANTIGAY', 'xaaxx', 'sg', 'yuoyu', 'kidiing', 'bodyguard', 'small', 'KITER', 'AUTOLOSE', 'flaw', 'ang', 'beware', 'streka', 'handicap', 'hv', 'rong', 'etc', 'suffered', 'hahahahha', 'Kapaa', 'bahahahah', 'warddd', 'hagaga', 'windranger', 'wowowowo', 'mous', 'twq', 'soooooooooooooooo', 'sending', 'sms', 'owns', 'mage', 'dosnt', 'oyoy', 'overheated', 'lob', 'yeaaaah', '3x', 'jg', 'everywhere', 'idioto', 'Ta', ':slaty', 'standard', 'share', 'handing', 'behave', 'bluffing', 'hehje', 'oiut', 'lol7', 'huauha', 'leagueoflegends', 'register', 'filipinop', 'Come', '1vs', 'salita', 'BuyBAck', 'THanks', 'Mmr', 'tASTy', 'accbuyers', '1.', 'autoattack', 'PICKERS', 'aahhaha', 'blow', 'soup', 'deserv', 'inc', 'FLYING', 'uck', 'aahahhahahah', 'tetris', 'HIJOS', 'DEPUTA', 'seeing', 'comin', 'Batrider', 'CHE', 'KAK', 'TAM', 'ZOMBI', 'roamer', 'hellooooo', 'ooopss', 'terror', 'maidan', 'midd', 'Woah', 'noticed', '=gg', 'tbelieve', 'Wr', 'fegget', 'dcp', 'staralsya', 'haahahah', 'profesional', 'BITCHES', 'WOOOOP', 'JAHAHAHA', 'THat', 'mids', 'skills', 'ench', 'ehh', 'ULTRA', '213', 'craggt', ':@', 'thru', 'HUSKA', 'Gyro', 'Weirdest', 'PHOENIX', 'shameless', 'iidot', '2non', 'beforehand', 'focusing', 'arm', 'combackl', 'dove', 'Gang', 'bang', 'porblem', 'arryin', 'carryin', 'mexican', 'CHOP', 'HS', 'tini', 'awwwww', 'yourselves', 'tink', 'wole', 'Cocky', 'inboker', 'duneo', 'valcano', 'trend', 'dollars', 'palyed', 'murica', 'Intro', 'malay', 'sooo', 'wintendo', 'PICKING', 'RUGAL', 'totally', 'AWAY', 'major', 'scientist', 'figure', 'ignorant', 'ENJOY', 'TRASHCAN', 'PICKER', 'BOSY', 'pahaha', 'handling', 'diiot', 'mib', 'calls', 'distance', 'picking', 'reached', 'rerpot', 'fri', 'somthing', 'lack', 'education', 'irrelievant', 'dslmdlas', 'HYAHA', 'spoiler', 'PLESAE', 'unless', 'horn', 'chese', 'aprty', 'ggggggggggggggggggggggggggggg', 'swapping', 'GAIS', 'secure', 'yeahb', 'HAHAHAHAHAAHAHAHAHAHA', 'iyak', 'nxt', '8kg', 'germans', 'bleat', 'PAK', 'werent', 'DAAAZEHL', 'evne', 'causer', 'POWER', 'effigy', 'lanjiao', 'somevont', 'Techis', 'awtx', 'SCARE', 'fuckwit', 'daaaamn', 'provoking', 'sereiously', 'cmap', 'CHASE', 'knnow', 'smhall', 'Fuckin', 'hilariously', 'GODLIKE', 'yalll', 'una', 'misha', 'intence', 'eaaaaaaaaaaaaaaaaaasy', '3v1', 'AHAHAHAAHAHA', 'c0meback', 'noo', 'ilencer', 'fkboi', 'EERROOOOOY', 'toon', 'unpausers', 'mongoloid', 'Bs', 'nwx', 'leaved', '130cannot', 'geeeeeeeeeegeeeeeeeeeeeeeeeeee', '2008', 'payuse', 'chupadmela', 'JUMP', 'ltr', 'woaw', '1150', 'chorno', 'far', 'shhihtter', 'helped', 'alot', 'axaxax', 'HOPING', 'pobre', 'lloron', 'sadly', 'Better', 'NONONONONO', '4v1', 'GAYS', 'leT', 'waaahahahahaaha', 'neutrals', 'JST', 'search', 'recked', 'Afl', 'habit', 'commen', 'jay', 'feet', 'adadas', 'scouting', 'yelling', 'yeling', 'iten', 'thnqq', 'DEADS', 'yeha', 'foru', 'Fantatsic', 'alchesa', 'replay', 'jguger', 'glitch', 'lighning', 'ball', 'catcher', 'macro', 'EUUUUUUUUUUUUUUUROPPPPPPPPPEEEEEEEEEEEEEEEEEEEEEEEEEEEE', 'boyssssss', 'junkie', 'pudghe', 'meaning', 'SONS', 'gracefully', 'msged', 'hahahhahah', '2es4us', 'itshis', 'stunned', 'arrowed', 'abt', 'HOUSE', 'SHAREING', 'pussys', 'encouragement', '102', 'ghad', 'teamate', 'hat', 'banging', 'girlfriend', 'ALl', 'sbv', 'actualizacion', 'va', 'demorar', '352', 'gb', 'diga', 'creo', 'entre', 'rapido', 'Shutup', 'rEALLY', 'SHHH', 'illeagle', 'safely', 'bumhole', 'FLAME', '6mid', 'ABA', 'hehehehe', 'kil', 'huy', 'sosnesh', 'ants', 'pre', 'DENY', 'neutral', 'Ahhh', 'Btw', 'NONE', 'kpd', 'shakere', 'igraew', 'drug', 'briezi', 'DOTACINEMA', 'abusing', 'insulte', 'letz', 'ermm', 'Zzzzzzzzzzz', 'razes', 'dotaing', 'caryy', 'FRESH', 'MEAT', 'beside', 'necrophile', 'wahahahhahaa', 'NOOBSSSSS', 'PUB', 'GAMMER', 'comm', 'haahahahha', 'fae', 'das', 'estrelas', 'GLFHF', 'oghhh', 'Act', 'lmai', 'uiCK', 'cuh', 'gagagaga', 'WC', 'HelenaLive', 'LOVER', 'ary', 'nowaday', 'thoiught', 'wer', 'havnt', 'friendship', 'Hahhaha', 'spooky', 'INPLAY', 'STACK', 'HAAHAHHAA', '5vs4', 'GAYYYYYYYYY', 'wll', 'traxes', 'wi', 'couse', 'reinstall', 'refreshed', 'offlaners', '500h', 'YOu', 'soonTM', 'disease', 'comeon', 'sohuld', '8min', 'shake', 'geeeeeeeeeeeeeeeeeee', 'geeeeeeeeeeeeeeeeeeeeeeeee', 'jerk', 'store', 'spin', 'bottles', 'Mmm', 'Windrunner', 'pliz', 'refrac', 'ezist', 'sprout', 'tanky', 'platemail', 'BLAMEE', 'vepe', 'tinyyyy', 'cozuld', 'crited', 'intentional', 'SINGLE', 'ASTRAR', 'zica', 'ahhhhhhhh', 'nowadays', 'Arent', 'vahahaha', 'leat', 'THISGAME', 'roshing', 'aggresif', 'Watta', 'edn', 'unpaybale', 'any1', 'elad', 'ALAHU', 'AKBAR', 'halp', 'buback', 'hwo', 'liv', 'midle', 'afrer', 'MEMEK', 'shallwe', 'bahaha', 'FRE', 'ENJOUY', 'WINter', '4Head', 'PJSalt', 'punishes', 'beggining', 'EVERTIEM', 'My', 'yell', 'freidn', 'RAPIRAA', 'farm2', 'til', 'huehue', 'Rekt', 'cahging', 'gameplay', 'Crit', 'reddit', 'waw', 'coffee', 'hoiw', 'link', 'starving', 'waya', 'wud', 'doctor', 'wpgg', 'wbu', 'cactuses', 'KNOWING', 'WORSE', 'odin', 'ohuennee', 'drugogo', 'TRYING', 'Dedz', 'DAUN', 'course', 'leart', 'BULDOG', 'nekked', 'blowjob', 'basmati', 'rice', 'heaven', 'minglee', 'european', '2x', 'Ignore', 'kitten', 'agressive', 'cancers', 'carai', 'vc', 'soh', 'crita', 'jogar', 'nagga', 'ULOL', 'thoght', 'tenkz', ':Q', 'wivern', 'neck', 'myself', 'DAGGER', 'clicking', 'unclickable', 'accounts', 'verde', 'burdenb', 'moves', 'ethan', 'BFury', 'Silver', 'Edge', 'drgaon', 'soul', 'ring', 'runs', 'desease', 'coment', 't0', 'ahhh', 'okie', 'russtard', 'nbooob', 'ort', 'thigns', 'dumbest', 'broser', 'daaaaaaa', 'MOFOZ', 'combine', '42', 'uphill', 'LITERALLY', 'WARDING', 'HELPING', 'kawo', 'kaw', 'CHTO', 'mahhhhhhhhhhhhhhhhhhhhhhhh', 'reatd', 'ussles', '900', 'REPOR', 'proves', 'On', 'IQ', 'Hayz', 'silento', 'honest', 'emnd', 'mortred', 'CLIFF', 'CLIFFS', 'AF', 'COMBO', 'pakyu', 'selg', 'aoxaoxaoxaoao', 'tumbaron', 'todo', 'tsambahero', 'heee', 'hoy', 'HIGHHHHHH', 'pair', 'yeezys', 'talkinga', 'kyxy', 'KYXY', 'scratched', 'gary', 'clark', 'quiter', 'knos', 'nt', 'craptastic', 'akowokwakoawo', 'ault', 'ggnore', 'easyx', 'diving', 'Cac', 'co', 'thay', 'soi', 'dong', 'fEED', 'fuman', 'MOAR', 'keeper', 'wop', 'horns', 'therefore', 'BM', 'DRUM', 'UNPAUSING', 'wake', 'sos', 'SADEST', 'boyus', '3pl', 'pressing', 'Lyin', 'VENGE', 'chrnoo', 'hgrsoiuherjs', 'haahaha', 'cut', 'MOTHERFUCKER', 'Hahhahaha', 'aadu', 'Was', 'butuh', 'BAIA', 'douche', 'AKSDAKJDSJKASKDJA', 'speccccccc', 'alredy', 'greenm', 'FORGET', 'DAMN', 'meatballs', 'Shit', 'NOM', 'whenever', 'fairly', 'jhahaha', 'spectr', 'cancel', 'hehez', 'violado', 'porra', 'perdi', 'nessa', 'semana', 'kkkkkkkkk', 'whahahaha', 'Deluxe', 'Pony', 'mushi', 'gor', 'catchy', 'Tacos', 'wooho', 'edi', 'somali', 'robbing', 'SUPORT', 'tunnel', 'gayer', 'secrets', 'reference', 'PENIS', 'ufhm', 'ERAL', 'DASjklpfsegscg', 'FKINNNNNNNNN', 'MEDUSAAAAAA', 'fjuck', 'uuuuuu', 'Log', 'smg', 'scrublord', 'dela', 'boii', 'repoc', 'MORON', 'PHASE', 'BOOT', 'ghhahhaha', 'WPO', 'BADLY', 'DONEE', 'loooooolll', 'fcukin', 'retared', 'waaaaaaa', 'EFFOR', 'kingg', 'BAR', 'workin', 'OGRE', 'AAAAAAAAAAAAAAAAAA', 'DIIIICKKKK', 'isso', 'SHET', 'HAPPENED', 'EXPLAIN', 'nenado', 'HERRREEEE', 'EZZ', 'grandmother', 'rubbick', 'pasie', 'benjaz', 'undyingpicker', '999', 'RAPE', 'unp', 'THRONE', 'hei', 'believes', 'thgis', 'sadist', 'CD', 'lalalala', 'moment', 'vuz', 'cho', 'nhanh', 'yebok', 'wirht', 'ally', 'therer', 'bootcamping', 'nooooo', 'slvrdota', 'Finish', 'dear', 'yer', 'overplay', 'hahahhahahaha', 'unlimited', 'bombs', 'lewl', 'youknow', 'express', 'mysefl', 'disra', 'prior', 'recotnra', 'ese', 'pelase', 'mierda', 'century', 'ahahayeah', 'james', 'aHI', 'FUCVK', 'likes', 'brazzers', 'lifted', 'policy', 'EZZZZZZ', 'tame', 'JAJAJA', 'buld', 'mortal', 'kombat', 'mile', 'CLOKC', 'cape', 'grandpa', 'chicken', 'haduken', 'COLD', 'SNAP', 'screaming', 'mic', 'screw', 'runa', 'gente', '3miss', 'leeching', 'xp', 'patetic', 'HAI', 'CAO', 'NI', 'LAPSAP', 'funnik', '15y', 'elses', '5)', 'elvinskin', 'ut', 'ena', 'Frere', 'beaten', 'hacks', 'Plot', 'twist', 'Huskar', 'himself', 'alyway', 'jungles', 'Slam', 'dunk', 'GGWo', 'threw', 'GREEN', 'DORITO', 'HURTS', 'MUST', 'CLICK', 'pendejo', 'prepare', 'pussyh', '71', '2000', 'fagate', 'tin', 'poutsa', 'tryed', 'dombshit', 'detection', 'menya', 'iskal', 'xx', 'mfs', 'donger', 'okidoki', ':::::::::::::::::::::::::::)', 'teh', 'worrying', 'thanking', 'wot', 'special', 'uuseless', 'stopd', 'carrubick', 'DIFUSAL', 'goblack', 'BOSS', 'CALLS', 'ro', 'dedication', 'sjwsahashbas', 'HAAHHA', 'predick', 'DIe', 'surrender', 'nu', 'fcku', 'rewtar', 'cram', 'eg', 'settled', 'euw', 'white', 'meat', 'tasty', 'sooking', 'Sucker', 'ahhahahahaha', 'swimm', 'Cw', 'yeye', 'Sven', 'jaajja', 'carl', 'wtrf', 'sss', 'asquitos', 'Idiot', 'abadon', 'plahing', 'phonix', 'baboons', 'lsoe', 'PIDARAS', 'judge', 'hahahahahhahaa', 'uyes', 'lagggggggggggggggggggggggggggggggggggggggggggggggggg', '70', 'partY', 'conneccting', 'yyyyyyy', 'commends', 'MEET', 'LENCER', 'mages', 'MASAYOSHI', 'MIDDLE', 'GANK', 'uu', 'lkala', 'coco', 'brewmaster', 'light', 'fuckiig', 'cucumbertube', 'aLL', 'mnt', 'fatter', 'Legion', 'Kill', 'Plox', 'Nope', 'cheeckt', 'Ahahahah', 'zel', 'struggling', 'luchshii', 'THEM', 'NOTHING', 'EVERYTHING', 'chinks', 'toa', 'yeeha', 'biatch', 'au', 'batrider', 'designed', 'insult', 'TUSK', 'resuming', 'shup', 'anybody', 'suffering', 'gook', 'login', 'QoP', 'ajjaja', 'sod', 'eve', 'putangina', 'tae', 'rampege', 'noobbb', 'wipo', 'farmlane', 'hahhha', 'CLEMENT', 'fhm', 'photoshoot', 'achievement', 'neh', 'phandon', 'fiend', 'ba', 'ibig', 'sabihin', 'kampi', 'tahimik', 'UYDI', 'LAte', 'whattagame', 'uve', 'n0t', 'ayaw', 'lumabas', 'init', 'pushhhhhhh', 'alarm', 'EZZZZZZZZZZZZ', 'LOLOLOLOLL', 'hahahahhahaha', 'obviously', 'devil', 'TH', 'husky', 'sparkly', 'homo', 'fagnuts', 'alreayd', 'wings', 'mppb', 'Ppd', 'rotate', 'feeded', 'closes', 'kolakaoaw', 'doono', 'unbalanced', 'cooties', 'NOOOOOOOOOOOOOOOOOOOOOB', 'urn', 'keeping', 'AHAHAHAHAHAHAAH', 'salt', 'vinegar', 'leaves', 'Test', 'cRY', 'pinOYYYYYYYYY', 'aW', 'loST', '85st', 'jsagdhjkasgd', 'thye', 'techhies', 'huk', 'dende', 'HOHOHHO', 'impressed', 'shitttt', 'baggg', 'whaty', 'DAMAGE', '5mnt', 'saad', 'stryong', 'overexcited', 'HAHHAHAH', 'DREAMING', 'Ca', 'REPORTEN', 'ESA', 'PUGDE', 'comento', 'QUIEN', 'LOS', 'REPORTA', 'ngenge', 'jam', 'pfffttt', 'goodness', 'org', 'CW', 'M7', 'ENIGMA', 'MEK', 'beeing', 'feedy', 'rpoflmao', 'round', 'offer', 'meepos', 'heads', 'QUAZ', 'sodium', 'erdogan', 'canoot', '44', 'donno', 'suporte', 'ASDJSADUHHDAS', 'noooooooooooo', 'potM', 'blushes', 'FEEDER', 'mIRANA', 'locking', 'NYX', 'GEM', 'HUNT', 'plane', '10mins', '27MIN', 'BFYRT', 'HAA', 'burdens', 'burdeness', 'WAt', 'F9', 'STOLE', 'BIKE', 'nas', 'ewe', 'waite', 'sentence', 'noobz', 'iwas', 'pinging', 'SERVERS', 'CANNOT', 'TANGO', 'et', 'ags', 'ynf', 'sex', 'autis', 'lalalalal', 'AHHAAH', 'dUMB', 'YIYI', 'jajajaj', 'Beautiful', 'chasing', 'Nothing', 'msg', 'MISSIS', 'DOUBT', 'yurnero', 'MOUTH', 'ET', 'DEGANCIA', 'BLAT', 'DELETE', 'Necro', 'CHILL', 'isntenough', 'High', 'rollers', 'teneg', 'dir', 'TERROBLADE', 'TRAVEL', 'INvok', 'fura', 'enmy', 'Yoshi', 'Mario', 'court', 'room', 'balck', 'fuckng', 'skadi', 'dayum', '61', 'ghhaha', '=[', 'chink', 'boutt', 'autsist', 'ugay', 'idrk', 'inflated', 'disco', 'juggs', 'twat', 'raise', 'relaxxx', 'leg', 'Did', 'stand', 'uou', 'gos', 'BALA', 'Npn', 'infidel', 'HAHAHAHAHAHAAHAHAHA', 'wating', 'noting', 'DROWWWWWWW', 'untouchable', 'Zeus', 'terrorblade', 'pnkg', 'gme', 'Heehehehhe', 'ofcc', 'Deal', 'USED', 'somebody', 'pt', 'skewer', 'fir', 'obv', 'havenet', 'nh', 'Both', 'rethink', 'skyp', 'med', 'sloth', 'naationality', 'redtube', '881', 'Waow', 'remy', 'boyzz', 'Reort', 'peruasno', 'FOREST', 'shall', 'leav', 'biggest', 'turns', 'Morph', 'louy', 'pd', 'ebal', 'breathe', 'nose', 'vp', 'fuicken', 'sc', 'sook', 'voltis', 'zzzzzzz', 'rocks', 'mh', 'YORU', 'FUCKIGN', 'nasad', 'jud', 'mistake', 'hardest', 'pve', 'creaps', 'NERDS', 'M888', 'lamo', 'uR', 'DAN', 'PEENOTY', 'dadadqa', 'tped', 'feal', 'abanuti', 'pizdec', 'viweres', 'LIVe', 'tik', 'tok', 'provider', 'muere', 'callada', 'perra', 'duken', 'giusy', 'ggs', 'ookay', 'Tinny', 'deffs', 'leonidas', 'awj', 'img', 'etting', 'spikes', 'jhj', 'xddd', 'refract', 'eazzz', 'hhhhhhhhhhh', 'PISSFACE', 'MGA', '3kmmr', 'lasst', 'TAS', 'CNT', 'COMPETNENT', 'abanbdoned', 'Asdgfikom', 'Biper', 'Viper', 'honor', 'expensive', 'body', 'borderline', 'suicidal', 'spykes', 'poop', 'LEAR', 'TEAMMATE', 'MEANS', 'fianlly', 'okkkey', 'wkwkwkwkwk', 'pui', 'blodd', 'nvo', 'tow', 'watermelon', 'axxaxaxaaxaxax', 'clink', 'fyuuuhhh', 'MIC', 'obviosly', 'jurkoff', 'wht', 'mummys', 'nbedroom', 'sacrifice', 'imj', 'preety', 'RECORDED', 'siege', 'creepz', 'fucong', 'fukciong', 'reprt', 'runner', 'AHAHHAH', 'asissts', 'tat', 'omG', 'commendos', 'Sexo', 'butto', 'butt', 'under', 't1', 'misn', 'prove', 'agk', 'palky', 'kontool', 'Sup', 'zeyus', 'discussing', 't3', 'filthy', 'sand', 'Notlikethis', 'jpg', 'triple', 'Xuan', 'Mai', 'payback', 'toggle', 'tight', '2compos', 'CYAK', 'caca', 'sohai', 'OUUU', 'CH', 'loggin', 'Slardar', 'pertty', 'dame', 'Peru', 'bobby', 'bigger', 'ammirite', 'JAHAHHAA', 'lti', 'enig', 'ATRAS', 'RATAS', 'dewarding', 'Ofc', 'reportnite', 'etix', 'za', 'nityo', 'bst', 'WT', 'BOUGHT', 'COUR', 'TRYHARD', 'weee', 'whys', 'disconnnecting', 'encountered', 'LEADING', 'SKILLS', 'WUDUP', 'HEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEERES', 'feggets', 'sosator', 'sosater', 'ironic', 'dontg', 'wouldndt', 'NAHUJ', 'nigguh', 'ezez', 'graves', '50min', 'courriers', 'Shakel', 'TIMEE', 'whit', 'art', 'qwat', 'NOICE', 'JIJIJIJI', 'shadowfiend', 'footlocker', 'stonf', 'medicine', 'ASA', 'SI', 'BOBOB', 'satiesfied', 'JKAKAJAJAJAJAJ', 'supposed', 'happeend', 'drops', 'nuclear', 'Meracle', 'ahhahahaa', 'orospu', 'ocugu', 'CHIPPREL', 'NUTS', 'PATALO', '43232', 'sso', 'wrs', 'houses', 'sentires', 'sorta', 'SOMEHOW', 'ksd', 'WASTing', 'wkwkwk', 'wkwwk', 'deez', 'nutz', 'gryas', 'afucking', 'alchj', 'TOPO', 'starfall', 'SOMETHING', 'pikon', 'filipinos', 'WHYYYY', 'feder', 'warder', 'PUPPEY', 'ahghaha', 'frog', 'existing', 'GGp', 'UNPAUSE', 'ORE', 'tm', 'SHITTIES', 'nutshell', 'blrr', 'OA', 'fyi', 'vendetta', '2018', 'wbghat', 'eul', 'alyer', 'rizwan', 'GALSNDLASNDJ', 'OFC', 'buy1', 'fuckwad', 'selfish', 'suits', 'PH', 'outfarming', 'riky', 'katkaaa', 'igot', 'mormon', 'bnooob', 'As', 'inspect', 'read', 'gentelmen', '31', 'NABBED', 'HUA', 'urs', 'tapped', 'Jesus', 'found', '`', 'abd', 'Care', 'aaxax', 'allowed', 'bedroom', 'jakol', 'lesson', 'TWICE', 'meed', 'ggWp', ':DDDDDDDDDDDD', 'dn', 'couriers', 'strom', 'arguing', 'pLS', 'blog', 'stud', 'Hear', 'Were', 'argument', 'naw', 'askin', 'tactics', 'jokers', 'soda', 'FGUCK', 'fuxk', 'ahahahjajhajajajja', 'motherfuker', 'yeee', 'teamgame', 'LIVING', 'hje', 'WHIPE', '1year', 'tackle', 'NUB', 'rps', '1389461397419', 'wildkin', 'camps', 'ecvho', 'DL', 'rEPORT', 'TRYHARIDNG', 'stitch', 'planet', 'kept', 'DOUCHE', 'PICKED', 'While', 'afkd', 'baits', 'CLOSE', 'PUBLIC', 'URSA', 'jkajaja', 'DansGame', 'rspe', 'CONSECUTIVE', 'HAHAh', 'infinity', 'uze', 'ebqal', '2800', 'aiming', 'omkg', 'TUSKAR', 'TEACH', 'ASSHOLE', 'SHU', 'thinkg', 'causing', '15min', 'TEAMATE', '2vice', 'ajahhahahaa', 'regen', 'RAIJIN', 'Virgin', 'alert', 'gosu', 'REFPORT', 'DZZLE', 'gate', 'donde', 'ayubowan', 'dats', 'gree', 'PLEAE', 'ELECTRIC', 'downschild', 'hhqhqqhhq', 'HP', 'clarity', 'wrking', 'alchs', 'pleeeeeeeee', 'arcana', 'MOuise', 'silly', 'SUPPORTS', 'lMAO', 'dominator', 'successful', 'Dami', 'unbelievebale', 'wjhat', 'ursaz', 'produced', 'REALty', '15200', 'waaw', 'EVERY1', 'ION', 'BRACKET', 'everytime', 'bitchhhhhhh', 'mechanic', 'ULTO', 'HOYLFUCK', 'mq', 'dillon', 'harper', 'credit', 'faggets', 'survived', 'esteemed', 'mutelist', 'vooral', 'geen', 'stealed', 'businees', 'misstype', 'waiy', '24hrs', 'masturbating', 'Wasting', 'Hahaa', 'Hais', 'BUTT', 'HEART', '2EASY', 'englihs', '3300', 'Tabbed', 'KIDZ', 'TYPE', 'whooow', 'youve', 'organise', 'race', 'papi', 'paki', 'diarrea', 'eos', 'vas', 'medio', 'breaker', 'silenced', '40mins', 'lvl2', 'Ahhaah', 'PUNCH', 'CUNTS', 'Tipical', 'dnno', 'odn', 'Pudge', '100000', 'AHI', 'AXAXXA', 'Greed', 'indian', 'ook', 'imma', 'bagging', '2in', 'wwwwwwwwwwiiiiiiiiiiiiiiiiii', 'shhshhshshshnh', 'looser', 'whould', 'Got', 'mikes', 'converted', 'sadness', 'KOL9Y', 'blind', 'Girls', 'shot', 'eartshaker', 'trahs', 'cac', 'thanh', 'nien', 'awhile', 'mought', 'energy', 'omnbi', 'IDK', 'ahahaahah', 'hotkey', 'bone', 'chick', 'thooo', 'oj', 'blackput', 'wed', 'WArded', 'lone', 'ape', 'comnig', 'quicker', 'HAAAAAAAAAAAAAAAAAAAAAA', 'SEEMS', 'LIKELY', 'cocck', 'beer', 'HARDER', 'anymmore', 'TRYHARDING', 'root', 'WOA', 'mentally', 'WOOOO', 'MAXING', 'SENTRIES', 'OBS', 'UPGRADED', 'HCICKEN', 'SHITHEAD', 'DUSA', 'DYING', 'UNDER', 'BOOTY', 'SHITSTAINS', 'HAHHAHAHAHAHAHA', 'Peenoise', 'rprobems', 'GEGGE', 'WEP', 'EP', 'inish', 'ojala', 'vuelva', 'quiero', 'jugar', 'este', 'shitters', 'nevermoreland', 'GGGGG', 'gws', 'wifi', 'nmn', 'kau', 'AFk', 'iget', 'mir', 'teamwipe', 'dizaztah', ':salty', 'MIGHTY', 'grats', '748', 'bukake', 'quuuuuiiiiitEErasgx', 'premuted', 'pw', 'wreck', 'CHISTRIS', 'SPIELEEEEEN', 'svenb', 'Xdd', 'killsl', 'imd', 'Leave', 'pleae', 'Miran', 'WOLF', 'ad', 'hvnt', 'hardlaner', 'WARUM', 'EINFACH', 'xaxaxaxa', 'SWEET', 'DREAMS', 'aer', 'sutpid', 'POWEL', 'NAHYI', 'VIRODOK', 'crap', 'invuln', 'immune', 'physical', 'destoy', 'karo4e', 'HAHAHAA', 'wHOOOOOOOOOOOO', '5hp', 'loes', 'Twitter', 'resetin', 'graphh', 'ruskaya', 'svinya', 'divin', 'clap', 'STIL', 'HEAL', 'allah', 'tanginamo', 'Kriv', 'je', 'litaaaar', 'vinaaaaaaaaa', 'sexual', 'preference', 'acutaly', 'JUKES', 'profarmer', 'farmville', 'LALALLA', 'ahyhahha', 'Keeper', 'LIXO', 'DOCTO', 'FILHO', 'PUITA', 'yusss', 'circus', 'hiding', 'mhmm', 'sz', 'xaxaaxax', 'engines', 'KILLED', 'eruvians', 'Dun', 'yesterday', 'dos', 'duelos', 'FELANKOR', '1x1', 'caried', 'baban', 'sene', 'sickde', 'boobs', 'teamplay', 'FVCKING', 'nha', 'GWp', 'zoo', 'grammar', 'WHYYYYYYYYYYYYY', 'hash', 'middddddddddddddddddd', 'rect', 'ownit', 'doNT', 'sRY', 'pLZ', 'faGGOT', 'PELEAN', 'fuyck', 'HAWHWAHAW', 'agh', 'par', 'lar', 'defense', 'fury', 'learner', 'Sri', 'Lanka', 'tursk', 'DALLLI', 'Valar', 'Morghulis', 'Japan', '1mins', 'Ks', 'bay', 'FUCKTARD', 'Glhf', 'piost', 'stromn', 'silencing', 'Rly', 'talker', 'toxics', 'wars', 'lmaoooo', 'wutface', 'Dog', 'playert', 'mhm', 'stafcks', 'anus', 'pilaet', 'Mid', 'ckckck', 'BOYSSSSSSSSSSSSSSS', '2500ms', 'reuse', 'Woo', 'WOWOWO', 'surrneder', 'avrg', 'BURNING', 'soooooooooooooooooooo', 'Sut', 'pid', 'gives', 'stunrange', 'wehat', 'fits', 'MNY', 'THING', 'SLARKA', 'kekn', 'scrabbling', 'area', 'thankyouuu', 'gs', 'WAOW', 'REKITY', 'byebek', 'switggity', 'swooty', 'pesti', 'yawa', 'gia', 'tay', 'picki', 'tearing', 'johan', 'hav', 'banter', 'wkwk', 'alchemas', 'tambien', 'HAHAA', 'EleFuckingGiggle', 'nb', 'ritw', 'supercreeps', 'hhhahahah', 'babysat', 'Stone', 'SHIELD', '30min', 'TOUCHDOWN', 'mexico', 'dizazterr', 'statss', 'sooon', 'BOAT', 'unnistal', 'Ezzz', 'fiuck', 'midder', 'scream', '=/', 'bish', 'magno', 'pude', 'quiras', 'SMOKE', 'MAN', 'gL', 'FUCKS', 'nowdays', 'sjot', 'mutes', 'MT', 'CHERS', 'thejm', 'Commended', 'honey', 'noncontributory', 'warlok', 'hhahahahhahahaha', 'peri', 'hype', 'MOMMAS', 'BOOII', 'noobwd', 'rubbish', 'deffffff', 'tilted', 'sigue', 'ingles', 'medu', 'series', 'slarsadder', 'HEHEHE', 'muereeeeeeeeeeeee', 'guyzzz', 'leglas', 'Out', 'bas', 'Rsdfkpghsd', 'jhjosfh', 'poshel', 'urgent', 'salami', 'THEEE', 'slardars', 'vigilante', 'bandot', 'VERY', 'become', ':po', 'FUCKN', 'whereeee', 'heeeeeeeeeee', 'tc', 'cheecky', 'clever', 'gho', '211', 'hast', 'zzzzzzzzzzzz', 'gucci', 'dony', 'didt', 'Pa', 'lagg', 'IHhi', 'escort', 'LMAOOO', 'sp', 'zaebal', 'GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG', 'purge', 'kicked', 'dayna', 'walang', 'cuming', 'ruptured', 'eneemies', 'tornadio', 'waitcan', 'confirm', 'andwaitforhimself', 'ich', 'versteh', 'kein', 'wort', 'landing', 'DROP', 'whores', 'lonedruid', 'West', 'virginia', 'KKKKK', 'KKKKKKKKKKKKK', 'KKKKKKKKKKKKKKKKKK', 'VEJAM', 'WINTER', 'VALE', 'PENA', 'DAR', 'RIZADA', 'drums', 'Sunder', 'aclick', 'sedih', 'lagi', 'SHACLE', 'mangoes', 'Napakatanga', 'Smh', 'gret', 'wared', 'didn', 'befoire', 'botm', 'ar1se', 'polite', 'jib', 'watched', 'ainsley', 'harriott', 'cokking', 'duno', 'sickest', 'lucies', 'lkmao', 'bher', 'ownes', 'commned', 'mothercukeer', 'PREDICK', 'SKY', 'nowww', 'UMR', 'globl', 'globals', 'ropsh', 'lur', 'cuint', 'CUM', 'onilne', 'bum', 'SHUTUP', 'ARSE', 'CHICKEN', 'NOISY', 'abusive', 'tream', 'ths', 'bosting', 'Midlane', 'prefer', 'mao', 'moooooh', 'MLG', 'hon', 'tifa', 'RiP', 'RAVAGE', 'DUMBSHIT', 'brilliant', 'rotations', 'Unless', 'zez', 'machismo', 'noobi', 'setnry', 'romans', 'greeks', 'statues', 'naked', 'wrestling', 'dmid', 'matched', 'KAAAAAAAAMMMMMMMMMMEEEEEEEEEEEEEE', 'HAAAAAAAAAAAMMMMMMMMMMMMMEEEEEEEEEE', 'concernedstudent1950', '3v5', 'asap', 'huehuehuehue', 'pld', 'surpriseee', 'ru', 'kitty', 'spider', 'seg', 'immortal', 'everyon', 'atta', 'cyou', 'delet', 'oufhsjghsdg', 'invokeeeer', 'ours', 'noyt', 'slardera', 'Rape', 'hehhe', 'fucksake', 'hhhh', 'SPCE', 'alwys', 'cracked', 'SHORT', 'ezgame', 'tommorow', 'levi', 'Seconecto', 'Te', 'odiO', 'hpd', 'indonesia', 'wodota', 'george', 'brezzy', 'TONYH', 'TONY', 'Mangoes', 'TBD', 'ditch', 'whoop', 'domu', 'lagggggggggggg', 'xzxaaxaxaxaxaxaxa', 'gggwp', 'Jk', 'acalming', 'JK', 'ruskis', 'BARAT', 'neuts', '50:00', 'supoer', 'TIWALA', 'sneaky', 'kale', ':derp', 'screwing', 'yas', 'Double', 'yap', '=s', 'harras', 'eminem', 'doomn', 'drum', '340', 'dip', 'dcs', 'waits', 'rages', 'kod', 'hookshot', 'tiki', '4vs', 'youmadbro', 'movistar', 'step', 'Used', 'Make', 'idiiot', 'atay', 'optjer', 'concedes', 'baia', 'Is', 'wipeout', 'appeared', 'heang', 'prolem', 'address', 'jobs', 'fuzzy', 'wuzzy', 'zayehal', 'pahha', 'SWAP', 'tom', 'wrwrw', 'soooo', 'premute', 'Should', 'Didnt', 'fickijg', 'motehr', '25mins', 'QQ', 'yyy', 'silent', 'credits', 'ez4', 'commed', 'COMMNED', 'timbersaw', 'octine', 'inoker', 'flamming', 'wutever', 'duuude', 'mnay', 'woa', 'linch', 'commendable', 'motion', 'witing', 'thistime', 'Kek', 'Tusk', 'supprt', 'otvechay', 'pikaite', 'looooool', 'rooting', 'fucke', 'mahirap', 'zzzzzzzzz', 'torll', 'bithces', 'CMD', 'PT', 'SOS', 'UN', 'ASCO', 'TE', 'REPORTO', 'PODES', 'JUGAR', 'ASI', 'EN', 'RANKED', 'mjst', 'sureness', 'fo', 'rhim', 'chickens', 'omi', 'joob', 'poser', 'comming', 'gangsta', '84', 'LETAS', 'LULZ', 'ohmy', 'lelele', 'rubikc', 'lanning', 'basement', 'rme', 'ead', 'Muting', 'michael', 'phelps', 'randmon', 'Lesh', 'daynov', 'krome', 'wispa', 'malaysia', 'FKC', '330', 'AHhaah', 'deine', 'dag', 'attitude', 'PINOY', 'bobong', 'barbaric', 'ENOPJOUAY', 'tusks', 'waoit', 'CTM', 'mission', 'ohkay', 'predic', 'Straight', 'qward', 'recomiendane', 'qopa', 'dura', 'sobrala', 'yooohoo', 'unerstand', 'Hahahahahahah', 'HAHAHAHAHAHAHAHA', 'ALEG', 'AELG', 'roshd', 'wsip', '2moro', 'comps', 'jogo', 'muito', 'desisti', 'dessa', 'partida', '2300', 'lusting', 'qb', 'trilaned', 'VENOM', 'excuses', 'kok', 'lawannya', 'cupu', 'bgt', '96', 'nightr', 'katushka', 'dfsgahzwreas', 'patehtic', 'respawns', 'wai', 'shouldve', 'snickers', 'wrecking', 'itself', 'Davai2', 'bratan', 'accidentally', 'dualed', 'lov', 'shackels', 'group', 'vk', 'HAHAHAHAHAHA', 'watchin', 'replays', 'prt', 'NOBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB', 'topgame', 'europa', 'SWAN', 'mole', 'ox', 'dang', 'bravo', 'form', 'yan', 'frags', 'WAITING', 'hahg', '::@', 'PFF', 'LOX', 'nad', 'wrok', 'uncle', 'Benn', 'zl', 'greeting', 'decline', 'adoro', 'bater', 'quer', 'pagar', 'joga', 'kkkkk', 'Munic', 'peen', 'mrr', 'COMMING', 'EULS', 'WHICH', 'CAST', 'HOOKED', 'cruel', 'flash', 'deserves', 'wash', 'clothes', 'THESE', 'suffers', 'insta', 'wtv', 'ezMMR', 'size', 'flashy', 'LOLz', 'whhy', 'ezzzzzz', 'ALCHEEEEE', 'WATASHIWAA', 'HIGH', 'GROUND', 'HAHAHAHAHHA', 'NOOOO', 'galing', 'LUCKER', 'hilarious', 'trigger', 'split', 'nudes', 'Oo', 'BASURA', 'tudsun', 'JAJAHJAHAHA', 'alpha', 'chapstick', 'chavstick', 'shoot', 'GONNA', 'WAHAHAHA', 'wasteour', 'jajajajajaja', 'capt', 'PLSS', 'FULL', 'LUNATICS', 'ohard', 'tobias', 'helvete', 'UNTIL', 'laner', 'lapsap', 'ALLLLLL', 'BREW', 'Live', 'xarub', 'Awesome', 'essence', 'shift', 'Coinz', 'headshot', 'teamfights', 'blinked', 'jams', 'NERD', 'passion', 'RUNNER', 'absolutley', 'ahahahahahahahahha', 'HAHAHAHAHAHAHAHAH', 'haaaaaaaaaaaaaaaaaaaa', 'hakey', 'HER', 'dazl', 'crfat', 'wstyd', 'zaoszczedzony', 'panowie', 'crybabies', 'niga', 'mooooooh', 'briste', 'retribution', 'Boris', 'meka', 'reconncet', 'focken', 'unranked', 'TIDE', 'dauni', 'lesu', 'jugs', 'reportslark', 'JUGGER', 'volume', '::_', 'MEDUSA', 'Losing', 'Isntant', 'Somee1', 'RESTART', 'rematch', 'eyeballs', 'SUICIDE', 'syhit', 'cnacer', 'dist', 'ahhhhhhhhhhhhhh', 'AHA', 'previous', 'smaterz', 'Dk', 'stum', 'ooohoo', 'ezzzz', 'caya', 'cmtr', 'TAKDE', 'BGTAU', 'AWAL', 'opps', 'darling', 'frieenddd', 'intelligient', 'WOOOOOOOOOOOOOW', 'control', 'teamfighting', 'greek', 'Trable', 'SJ', 'spics', 'Rs', 'cristalis', 'bcos', 'terminen', 'STFUUU', 'holyshit', '2:11', 'areu', 'Spouky', 'owuld', 'ttrash', 'depression', 'ahgahhaa', 'discuss', 'situation', 'horoshiy', 'freeand', 'Yeha', '|', 'tampar', 'aku', 'pressence', 'receive', 'Lfdyj', 'gjhf', 'rthe', 'fuckboys', 'English', 'illiterate', 'JOJOJO', 'JOJOJOJOJOJOJO', 'oie', 'agnus', 'shouldnt', 'BRAVO', 'picknut', 'mmmmmmmmm', 'rnked', 'AR', 'HARDEST', 'OKE', 'STEALER', 'TCH', 'lyfe', 'wass', 'remotely', 'opinion', 'quote', 'SASGGGDDD', '69', 'bristleback', 'landed', 'plenty', 'paket', 'tengo', 'bummer', 'tuesday', 'repoted', 'cookkk', '34min', 'fest', 'trashlords', 'moly', 'ELSa', 'lolc', 'JOJOO', 'JIOJOJOJOJO', 'buhat', 'kingina', 'HAHHAH', 'WHORE', 'liched', 'embarrasing', 'multiplayer', 'videogame', 'enviroment', 'DISGUSTING', 'gaycunt', 'plans', 'Hello', 'sy', 'Fly', 'rak', 'moreplz', 'tyiny', 'haVBE', 'ISSUE', 'ABANDON', 'uit', 'messing', 'bitvh', 'leading', 'future', '2111', 'aggg', 'middle', 'hae', 'werk', 'wizard', 'DUel', 'acommend', 'HIII', 'havin', 'BIASA', 'pathetic', 'ahghahahah', 'idd', 'plater', 'EZZZ', 'chops', 'thankyou', 'serving', 'wisped', 'Io', 'rocked', '190', 'winnable', 'klikl', 'wtF', 'asdgsdgh', 'gabe', '1v4', 'thais', 'belive', 'jstbreak', 'Ns', 'papa', 'noooow', 'freezes', 'LOLOL', 'ghusk', 'TRAMP', 'eVA', 'hpta', 'effeect', 'blockers', 'hayne', 'doller', 'alienware', 'yuked', 'CARYY', 'BES', 'sipport', 'h3h3', 'templer', 'AHHAHAHAA', 'Tuskar', 'Bought', 'ZZZZ', 'Intense', 'Repport', 'transh', 'ennd', 'idioot', 'okj', 'thou', 'TOSSING', 'YOUVE', 'ANYWAY', 'fuckler', 'SU', 'vl', 'LOOOOOOOL', 'ocampo', 'WAHAHA', 'defim', 'piggy', 'ways', 'sevn', 'tanks', 'roll', 'sharpest', 'bulb', 'usap', 'tau', 'broadswor', 'Marvel', 'sitted', 'PUTIN', 'THEH', 'tonker', 'members', 'baby4', 'thursday', 'enjoying', 'thirsty', 'Catcher', 'saba', 'dira', 'sell', 'ampas', 'disconected', 'loved', 'Give', 'WPEE', 'dirge', 'WEEEE', 'arruine', 'showed', 'ehat', 'Hows', 'bz', 'sua', 'wana', 'pgg', 'Winning', 'TIZ', 'TRAP', 'Relocate', 'fountaion', 'Fountain', 'nexrt', 'kaapa', 'finn', 'asd', 'ogin', 'gto', 'MAgnus', 'finds', 'ultie', '830', 'claim', 'FUNNNY', 'HOHO', 'AEWFIOoiufbFON', 'fresh', 'Afk', 'ssentry', 'MONGOLOIDS', 'broi', 'tihnk', 'jerking', 'jst', 'bhai', 'khaana', 'kha', 'ke', 'aaya', 'jewish', 'glose', 'tks', 'rx', 'Le', 'redhead', 'NUMBER', 'HARASSING', 'purch', 'reaver', 'waiitng', '120s', 'regret', 'BNYAK', 'GAYA', 'KAU', 'ganr', 'Almost', 'BOOOO', 'commited', 'KAPPAROSS', 'backup', 'dro4it', 'masturbate', 'YEY', 'WAH', 'FVB', 'kurwo', 'https', 'rupees', 'MUAHAGAHAHAHAHAAH', 'LOOOOOOOOOOOOL', 'sme', 'hahaahaha', 'idolaku', 'stinked', 'nut', 'itchy', 'title', 'loto', 'pity', 'FUCKing', 'worthless', 'HAHAHHAHAA', 'ahhaa', 'writed', 'weave', 'sadfaceariono', 'sadfacearino', 'plags', 'nigsd', 'bitchh', 'dieee', 'lala', 'factor', 'transition', 'morreu', 'susto', 'univeirse', 'dem', 'DIFFUSAL', 'OMFg', 'fuckings', 'mens', 'eeeidiot', 'racks', '2many', 'strg', 'MIDD', 'definitly', 'Yay', 'tastes', 'mu', 'biasa', 'tussle', 'cago', 'plzi', 'JAJAJAJJA', 'SABE', 'GOLPEAR', 'bomji', 'hhtfu', 'sur', 'WKWK', 'yeajj', '=P', 'fked', 'blat', 'portal', 'scroll', 'nevermind', 'possess', 'Urn', 'unneeded', 'vby', 'cleavbe', 'dragon', 'ax', 'babeeeeeeeeeeee', '5000', 'alkemist', 'kalemn', 'traitor', 'neither', 'stopm', 'itms', 'wewerw', '490', 'Wins', 'Rat', 'lemon', 'sqeezy', 'tabla', 'land', 'WhERE', 'lmol', 'errrr', 'rediculous', 'ritardati', 'hoook', 'lols', 'Ahahaha', 'boyos', 'ROPFL', 'bending', 'Hence', 'penetration', ';-;', 'stpd', 'zbs', 'With', 'abysal', 'pull', 'outlevling', 'plys', 'awhi', 'thge', 'fycj', 'LOLOLOLOL', 'allways', 'STANDING', 'me2', 'usage', 'haahah', 'naab', 'WELCOME', 'shakled', 'telstra', 'ulted', 'arl', 'complete', '338', 'baara', 'playe', 'accont', 'TERRORBLADE', 'EZZZZ', 'nervous', 'exec', 'madcuzbad', 'ilidan', 'QO', 'mothers', 'fortune', 'omw', 'THNIS', 'SORRU', 'mmmmm', 'Venge', '3winstreak', 'passing', 'demon', 'sus', 'oki', 'espect', 'Shup', 'furi', 'undaut', 'cosplay', 'Clock', 'sign', 'memorandum', 'clinton', 'loomis', 'hahahahaahaha', 'difussalk', 'Culda', 'nyet', 'pieces', 'fu9ck', 'lami', 'perrra', 'HAHAHAHAHHAHAH', 'HHAHAHAHAHAHAHAHAHAHAHAA', 'KUNKA', 'awe', 'f4', '13mins', 'qwait', 'FML', 'WTFFF', 'Surprise', 'golem', 'pode', 'mail', 'clockwork', 'woop', 'deffiing', 'cryts', 'zaaaaaaaaaaaaaaaaaaaaaa', 'SPICCY', 'Zero', 'GLGL', 'mads', 'brahs', 'isin', 'tryahrds', 'kfucking', 'shity', 'rockhead', 'pride', 'NS', 'riperino', 'Np', 'ramge', 'Hook', 'Fat', 'edz', 'Throws', 'rcn', 'whiners', '5s', 'ooon', 'kakakak', 'tlaking', 'oyu', 'STALKING', 'SHOTS', 'FIRED', 'tentando', 'ensinar', 'meu', 'precisa', 'comprar', 'matar', '8K', 'Nooo', 'acted', 'dickheads', 'aff', 'ruinetr', 'chaos', 'acutalyl', 'STUNS', 'ttuskk', 'p0ta', 'fit', 'TROW', 'togehtr', 'umaru', 'yayaya', 'donate', 'nvoid', 'linking', 'links', 'wrg', 'hac', 'thatga', 'chupa', 'shitshaker', 'VOD', 'okairi', 'STAR', 'START', 'sooooooooooooooooooooooooooo', 'PROBLEM', 'NBEVER', 'galeng', 'pauzka', 'unpauzka', 'zakonjelas', 'igra', 'BABE', 'hilakay', 'bubulok', 'nito', 'p0tang', 'ywa', 'jembut', 'nganaaaaaa', 'yf', 'hfdifyt', 'doNE', 'ALREDY', 'nojeira', 'nothign', '35m', 'ins', 'Safelaen', 'mazing', 'ought', 'DELA', 'WEST', 'XO', 'supamida', 'blablabla', 'movespeed', 'midgame', 'perspective', 'UFCVK', 'Looks', 'whaaaaaaaaaaaat', 'bich', 'mide', 'Whos', 'tnker', 'rudeness', 'friendliness', '1by1', 'pleeaassse', 'ECUADOR', 'mi6kiiiiiiiiiiiiiii', 'Sick', 'Rep', 'RESUME', 'AHHA', 'Nc1', 'nus', 'cosmetic', 'winsgaes', 'kunkkar', 'beinga', 'chron', 'rampae', 'htings', 'sil', 'yuor', 'autos', 'microing', 'Carry', 'Blame', 'boosted', '524', 'Here', 'Take', 'nee', 'agamis', 'ZZZZZ', 'ISNT', 'MORPHLINGS', 'FAULT', 'topor', 'htat', 'snowballing', 'hacker', 'zeusss', 'ultiiiii', 'strats', 'Tipo', 'daj', 'ushel', 'iz', 'stuna', 'dued', 'compassion', 'uptime', 'age', 'wouldfk', 'cliff', 'thug', 'fuckkin', 'Lich', 'Scary', 'kapap', 'bitching', 'illusion', 'proofs', 'CURRIER', 'healtrain', 'leet', 'Yahh', 'Ahahahahah', 'AHahhaahahah', 'Hahahhaha', 'YEah', 'yaphets', 'rushing', 'diffu', 'Assholes', 'aretard', 'ebtter', 'umanner', 'DAMI', 'jennifer', 'aniston', 'bick', 'pone', 'plzzz', 'metapicker', 'atard', 'MARICA', 'desk', 'burning', 'byr', 'mostimpotant', 'Alceh', 'bengap', 'bouhgt', 'blamer', 'TMR', 'AGUANTA', 'PSS', 'CRTM', 'ggoing', 'aganim', 'HIGHLIGHT', 'kkkk', 'commment', 'ko', 'danh', 'thua', 'lau', 'roi', 'wha', 'pple', 'healers', 'jooked', 'Eul', 'wooo', 'rick', 'morty', 'annoucner', 'jigg', 'certainly', 'rain', 'hahahahahahaha', '900HP', 'poitns', 'iam', 'Perfect', '<<<<<', 'expressed', 'fead', 'phreshin', 'striggers', 'haist', 'Tgate', 'ilknjrhg', 'Bro', 'fuqn', 'RPs', 'Magnus', 'thusfar', 'Catch', 'STD', 'Awwh', 'accident', 'yessssssssssssssssss', 'mena', 'looool', 'human', 'sexi', 'wjo', 'wodden', 'nws', 'rought', 'imdeed', 'elfticle', 'restarted', 'LOOOOOOOOOOOOOOOOOOOL', 'Ded', 'GLIMMER', 'TAB', 'moneyyy', 'BEM', 'JOGADO', 'inchs', 'llife', 'BADS', 'STUPIDS', 'PINOYS', 'Hf', 'baaaaaag', 'mto', 'stab', 'mapxak', 'whata', 'SHOW', 'esx', 'duded', 'lolqop', 'quien', 'bruto', 'PETER', 'fIRST', 'kasrma', 'bithc', 'SMALL', 'AFTERALL', 'MICRO', 'mapa', 'Angry', 'buffalo', 'aroound', 'trist', 'WYWERN', 'etcetcetc', 'pedge', '228', 'furious', '040', 'bright', '185', 'ajaja', 'glim', 'therei', 'succes', 'thnk', 'specially', 'HAHAHHAHA', 'twot', 'LMFASO', ':FMAOP', 'Lf', 'vbl', 'yjhv', 'nfr', 'HOok', 'auawj', 'egofkl', 'PLAYE', 'ENOUGH', 'FFF', 'exz', 'campaign', 'tenks', 'exicte', 'ono', 'twr', '=M', 'bieng', 'emo', 'shittest', 'windrun', 'italy', 'GENOIUS', 'tricky', ':X', 'GARBAGE', 'fuycku', 'monney', 'doooo', 'eeeeeet', 'eeeeet', 'tranq', 'ai', 'aeg', 'aego', 'pissy', 'KWOWK', 'KWOKWOWK', 'fired', 'bitchas', 'ACTUALLY', 'motivation', 'rasta', 'motherfucekrew', 'Feeling', 'ful', 'chilled', 'brosky', 'noi', 'retads', 'FUCKSDF', 'SKILS', 'Winter', 'basics', 'GOLDEN', 'SHOVE', 'SKADI', 'BASHER', 'anjing', 'Lose', 'massively', 'regbnt', 'utv', 'rkbyrp', 'dfvb', 'hzjv', 'tuftn', 'UDAH', 'AEGIS', 'LU', 'BRAINLESS', 'HAHAHHAHHAHA', 'leddit', 'LOTAR', 'htfu', 'Vl', 'xanh', 'vy', 'expensice', 'danny', 'volteo', 'TECHIES', 'everywehere', 'unskill', 'scurbs', 'canyou', 'fuaskf', 'Bristle', 'jhave', 'GGgg', 'improve', 'properly', '400g', 'myh', 'REALL', 'jgug', 'machine', 'omgg', 'farrrrrrk', 'iodiot', 'horseman', 'chegamos', 'ao', 'heterosexual', 'brainly', 'akiro', 'HUH', 'submit', 'Crom', '13:8', 'CARRIED', 'dayuuuuuum', 'repot', 'hoe', '3vs5', 'Luna', 'loptop', 'Creep', 'ACID', 'SPRAY', 'RP', 'EBOLA', 'anyyhing', '250', 'mang', 'EPPI', 'AHHAHAHAH', 'army', 'pudsge', 'coommend', 'fukking', 'Worth', 'allow', 'jack', 'ie', 'papech', 'podrubil', 'seeu', 'launched', 'immop', 'bladmail', 'aime', 'Ahi', 'Ayyyy', 'Ezz', 'eiiii', 'calculator', 'Gk', 'rexxar', 'ALYANSOV', 'NASMOTRELIS', 'SOLYANOVO', 'alwayz', 'beffore', 'SUQOOA', 'famapage', 'ra', 'embarasing', 'ft', 'ASDIJANOSDAS', 'plyer', 'uyy', 'jag', 'thnak', 'ggwpp', 'WTB', 'SUN', 'STRIKE', 'kjkustu', 'disrupter', 'DEFF', 'culling', 'kuunka', 'gooddddddddddddd', 'Soup', 'Kitchen', 'fab', 'WAHAHHA', 'nop', 'umad', 'monogolian', 'ggo', 'ahaahaah', 'RUn', 'resdtart', 'LATE', 'siap', 'ACHE', 'WHATS', 'WRONGGGG', 'OUCH', 'KUTN', 'wAS', 'FUKING', 'ROUND', 'hlp', 'xboct', 'mther', 'GRET', 'everysingle', '1z1', 'juz', 'easyyyyyyyyyyyyyyyyyyy', 'freefarmed', 'timer', 'flag', 'stepd', 'xdddd', 'devoting', '0:00', 'CHALLENGE', 'ting', 'CRYSTAL', 'vete', 'xonshaotmare', 'neiter', 'ege', 'ultrakill', 'cf', 'saimung', 'ofline', 'sryt', 'morps', 'WINDOWS', 'UPDATE', 'a3', 'slivaetsya', 'alrighty', 'korean', 'mema', 'twitter', 'mech', 'v1', 'bicht', '60min', 'mythical', 'jojojojojo', 'wkwkwkkw', 'brushan', 'GANKS', 'TREASH', 'cary', 'Ow', 'shutting', 'PUnit', 'XAXA', 'BIATCH', 'h8', 'yiyi', 'mam', 'PORR', 'abaddon', 'jajjaa', 'ultimates', 'keper', 'jode', 'mrda', 'lowl', 'honesty', 'loan', 'nin', 'sanya', 'havn', 'winnign', 'COINS', 'Nobody', 'defence', 'guarding', 'siht', 'memeing', 'AHAHAAH', 'cooperate', 'dident', 'dide', 'nahuy', 'idi', 'goverment', 'hHAHAHA', 'wauiting', 'desperationj', 'REALY', 'sCARE', 'frens', 'wpee', 'inhouse', 'REPORTE', 'lucker', 'syllabear', 'legend', 'catapult', 'sooooo', 'ride', 'wreking', 'ahrd', 'zmuffinman', 'holu', 'shittttt', 'spark', 'OI', 'IDI', 'NYLEVOY', 'HAHAHAHAHAHAHAHAHAHAHAHAHAHA', 'HAHAHAHAHAHAHAHAHAHA', 'sinned', 'owh', '2kmmr', 'las', 'scorpion', 'Made', 'USA', 'Ultie', 'downside', 'enimga', 'matters', 'surgery', 'duble', 'wornggg', 'coiier', 'virgins', 'faggors', 'HURRY', 'dweller', 'looya', 'realise', 'breakes', 'shackleshot', 'dan', 'gib', 'LELELEL', 'fissure', 'suppoort', 'awaw', 'sed', 'cried', 'torture', 'JOke', 'couri', 'coaching', 'yesss', 'billing', 'wron', 'Feeding', 'blya', 'Empire', 'Liquid', 'HEHEHEHEHEEHEHEHEHEHEHEHEEHEHEHEHEHEHEHEHEHEEHEHEHEHEHEHEE', 'HUHUHUHUHUHUHHAHAAHAHAHAUAHUAHUAHAUHAUHAUHAUHUAHAUHAUAHUAHUAHAUAHUAHUHEHEUEHUHEUEHUEHUEHUE', 'HUEHUEUHUEHUEHUEHUEHUEHUEHUEHUE', 'konw', 'uf', 'simples', 'creazy', 'okeh', 'email', 'remove', 'science', 'Fuckingmmr', 'analed', 'MALES', 'buly', 'pease', 'intent', 'semblance', 'tqtq', 'teeny', '175', 'challange', 'tarzan', 'asssisst', 'Ti6', 'sreated', 'meppo', 'msgd', 'Abuser', 'GALACTIC', '1x5', 'LEave', 'tornade', 'hahaahahaha', 'oir', 'absurb', 'Silencer', 'mmrs', 'Takes', 'huska', 'Calm', 'ahs', 'parody', 'REpORT', 'XDX', 'ECHJO', 'FCUK', 'TESAM', 'linavs', 'basterds', 'meppen', 'code', '11mins', '22mins', 'minus', 'larth', 'dragging', 'drawing', 'sien', 'backdoor', 'HOOORRRRYYY', 'SHHIIITTT', 'recing', 'DJON', 'SINA', 'twatted', 'prick', 'jjust', '5555555555555', 'gahahhhhh', 'LEE', 'PAL', 'KR', 'becuase', '150', 'Love', 'active', 'WIT', 'THEIR', 'ROFLLLL', 'YALL', 'MATES', 'weaboo', 'kden', 'slown', 'Super', 'mael', 'teeam', 'heff', 'minded', 'PIRT', 'toewr', 'shallow', 'AXAXXAXA', 'Tanginamo', 'FUC', 'KNO', 'GANKED', 'atack', 'COMPEDIUM', 'weakest', '7u7', 'KRBEN', 'LEICHFANZ', 'TEMAMMATE', 'WAHT', 'steel', 'coureirs', 'eanwhile', 'shkel', 'fnatic', 'SLARKJ', 'wirdo', 'ASDFSADFASDFASDFASDFASFASDFASDFSAFASDFSDAFSADFASFADSFASDFASDFASFASDFASDFSADFSADFASDFASDFASDFADSFASDFSADFDASFDSAFDASFASDFASDFAS', 'proo', 'sdelayu', 'ru9n', 'fukboi', 'SAMUL', 'cumb', 'vf', '5th', 'seee', 'ac', 'overrated', 'insect', 'WITHOUT', 'POINT', 'compendium', 'bvoid', 'RUSSTARD', 'ler', 'bnro', 'awkward', 'fucku', 'unlike', 'maxing', 'sandking', 'jungling', 'refusing', 'afterwards', 'Ahahahha', 'nic2', 'more2', 'dde', 'WOULD', 'eaglesong', 'screenshoot', 'cli', 'Maybe', 'besides', 'leech', 'cung', 'qui', 'cangkeman', 'immature', 'slant', 'fxxk', 'goodboy', 'weve', 'knife', 'chode', 'baracks', 'Co', 'ooooooooooooooooo', 'tickect', 'GALAHD', 'ALUUKHAWAKBAR', 'uless', 'frank', 'BHITTER', 'MUCH', 'lencer', 'sauy', 'enuf', 'BET', 'exploded', 'TRI', 'PRETTY', 'nlob', 'vamatem', '=-', 'imposible', 'suuport', 'accepted', 'EleNiggle', 'msging', 'sthap', 'GONE', 'RADIANCE', 'SANDY', 'HTJGHN', 'GKP', 'CA', 'kristen', 'laste', 'ilike', 'tammates', 'smell', 'iceshards', 'shards', 'horny', 'polie', 'TJHAT', 'vbane', 'HAHAHAAHHAHAHHAAAAH', 'w8ing', 'inch', '30k', 'networth', 'mroe', '66mins', 'DOGE', 'fuknh', 'gtamne', 'dousnt', 'tryna', 'TRYNA', 'picE', 'CRAP', 'fiSH', 'didntt', 'imrpeganted', 'cuoi', 'lon', '1651', 'murdered', 'idioot22', 'EAYH', 'Taking', 'pinaka', 'buong', 'mundo', 'aylmao', 'rpeorten', 'entren', 'noma', 'pero', 'whrre', 'izz', 'emdio', 'dijo', 'llevaran', 'kupal', '12y', 'rembo', 'wacth', 'UEBISHE', 'pornsite', 'chased', 'kin', 'jippers', 'trippers', '2721', 'awtsu', 'spoted', 'goood', '1450', 'sladdar', 'welcum', 'forcestaff', 'analfisting', 'neva', 'meister', 'unpuase', 'UVE', 'GAURDIANS', 'Rata', 'PEENOYS', 'foodtrip', 'lell', 'WIPEOUT', 'sue', 'copyright', 'infringement', 'PDUGA', 'RAGE', 'alca', 'bitchass', 'awkawkakwkwa', 'lachi', 'retrad', 'square', 'est', 'silncer', 'SINGSING', 't4', 'serves', 'GGGGGGGGGGGGGGGGG', 'gamesr', 'Since', 'commead', '5v1', 'retk', 'bolder', 'anybodsy', 'elkse', 'masters', 'TAke', 'gahaha', 'ranfom', 'thd', 'godong', 'godthel', 'firstpickl', 'emotional', 'stinky', 'pucj', 'gyrohc', 'marko', 'Stun', 'pq', 'coel', 'masta', 'hating', 'rfc', 'BASE', 'onkly', 'sielencer', 'noobshit', 'DETECTED', 'loster', 'Ina', 'madness', 'service', 'spik', 'englis', 'OIHHH', 'taco', 'vaginitis', 'Early', 'loll', 'dotra', 'ngewes', 'infront', 'comr', 'WTFUCK', 'NIGGAS', 'goddamn', 'logi', 'reallyh', 'fucktards', 'thomas', 'cloack', 'plase', 'REPORTENME', 'commend2', 'fucktad', 'IMA', 'MAKE', 'y3a', 'performance', 'bakbuki', 'torando', 'lacky', 'pleasse', 'crimson', 'guardian', 'btf', 'QUIT', 'applaud', 'observer', 'hahahiz', 'uwon', 'rightr', 'ughh', 'gegege', 'foo', 'regrets', 'jung', 'gry', 'VENO', 'balnce', 'GRREDY', 'vd', 'bd', 'Zenokaiais', 'actualyl', 'THWN', 'ORAXCLE', 'WIM', 'NB', 'yoor', 'huhuh', 'record', 'puch', 'ACLHE', 'google', 'Neaaaaaaaar', 'huhuhu', 'ads', 'LMOFA', 'Yah', 'blakc', 'hol', 'HHSHSDHSD', 'ANIMAL', 'wh', 'Da', 'toaday', 'Push', 'FREAKING', 'KEYBOARD', 'WARRIOR', 'fku', 'uya', 'kayyyy', 'esss', 'Share', 'wadap', 'bc', 'ditto', 'yeyah', 'ezzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'reisen', 'itny', 'rperot', 'ama', 'treee', 'fro', 'mthat', 'JAJAJAJA', '4th', 'HJAHH', 'uguys', 'gogog', 'zhdu', 'forgive', 'dictates', 'SOOOO', 'NOOOB', 'SEC', 'Id', 'ont', 'QUITRR', 'fiesta', 'esta', 'lica', 'FIESTA', 'Dcm', 'ngay', 'PUssy', 'hahaahahahahaha', 'NOOOOOOOO', 'lows', 'qopp', 'MEAN', 'niet', 'quesiton', 'tops', 'buns', 'hasnt', '1rs', '1rst', 'RECION', 'kate', 'ness', 'GGGG', 'builddings', 'BOOOM', 'WHYY', 'WHYYY', 'prretty', 'Shet', 'struggled', 'LAN', 'brokenn', 'multiple', 'yeanhj', 'diurrrr', 'saiyan', 'laik', 'IMBA', 'Black', 'nnnnnnnnnnnnnnnn', 'gooooood', 'pepet', 'wpp', 'tinke', 'jungler', 'akf', 'HGhaha', 'b9', 'barely', 'UIFHIUWEHFOUIHWEF', 'twisted', 'VLADS', 'hung', 'maddest', 'lightr', 'float', 'rap', 'easir', 'yewa', 'pissing', 'gratification', 'aaaahaaajajaa', 'atos', '2ez4WR', 'Mexicans', 'exex', 'waved', 'BANE', 'JAJAJAAJAJAJA', 'againsty', '8ks', 'LIAT', 'BANGSAT', 'taxi', 'driver', '345', '00', 'rebooting', 'ECHO', 'ppls', '348', 'bruuuhh', 'agaw', 'naa', 'meeting', 'chatwheel', 'tinhker', 'qesseo', 'plaryer', 'spisn', 'mtued', 'wotn', 'UH', 'UHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH', 'Agies', 'SIDE', 'spectra', 'barracks', 'tanked', 'beginning', 'wanting', 'loseing', 'semi', 'braindeadm', 'onkey', 'bullshjit', 'lucu', 'lu', 'ezmode', 'smoking', 'fuckton', 'NOIOO', 'USCK', 'wastn', 'vsf', 'tn', 'chemical', 'component', 'recently', 'FEEDED', 'laggggggggggggggggggggggg', 'freaking', 'gahi', 'kaayo', 'haahh', 'pult', 'gameruining', 'moofta', 'salrk', 'relentless', 'chats', 'dooooooooom', 'DUUUUDe', 'Wish', 'Mate', 'bill', 'waldo', 'bitched', 'folks', 'lately', 'rid', 'Reporta', 'cheisnese', 'olso', 'present', 'Saw', '2dedos', 'Miracle', 'sgut', 'UNPY', 'crackwhores', 'router', 'AI', 'SIA', 'HAROMO', 'nagelfar', 'ojh', 'bugging', 'disappearing', 'incest', 'nicedoom', 'tamrae', 'wlangbawas', 'RATA', 'shapes', 'explane', 'famr', 'travel', 'ache', 'eulsed', 'MOOOOOOOH', 'FAGGOT', 'slaughtered', ':{', '06', 'ZE', 'taling', 'urejsut', 'homosexual', 'lolzzz', 'andu', 'youporn', 'humble', 'WORKING', 'INFILTRATING', 'xDDDDD', 'refused', 'rpg', 'FPS', 'ANYMORE', 'sayin', 'engalndski', 'lunatic', 'utterly', 'deranged', 'rpeorting', 'UPHILL', 'FIUCK', 'CNACNCELED', 'UWANT', 'GGGGGG', 'ssss', 'initiate', 'profeed', 'talento', 'GLOBAL', 'booster', 'warudo', 'brainless', 'TEL', 'FSSIISURE', 'DINT', 'GEt', 'HITTERS', 'nyakl', 'wits', 'tehn', 'highlight', 'prediccion', 'oooooo', 'ckise', 'mnvp', 'otherwise', 'spoill', 'excite', 'sny', 'dst', 'fkb', 'mmmr', 'nnt', 'Geegee', 'singlehandely', ':ddd', 'manfight', 'creapwave', '50th', 'pig', 'elo', '0coins', 'htink', 'shoiuld', 'askd', 'esteroids', 'cas', 'kunkaa', 'iria', 'direto', 'inteligente', 'powerful', 'reconsider', 'Loll', 'spawned', 'Smart', 'botbo9t', 'three', 'fiz', 'oq', 'nucna', 'cotnra', 'hardcore', 'mans', 'overly', 'dramatic', 'sinadya', 'lke', 'fututre', 'chicks', 'ehehehe', 'hikhik', 'OIIII', 'solar', 'lieslie', 'AHAHAHAHAHHA', 'sideeee', 'nice1', 'HAYOP', 'COULDNT', 'stars', 'clocks', 'T3', 'Wejiahbekjebqkjedbqkjd', 'cat', 'houise', 'tacnies', 'crEap', '2m', '3m', 'bnut', '30m', 'beastmode', 'rise', 'wwat', 'fw', 'met', 'PERRO', 'WtF', 'terussss', 'whoa', '201', 'surte', 'rez', 'SCRIPTER', 'SPELL', 'nyo', 'slota', '39', 'minut', 'ju', 'Wasn', 'unwinnable', 'sIark', 'mainly', 'NING', 'silenser', '2005', 'Slow', 'nto', 'comemnd', 'pricks', 'kritami', 'typoe', 'sozdanie', '8D', 'AHHAHAHA', 'nAH', '=6k', 'booty', 'nm', 'Ey', 'Suicide', 's4', 'zZz', 'toplane', 'waddup', 'cpu', 'harem', 'gameplan', 'HAEHAEHAE', 'Facke', 'discoonect', 'munny', 'gangerion', 'chickenon', 'TUSKY', 'shockingly', 'NvM', 'deni', 'SADUHHSAD', 'COININ', 'ASU', 'woooooooaw', 'Mr', 'katkovich', 'hayy', 'nevertheless', 'lolololol', 'shhhh', 'Shh', 'whaaaaaaat', 'GGGGGGGGGGGGGG', 'untol', 'ibundak', 'stoy', 'hetting', 'charger', 'aSShole', 'france', 'cuppa', 'marry', 'bucther', 'alrigh', 'Yep', 'dealer', 'LEGENDARY', 'apperenty', 'doestn', 'baitttttt', 'creepo', 'yEAH', 'coutnerpickers', 'JOKER', 'noovs', 'slarke', 'skulls', 'ggwomi', 'mich', 'auch', 'meca', 'Debuff', 'loudest', 'aaaaaaaaaaaaaaaaa', 'linken', 'park', ':laugh', ':Laugh', 'AYUDEN', 'GUSTARIA', 'TOQUE', 'ESAS', 'LACRAS', 'respawned', 'RARE', 'healthbar', 'Lmfao', 'BUGOK', 'farms', 'dkajwd', 'ladja', 'okeyy', 'ecchi', 'rusty', 'bitchez', 'fa', 'tiome', 'LOLL', 'Deward', 'yu', 'medium', 'jiji', 'realistic', 'shackel', 'BAGO', 'mastered', 'WEWEWEW', 'fuckimg', 'suppoprt', 'mekans', 'LOLOLOKOL', 'licj', 'tjhanks', 'JAAJAJAJAJJA', 'kawkawkawkwakaw', 'tyes', 'nahui', 'vsem', 'poxui', 'HAHAHAHHA', 'shodnt', 'shag', 'dl', 'HGHAHAHAHAAH', 'alachi', 'mayra', 'moutch', 'Shakermon', 'dandom', 'mantaed', 'sites', 'Warded', 'CHCUA', 'ABADON', 'TIENE', 'DIVINE', 'basic', 'noobie', 'mentioned', 'asia', 'capital', 'myanmar', 'restroom', 'wlel', 'onob', 'sak', 'Zz', 'overextending', 'fuckkk', 'DIRT', 'diddnt', 'hunter', 'ahhahha', 'LOSERS', 'squad', 'vwwgg', 'boobo', 'lowara', 'manga', 'xsend', 'mele', 'puting', 'unaware', 'whiny', '::DD', 'nowwww', 'Alright', 'EASI', 'ce4rf', 'eeezzz', 'neco', 'azaza', 'sacrifish', 'doooom', 'zone', 'mnuted', 'linas', 'wehn', 'snipa', 'becouse', 'bodied', 'coiuld', 'voided', 'sif', 'holys', 'fark', 'jiahou', 'Xu', 'mnow', 'sould', 'jejemon', 'nailed', 'cybercafe', 'theirselves', '3secs', 'settings', 'travels', 'unmuted', 'breathing', 'dribble', 'SCORE', 'thunderstorms', '4lyf', 'mustve', 'daamn', 'whahah', 'hhm', 'ata', 'timers', 'MINE', '4300', 'spared', 'bruv', 'nuthing', 'SPRO', 'fuckinearth', 'abuser', 'hen', 'negro', 'bfury', 'thinker', 'aahha', 'copo', 'njeng', 'Dominator', 'BLANCED', 'tehnku', 'woierjewkhfiwepojoiwehfijwer', 'phanter', 'whingeing', 'slack', 'lego', 'nyjno', 'chtobu', 'napusal', 'crono', 'CROM', 'FELIX', 'SECRETSHOP', 'Nvm', 'viebite', 'reportnu', 'ytolyu', 'There', 'KOTL', 'LOLK', 'kala', 'moha', 'THrow', 'penalty', 'decision', 'Extend', '4:10', 'complaning', 'HUskar', 'shinken', 'hakyouken', 'ehehehehee', 'mev', 'GAGLHWSLHW', 'HSLDHLWHWL', 'LHAWLGAL', 'AHAHGAH', '100HP', 'ULTY', 'SELL', 'muslim', 'poisin', 'pulled', '000000000000000', 'SPASIBO', 'chaserr', 'jALO', 'PISSING', 'PROMISE', 'CHANCES', 'bootcamp', '400ms', 'updates', 'fukn', 'CDEC', 'AGRESSIF', 'mestik', 'schoolboy', 'nickname', 'pohui', 'lomaite', 'Cse', 'stoyat', 'commemd', 'radik', 'dieddddd', 'baneeee', 'aliev', 'dumbcunt', 'Wahahhah', 'finis', 'hahahhahaa', 'maleware', 'thos', 'creatyre', 'nina', 'OWNITTT', 'j00ked', 'aiiiii', 'waaat', 'OFCI', 'weeb', 'geh', 'clinks', 'Ensd', 'nicee', '9999k', 'COMPARED', 'GRP', 'vajayjay', 'counterpicker', '1:23', 'okok', 'weeks', 'NAMIN', 'lele', 'COOOOOOOMEEEEND', 'aabut', 'vs1', 'WHYYYYYYYYYY', 'winte', 'fuckker', 'wrecked', 'passsion', 'website', 'slayers', 'finnaly', 'slarda', 'kycha', 'soboy', 'nosyat', 'require', 'relly', 'recomenden', 'mrdas', 'oO', 'GabeN', 'FAIR', 'part', 'btmm', 'null', 'cYKA', 'RUSSIAN', 'meld', 'foook', 'winrun', 'whom', '4500', 'ggpw', 'lichg', 'BTW', 'DISRUP', 'jungla', ':PP', 'howlonghave', 'terribles', 'pugde', 'maiy', 'phor', 'feggots', 'boludo', 'siente', 'gordito', 'pavo', 'HOOKS', ':DDDDDDDDDDDDDD', 'defance', 'td', 'RNG', 'kawawa', 'PRIORITY', 'dicks', 'mc', 'tusklar', 'lghf', 'lg', 'idonjt', 'canadians', 'dallae', 'Que', 'manyu', 'ddosser', 'dammit', 'rubrick', 'clear', 'charges', 'rubik', '5vs1', 'desable', 'pepe', 'AUTISM', '530', 'guesss', 'DUE', 'recfraction', 'stoP', 'madda', 'ogld', 'Gorrila', 'Dunk', 'ABBADONG', 'frankfurt', 'tricked', 'ganker', 'dunwan', 'sAD', 'Internet', 'xaxaxaxaxaxaxaxaxa', 'NIGGER', 'wadhawdujaw', 'bitach', 'WISP', 'licky', 'paus', 'akoy', 'GoD', 'Hahahahaha', 'deef', 'merica', '025', 'huesos', 'whyyyy', 'defeding', 'trk1j325rj123', 'AHAHHAA', 'Greedy', 'goof', 'Tide', 'agro', 'related', 'clown', 'mrrS', 'SCHOOLBOY', 'AAAHA', 'oooooooooooh', 'fuckiong', 'wahha', 'YOURE', 'urSA', 'SSS', 'mcdo', 'demand', 'mmy', 'squishy', 'sayo', 'gangbang', 'yoruself', 'produ', 'siraptor', 'MERCY', 'swing', 'air', 'hahaqha', 'NAPS', 'noise', 'damned', 'hhhhhhhhhhhhh', 'HIHI', 'amke', 'radi', 'ahahahh', 'AHAAHAHA', 'anough', 'kapa', 'sanking', 'caarry', 'perma', 'exort', 'pusyy', 'PUSSSSSYSYYYSYSYSYSYS', 'saki', 'bluff', 'fappy', 'tuesdays', 'higher', 'solos', 'annoy', 'RING', 'BASILUSS', 'USEFULL', '30seconds', 'usual', 'nica', 'woden', 'agaisnt', 'thuis', 'mummy', 'rubs', 'fortnight', 'kys', 'listening', 'comparing', 'DEBILI', 'ALEE', 'sosi', 'ze', 'vip', 'FOLLOWING', 'rainfall', 'tyrazor', 'bashed', 'sassy', 'nbever', 'stomped', 'poreso', 'unity', 'media', 'chronio', 'seriouslyt', 'SERIOUSLY', 'KYS', 'jgn', 'asik', 'anjign', 'grills', 'CENA', 'FALLEN', 'stall', 'dochu', 'fuckingg', 'ahv', 'etime', 'jacking', 'offfffff', 'Meow', 'AHAHH', 'BLUE', 'salisi', 'claims', 'closed', 'mere', 'greedisgood', 'Godot', 'aussie', 'Relt', 'boty', 'ORO', 'OMGGGGG', 'spooked', 'itde', 'soryr', '210', 'zoos', 'pausr', 'gntie', 'dank', 'dmge', 'BOBBY', 'BRACKINS', 'realx', '=W', 'slacko', 'commende', '=DD', 'pegde', 'pudgr', 'repoprt', 'Didn', 'Despite', 'perhapse', 'hsould', 'relt', 'motherf', 'PE', 'aquilla', 'CUNTKA', 'oxigeno', 'cerebro', 'porfavor', 'mnore', 'rto', 'directly', 'ir', 'reporn', 'PLIZ', 'sence', 'englioh', 'Rng', '4et', 'narutard', 'pool', 'MOOD', 'plaued', 'phantom', 'Shitstain', 'suitable', 'WADDUP', 'worsth', 'rtd', 'BAIT', 'HELLo', 'FROm', 'OTHER', '2hits', 'coordinator', 'JUKED', 'min3', 'bings', 'talino', 'jeniffer', 'lawrence', 'kissing', 'natalie', 'dormer', 'rager', 'SHIITS', 'Washington', 'proccesor', 'sakit', 'hati', 'TI5', 'blachhole', 'ALchEMist', 'reserve', 'jogaram', 'bem', 'setting', 'PNoy', 'amf', 'MURTAZAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA', 'professional', 'ahaahahahha', 'hahahhahahahhahahahhahaha', 'oy', 'katoska', 'hanging', 'SATAN', 'SITTING', 'TREEE', 'SHADES', 'GREY', 'Wooden', 'hacked', 'Laptop', 'owww', 'rarely', 'sharp', 'sakita', 'premade', 'gEASY', 'DAYN', 'difficuklt', 'xDDDD', 'mudda', 'labert', 'oky', 'coomend', 'UTMOST', 'CERTAINTY', 'arrogant', 'section', 'Secret', 'DDDDDD', 'barbie', 'OOO', 'ere', 'wewt', 'BG', 'firsts', 'assistrs', 'NATURE', 'especialy', 'USLES', 'Skype', 'Wont', 'HUGE', 'ec', 'neo', 'wanto', 'afasihon', 'vs5', 'Right', 'donp', 'giting', 'AJJAJAJA', 'Potuition', 'TOT', 'peeeeeee', 'peeeeeeeeeeeeeeeeeeeeee', 'rikki', 'pnoy', 'ALOWED', 'cocksuck', 'serv', 'jUGG', 'THO', 'usky', 'asks', 'bbopes', 'NOBOS', '833', 'sheck', 'SUPPLIES', 'huesosi', 'BRAINED', 'IMPACT', 'nooobs', 'period', 'TANGINA', 'Stack', 'HOUES', 'badddddddddddddddddddd', 'obsessed', 'NYA', 'NAKAAAAL', 'cCntt', 'KAMAZEEEE', 'itmorning', 'streamers', 'pogChamp', 'g3g3', 'phub', 'sounded', 'helkl', 'beack', 'counts', 'Gottes', 'willen', 'pols', 'Best', 'mangs', 'cumbacket', 'XAXAXAX', 'gahahfa', 'WORK', 'OFFLANE', 'freakin', 'hahhhahahhahah', 'blocked', 'acting', 'shjit', 'WOWOW', 'REMNANT', '2months', 'asdkljasdjklasdasd', 'DRAGON', 'KNGHT', 'PLLEASE', 'dota2smut', 'dd', 'voids', 'firs', 'gyri', 'mkm', 'final', 'nanashi', 'pablo', 'didjnt', 'intresting', 'moon', 'shard', 'dada', '<<', 'uni', 'Reconnet', 'grapic', '90', 'uis', 'cask', 'fing', 'suprise', 'BETRAYED', 'Stamos', 'evberywhere', 'clutch', 'pourri', 'club', 'JUG', 'ceci', 'tout', 'fait', 'dingue', 'POWERBALL', 'MIL', 'okay2', 'imagination', 'EUL', 'tng', 'queueing', 'requested', 'Value', 'ucnt', 'pop', 'aHAhahhAAHHA', 'epwoer', 'woohooooo', 'usually', 'thzis', 'YeSSSSSSSSSSSSSS', 'WFEPI', 'J', 'WPIJWPEIFG', 'qfhqiuhfouqehfoqwf', 'OUY', 'FGSIEF', 'jerw', 'ohfoui', 'hfoqho', 'OUFHEOUIHG', 'Wk', 'nthing', 'suki', '198', '3000', 'pinOY', 'bullied', 'ANOTHER', 'LOSING', 'VALVE', 'GABEN', 'DEEP', 'DELET', 'thta', 'barelya', 'matrix', 'vovlo', 'recons', 'plausible', 'HAVENT', 'Players', 'RUNING', 'uselses', 'Brother', 'bain', 'hmmmmmmmmmmmmmmm', 'TREDE', 'congratulations', 'rtop', 'NUKEPERU', 'relocate', 'hoes', 'mueren', 'theese', '3times', 'oui', 'vueki', 'abddon', 'MINUTE', 'burden', 'Commdnd', 'CALLATE', 'MRD', 'oso', 'ORLF', 'TMOHER', 'BUYERS', 'spiral', 'WPP', 'lile', 'ezi', 'katkas', 'ahahasha', 'defing', 'biscuit', 'vse', 'poocheredi', 'sam', 'dickriding', 'Idk', 'CAn', 'PISTE', 'frm', 'haahha', 'asmruf', 'CREATED', 'NI4EGO', 'PIWI', 'vacuume', 'AHAAHAHAHAH', 'Cunty', 'annoyance', 'OLOL', 'ougna', 'Ruh', 'roh', ':DDDDDDD', 'gun', 'Whthapnd', 'HIIII', 'qoq', 'Scare', 'lycane', 'Ward', 'kos', 'madara', 'SERINITY', 'pilde', 'raka', 'geez', 'pleb', 'LUSER', 'senk', 'snaiper', 'OT', 'MENYA', 'posla', '2gud', 'mobkey', 'HOME', 'COUNTRY', 'ROAD', 'RAZE', 'shite', 'ekkk', 'moonwalk', 'rustards', 'Asad', 'WERK', 'GOES', 'willing', 'sop', 'playign', 'anal', 'BLADEMAIL', 'hu', 'sickened', 'builds', 'randomer', 'messed', 'golems', 'dop', 'mini', 'misplayed', '21mins', 'nagbayag', 'mabisinakun', 'lancau', 'upon', 'dawn', 'owning', 'apes', 'sack', 'FRIENDS', 'oen', 'thas', 'TEAMM8', 'seexy', 'exprinece', 'betcha', 'moce', 'kukita', 'GOOOD', 'instagram', 'looooollll', 'idiotly', 'swin', ':=', 'clok', 'CAPS', 'LOCK', '4HEAD', 'lalalal', 'heeeeeeeeeeeeeeeee', 'HAHAHHAAH', 'AGHAHAHHAHA', 'spokesman', 'reci', 'Antifun', 'unfortunate', 'MMore', 'haaa', 'TAEM', 'IOS', 'SHTI', 'withj', 'tuiny', 'rpeott', 'ANAL', 'ditched', '8th', 'tomb', 'losting', 'HITTER', 'WEAK', 'WHAHAHHA', 'willw', 'ait', 'aura', 'bited', 'hahahahahahah', 'iq', 'morphg', 'fattttttttttttttttttttttttttttttt', 'initiating', 'wallhacks', 'Solo', 'ISI', 'Everyone', 'dooes', 'knowing', 'smurfs', 'TWF', 'polease', 'amchong', 'TANCHEEYUAN', '0162282307', 'fuckinng', 'russiinn', 'JUGGN', 'wuith', 'eagis', 'sone', 'hetp', 'ahwh', 'sthe', 'satisfaction', 'csing', 'ikkeh', 'yie', 'supported', 'pota', 'rmemeber', 'wewo', 'boohoo', 'ahiuhi', 'randomn', 'ey', 'somtiems', 'necrolyte', 'cookie', 'crumbles', 'cheaper', 'RANK', 'COmend', 'juas', 'HEATHENS', 'church', 'AKBAAAR', 'ctm', 'ex', 'TAKOE', 'REPORTADO', '12k', 'gunggong', 'foul', 'belond', 'Gahaha', 'ahhahahaha', 'invite', '65', 'WRECK', 'dogged', 'SAVE', 'Mineski', 'tides', 'cough', 'ctr', 'kited', 'rjyxtyfz', 'idfkm', 'nunal', 'fend', 'walao', 'misclickded', 'wc3', 'yxcv', 'Waht', 'shakle', 'Ctrl', 'YEa', 'Doesnt', 'AJAJAJAJAHAHAHAH', 'HSJJAHAHA', 'DCs', 'gna', 'hrs', 'COMEeeeee', 'mexicans', 'Atleast', 'nol', 'brat', 'su4ok', 'wrng', 'heeh', 'RAge', 'gfamer', 'Blade', 'xDDDDDDDDDDDDDDDDDD', 'inchoker', 'Blood', 'FA', 'KAMEN', 'paty', 'diversion', 'suckoff', 'dadadada', 'jahjahahajajaja', 'enchantress', 'DANCE', 'aganimas', 'rebooted', 'modafuka', 'howd', 'WOOHOO', 'solid', 'imprisonment', 'kser', 'hoi', 'original', 'VBS', 'teamed', 'math', 'hgahaha', 'ISIS', 'Funny', 'Tag', 'mike', 'kuma', 'FOOD', 'suchj', 'angle', 'DIS', 'soooooooo', 'disable', 'Sange', '7min', 'villain', 'commonwealth', 'raz', 'papanya', 'TRAXEX', 'BRUHHH', 'nag', 'ug', 'mightve', 'ohk', 'honour', 'wowowo', 'sh', 'rektkatka', '5kego', 'building', 'melt', 'enyway', 'FISURE', 'BLYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAT', 'tidner', 'farmou', 'inicio', 'kepp', 'norm', 'CENAAAAAAAAAAAAA', ';:D', 'doens', 'kidn', 'feeeder', '900gold', 'Realy', 'current', 'jks', 'MAKING', 'BHS', 'maxine', 'sall', 'hair', 'razing', 'proof', 'BibleThump', 'wkdopqwkdqwp', 'lvl4', '4chan', 'kidz', 'wife', 'rotated', 'opponents', 'pup', 'FIIIGHT', 'TPS', 'magn', 'asshoels', 'depot', 'calla', 'morf', 'ww3w', 'handedly', 'keping', 'realist', 'FRAPS', 'guesxzs', 'fuckload', 'whY', 'plsz', 'hush', 'faithless', 'ngiga', 'FICKING', 'shoutout', 'fegs', 'PUTA', 'negros', 'Smurfs', 'ceasepool', 'muting', 'Dynasty', 'amigos', 'Zzzzz', 'puases', ':^', 'stronmg', 'Fk', 'Does', 'tranqs', 'ahahhaah', 'wevaer', 'grrr', 'gotya', '37', 'slots', '1584', 'axaxa', 'dawg', 'hahahahahahahahahahahahahahahhahahahahaha', 'LUKCY', 'allov', 'thissf', 'iwasnt', 'ajajajajaja', '87mb', 'pack', 'hahaiz', 'humor', 'SaY', 'isreal', 'investing', 'sing', 'national', 'anthem', '30am', 'nneed', 'instaloss', 'kunkha', 'sleepZZZ', 'WOOOHOO', 'WINNING', 'suspen', 'damaged', 'chimp', '3kForLife', 'SG', 'haveen', 'mopl', 'geeett', 'reeeeekt', 'macropyre', 'Boom', 'masturbation', 'Shitpoo', 'ezs', 'shitface', 'ggggggggggggggggg', 'ggggggg', 'EZWP', 'EEZ', 'Ezeist', 'cM', 'Ezzzzzzzzzz', 'OMNI', 'mmrhunter', 'OMW', 'CHEN', 'kunkkaaaa', 'fff', 'faggerts', 'DDDD', 'AAAAAAAAAAAAAAA', 'hELP', 'Support', 'ALcheMist', 'Down', 'OFFLANER', 'rikik', 'STUPIUD', 'AGGRESSIVE', 'P0ta', 'slardasr', 'Kotl', 'Theres', 'gayteam', 'TOWER', 'EZSZZ', 'peruano', 'cochino', 'Wd', 'peruANOS', 'inutiles', 'YOURSELF', 'eez', 'RIky', 'niggaz', 'Shitty', 'Chill', 'HOES', 'EZZZZZZZZZZ', 'Fcuk', 'Dp', 'Bh', 'PTM', 'lanaya', 'CUMMING', 'alchem', 'COMN', 'CENT', 'Other', 'sluts', 'MOFO', 'juking', 'BUD', 'guysss', 'FOKKKEEEN', 'LOOOST', 'yaeh', 'juggernaut', 'trashcan', 'jeez', 'rroamer', 'METAAAAAAAAAAAAAAAAAAAAAAAA', 'BD', 'insted', 'NEGGER', 'SUch', 'lifer', 'Everything', 'bratans', 'guyzzzz', 'LITTLE', 'HIGHLIGHTS', 'MEKA', 'roshans', 'CS', 'MIDA', 'ROT', 'EBAL', 'SALO', 'ZAGLOD', 'EBANYYT', 'embers', 'slash', 'gqame', 'peruanos', 'dejen', 'servidor', 'illus', 'Welcome', 'Pinoy', 'plentiful', 'plurals', 'motomu', 'stupiud', 'hybrid', 'lothars', 'ROW', 'RUNS', 'WEN', 'YUOR', 'NUDE', 'pouncy', 'bested', 'epenis', 'fagets', 'FUCKEN', 'goi', 'WTG', 'aeghis', 'rube', 'MMr', 'ZUERS', 'mirna', 'Sexyyyyy', 'fancy', 'DENYYYYYYYYYYYY', 'sds', 'LIOn', 'PIT', 'jiungling', 'potms', 'cumwaste', 'disposal', 'abortion', 'clinic', 'SAW', 'meks', 'obs', 'crep', 'rylai', 'feelling', '527', 'INVOKE', '56min', 'sperm', 'Logic', 'sen', 'invkr', 'niggu', 'tenemos', 'livewwr', 'asscrack', 'lif', 'addtime', 'JAJAJAJAJAA', 'REZZZZZZZZZZZZZZZZZZZZZZZZZZZZ', 'JAJAJAA', 'skillshot', 'slards', 'bitcheeees', 'lelelelelel', 'kunnkka', 'junle', 'gankin', 'lou', 'botle', 'din', '11PM', 'Tell', 'PAUSES', 'secured', 'bieliebers', 'unite', 'slarky', 'musor', 'gggame', 'anyting', 'feeden', 'Earthshaker', 'shaked', 'beneath', 'MAIDEN', 'WAR', 'DEWARD', 'Terrorblade', 'abyss', 'OMGGGGGGGGGGGG', 'wtffff', 'happenign', 'madafucka', 'Focus', 'retardedw', 'EFFECT', 'CHEAT', 'hitbox', 'duration', 'blademaiol', 'everyting', '419', 'LESHRACK', 'oohh', 'rael', 'buyabakc', 'radidance', 'Death', 'XDLMfao', 'burrow', 'DAVAI', 'RUSKI', 'thc', 'noobies', 'sis', 'HAHAHAHAHAH', 'wz', 'OMMNI', 'Miss', 'GOOK', 'Idiots', 'fvking', 'begi', 'YASHA', 'DEON', 'FUCKNIG', 'blasts', 'Cocks', 'lIXO', 'FISSURE', 'THY', 'masakit', 'CRIT', 'creeep', 'damge', 'PICKD', 'Motherfuckers', 'picka', 'silncver', 'fuc', 'fuuck', 'agans', 'Account', 'kiting', 'STAHP', 'COURIERS', 'pickings', 'mams', 'spaghetti', 'slus', 'ave', 'sget', 'Void', 'backtracks', '4x5', 'maledict', 'TELLS', 'TALES', 'benla', 'tira', 'six', 'Illuminati', '1110', 'HAHAHAHAHAHAHA', 'HANDLE', 'nOOB', 'SNIPE', 'THEE', 'recall', 'slrk', 'fml', 'burrito', 'shitbag', 'ALGUIEN', 'PARA', 'USTEDES', 'TAMBIEN', 'ENTIENDAME', 'OTHERS', 'dieofcancer', 'hahahahh', 'wHY', 'fuckme', 'l0l', 'REALITY']\n",
            "--------------------------------------------------------------------------------\n",
            "num tags: 9\n",
            "{'<START>': 0, '<STOP>': 1, 'O': 2, 'T': 3, 'P': 4, 'SEPA': 5, 'S': 6, 'D': 7, 'C': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "pos_to_ix = {}\n",
        "for sentence in train_pos+val_pos+test_pos:\n",
        "    for pos in sentence:\n",
        "        if pos not in pos_to_ix:\n",
        "            pos_to_ix[pos] = len(pos_to_ix)\n",
        "\n",
        "pos_embedding = np.eye(len(list(pos_to_ix.values())))\n",
        "\n",
        "dep_to_ix = {}\n",
        "for sentence in train_dep+val_dep+test_dep:\n",
        "    for dep in sentence:\n",
        "        if dep not in dep_to_ix:\n",
        "            dep_to_ix[dep] = len(dep_to_ix)\n",
        "\n",
        "dep_embedding = np.eye(len(list(dep_to_ix.values())))\n",
        "\n",
        "ent_to_ix = {}\n",
        "for sentence in train_ent+val_ent+test_ent:\n",
        "    for ent in sentence:\n",
        "        if ent not in ent_to_ix:\n",
        "            ent_to_ix[ent] = len(ent_to_ix)\n",
        "\n",
        "ent_embedding = np.eye(len(list(ent_to_ix.values())))"
      ],
      "metadata": {
        "id": "KVZnYnvTTool"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_embedding)\n",
        "print(pos_to_ix)\n",
        "print(len(pos_embedding))\n",
        "print(len(pos_to_ix))"
      ],
      "metadata": {
        "id": "bLug2w5_URh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaa25b6-bc11-4244-e829-4a03543b9285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "{'UH': 0, 'NNP': 1, 'PRP': 2, 'NN': 3, 'XX': 4, 'VBP': 5, 'IN': 6, 'CD': 7, 'VB': 8, 'PRP$': 9, 'NNS': 10, 'RB': 11, 'JJ': 12, 'DT': 13, 'VBZ': 14, 'VBG': 15, 'TO': 16, 'RP': 17, '.': 18, 'VBD': 19, 'MD': 20, 'JJR': 21, 'CC': 22, 'WDT': 23, 'JJS': 24, 'VBN': 25, 'WP': 26, 'NFP': 27, 'RBR': 28, 'WRB': 29, 'LS': 30, ':': 31, 'PDT': 32, 'NNPS': 33, 'FW': 34, 'SYM': 35, 'ADD': 36, '-RRB-': 37, '``': 38, 'EX': 39, 'POS': 40, 'RBS': 41, 'WP$': 42, ',': 43, '-LRB-': 44, 'AFX': 45, 'HYPH': 46, \"''\": 47}\n",
            "48\n",
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dep_embedding)\n",
        "print(dep_to_ix)\n",
        "print(len(dep_embedding))\n",
        "print(len(dep_to_ix))"
      ],
      "metadata": {
        "id": "d9OSoO2YUart",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ee9303-851e-4924-e89e-12c7e4045cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "{'ROOT': 0, 'compound': 1, 'nsubj': 2, 'punct': 3, 'ccomp': 4, 'prep': 5, 'nummod': 6, 'pobj': 7, 'intj': 8, 'dep': 9, 'poss': 10, 'advmod': 11, 'dobj': 12, 'det': 13, 'acomp': 14, 'aux': 15, 'neg': 16, 'npadvmod': 17, 'parataxis': 18, 'xcomp': 19, 'mark': 20, 'amod': 21, 'cc': 22, 'dative': 23, 'nmod': 24, 'conj': 25, 'relcl': 26, 'appos': 27, 'attr': 28, 'nsubjpass': 29, 'auxpass': 30, 'quantmod': 31, 'prt': 32, 'advcl': 33, 'acl': 34, 'pcomp': 35, 'agent': 36, 'meta': 37, 'csubj': 38, 'expl': 39, 'predet': 40, 'csubjpass': 41, 'case': 42, 'preconj': 43, 'oprd': 44}\n",
            "45\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ent_embedding)\n",
        "print(ent_to_ix)\n",
        "print(len(ent_embedding))\n",
        "print(len(ent_to_ix))"
      ],
      "metadata": {
        "id": "_uAwnoqjUwam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715ff6a6-f9c9-40ff-a5a8-feb854a3f110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "{'': 0, 'ORG': 1, 'CARDINAL': 2, 'PERSON': 3, 'GPE': 4, 'NORP': 5, 'TIME': 6, 'DATE': 7, 'ORDINAL': 8, 'QUANTITY': 9, 'FAC': 10, 'PRODUCT': 11, 'LANGUAGE': 12, 'WORK_OF_ART': 13, 'PERCENT': 14, 'MONEY': 15, 'LOC': 16, 'EVENT': 17, 'LAW': 18}\n",
            "19\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_index(data, to_ix):\n",
        "  if (to_ix != ent_to_ix and to_ix != dep_to_ix and to_ix != pos_to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent.split()])\n",
        "    return input_index_list\n",
        "  else:\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(x_train,word_to_ix)\n",
        "train_output_index = to_index(y_train,tag_to_ix)\n",
        "train_ent_index =  to_index(train_ent,ent_to_ix)\n",
        "train_dep_index = to_index(train_dep,dep_to_ix)\n",
        "train_pos_index =  to_index(train_pos,pos_to_ix)\n",
        "\n",
        "val_input_index = to_index(x_val,word_to_ix)\n",
        "val_output_index = to_index(y_val,tag_to_ix)\n",
        "val_ent_index =  to_index(val_ent,ent_to_ix)\n",
        "val_dep_index = to_index(val_dep,dep_to_ix)\n",
        "val_pos_index =  to_index(val_pos,pos_to_ix)\n",
        "\n",
        "test_input_index = to_index(x_test,word_to_ix)\n",
        "test_ent_index =  to_index(test_ent,ent_to_ix)\n",
        "test_dep_index = to_index(test_dep,dep_to_ix)\n",
        "test_pos_index =  to_index(test_pos,pos_to_ix)"
      ],
      "metadata": {
        "id": "9t9x0jHEbxh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_input_index)\n",
        "print(val_output_index)\n",
        "print(val_ent_index)\n",
        "print(len(val_input_index))\n",
        "print(len(val_output_index))\n",
        "print(len(val_ent_index))"
      ],
      "metadata": {
        "id": "SUEk_Ym0dUKr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786ab9e5-c139-4732-82b4-a632fba59ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[215], [14], [215, 7, 123, 376, 49], [7884], [446], [470, 5, 105], [386, 104, 132, 4437], [427], [677, 1319, 7, 754], [11498, 42, 7, 15, 1377, 19], [245], [160, 4369, 2537, 1052, 1315, 2018], [5, 148, 224, 2151, 472, 5, 454, 3717, 49], [617, 2409, 11499], [58], [62, 91], [62], [2153, 386, 352, 177, 1763], [944], [581], [368, 11500], [1449, 11501, 127, 825, 7, 4408, 407, 62], [0, 372, 7, 417, 263, 186, 104, 228, 72, 1061, 44], [3867, 7, 20], [17, 3744], [1857, 2551], [3580, 953, 326, 45, 11502], [11503, 1470], [62], [17, 242], [104, 386, 88, 1016, 303, 928], [19, 15, 782], [220, 270], [51, 319, 160], [3911, 4919, 11504, 11505, 821, 5673], [2829, 386, 27, 8225, 68, 44, 7, 99, 2154, 78, 68, 446], [102, 96, 37, 49], [474], [245, 7, 217, 7, 1980, 11506], [794, 7, 11507], [58], [16, 17, 39, 859], [11508, 425], [20], [715], [90, 66, 2373, 246, 8673], [245, 7, 56, 159, 7, 88, 3642, 7, 20, 3063, 7, 323, 1028, 7, 2526, 7, 11509, 3063, 741, 103, 7, 56, 11510], [849], [64, 732], [215, 59, 7, 603, 7, 1106, 11511, 7, 11512, 7, 10, 7, 797, 7, 145, 2944, 947, 7, 4829, 592, 2181, 7, 10], [467, 239, 11513], [2014, 7, 1723, 549, 7, 2014, 7, 4748, 4748], [104, 94, 349, 823, 7, 1039], [11514, 39, 287, 956, 125, 359, 205, 3976], [181, 361], [102], [3100, 1028, 870], [19, 5, 11515, 177, 7, 524, 27, 754, 160, 11516, 65, 7, 1370], [14], [655, 89, 27, 95, 1573, 1039], [11517], [660], [97, 743, 7, 93, 640, 11518, 44, 72, 11519, 1847], [788], [11520, 51, 1063, 27, 72, 5244, 1847, 264, 11231], [1992], [15, 1377, 7, 19, 1410, 7, 472, 18, 7, 95, 62], [69, 279, 39, 7067, 185, 72, 179], [366, 1628], [11521, 11522], [420, 160, 17], [0], [1210], [727, 104, 269, 2044, 2045, 7, 5, 148, 105, 7, 417, 104, 386, 132, 2151, 1661, 1686, 7, 898, 150, 1531, 726, 231, 7, 1639, 104, 45, 454, 72, 925, 502], [11523], [50], [52, 40, 7, 104, 925, 270, 21, 7, 788, 7, 2096, 7, 64, 7, 16, 2119, 242, 104], [120, 7, 472, 299, 264, 277, 619, 11524, 637], [14], [366, 773, 7, 634], [62], [5742, 44, 11525, 7, 472, 1471, 7, 41], [3026, 7, 155], [315, 719, 7, 26], [718, 7, 1927, 7, 884], [581, 205, 485], [11526], [414], [202, 11527], [2944, 17, 39, 1361, 111, 1463], [11528, 974, 1475], [192, 44, 437, 160, 49, 1253], [474], [795], [977], [11529], [1346], [1011, 72, 2635, 88, 263, 3170], [14, 1034], [120], [123, 205, 17, 81], [15, 732], [78, 299], [517, 363, 51, 3864, 361, 7, 2714], [420], [41], [6730, 7, 90, 2336, 11018, 145, 2944, 947, 7, 215], [14], [3], [663, 99, 27, 319, 473, 235], [1010, 115, 134, 14], [14], [56, 7, 663], [51, 39, 4177, 7, 45, 489, 355, 7, 427], [15, 21, 7, 102], [1540], [15, 42], [1857, 44], [3432, 7, 2154, 2489, 609, 7, 88, 1661], [719, 39, 160, 49], [11530], [88, 4708], [1548, 7, 1, 7, 4907, 1358, 7, 776, 310, 3796, 131], [245], [41], [166, 4902], [11531], [1411, 111, 37, 2545], [431, 410, 17, 1665], [417, 106, 27, 152, 9, 10, 2090, 68, 69, 17, 7, 7, 306, 2151, 78], [39, 472, 722, 1967, 11532, 749, 1289], [439, 17, 3024, 64, 7, 166, 272, 109, 928, 39, 18, 7, 62, 7, 252, 7, 11533, 7, 1714], [420], [1558, 1475], [370], [366, 428, 2568], [863, 125], [259, 7, 4313, 1990], [102, 96, 87, 7, 11534], [636, 4, 7, 513, 386, 27, 68, 16, 4590], [26], [634], [1022, 622, 107, 78, 521, 7, 104, 105, 417, 93, 386], [123, 2694], [27, 319, 467], [1282], [3418, 3236, 7, 1660, 7, 11535, 11536], [14], [259, 3985, 7, 5598, 11537], [977], [5, 1987, 284], [123, 8930], [901, 1659], [4, 51, 11538, 463], [88, 719, 386, 27, 1650, 11539], [11540], [850, 952], [4706], [8327, 21], [1215], [215], [521, 21, 15, 365], [2454, 5, 306, 5, 185, 72, 4717, 1326], [1588, 7193], [20, 1486], [69, 52, 230, 11541, 7, 11542], [467, 1375, 7, 90, 94, 3267, 7, 37, 5559, 5506, 111, 7, 10850, 8965], [368, 741, 355, 49], [101, 1253], [1199], [104, 386, 1208, 347, 166, 765, 96, 317, 270, 479, 7, 5945, 524, 104, 319, 7597, 68, 489, 153, 166, 5158, 78, 971, 246, 660], [64, 341, 7, 20], [619, 472, 299, 11543], [2496], [1], [1383, 11544], [688, 7755, 2874, 7, 11545], [20], [177, 413, 11546], [493], [148, 149, 365, 7, 5, 148, 185, 1572, 7, 474], [27, 94, 349], [11547], [474], [749, 744, 7, 88, 352, 148, 1531, 7105], [859, 2576, 7, 11548], [474], [3532, 762, 7, 111, 7, 782], [5, 209, 349, 9, 1247, 21, 7, 291], [62], [55], [474], [20, 385, 49, 7, 1353, 363, 72, 8, 160, 565, 956, 264, 361, 884, 7, 11549, 104, 7, 11550], [11551, 11552, 11553, 7, 453], [370, 467, 5468, 16, 1241], [681, 366], [11554, 4, 43, 181], [470, 46, 1253, 7, 352, 386, 540, 7, 62], [20], [11555, 39, 175], [2108, 2893, 428], [706, 11556], [516, 341], [78, 39, 7, 52, 30, 10018], [372, 7, 3], [352, 185, 2169, 101, 124, 119], [5, 461, 37, 11557, 5870, 45, 96, 104, 902], [11558, 101, 11559], [185, 264, 287, 49, 949], [7825, 9818], [7714, 7, 217], [474], [811, 3184], [8567, 17, 39, 471, 88, 263, 507, 17, 2351, 39, 11560, 11561], [46], [215, 1831, 7, 20, 694, 20, 334], [11562], [937], [368, 635, 370, 859, 791], [14, 64, 17, 7, 101, 376, 72, 327, 1382], [14], [1664], [366, 44], [5, 3454, 11059, 11563], [11564, 104, 272, 106, 8, 898], [62, 11565], [437], [372, 7, 3972, 39, 45, 264, 1924, 746], [8, 9, 11566], [216], [414], [215], [10, 7693, 8960, 78], [1365], [20, 21], [1184, 771, 74, 72, 1128], [11567, 1926], [2213, 7, 11568], [1385], [1828, 7, 754, 19], [1], [11569], [62], [368, 205, 2748, 2351], [26], [370, 1961], [11570, 95], [14, 120], [155], [62], [272, 489, 15, 6954, 49, 3036], [123, 49], [11571], [369, 49], [279], [14], [1458, 149, 35, 21], [2367], [20, 7, 64, 190], [818], [245, 7, 6071, 135], [835], [179, 286, 9823], [378, 23], [474], [14, 7, 14, 6378, 7, 5, 1961, 7, 5, 46, 3046, 7, 102], [465, 49, 7, 2125], [1385, 7, 414, 52], [850, 5, 94, 2608, 1891, 7, 11572, 7035], [14, 20], [46], [1240, 5162, 7, 2944, 8037, 11573, 7, 11574, 11575, 7, 11576], [414, 27, 910, 205, 695], [11577, 2325, 392, 7, 11578, 11579, 11580, 136, 5308, 5641, 7, 1532, 27, 2489, 96, 64, 11581], [34, 11582], [44, 75], [977], [1947, 242], [26, 472], [5, 2076, 492], [1422, 21], [9, 37, 94, 111, 894, 7, 215, 894, 7, 7630, 1574, 88, 164, 7, 749, 11583, 2537], [1452], [352, 604], [11584, 7, 1342, 7, 3755, 7, 1034, 7, 11585, 7, 49], [15, 1638, 365], [2137], [11586], [245], [826, 181, 35], [410], [11587, 264, 49], [1987, 78, 326, 1018], [217], [2419], [88, 11588], [4016, 303, 7, 1041, 303], [102, 91], [3914, 104, 159, 743, 69, 2286, 268, 11589, 7, 1052, 517, 11590, 1088, 1128], [27, 185, 4664, 1381, 812, 7, 95, 8, 1837, 365], [259, 7, 259, 7, 259], [1873], [270, 49], [1723, 776, 4850], [215], [656, 334], [95, 1422], [474, 27, 88, 164, 7, 283, 37, 26, 284], [362, 609], [420, 7, 440, 1346, 743, 104, 435], [5250, 788], [719, 104, 888], [6253], [4537], [5696, 72, 186, 1052, 404, 7, 524, 52, 27, 1010], [9238, 37, 8964, 11591], [75, 11592, 64], [11593], [62], [5534, 229], [859, 109, 104, 159, 386, 11594, 88, 263, 72, 117, 44, 7, 166, 1760, 1885, 186, 1326, 109], [370, 104, 640], [58], [14], [16, 1795, 7, 9739], [1457, 30, 37, 3584], [37, 1147, 11595, 370, 222, 3203, 7, 88, 120], [1088], [1804, 564], [6767, 7, 738], [370, 69, 272, 264, 3310], [20], [288, 3544, 294, 7, 1521, 299, 62, 740], [14, 7, 262, 2135], [8747], [719, 4212], [6, 2100], [870, 152, 902], [1855], [3, 7, 368, 2940, 746, 7, 44], [702, 557], [5, 4134, 5, 1011, 264, 17], [659], [14, 120], [5216, 4095], [513, 39, 1650, 1203], [14], [163, 334, 7, 1370, 4390, 137, 11596, 5740, 135], [14], [1645], [245], [102], [0], [370, 4664, 11597, 270, 240], [14, 120], [27, 148, 185, 72, 224], [519, 860, 284, 272, 489, 361, 492], [20, 11598, 7, 9326, 7, 1028, 1789, 11599, 11600, 7, 64], [102, 166, 185, 264, 123, 1375], [3655, 386, 574, 26, 7941], [26, 186, 52, 115, 510], [14, 120, 159, 41, 102, 96, 37, 49], [977], [14, 7, 88, 164, 7, 2896, 369], [719, 719], [3210, 1708, 7, 417, 563, 472, 542, 713, 2472], [14, 7, 437, 1253], [1458, 149, 7, 859, 17], [1360], [261, 44, 51, 39, 52, 1659, 1187], [680], [817, 81, 7, 4, 568], [1152, 5279, 370, 5279, 1377], [11601], [27, 185, 370, 948, 160, 49], [14, 120, 7, 120], [11602], [102, 7, 6264], [75, 119, 7, 11603], [102], [102, 7, 11604, 7, 2060], [65, 7, 4], [20, 11605, 6106], [3], [370], [843, 49, 111, 16, 694], [528, 2859, 2731, 101, 263, 7, 975, 42], [26, 104], [2032, 11606], [62, 7, 5, 862], [11607], [362, 17, 1828, 7, 693, 7, 316, 7, 10, 7, 1966], [11606], [1661, 11608], [14], [7296], [34, 148, 8, 413], [11609, 11610, 4706], [120, 177, 17], [310, 219], [11611, 11612], [474], [417, 186, 104, 163, 210, 10, 119, 270, 181, 2484, 7, 72, 264, 163, 609], [114, 31, 96, 104, 528], [245], [99, 431, 89, 52], [58], [810], [14], [15, 160, 2045, 7, 369, 1844, 111, 26], [372, 7, 120], [11613], [1723, 1980, 505, 4851], [14, 320], [14, 120], [619, 1067, 513], [1444, 11614, 7, 14], [27, 72, 1319], [447, 19, 7, 779, 1903, 2229], [513, 39], [6, 3217], [26, 1847, 1628], [11615], [120], [215], [489, 96, 181, 52, 164], [322, 93, 105, 7, 58], [186, 27, 159, 185, 264, 11616], [11617, 2833, 1617], [102], [474], [3479, 648, 2578, 569, 7, 2352], [5, 5675, 8721, 284, 7625], [8, 489, 11618], [399, 3331], [166, 5644], [20, 21], [160, 11619, 487, 285, 166, 370, 445, 370, 1382, 166, 370, 2643], [568, 49, 7, 365, 7, 6408], [1296, 528, 160, 49, 94, 361, 2310, 11620, 7, 45, 323, 7, 1039], [1987, 44, 413, 11621, 34, 5, 306, 2151, 78], [0], [11622], [1856, 7, 90, 341, 2873, 68, 16, 1445, 7, 9, 952, 7, 88, 104, 604, 7, 717], [5438, 1548], [2202, 7, 62], [2845], [245], [7670, 489, 1783, 935, 52, 67, 3000, 467], [2798, 671], [1060], [9315, 7, 11623], [215, 120], [6407, 104, 101, 7, 64, 177], [5248, 1538, 2361], [7366], [11624, 74], [370, 7, 104, 116], [37, 38, 39, 40], [984, 984, 11625, 1815, 7, 11626], [217], [1449, 1622], [728, 925, 7, 106, 352, 95, 7, 104, 228, 42, 242, 97, 763], [120], [2292], [800], [11627], [41], [14], [453], [1039], [2601, 7, 160, 341], [11628], [56, 96, 52, 11629, 74, 341], [11630], [120, 65], [14, 90, 1560], [123, 1411, 41], [95, 46, 7, 5, 94, 242, 6698, 7, 35, 7, 330, 7, 330, 35], [107, 264, 7, 1333, 5329], [892, 7, 20, 103], [7], [738, 7, 11631], [164, 6581], [14], [13], [310, 6791, 215, 1085, 4546, 11632], [14], [14, 4170], [27, 1661], [5698, 7, 2844, 1544], [1405, 7, 892, 186, 27, 11633], [1853, 11634], [1333], [65], [988, 11635, 7, 1719, 3506], [333, 1123], [120], [4], [58], [123, 220], [91], [11636], [160, 159], [1016, 410], [11637, 7, 179, 4606], [11638], [14, 7, 15, 160, 334], [2608, 370, 3177, 72, 37, 4596], [114, 6835], [6158], [58], [232, 7, 5, 440, 9702], [215], [497, 1669, 88, 263, 3044, 7, 5, 1568, 407, 111, 37, 2129, 11639, 7, 1791, 270, 160, 49, 7, 2731], [489, 97, 355, 660], [460, 235], [3690, 8856, 11640, 11641, 3553, 11642], [884, 7, 1], [291], [453, 7, 1, 7, 1125, 3796, 672, 4316, 7, 798, 3514], [11643], [64, 7, 656, 365, 7, 14], [14, 120, 7, 64, 244], [20, 152], [62], [794, 205, 1077, 1074, 78], [715], [11644, 39, 37, 3482, 72, 694], [493, 103], [10106], [513, 4263, 44], [638, 472], [11645, 1572], [27, 159, 106, 46, 21, 7, 102], [382, 1147, 7, 639, 7, 431, 1385, 152], [90, 372, 942, 743, 262, 11646, 1538], [3], [44, 166, 37, 361, 266, 8, 7597], [94, 630, 6080, 96, 27, 397, 91, 7, 460], [6253, 11647], [366, 2064], [62], [102, 10803, 7, 4490, 448, 7, 90, 341, 4421, 1678], [11648, 1999, 1011, 264, 49, 160, 467, 3894, 270, 264, 1721, 7, 655, 262, 68, 37, 11649, 17], [177, 15, 582], [43, 75], [6060, 11650], [14], [14], [148, 305], [382, 7, 655, 106, 5, 7310, 2047], [14], [1402, 51, 39, 1915, 1399, 3321], [723, 7, 11651, 7, 39, 1077, 445, 27, 160, 363], [11652], [1670, 5306, 4697], [4383], [89, 732, 762, 11653, 31], [412, 7, 1010, 489], [11654], [5751, 11655, 39, 819, 7, 44], [412], [341, 10, 355, 3498, 7], [715], [217, 7, 181], [14, 120], [4, 104, 148, 700, 9, 205, 7047], [45, 95], [4540, 6315, 3314, 1039, 7, 143, 505, 1370, 11656, 884], [3093, 1529, 27, 630, 37, 103], [58], [2402], [352, 2763, 1747, 264, 2429, 7, 472, 1119, 4198, 299, 418], [1315, 39, 117], [2432], [810, 30, 104, 159], [719, 264, 49], [20], [667], [95, 2681], [148, 11657], [596], [985, 985], [14, 120], [810, 30, 104, 64, 104, 11658, 186, 125, 272, 205, 17, 11659], [15, 1637], [20, 1219], [11660, 11661], [15, 341, 102], [16, 11662, 1274, 893, 2435, 6612], [8587], [123, 53, 5498], [11663], [521, 49], [177, 662], [11664, 96, 894, 4545, 7, 931], [215], [3208, 3209], [5322], [46, 322], [9427, 1010], [472, 11665], [11666, 7, 3525, 489, 7, 1370, 7, 3525, 7, 11667], [75, 761, 11668], [634, 7, 7155, 7, 1648], [7, 715, 11669, 7, 14, 7, 287, 72, 8, 1054, 7, 27, 5326, 6450], [680, 7, 1039, 7, 592, 1304], [1081, 7, 1099, 2326, 7293], [656], [492], [5664, 7, 4675], [14, 2541], [148, 6078], [341, 7630], [14], [11670], [582, 479, 1106, 582, 21], [5, 228, 101, 7, 1219, 1117, 7, 2787, 7, 437, 262, 2135], [1997], [215, 7, 15, 428], [11671, 672, 1815], [2135], [46, 1253, 2310, 64, 1273, 17], [62, 11672], [434, 363, 27, 630, 43], [20, 7, 14], [352, 519, 720, 10, 43, 407, 728, 9472, 3270], [26, 27, 277, 263], [412, 365], [365, 15, 11673], [14], [5106, 6126, 7, 163, 11674, 7, 902], [11675, 902], [2757, 78], [27, 45, 454, 72, 297, 264, 697, 166, 264, 3483], [474], [11676], [91, 2552], [3], [22], [51, 3507, 264, 1726, 96, 370, 444], [215, 7, 1369, 7, 217], [20, 9618], [148, 246, 11677, 7, 3970], [319, 6507, 6399, 643, 1321, 45, 34, 7, 695, 7, 90, 341, 7, 166, 5, 185, 264, 859, 444, 72], [46, 997, 1499, 7, 582, 728], [44, 96, 11678, 27], [14], [5, 2076, 99, 49, 268, 11679], [90, 185, 72, 1728, 1977], [1661, 565], [57, 7, 46, 7, 57, 7, 10395, 7, 46], [14], [125], [89, 11680, 210], [634], [20, 1152], [2388, 7, 2388, 49], [45, 2561, 7, 507, 21, 39, 88, 859, 7, 11681, 11682], [462, 2080, 39, 40], [41], [1804, 1805], [2915], [88, 39, 205, 994], [123, 11683], [489, 68, 489, 1034, 370, 1241], [14], [2689], [215], [4, 7, 5, 910, 568, 7, 1240], [11684, 11685, 9856, 11686], [245], [11687, 7, 11688], [417, 72, 908, 341, 1105, 7, 91], [2359, 58], [104, 431, 11689], [4966, 319, 1262, 263, 473, 607, 527], [11298, 7, 155, 7, 11690], [7280, 7, 453, 7, 1040], [52, 495, 884], [2919, 371, 7, 62], [120], [2404, 2405, 91], [568, 96, 264, 11691, 1780], [728], [5, 95, 1728, 7, 95, 1422, 7, 166, 15, 1574], [58], [3674, 363], [810, 30, 16, 11692, 10], [14], [352, 247, 439, 507, 609], [215], [245], [719], [163, 134, 3489, 7, 62], [166, 51, 431, 319, 75, 355], [675, 982], [20], [11693, 69, 88, 2121, 7, 39, 472, 264, 11693, 7], [58], [940, 216, 7, 102, 7, 50, 359, 629], [1018, 7, 901, 52, 94, 330], [57], [11694, 270, 11695], [738, 7, 1410], [14], [810, 2032, 7448], [11374, 4554, 7, 16, 2175, 9563, 749, 11696, 5051, 11697, 51, 89, 52, 630, 37, 1361, 4602], [227, 1708, 148, 1103], [120], [4894, 319, 806, 111, 264, 613, 8878, 291], [1899], [64, 677, 17], [56, 1346], [2096, 7, 11698], [743, 78, 11699], [296, 1180, 2057, 3738, 7, 64], [1010], [5912, 1770, 11700], [7, 11701, 7, 20, 49, 20, 694], [5, 148, 229, 7, 62, 7, 9921, 11702, 7, 387, 5, 66], [414, 88, 20, 7, 277, 20], [297, 11703], [10, 11704, 270, 17, 1948, 263, 7, 630, 4556, 11705], [1457], [4119], [1772, 132], [90, 319, 1172], [590, 931, 604, 20], [245, 2096, 27, 2774], [14], [62, 5866, 2973, 20, 7, 1826, 266], [2081, 163, 2082], [2621], [104, 101, 3201, 133], [1225, 239, 1573, 21], [589, 7, 239], [166, 34, 7, 2079, 4946], [11706, 4166, 3825, 3119], [705], [2151, 363, 898, 27, 210, 7, 27, 386, 88, 147], [14, 120], [91], [14], [1707], [1], [14], [96, 390], [1215, 1067, 205, 2395, 2615, 11707, 2050, 7, 1514, 37, 152, 7, 1268, 2090, 386, 1268], [788, 7, 1289, 16, 1867, 2018, 7, 205, 69, 1867, 2018, 7, 3167, 4581], [36, 70, 2007, 7, 412], [1538, 7, 11], [2395, 2973, 78, 177], [3], [11708, 10656], [568], [27, 94, 2783, 7, 474], [667], [9304, 492], [1481, 895, 11709, 7, 8090, 1029, 11710, 7, 78, 4020, 1863, 39, 490, 7, 934, 125], [7317], [14], [370, 11711, 1576, 693, 157, 157], [717], [859, 109, 5, 640, 1431], [1082], [6, 412, 96, 5460, 3646, 7, 2046, 467, 607, 467, 7, 743, 1248, 7, 163, 1965, 7, 843, 21, 111, 16, 694], [977], [655, 3353], [14, 120], [474], [46, 1253], [14], [88, 163, 1062, 7, 761, 7, 1997], [58], [7, 660, 7, 7, 50, 7, 14, 7, 2388, 49], [761, 47, 117, 44, 2977], [417, 416, 104, 677, 21], [14, 120], [262, 2526, 11712, 27], [11713, 78, 1187], [2193], [125, 262, 819, 91], [490, 1640, 246, 264, 504, 801, 37, 2927], [11714], [14], [412, 19], [1422, 7, 14, 7, 64, 1969, 507, 17], [1723, 5683, 374], [2299, 7, 776, 672, 3339, 3338], [368, 476, 4401, 2484, 6898, 431, 1399], [1383], [14], [701], [5, 319, 1016, 91], [1088, 7, 636, 7, 4438, 7, 1639, 104, 1640, 117, 1863, 1864], [14, 120], [62, 7, 2333, 91, 7, 27, 272, 454, 11715, 7, 52, 69, 87, 2127], [14], [362, 244, 1828, 7, 366, 42], [215, 7, 370, 1382, 7, 370, 11716, 7, 20, 49, 7, 52, 264, 7522, 371, 275, 1128], [11717], [123, 479, 1988], [431, 1010, 96, 264, 11718, 7, 940, 7, 1741, 471], [622, 11719, 3142, 49, 7, 3026], [46, 160, 11720, 56], [11721], [3107], [148, 149], [299, 69, 1867, 3359], [1551, 4633, 185, 6408], [453], [5, 3370, 52, 5847, 133, 104, 386, 16, 2168, 2285], [5, 148, 743, 472, 866], [722, 909, 1373, 7, 104, 464, 465, 6046], [123], [223, 11722, 7, 5, 15, 42], [95, 72, 1381, 6841, 761, 7, 761, 3499], [93, 1144, 2057, 7, 262, 11723, 177, 181, 7, 11724, 7, 352, 185, 407, 1267, 68, 8938, 17, 7, 1222, 9, 78], [370, 11725], [2877], [663, 11726, 9398], [352, 604], [1427], [5, 2088, 7, 93, 117], [91], [3947, 91], [2066, 1317, 7, 1079, 7, 282, 163, 164, 7, 11727, 177, 111, 104, 7, 1540, 34, 255, 44, 41, 7, 282, 163, 2292, 177, 111, 929], [36, 239], [88, 1661], [370, 487, 1924, 7, 1385], [2060], [26, 104, 582], [215], [5426, 2476, 7, 884], [11728], [11729, 43, 11730, 236, 1077, 152], [215], [14], [52, 352, 69, 341, 272], [41, 7, 219, 26, 1847], [136, 2328], [215, 62, 7, 262, 64, 7, 123, 464, 1054, 7, 2162, 68, 7, 2154, 4821, 1054, 7, 62], [655, 39, 51, 16, 1204], [11731, 7, 11732, 7, 11733], [14], [1723, 1678, 776, 136, 3331], [166, 16, 8129, 7, 80], [7, 513, 1828, 7, 15, 513, 19], [123, 21], [1063, 929, 489, 2545, 72, 330], [4654], [7, 931], [5, 11734, 7, 1447, 1117], [11735], [205, 68, 507, 163, 17, 104, 1640, 246, 9579, 507, 504, 7, 524, 51, 463, 1460, 49, 7, 11736], [2760, 8606], [513, 454, 264, 940, 7, 2202, 51, 862], [14, 870, 5585], [901, 164], [11737], [691, 19, 7, 45, 192, 507, 1288, 630, 407, 7, 51, 862, 51, 39, 372, 859, 956, 2744, 11065], [14], [1029], [15, 2262], [62], [11738], [1774, 17, 80, 7, 1449, 17, 4430, 80], [102], [811, 2090, 159], [14], [50, 7, 14], [368, 1203, 235, 2246], [259], [245], [619, 7, 19, 2418, 264, 11739, 72, 615, 7, 1378, 929, 7, 19, 11740, 55], [794, 64, 3310, 1541], [14, 120], [884, 7, 489, 76, 7, 1016], [14], [245, 7, 5, 314, 27, 7, 9506], [64], [187, 97], [532, 743, 771, 2243], [2296, 7, 6149], [89, 27, 9555, 11741, 7, 761, 7, 186, 27, 105, 1961, 319, 1115, 7, 70, 26, 7, 370, 1770, 126, 125], [155, 7, 3514, 7, 10078, 7, 1073, 1253, 7, 11742], [20, 2262, 7, 630, 11743], [11744, 5069], [104, 1077, 8148, 9, 256], [1365], [46, 37, 49, 365, 7, 102], [5, 106, 1532, 1074, 16, 7825], [1927, 7, 6, 1531, 220], [95, 185, 264, 1443], [102], [3121, 1106, 720], [56], [287, 49], [3366, 2174, 7, 448], [513, 463], [14, 7, 20], [6118, 7168], [5, 228, 100], [14], [581], [90, 341, 6864, 472, 1574, 39, 264, 11745], [148, 8, 413, 11746, 7, 8, 8178], [428, 235, 414, 27, 1144, 88, 8611, 795], [655, 386, 27, 765, 229, 7, 776, 1458, 7, 26, 104, 1273, 7, 26, 104, 7, 5, 4229, 69, 3642, 7, 27, 163, 64], [90, 341, 1259, 72, 8, 99, 5, 341, 1669, 264, 17, 111, 917, 812, 223, 6572, 11747, 68, 1450, 713, 11748, 111, 287], [20], [2108, 1105], [1572, 1572], [732, 7, 20, 21], [11749, 7, 366, 524, 104, 743, 91], [910, 27, 190], [9393, 1743], [8327], [62, 0], [160, 11750, 39, 2604, 80], [2322], [487, 408, 11751, 487, 3060, 7, 127, 7, 11752, 247, 7, 434, 96, 52, 1422, 7, 20, 285, 886], [11753, 7, 3350], [15, 1708, 365, 7, 3130], [794, 99, 2833, 166, 817, 88, 1268], [423, 7, 127], [5733], [1828, 291], [2359, 11754], [159, 149], [1640, 6582, 11755], [370, 6540, 7, 370, 163, 6540, 7, 99, 104, 94, 349, 37, 49, 160, 1529, 159], [91], [10189], [62], [41], [62], [1961, 39, 2079], [1588], [1039], [14], [26, 1847, 229], [364], [62], [62, 472, 299, 264, 7045], [925, 907], [160, 1783], [87, 96, 2382], [7517], [3170, 11756], [15, 341, 11757], [14], [49, 39, 465], [3, 902], [20], [14], [97, 743, 3350], [51, 11758, 44, 68, 2316, 7, 2973, 27, 159, 106, 590], [11759, 2087, 7, 46, 19], [20, 1061, 285, 9, 3033, 166, 1481, 7, 3034], [4170, 5870, 7, 7377], [51, 39, 81], [1062, 78, 7029, 859, 72, 630, 473], [1067, 7, 50], [245, 7, 1670, 947, 1995, 7, 1085, 672, 11760], [4029, 7, 242, 7, 272, 11761], [0], [20], [794, 1987, 1622], [259], [7317], [3411, 16, 3310, 91], [0], [26, 160, 510], [1815, 11762, 427], [166, 34, 264, 5458, 3024, 7, 166, 34, 264, 11763], [11764, 7, 62], [11765, 1699, 413, 75, 270, 1048], [217], [719, 3573, 5, 1650, 1128, 7, 160, 39, 88, 11766], [532], [58], [11767, 7967, 37, 49], [3500, 2296, 11768], [420, 7, 1574, 462, 2039], [892, 370, 26], [20, 8193, 7, 259, 10931], [123, 489, 7570], [11769, 75], [14], [341, 2506, 1296, 2576], [99, 11770, 372, 64], [26, 27], [3419, 7, 11771, 74], [64, 134], [1826, 7426, 2333], [925], [1342, 1369, 7, 160, 428, 7, 517, 994, 11772, 7, 361, 233], [4537, 7, 352, 2763, 96, 27, 239], [3382], [216], [453], [10733], [4675], [5, 15, 9775], [14], [160, 49], [57], [10, 43, 181, 49], [12], [524, 5, 1011, 489, 7, 5, 971, 152, 160, 11773], [884], [90, 3686, 1337, 2326], [10738, 414, 492], [104, 386, 164, 7, 270, 10720, 7, 1331, 4069, 7, 104, 106, 246, 296], [51, 10499, 72, 246, 2925], [14], [262, 81], [4939, 579, 7515, 7, 3284, 131, 4583, 11774, 2182, 7, 70, 125, 7, 15, 448, 7, 6413, 177, 1117, 166, 461, 1178, 7, 10278, 125, 7, 934, 125], [2955, 7, 253], [11775], [368, 270, 37, 544, 1599, 1629], [352, 1659, 21, 7, 412], [4], [366, 303], [2404, 2837], [3], [11776, 7, 11777, 11778], [718], [1425, 702, 131, 1775], [4807, 3572], [368, 88, 4808], [62], [262, 1763, 7, 3, 7, 262, 1763, 229], [35, 3384, 622], [414, 386, 104, 88, 5099, 303, 7, 790, 104, 45, 412, 743, 713, 2031, 677, 7, 1630, 52, 7, 186, 52, 104, 743, 720, 1626], [15], [7, 414, 341, 5, 3090], [447, 448, 7, 2199, 1166], [1524, 743, 1147, 2154, 7549, 96, 719], [45, 192, 44, 105, 524, 27, 159, 202, 5176], [1590, 166, 11779, 256], [1016, 11780, 41], [51, 39, 4177], [6569, 343, 884], [11781, 7, 268, 525], [215, 7, 215], [1106], [447], [5673, 595, 3338, 3339, 7, 46, 102], [1378, 44, 365, 7, 417, 104, 926, 42, 7, 45, 1378], [2445], [1062, 279, 565], [977], [985, 2468], [1436], [95, 7, 51, 498, 330], [62, 11782, 1241, 2576, 454, 11783, 322, 431, 52, 11013, 30, 11784], [1039, 7, 2083, 196, 52, 11785], [58], [215, 7, 3146, 845], [7917, 2875, 7, 88, 740, 11786, 27], [472, 299, 472, 740], [14, 937], [794], [5, 45, 2335, 464, 804, 49], [41], [372], [7238, 7, 817], [1120, 2998, 166, 4596], [1992], [210, 788], [215], [330, 8, 9, 44], [56], [1716, 1590], [14], [283, 37, 26, 284, 1751], [634], [64, 132, 125], [46], [15, 732, 102], [315, 438, 870, 101, 7, 125, 414, 27, 159, 11787, 160, 110, 27, 11788, 81], [442, 7, 3173, 3963], [334], [1629], [1383, 7, 5248, 181, 239, 1867, 6467, 7, 40, 1538, 49], [493, 589, 7, 58], [630, 4288], [123, 609], [62, 7, 1961, 96, 117, 44, 7, 11789], [1529, 296], [123, 5279, 7, 2175, 7, 5, 148, 2875], [414, 104, 516, 743, 264, 788, 7, 1124, 44], [14], [5, 113, 27, 10, 317, 7, 270, 264, 3749], [15, 7, 11790], [1969], [11791, 11792], [3], [370, 7, 5, 640], [4953], [738], [88, 20, 7, 20, 21, 7, 20, 694], [474, 322, 104, 1727], [179, 493], [37, 3199], [11793], [3135, 971, 246, 521, 9, 6303], [1773], [3], [1558, 849], [11794, 11795], [2083, 251], [14, 7, 163, 27], [13], [2060], [1853], [282, 186, 52, 2585, 743, 1052, 11796, 11797, 472, 4642, 51, 89, 286, 96, 749, 17], [16, 17, 39, 1716], [102], [489, 355, 365, 7, 365, 7, 57, 7, 3691], [15, 19], [660], [37, 64, 299, 205, 1147, 1856], [262, 52, 841], [7], [11798, 46, 160, 39, 369], [20, 21], [2689, 2689], [494, 7, 988, 2128, 1125], [14, 7, 1449, 7, 1775, 7, 19], [14], [14, 7, 3, 7, 14, 8980], [2125], [11799], [11800], [619, 7, 27, 454, 72, 210, 88, 7, 1215], [11801, 11802, 11803], [581, 4250, 1010], [20, 2109, 7, 369, 2108], [14], [619, 368, 52, 11804, 111, 27], [64, 17], [227, 746], [18, 413, 362, 413], [2119, 1987, 104, 11805, 404, 7, 11806, 7, 8567, 2119], [460, 7, 370, 742, 7, 368, 1754], [5, 1530, 471, 490], [123, 38], [366, 62, 7, 120, 71], [412, 105, 42, 7, 775, 571], [582, 1010, 9, 5460, 279, 11807, 7, 62], [898, 39, 189, 7, 45, 15], [57, 7, 764], [245, 7, 7, 5118, 7, 11808, 11809, 3984, 7, 11810, 7, 11811, 4383, 4732, 947, 11812, 374], [2096, 11813], [14, 7, 160, 17, 7, 370, 445], [414], [717], [11814], [453], [1664], [2601], [370], [186, 52, 306, 104, 386, 3413, 1916, 7, 45, 11815, 74], [754, 509, 96, 802, 722, 485], [56], [14, 235, 101], [1039, 7, 527, 7, 9, 370, 87, 7, 705, 798, 2352, 947, 7, 7670, 385, 39, 497], [453], [660], [296, 1180, 160, 134], [2678], [762, 21], [215, 7, 11816, 215], [7, 2892, 7, 6080, 7, 11817, 7, 4], [1365], [14, 7, 11818, 111, 1907], [892, 27, 11819, 72, 246, 9271], [26, 216, 4804, 7, 27, 27, 7, 26, 27], [901, 2529, 103, 4020, 125], [2596, 7, 8171, 11820], [2641, 125], [52, 372], [14], [26, 160, 528], [4806, 11821, 374], [120, 120], [95, 9399, 11822], [1293, 1175], [166, 37, 172, 7, 166, 1490, 177, 78, 2864, 7, 564, 223, 272, 11823, 9467, 359, 37, 2747, 39, 1361, 76], [62], [11824], [719, 264, 17], [474], [892, 27, 105, 7, 5797, 5, 862, 7, 245, 219, 7, 5, 7105, 160, 765, 72, 816], [493, 493, 3073, 7, 166, 322, 5, 185, 2310, 1241, 7, 102, 460], [245, 7, 3659, 4162], [125, 340, 27, 148, 185, 713, 6895, 928, 96, 974, 4047], [288, 3201], [245, 7, 160, 1401, 7, 11825, 1499], [62], [3041, 11826, 11827, 7, 7052, 11828, 2881, 4630], [1540, 51, 3024, 294, 270, 72, 44], [11829, 5398, 7, 420], [688, 310, 6623, 1980, 11830], [4114, 1375], [622, 39, 11831], [367, 7, 194, 4956, 7, 9, 487, 285, 7, 894], [14, 120], [14], [14, 120], [368, 264, 330, 1187], [370], [3893, 101, 859], [1128, 74, 11832], [489, 263, 343, 3203], [11833, 11834], [14], [215, 334, 7, 77, 2199, 7, 3891], [90, 310, 685, 7, 2944, 11835, 822, 11836, 579, 1723], [1829, 39, 807, 111, 11837], [524, 51, 2046, 1717, 1454, 743, 160, 7, 37, 3497, 9, 11838, 39, 3981, 1659], [91, 7, 1538, 2243, 96, 1147], [51, 299, 2899], [11839, 5290], [205, 732, 39, 1248, 740], [102, 823, 7, 96, 21], [470, 7, 27, 859, 101, 2675], [390], [3690, 7, 8361, 7, 4, 7, 4265], [3575], [1465], [7, 9170, 1319, 7, 892, 27, 10828, 11840, 44], [148, 568, 30, 6905], [123], [14], [769], [262, 1385, 11841, 1144, 714, 1180, 1134], [123], [262, 925, 111, 53], [3138, 11842], [365, 1422], [14], [2095, 524, 27, 297, 939, 7, 3668, 246, 1848], [1822, 69, 413, 627], [217, 7, 3514], [1736, 974, 7, 10704, 974], [24, 432, 1916, 88, 1490, 37, 1445, 109], [859, 72, 105], [13], [3135, 268, 544, 11843], [11844], [20], [2060], [11845, 132], [14, 7, 58], [490, 27, 95, 1422], [2359, 501, 98, 3090], [8349, 44, 448], [0, 2108], [20], [2133, 27, 104, 1953, 16, 2678, 1383, 525, 264], [1833, 7, 1549], [474], [215, 7, 2409, 947], [599, 6544, 7, 474], [264, 7, 1215, 6972, 11846, 463], [368, 859], [62], [370, 7, 91], [393], [14], [223, 299, 1650, 1294, 51, 116, 72, 11847, 16, 153, 7, 5, 299, 261, 42, 719, 72, 186, 166, 51, 299, 1650, 3719, 5890, 7, 72, 4026, 37, 49, 166, 72, 5953, 44, 1847, 7, 365, 15, 37, 10729, 64], [850], [1617, 2399, 7, 62], [719, 39, 387, 790, 294, 5050, 44, 11848], [924, 7, 2699, 299, 472, 7, 64], [11849], [102], [62, 7, 1853, 7, 11850, 1187], [76], [5, 440, 104], [14], [521], [1558, 849], [794, 5, 743], [3382, 3537], [415, 101, 300, 11851, 4187], [352, 3914, 37, 37, 11852, 363, 733, 7, 352, 630, 78, 7, 14, 7, 352, 319, 78], [630, 17, 369, 7, 11853, 7, 38, 39, 40], [2478], [148, 255, 1147], [7541, 166, 11854, 11855], [2096, 7, 1201, 1681], [5, 1386, 7, 5, 516], [62, 7, 4324, 431, 132, 291], [660, 513], [14], [215, 1346], [835, 528, 7, 835], [14, 898, 7, 5741], [20, 103, 96, 27], [412, 96, 4768, 72, 630, 4481, 7, 3381, 437, 365, 7, 14, 160, 49, 2783, 2730, 7, 223, 2476], [1004, 11856, 96, 44], [22], [1723, 4340, 3189], [90, 148, 743, 104, 132, 2151, 1326], [11857, 137, 11858, 145, 3103], [2328, 10663, 1995, 3825, 9157], [1833], [104, 319, 64, 953], [274, 52, 461, 264, 11859, 7, 492], [14], [1723, 549], [45, 192, 256, 305], [56, 741], [20], [372, 11860], [14, 120], [11861], [6453, 2406, 11862], [1242], [51, 39, 4177], [490, 39, 681, 11863], [215], [88, 300, 472, 78, 106, 246, 264, 10901, 111, 264, 2057, 7424], [88, 7, 160, 39, 11864, 7, 2900, 363], [4], [16, 5742, 7, 96, 104], [11301, 52, 69, 746, 7, 470, 247, 37, 49], [14], [11865, 7, 27, 640, 447], [14], [2686, 7, 7770], [20, 49], [51, 39, 1856, 1659, 1187, 2060, 7, 11866, 841], [4968, 35, 3325], [52, 495], [15, 10060], [14, 160, 39, 1600, 7, 1999, 7, 1216, 11867, 4559, 7, 11868, 52, 11869, 52, 3206, 713, 609, 1241, 1828, 160, 49, 7, 85, 11870, 72, 87, 2639, 713, 1124, 7, 272, 11871, 7, 264, 17, 1361, 111, 1463], [4906, 5251, 7, 2060], [2333, 7, 3530], [11872], [215], [11873, 7, 11874], [69, 75, 6378, 1241, 39, 16, 1241, 4302], [112, 7, 27, 96, 40, 11875], [2798, 11876, 776, 1817, 7, 1653, 560, 4005], [125], [77, 361], [4165, 1775, 7, 596, 7, 596], [62], [794, 7, 5017, 5941, 19], [14], [524, 16, 5168, 39, 859, 5, 94, 4270, 205, 485, 469, 978, 111, 104], [647, 1961], [50], [11877, 341], [120, 159, 41], [7056], [1833], [245], [5, 45, 2335, 107, 264, 11878, 41], [262, 101, 8524], [26, 104, 7, 369], [21, 166, 361, 101, 762, 1028, 1997], [2298, 762, 125, 3269], [5, 106, 15, 11879], [483, 68, 622], [370, 305, 19], [386, 104, 1303, 44], [310], [367, 352, 106], [88, 155], [1320], [6, 1531, 297, 1187], [11880, 524, 16, 1684, 971, 6081, 7, 1612, 186, 286, 11881, 11882], [4, 7, 474], [152, 463, 11883, 11884, 1629], [11885], [120], [3], [516, 516, 11879], [164, 8, 627], [1314], [11886, 1004, 11887], [11888, 817], [370, 467, 1128, 72, 445, 104, 322], [1682], [1088, 268, 1950], [11889, 2175], [2844, 2221, 233], [245], [0, 104, 106, 4521, 1315], [4, 7, 104, 11867, 6670], [78, 94, 246, 1078, 72, 323, 359, 51, 463], [382, 7, 1723], [370, 496, 1541, 7, 2204, 2696], [62], [14, 120], [14, 695], [14, 7, 15, 622, 7, 901, 6819, 7, 367, 7, 69, 4408, 181, 7, 15, 622, 322, 7, 200], [660, 104, 10265, 1681, 7, 412, 7, 41], [6728], [88, 104, 386, 264, 1116, 2614, 7, 120, 861], [741, 940], [11890, 567, 2763, 88, 124, 163, 119], [1655], [57], [4036], [14], [69, 122, 2179], [2050, 132, 7, 934, 125], [330, 187], [4184], [14, 7, 370, 2381], [27, 179, 46, 99, 27, 2154, 720, 7, 761], [4521, 194], [64], [123, 7, 148, 4399, 44], [91], [227, 7, 11891, 268, 3431], [7674, 7, 262, 765, 801, 27, 7, 898, 7, 69, 81, 359, 5, 630, 16, 5222, 11892, 68, 27], [634], [57], [95, 35, 7, 2694, 166, 11893, 7, 1253], [493, 582, 7], [5, 1011, 287, 7, 120], [11894, 11895], [2997, 524, 5, 185, 97, 15, 11896, 5, 971, 246, 1458, 15, 42], [11897, 7, 11898], [19, 437], [3133, 11899, 677, 1828], [472, 163, 1628, 222, 7, 4228], [3773], [2759, 74, 11900], [2190, 4166, 137, 11901, 11902, 4591], [884, 7, 1], [2579, 247, 256, 37, 49], [1639, 27, 45, 185, 75, 630, 4906], [1010], [14], [474], [106, 90, 163, 7313, 16, 17, 1296, 5010, 96, 264, 408], [474], [11903, 228, 3226], [62], [45, 15], [11904, 56, 72, 44], [1170, 97, 448, 7, 52, 11905, 7, 11906, 984, 2182, 7, 158, 893], [1770, 11907], [62, 91], [2002], [365], [579, 1723, 7, 2175, 27, 26], [6730, 11908, 612, 11909, 5673], [366, 44, 193], [14], [182, 1775, 7293], [879, 738], [120], [3128], [719], [825], [2699, 264, 266], [2367], [123, 49, 7, 11910, 7, 64, 7, 1997, 7, 88, 64], [27, 919, 7743, 51, 1953, 68, 2661], [45, 2721, 749, 1047], [11911], [187, 44], [62, 11912, 1337], [2875, 527], [11376], [2060, 6674], [11913, 72, 2091, 96, 77], [382, 27, 105, 37, 3603, 7539, 1972], [4250], [1897, 7, 372], [1707, 7, 10, 361, 7, 489, 11914, 7, 985], [439, 111, 16, 344], [52, 11915, 7, 101, 293], [423, 662], [11916], [433], [299, 11917, 1863], [977], [259, 595], [11918, 622], [2302, 11919, 136, 11920, 1085, 7119, 11921], [27, 66, 325, 270, 1022], [117, 438, 8857, 7, 2151, 1855, 119, 7, 88, 51, 895, 967, 177, 37, 1911, 363, 7, 2151, 2804, 3414], [58, 7, 120, 898], [798, 2160, 9020, 3163], [14], [11922, 11923, 11924], [62], [1099, 7, 1548], [120], [507, 341, 64, 125], [1486, 11925], [1640, 630, 754], [368, 818, 7, 211, 319, 160, 11926], [354], [62], [6, 202, 6742, 9, 749, 8209, 7, 65, 11927, 27, 88, 263], [245], [4854, 1699], [166, 16, 11928], [20], [123, 2875, 695], [69, 7047, 2783, 1829, 294, 322], [1401], [1575, 248], [5, 11929, 1457], [27, 101], [6657], [369, 17, 7, 20], [125, 7, 58], [3456, 4785, 7, 663], [2955, 2872, 7, 367, 7, 5050, 3413, 11930, 7, 3956, 221, 11931, 7, 7735], [62], [27, 88, 11932], [11933], [5354], [62], [245], [205, 1204, 101], [26], [262, 52, 2202, 233], [1377, 1541, 7, 210], [931, 7, 37, 26], [11934, 3752], [123, 1010], [245, 688, 3117, 2269], [3690], [1], [1288, 895, 994, 11617], [62], [282, 259, 21, 7, 62, 7, 5111], [9, 21, 2470, 7, 474], [940], [7, 1929], [472, 299, 16, 3359], [850, 1219], [245], [262, 2135, 9, 69, 9439, 435, 166, 11935], [2973, 460], [14], [2432], [14], [11936, 7, 1247, 88, 1549], [850], [318, 5087, 630, 4745, 9, 1374, 2804, 619], [516], [2153, 104, 21], [1422, 365], [3690], [27, 45, 64, 7, 1487, 3563, 789], [102, 96, 11937], [51, 247, 7, 372, 465], [26, 104, 681, 166, 1283, 7, 177, 49], [1966, 11938], [7, 259, 144], [223], [14], [123, 464, 397], [104, 185], [1961], [104, 386, 743, 11939, 11940, 11941, 1180, 256], [11942, 568], [7439, 37, 1869, 274, 1850, 2056, 7, 315, 412, 738], [245], [1645], [11943, 1070, 7, 11943], [2367], [11944, 64, 11945], [315, 78, 11946, 1665, 9, 528, 5, 3818, 2060], [14], [2921, 87, 7, 14], [215], [62], [11947, 1624, 44, 7, 11948, 9000, 458], [14, 120], [160, 299, 740], [11949, 139, 11950, 7, 11951, 4730], [561, 11556], [160, 1216, 563, 52, 2120, 72, 152], [62], [892, 7, 17, 784, 317, 7, 166, 5, 11952, 908, 16, 5279], [14], [62, 43], [1839], [51, 11953, 1574], [474], [11954, 11955], [202, 6157, 27, 81, 2285], [2095, 11956], [5646], [6369, 7, 330], [2856, 64, 7, 15, 2856], [15], [62, 7, 26], [1858, 20, 117, 7, 3], [7, 901, 6625], [27, 1856, 386, 9568, 72, 246, 1759, 166, 11957, 524, 104, 18, 34, 179, 14], [62], [386, 27, 11958], [11959, 612, 2128, 374, 1807], [288, 765, 72, 2919, 256, 7, 1645, 7, 11960, 16, 2114], [1449, 622, 7, 11961, 1499, 4690, 11962, 11963], [20, 103, 7, 4016, 4243, 375], [149, 1964], [11964], [11965, 264, 537, 7, 19, 7, 892, 11966, 7, 11967, 7, 11968, 3344, 7, 1010, 44], [283, 284, 788], [7250], [14], [58], [7017, 2303, 5959], [5, 415, 1825], [58, 7, 1057, 37, 115], [1784], [291, 7, 7834], [11969, 386, 104, 622], [487], [798, 1588], [58], [14], [3859], [798, 259, 612], [870, 7, 974, 7, 11970, 7, 11971, 7, 11972, 1232, 11973, 7, 3], [4646], [619, 242, 7, 372, 1300], [152, 16, 344], [11974, 7, 1319], [52, 372, 239], [57, 7, 428, 2395, 7, 1538, 7, 461, 722, 462], [62], [296, 17], [245], [245], [5559], [5, 106, 961, 16, 1952, 9, 9560, 7, 91], [663], [5, 1170, 901, 11975, 1967], [2670], [412], [420], [719, 264, 11976], [102], [352, 2562, 72, 349], [2478], [2373, 11977], [2014, 4905, 11978, 1088], [1850], [215, 1900], [3196, 7, 474], [879, 738], [14], [1232, 1574, 6630], [1645], [581, 7, 20, 7, 20, 7, 20, 7, 20], [1968, 10], [215], [977], [2373, 447, 7, 1987, 78, 72, 929], [525, 5507, 27, 11979, 7, 431, 1624, 44], [412], [639, 361, 1617], [1385], [10312, 5, 179, 20, 326, 286], [161, 64], [217], [884], [2111, 1481, 902], [472, 303], [307, 308, 801, 4664, 264, 574, 117], [160, 841, 7, 454, 205, 445, 7, 88, 164], [104, 1107, 1272, 104, 11980, 582], [498, 51, 1187], [3], [245], [102], [528, 1752, 7, 123, 528, 1828, 7, 474], [262, 52, 205, 1988, 1988], [152, 365], [59, 622, 7, 91], [4503], [719, 299, 472, 7, 8872, 8873], [782, 640, 1531, 908, 749, 1105], [102], [5, 185, 744, 732], [26, 18], [5838, 1240, 3883], [3293, 7, 11981, 3602, 7, 1487, 88, 64], [1659, 19, 7, 412], [11982, 11983, 7, 368, 1203, 7, 352, 519, 45, 1102, 287, 446], [20, 21, 513], [62], [14, 120], [569], [2010], [944, 2108, 11984], [910, 160, 49], [11985], [1334], [892, 564], [447, 42], [104, 1337, 7, 877, 2359], [3529, 11986], [4967], [630, 1253, 7, 5, 185, 264, 7698], [8295, 363], [1205, 223, 247, 160, 49], [20, 1436], [1773], [123, 381], [656, 44, 1661], [11987, 467], [9241, 104, 159, 285, 96, 472, 5166, 7462], [12, 7, 64, 17], [5, 3370, 270, 216], [892, 892, 7, 5, 896], [797], [4], [134, 5, 45, 5564, 2229, 7, 368, 11988, 7, 11805, 7, 52, 11988, 1039], [14], [1749], [219, 9284, 64], [761, 11989, 4290, 15], [1372], [2122, 11990, 11991], [10814, 375, 7, 1815], [5710], [11992, 7], [11993], [944], [738], [58], [352, 1897, 30, 693], [14], [490, 262, 1458, 7, 322, 46], [489, 499, 1147, 81, 41], [5, 6873, 72, 11994, 3678, 104, 640, 412, 96, 44], [386, 104, 1259, 72, 925], [93, 892, 1018], [120], [123, 2892, 4966], [985, 2468, 235], [507, 361, 341, 39, 125], [152, 811, 64, 942, 378], [437], [524, 27, 11995], [14], [1383, 5, 498, 117, 27, 1333, 7, 2299, 7, 11996, 2325, 11997], [1334], [8941], [13], [1369, 1370], [639, 1107, 679, 119, 7, 10476, 39, 132, 4437], [20, 31], [4145, 1245, 7, 14], [262, 264, 859, 239, 9, 264, 859, 2616], [728, 7, 95, 347, 7, 5, 94, 242, 7, 148, 228, 72, 8, 9, 677, 7, 268], [11998], [366, 1147], [352, 386, 270, 779], [1784], [470], [1086, 1545, 5608, 3371, 798, 5608, 5230, 7, 4939, 137, 11999, 3525, 457, 4546], [177, 37, 3398, 49], [2220, 1375, 270, 205, 694, 582, 7, 4264, 363], [5, 116, 52, 1430, 104, 7, 472, 299, 205, 3359], [850], [12000], [163, 1381, 5818, 49], [507, 599, 7, 39, 1716], [120, 14, 20], [14], [454, 1286, 68, 16, 153, 738], [10359, 849], [763, 619, 78, 340, 12001], [12002, 7, 597, 458], [22], [2944, 3636], [513, 205, 4664, 264, 344], [1062, 1745, 413, 39, 465], [850, 7, 90, 341, 765, 72, 12003, 37, 5585, 7, 1043, 9, 104, 7, 96, 12004, 12005], [160, 343, 1558, 525, 7, 88, 677], [46, 1253, 4430, 7, 16, 17, 64], [62, 719, 264, 163, 677], [849], [1756, 635, 164, 2399], [1997], [581], [2057, 2506], [12006, 7, 2303, 2713, 399, 12007, 4730, 7, 91], [1062, 1532, 370, 12008], [524, 104, 152, 7, 12009, 1457], [940], [3], [743, 264], [1558, 1475, 1558, 7, 62], [549], [5507, 21], [46, 21], [12010, 7, 430, 7, 3382, 690], [1422, 916, 437, 448, 7, 762, 21, 12011, 12012, 3130], [14], [1, 7, 8718], [5, 228, 72, 855, 472, 485, 96, 40], [26, 44, 34, 7, 1062, 1666, 7, 779, 2229, 68, 124, 1722, 166, 1502], [417, 106, 104, 1691, 1083, 801, 37, 1557, 352, 1011, 7, 104, 604, 3717, 166, 12013], [14, 120, 7, 12014, 12015, 1828], [7], [58], [2328, 7, 797, 579, 1723, 399, 12016, 145, 702, 1737], [5309, 693, 134], [1141, 487, 4031, 322, 160, 1463, 68, 264, 12017, 17, 7, 12018, 42, 294], [20, 21], [826], [10735], [12019], [20], [62], [265, 12020, 7844, 15, 10469], [163, 125, 5554], [719, 7, 582, 7, 7, 582, 719, 1144, 27, 3995], [365, 148, 4717, 44, 97, 157, 157], [1833], [776, 562], [1369, 7, 753], [414, 817, 414], [412, 36], [936], [148, 255], [581], [884], [435, 7, 27, 1681, 7, 10258, 10258, 5, 440, 27], [3156], [20], [901, 270, 413, 7, 45, 1987, 42, 264, 355], [27, 89, 78], [38], [467, 5222, 3282, 2310, 467], [3], [20], [1103], [3949, 189], [454, 264, 859, 239, 74, 1128], [732, 7, 655, 386, 27, 7, 322], [5407, 622, 2876, 5407, 9753, 1751, 7, 5407, 622, 7, 743, 5407, 9753, 1751, 7, 368, 52, 859], [259, 612], [5, 272, 9453, 27, 159, 1650, 472], [7, 90, 306, 15, 256, 177, 34, 7, 12021, 352, 604, 177, 37, 913], [120, 159, 7, 39, 12022], [378, 1471, 7, 62], [14, 120], [394], [62, 12023, 166, 5, 431, 12024], [521], [12025, 2600, 2792, 7, 14], [417, 386, 27, 4408, 569, 7, 4], [177, 21], [27, 228, 3630], [3291], [26, 688], [210], [12026, 12027, 4680, 216, 7, 743, 294, 801, 37, 1471, 91], [166, 69, 914, 125], [56, 96, 52, 3579, 1726], [2928], [45, 46, 78, 448], [51, 94, 246, 4481], [5, 1074, 101, 263, 8878], [2133, 27, 1216], [163, 7, 1524, 109], [7, 386, 27, 369], [417, 186, 104, 3159, 1542, 371, 5, 4031], [215], [120, 7, 15, 11534], [6080, 78], [104, 790, 1531, 3036], [46, 12028], [12029], [177, 4753, 12030, 7, 8574, 607, 9436], [215], [62], [12031, 4180, 7, 12032, 12031, 57], [20, 569, 7, 3184, 2243, 5917, 7, 99, 88, 1145, 7, 22, 7, 314], [14, 120], [977], [58], [12033, 7, 12034], [4196], [91, 7, 890, 1121, 841, 12035], [743, 5, 862, 7, 5, 113, 264, 4050, 2484], [125], [3733], [88, 259], [62, 1622], [62], [605], [14], [15, 341, 166, 190, 56], [2875], [262, 45, 1128, 96, 12036, 609], [599, 15], [2464, 136, 3132, 2855], [279], [13], [7360, 841, 7, 790, 1875, 43, 1708, 7, 476, 2076, 37, 362, 72, 1471, 37, 49], [10731], [330, 68, 1844, 111, 125], [177, 15, 7173, 1119, 2698], [12037, 12038], [738], [95], [513, 925, 472, 299, 1116, 7, 99, 160, 12039], [14], [56], [12040, 37, 362], [370, 107, 4101], [1044, 2855, 7, 2069, 12041], [14, 120], [12042, 11104, 1486], [985, 2468], [7, 12043, 12044, 7, 7570, 7, 732, 7, 117, 42], [5, 45, 186, 16, 3787, 7, 370, 12045, 1128, 62], [8046], [681, 11, 863], [104, 1018, 96, 1288], [1062, 2382], [12046], [5580], [62], [163, 3148, 62], [27, 10444, 777, 42, 3121, 7, 270, 285, 6678, 7, 5, 319, 129], [62, 352, 185, 2292, 528, 1346], [470, 5, 6, 152, 2731], [1022, 10395, 8536], [1490, 859], [12047, 7, 2303, 1240, 12047], [255], [1499], [487, 285, 79, 428, 1061, 285, 7, 352, 185, 264, 75, 2873, 7, 341, 166, 428, 7, 4590], [314], [102, 96, 1762], [471, 974], [20, 739], [7502], [617, 7, 1487, 618, 44, 19], [940], [370, 262, 12048, 1247, 1541], [315], [123, 1743], [17, 765, 489, 607, 489, 7, 2173], [12049, 2425, 1337, 410], [794, 7, 2823], [62, 7, 123, 38, 1751], [1103, 97], [2096, 7, 161], [3236], [45, 528, 44], [16, 17, 12050], [1240, 4560, 374, 12051], [1274, 270, 16, 7322], [3196], [20, 7012, 91], [13], [69, 1428], [6444, 7, 3550], [489, 12052], [245, 7, 245], [719, 6612], [4163, 19], [7, 7], [102, 179], [27, 159, 1011, 489, 609, 1490, 414, 27, 604], [4], [7331, 12053, 3038], [14], [45, 148, 126, 125, 1576, 104, 152], [1219, 299, 125, 30, 31, 62], [12054, 68, 134, 7, 91, 7, 362, 994, 1828], [5, 106, 1987, 27, 16, 12055, 7, 524, 27, 372, 386, 1452, 96, 103], [245], [1549, 189], [627, 39, 538, 5087], [15, 622, 19], [148, 12056, 12057], [58], [14, 21], [14], [12058, 7, 524, 104, 1011, 2010], [5222, 12059, 7, 166, 12060], [186, 52, 8, 21, 1454, 244], [370, 568], [38], [334], [160, 3350, 513, 7, 372, 1362, 44], [352, 412, 96, 181, 355, 7, 12061, 7, 431, 5514, 97], [215], [850, 14], [12062], [58], [1333, 11224, 52, 2135, 699, 7, 62], [2811], [89, 104, 297, 722, 462], [262, 1141], [740, 5, 2489, 21, 51, 2864, 78, 166, 2973, 524, 104, 790, 107, 78, 34, 308, 7, 166, 34, 3199, 7, 5, 440, 12063], [14], [14, 2655], [7623], [581, 3350], [447, 447], [14, 7, 14, 2787, 7, 472, 2514, 7, 1997, 7, 123, 865], [12064], [902, 7, 41], [354, 7, 1121], [352, 640], [366, 44, 91], [62], [62, 739, 308], [89, 472, 476], [719, 322], [62], [166, 1052, 467, 294, 12065, 111, 44, 862, 472], [12066, 7, 5943], [14, 120], [14, 7, 564, 1175], [1638, 12067], [463], [4162], [5673, 595, 374, 612], [1818, 259, 12068, 7, 797, 1130, 7, 14, 334], [12], [12069, 7, 1174, 3932, 4409, 160, 49, 81, 7, 5, 4524], [447, 7, 12070], [14], [794, 901, 743, 37, 2684, 111, 3486, 12071], [20, 7, 20], [14], [14, 120], [62, 1018, 97, 12072], [4364], [219, 7, 219, 1558, 7, 10654], [59], [62], [2248, 264, 1534], [366, 44, 102], [160, 1047, 96, 12073, 16, 1300], [428, 1353, 285, 34, 95, 12074], [12075, 1385, 754], [1605, 7, 12076], [37, 2804, 10, 45, 807, 3170], [431, 52, 14, 7, 12077], [12078, 1622, 39, 410], [2760], [368, 818, 5, 349], [4831, 3104, 6662, 6130, 592, 7, 4831, 3104, 3041, 12079, 3495, 430, 1085, 12080, 2944, 7790, 7, 688, 1240, 3161, 7, 2034, 1070, 5503, 7, 688, 8263], [2668, 2624], [58, 7, 11506, 10590, 7, 1815, 7, 2160, 1369], [62], [884], [14], [12081, 841], [619, 1699, 390], [417, 39, 749, 12082, 159], [75, 499, 7, 663], [447], [599, 89, 27, 1828, 777, 42, 270, 31, 62, 7, 2130, 120], [14], [259, 7, 88, 263, 445, 30, 21, 7, 2640, 630, 7630], [58], [5880, 291, 7, 1215, 12083, 7, 123, 12084], [12085], [215], [15, 622, 7, 102, 58], [14], [387, 1529], [365, 2359, 4779, 96, 435, 7, 96, 1450, 7090, 68, 2661, 7, 56], [965, 299, 20, 101], [58], [610, 1678, 776, 702, 1087, 696], [2931], [13], [448], [20, 1204], [517, 363, 965, 513], [260, 753, 658], [96, 538], [412, 12086], [850], [701], [245], [58], [90, 105, 7, 99, 431], [1288, 370, 12087, 326, 12088, 9467, 7, 732, 361, 1117, 91], [120], [102, 159], [412], [12089], [1342, 12090, 3889, 75, 1815], [1449, 42, 159, 7, 315], [12091], [62], [14], [20, 49, 20, 694], [95, 1010, 7, 2060], [6053, 9, 7605, 7, 52, 12092], [62], [7770], [3], [120, 7, 46, 41], [56], [474, 7, 1028, 1028, 1028], [6096, 120], [6106], [64], [102], [2154, 4088, 2243], [4501, 1751, 41, 7, 95, 8, 30, 37, 5847], [26, 1847, 3499], [12093], [62], [2829], [14], [12094, 21, 7, 12095], [50], [10, 43], [474], [1490, 78, 695, 7, 1074, 929, 1321], [447, 448], [412, 365], [14, 7, 17, 18], [2367, 1039], [27, 1844, 111, 125], [192, 256, 46, 78], [681], [20], [382, 16, 8843, 1204, 186, 52, 117, 64, 17], [12096, 7, 663], [12097], [14], [123], [1215, 7, 743, 721], [50], [800, 16, 344, 12098], [259], [2389], [7, 14], [9971], [8914, 264, 2429, 7, 763, 619, 7, 370, 12099], [719, 783], [581, 49, 9, 893, 2361], [1734, 12100, 134], [352, 1640, 10903, 37, 9789, 756, 7, 382, 7, 638, 284], [524, 8300, 96, 1704, 7, 5, 971, 111, 1867, 27, 159], [3224], [621, 2087], [524, 5, 720, 341, 368, 43, 8725, 24], [215], [5, 1011, 72, 3080, 16, 953], [1136, 7, 4363, 7, 120, 177], [370, 4212], [20], [62, 12101], [102], [285, 97, 898, 365, 7, 163, 11], [3785, 12102], [914, 542, 160, 49, 12103, 7, 5, 242, 34, 69, 2087, 727], [1106], [14], [963, 776, 2326, 7293, 7, 182], [3, 719, 386, 104, 1650, 235, 1039], [435, 7, 417, 2151, 322], [1766, 7, 3, 7, 123, 412, 44], [634], [259], [366, 44, 7860], [27, 94, 149], [14, 7, 245], [245, 12104], [1, 7, 581, 49, 1828, 7, 8445, 20, 21], [15, 96, 12105, 7, 12106], [12107, 12108, 24, 397, 1934, 37, 2804, 17], [12109, 12110, 1085, 12111, 118, 457, 2976], [474, 7, 2255, 363], [901, 52, 1659], [12112, 7, 702, 845], [20, 163, 721], [352, 2763, 96, 12113, 463], [412, 1349], [1680], [14], [3], [15, 1122, 7, 365, 7, 27, 106, 305], [1574, 12114], [39, 160, 264, 12115, 96, 27, 745], [4575, 7, 19, 412], [59, 12116, 7, 1638], [12117, 7, 4954, 4955, 7, 131], [78, 299, 818], [95, 8367, 68, 12118], [2845, 7, 219], [1333, 7, 148, 1987, 284, 699], [12119, 7, 2517, 12120], [46, 7, 186, 52, 149], [524, 104, 117, 44, 1454, 7, 756, 2931], [2213, 7, 2213, 7, 1801], [14, 1558, 12121], [58], [45, 1422, 7, 5, 94, 5590, 27], [166, 27, 386, 754, 27, 8110, 344, 1751, 7, 2468, 41], [6684], [91], [667], [27, 1756], [1422], [46, 21], [58, 7, 20], [382, 7, 1969, 7, 148, 117, 44], [14], [3561], [12122], [12123], [3525, 7, 1653, 2352, 7, 6474, 2352, 7, 3137], [1725], [181, 239, 35, 326, 21, 166, 46, 7, 365], [285, 894], [3071, 524, 272, 78, 519, 472, 521], [120, 7, 181, 239, 12124, 12125], [455], [177, 102], [14], [1172, 2243, 1884], [296, 308], [215, 59], [14, 120], [27, 106, 1319, 44, 322, 7, 1458], [805, 55, 7566, 7, 5, 2335, 314, 489, 859, 622, 7, 270, 16, 694], [118, 7, 11], [410, 21], [90, 6725, 702, 947, 7, 12126], [2025, 44, 7, 756, 361, 27, 7, 474], [660], [902], [400, 8, 96, 287, 27, 152], [11806, 160, 49, 1703, 75], [1172, 8096, 7, 51, 1187], [410, 77, 7, 489, 2359], [58], [4778, 12127, 7, 90, 4094, 3104, 6248], [4196, 7, 20, 7, 4196], [12128], [5, 766], [921, 607], [58], [4], [12129, 26], [493, 1300], [26, 27, 528, 1337, 7, 322, 51, 117, 44], [104, 6, 1926, 160, 20, 49, 7, 105, 414], [3, 7, 2568], [368, 476, 488], [6414, 851], [2096, 365], [8878], [3], [52, 12130], [581], [5, 412, 104, 152, 622, 7], [12131, 21], [12, 15, 360, 7], [2125], [181, 812], [391, 1941], [123, 1929, 7, 190, 7, 7605, 381], [1465, 691, 7, 5578, 732], [952, 7, 137, 12132, 12133, 12134], [3388, 202, 78], [20, 7, 3, 7, 20, 7, 12135, 27, 7, 14], [12136, 7, 1743, 7, 12137, 12138], [6955, 106, 246, 16, 371, 7, 12139, 4431], [1486, 159, 7, 12140], [414, 27, 148, 222, 627], [12141, 262, 52, 88, 859, 96, 1636], [127, 12142], [51, 4664, 722, 761, 30, 21], [44], [127], [1040, 7, 52, 1731, 7, 369, 1267, 7, 884], [12143, 1219, 39, 372, 164], [120], [223, 224, 41], [679], [7909, 574], [11404, 334], [1629], [1730], [4311, 185, 502, 2229, 97, 4085, 8120], [6265, 929, 7, 211, 152], [474], [20, 7, 12144], [223, 21], [741], [365, 2010, 21, 72, 1875, 190], [91], [1114, 568], [1141, 525, 929, 487, 363, 93, 1699, 7, 192, 2731, 9, 12145], [14, 4590], [37, 865], [58], [120, 7, 20], [14, 1574, 7, 64, 12146, 7, 12147, 1574], [544, 412, 7, 1716, 194, 184], [12148], [622, 9537, 1556], [414], [20, 103], [561, 770, 137, 947], [1334, 133], [794], [1499, 7, 8390], [2964], [99, 322, 1102, 463, 166, 1762, 574, 49], [1039, 7, 584, 118, 7, 1039], [4606, 16, 12149], [1205, 719, 7322, 160, 369, 528, 39], [2751, 7, 118, 3176, 2751, 7, 761], [15, 510, 7, 448], [14], [1540, 78, 299, 569, 12150, 12151, 504, 4245], [12152, 7, 2074], [1425], [89, 52, 743, 16, 1110, 2875, 7, 26], [4268], [659], [5071, 2673], [12153, 285, 341, 743, 264, 5942], [894], [91, 91, 91], [12154], [12155, 88, 164], [46], [211, 46], [14, 120], [2721, 7, 7448, 7, 3972, 65], [20], [788], [216], [46], [663, 728, 27, 81], [660, 334], [12156, 7, 12157], [14], [1385], [215, 1312], [5, 1987, 104, 722, 1241, 7, 415, 1999, 224, 1177, 7, 100, 7, 45, 15, 160, 49, 3651], [322], [365], [5880], [4465], [62], [516], [5647, 5301], [15, 728, 14, 120], [3], [12158, 166, 5239, 294], [13], [282, 7, 5111], [374, 947], [15, 513], [20, 7, 20, 7, 20], [45, 95, 117, 513, 352, 148, 149, 42], [120, 582], [460, 10046], [2423, 12159, 8576], [963, 7, 1163], [370, 7, 52, 1544], [20, 7, 4223], [17, 39, 37, 1826, 125, 1828], [1980, 1130], [821, 776, 685, 776, 2965, 770, 12160, 12161], [57], [8481, 7, 1855, 12162], [148, 1987, 72, 390, 2292], [12163, 12164, 105], [14, 1034], [104, 640, 7271], [215], [3868], [12007, 12165], [1016, 622], [1, 770, 776, 3825], [7869, 7, 487, 408, 7, 9403, 2242, 7, 1010], [259], [1028, 12166, 12167, 614, 12168, 7, 4, 7, 2802, 12169], [27, 148, 185, 467], [58], [795], [62], [215], [12170, 3900, 12171, 62, 492], [215, 12172, 41], [2823], [12173], [1377, 7046, 6744, 565, 7, 1507, 5274], [334], [148, 5977, 743, 2921], [12174], [46], [104, 431, 64], [123], [148, 1531, 3206, 9262], [215], [12175], [2997, 7, 12176], [1425], [688, 12177, 579, 1723], [177, 111, 104, 26, 104], [352, 415, 224, 7, 3], [14, 177], [123, 528, 8272, 7, 630, 718], [4265, 88, 369], [20], [4133, 160, 49, 7, 166, 15, 2050], [14, 120, 7, 15, 134], [1215, 1215], [447, 3028, 681], [492, 7, 19, 323, 44, 2731], [853], [5836, 5837, 5838, 5839, 5840, 5841, 5836], [185, 104, 777, 507, 1686], [1645], [366], [660], [884], [5, 2248, 2335, 1103], [7618, 2671, 7, 7618, 1141], [39, 1826, 413], [14], [62], [69, 732, 39, 37, 571, 7, 1848], [387], [5469], [26, 104, 750, 1283, 7, 39, 12178, 275], [370, 347, 96, 27, 7, 7, 4292, 3864, 294, 490], [37, 186, 104, 1856, 1665, 39, 37, 12179], [259], [245], [11473, 106, 104, 2154, 163, 1171, 1721, 205, 17, 2864, 2241, 472, 971, 246, 12180, 7, 3135, 268, 1261, 277, 619], [5087, 12181], [507, 3499, 12182, 12183, 7, 12184], [14, 120], [2464, 2965, 7, 12185, 7, 7962, 1125], [439, 51, 807, 104, 2549, 472, 39, 414, 7, 2636], [1862], [160, 17, 113, 44, 533], [62], [12186], [11812], [205, 55, 10823, 205, 9544, 12187], [12188], [245, 2108, 7, 936], [417, 563, 264, 438, 349, 472, 465, 72, 264, 662, 21, 7, 359, 44, 166, 582, 4618, 42, 1744], [41], [5, 265, 926, 27, 9, 205, 609], [102], [215, 1312], [738], [8598, 5, 89], [493, 7, 2074, 7, 26, 7, 125, 7, 5843, 370, 87, 7, 95], [15, 528, 51, 39, 1796, 16, 12189], [270, 62, 272, 185, 181], [1147, 7, 435, 862, 7, 148, 32, 101, 789], [1846], [4664, 11, 812], [12190, 7, 12191, 12192], [363, 72, 765], [120], [1039], [417, 563, 78, 95, 1454, 229], [7], [14], [12193, 465, 72, 1531, 464, 72, 8, 9, 1538, 2229], [2653, 44, 262, 893], [104, 386, 177, 88, 164, 7, 2248, 7, 99, 100], [795], [44, 101], [12194], [95, 999, 368, 284, 72, 104, 7, 62], [14], [155, 694, 1988, 330, 2025, 44, 68, 2032, 7, 1272, 205, 1315, 2783], [648], [14], [6449], [718], [660, 7, 341, 5032, 1362, 72, 349, 7, 5, 498, 202, 42, 808, 1650, 472, 7, 677, 274, 1172, 355, 2506, 9, 410, 4274], [62, 7, 69, 88, 859], [5, 152, 1542, 3548], [374, 6131], [78, 94, 62], [120, 2199], [719], [1521, 268, 719, 93, 179], [10814, 1241, 7, 166, 95, 7, 148, 46, 1253, 7, 245], [93, 640, 105, 7, 417, 93, 1650], [78, 39, 1122], [155, 7, 701], [37, 2204], [1941, 1941], [31, 299, 5412, 2247], [215], [465, 49, 7, 5, 12195, 9768, 7, 41, 7, 366, 44], [99, 89, 27, 210], [120], [12196, 548, 4818], [2957, 7, 892], [472, 299, 991], [6, 1531, 117, 44], [14, 7, 88, 164], [3137], [2478], [1456, 2382], [14], [102], [1682], [46, 997], [14, 2928], [88, 4967], [20, 627], [194, 1411], [7, 16, 2351, 7, 2973, 78], [427, 7, 8597], [494], [181, 812], [414, 386, 104, 132, 743, 104, 386, 264, 859, 266, 7, 104, 386, 802, 473, 607, 264, 12197, 565, 7, 101, 4451, 96, 3681, 7, 264, 565, 12198, 6315, 185, 862, 93, 94, 308, 524, 93, 1828, 314, 42, 270, 3681], [420, 7, 2248, 5114], [134], [5806, 901, 37, 444, 414, 352, 604, 7, 15, 42, 365], [52, 1544, 45, 1436], [410], [91], [417, 39, 78, 52, 264, 859, 444], [366, 1549, 582], [675, 982], [1499], [55, 7, 810, 30, 472], [12199], [370], [516, 30, 44, 7, 12200, 7, 262, 582, 7, 5, 185, 37, 1480, 111, 264, 1110], [319, 2359, 322], [489, 43, 181], [166, 4249], [447, 42], [366, 256], [102, 505, 902], [177, 1248, 12201], [12202, 7, 96, 64, 343, 7, 95, 26, 27, 12203, 7, 20, 21], [1548], [58], [259, 612, 7, 893, 103, 7, 125], [3506, 7, 27, 386, 125, 7, 2395], [12204, 110], [12205], [25, 464], [800], [27, 925, 44, 12206], [14], [91], [7630, 607, 264, 70, 662, 794], [356, 205, 381, 235, 7, 893], [14], [2478, 5, 341, 1661], [761, 7, 64], [447], [366, 44], [12207], [2961], [859, 109, 1183, 888, 72, 115, 37, 3142, 49], [58], [2753], [14, 120], [259], [412], [1099, 3785], [1832, 7488, 658], [738], [41], [5585, 2046, 7, 52, 749, 3359], [521, 21, 1708, 7, 5, 349, 7, 14, 12208, 366, 12209], [2014, 7247], [420], [7834], [1122, 7, 12210, 7, 378], [4664, 264, 123, 49], [1677, 7, 1732, 528, 7, 5, 888, 72, 568, 96, 27], [10365], [160, 1783, 7, 39, 12211], [14], [634], [14, 7, 366, 44, 102], [753, 7, 1908, 111, 363, 7, 6, 1531, 149], [12212], [382, 12213], [454, 1286, 322, 235], [62], [366, 44, 7, 1211], [2066, 39, 205, 3359, 7012], [1215, 5, 101], [1018, 365], [1778], [352, 12214, 247], [123], [62], [6512, 12215], [719, 12216, 8638, 2859, 750, 68, 617], [659], [4], [291], [622, 268, 2489], [1648], [826, 1240, 12217, 7672, 7, 1040], [2137], [1121, 7, 693], [148, 246, 264, 8514], [3717, 49], [382], [104, 64], [715], [45, 12218, 37, 12219, 125, 4068, 7, 322, 472, 262, 12220, 5, 106, 12221, 296, 166, 12222, 12223, 270, 413], [14], [2892, 220], [1141, 7, 655, 39, 205, 8930], [4], [865], [910, 44, 2267, 7, 372, 7, 126, 1054, 1162], [569, 1383, 937, 1941, 264, 7522, 371, 326, 7605, 381, 270, 37, 3142, 789, 49, 7, 619, 1531, 11170, 7, 898, 1011, 37, 49, 111, 749, 694], [102], [2069, 5514], [12224, 7, 470, 7, 78, 299, 12225, 44, 1847], [96, 12226], [123, 3410], [6444, 266], [3212, 7, 12227], [291], [352, 1011, 264, 4782, 487, 3060, 30, 4782, 2738, 9775, 3899, 487, 363], [27, 870], [155], [527, 1010], [15, 365], [12228, 788], [884], [228, 10522, 305], [14, 7, 120], [12229], [163, 418], [12230, 386, 1661, 7, 4311, 10658, 7639, 1128], [62], [2794, 35, 6152], [45, 1303, 7, 1215], [20, 622], [102, 96, 103], [15, 861], [1723, 7, 859, 1544, 10004, 287], [12231, 2087, 7759, 7, 11021], [14, 7, 2921, 622], [3696], [27, 12232, 221, 44, 166, 604, 21, 7, 27, 12232, 221, 44, 166, 1107], [41], [474], [1240, 12233, 7, 648, 4840, 4084, 457, 1035, 7, 705], [12234], [14], [265, 1078, 153, 12235, 303, 233], [7, 352, 7646, 604], [41], [1831], [1383, 127], [7045, 111, 12236], [12237, 11455, 12238], [414, 7, 762], [166, 1067, 2204, 352, 89], [215], [215, 7, 687, 1369, 7, 7355], [89, 104, 15, 898, 7], [8003], [62], [719, 563, 37, 2545, 185, 72, 186, 9, 5585, 1769], [58], [1063, 7, 104, 7, 101, 378], [62, 7, 27, 186, 1851, 177, 49, 166, 630, 489, 117, 7, 9828, 7, 69, 4172], [5, 5696, 261, 12239, 12240, 95, 72, 12241], [7817], [892], [884], [359, 89, 5, 126, 125], [1103, 68, 37, 3852, 12242], [1373, 35, 20, 152, 91], [352, 325, 7, 749, 4794, 3733, 7, 365, 412, 12243], [569, 7, 64], [2014, 1240, 12244, 6130], [850], [15, 1590, 12245, 102, 7, 15, 177, 4260, 365, 365], [12246], [90, 7659, 1099, 2269, 457, 75, 7, 1723, 688, 845], [215], [5, 148, 105, 638, 1140], [794, 7, 62], [794, 64, 341, 233], [14], [2952, 7, 259], [521, 103, 691, 7, 7699, 521, 7699, 7, 103, 3458, 12247], [3026, 7, 3026], [859, 5302, 568], [472, 406], [44, 7, 1314, 7, 8890, 17], [4313, 12248, 487, 499], [12249, 3516, 12250, 270, 5409], [27, 66, 4962], [104, 604], [90, 440, 417, 37, 7965, 17, 274, 1915, 3093, 12251, 1328, 96, 2346, 37, 7965, 49], [120], [300, 49, 7, 420], [12252, 7, 738], [215, 259, 612], [957], [366, 44, 102], [12253], [58], [14], [62], [738], [740, 7, 20], [2856, 719, 264, 12254], [1365], [291, 7, 75, 12255, 656, 7, 4, 39, 160], [370, 6540, 1102, 160, 9776, 12256], [2694, 7, 20, 7, 493, 7, 493, 7, 493, 7, 126, 7, 126, 7, 343, 1054], [997, 7, 1225, 7, 272, 164, 21, 7, 34, 1411, 7, 1212], [2147, 104, 46, 19, 7, 12257, 1060, 7, 2309, 1952], [663, 159], [166, 1457], [12258, 7, 12259], [330, 74, 96, 719, 1410], [521], [366, 44, 41], [20], [27, 234, 859, 817], [5426, 228, 12260], [776, 1678, 7, 11714], [5608, 12261, 458, 7, 1648, 7, 88, 5, 106, 314, 27, 12262, 7, 1482], [14], [3733], [202], [21, 7, 224], [20, 49], [62], [62], [26, 104, 352, 6, 1447, 37, 12263, 524, 5, 6, 12264, 929, 26, 27], [52, 270, 472, 103], [62, 7, 14], [343, 344, 345, 7, 2292, 343], [30, 37, 12265, 7, 104, 862], [51, 299, 9725, 746], [90, 971, 185, 727, 11915, 10621, 96, 12266, 8746, 65], [51, 106, 1089, 21, 7, 57], [608, 513, 7, 859, 21], [547], [507, 35, 12267], [5, 299, 12268, 479, 5, 640, 153, 5, 299, 1872, 8353], [3645], [6845, 7, 115, 7, 14], [95], [414, 44], [5244, 44, 34, 516], [15, 160, 3316], [27, 386, 921, 159], [1039], [215], [120, 159], [177, 15, 2532], [262, 473, 17, 7, 5, 2381, 52], [54, 7, 45, 1921, 7, 472, 12269, 12270, 435, 7, 96, 1450, 49, 68, 2661, 7, 51, 563, 37, 5890, 111, 719, 5, 1378, 42, 7, 72, 5953, 44, 1847, 7, 166, 72, 4026, 37, 49], [88, 1734, 694], [2299, 7, 374], [352, 177, 105, 2151, 472, 125, 7, 2228, 2243, 7, 12271], [12272, 12273, 11444], [892], [315, 125, 453], [259, 7, 2007, 7, 12274], [62, 732], [259], [14], [215, 7, 120, 11637], [163, 1844, 111, 125], [62, 4], [2382, 72, 231], [977], [52, 44], [1040], [4039, 44, 7, 330, 7, 1681, 513], [62], [3173, 612], [123, 4495, 159], [382, 719, 847, 847, 294, 474], [262, 12275, 294, 322, 1856], [7, 719, 39, 190, 1650], [20, 7, 27, 52, 378], [884], [3], [5, 185, 1915, 2366, 4456, 3276, 808, 1538, 96, 2204, 2537, 417, 418, 166, 34, 5, 2503, 264, 12276, 111, 2109], [14], [4141], [1039], [12277], [123, 467, 639], [3338, 776, 3886, 12278], [58, 7, 58], [1708], [474, 7, 453], [1286, 365, 445, 44, 21, 7, 5, 790, 2100, 42], [51, 463], [14], [14], [91, 7, 104, 386, 1077, 630, 205, 485, 5114, 270, 7232, 7, 62], [155], [62], [14], [20], [58], [45, 46, 7, 52, 588, 7, 1253], [743, 104], [1482], [78, 12279, 1115], [14, 7, 15, 7, 513, 365, 7, 677, 7, 75, 119], [11112, 7, 12280, 9053], [62, 7, 91], [6512], [32], [91], [1721, 27, 431, 640, 630, 42, 270, 17], [20], [58], [7198], [835, 1471, 7, 474], [863, 39, 8350], [217], [884], [88, 164], [634], [3093, 93, 95, 110, 1353, 7, 326, 4464], [2010], [474], [510, 7, 89, 5, 499, 27, 9, 177, 7, 717], [627, 274, 216, 233, 7, 622, 39, 3575, 565, 235, 7, 370, 76], [977], [12281, 7, 102, 7, 719, 39, 37, 12282, 12283, 111, 9096], [123, 1538], [14], [319, 264, 4050, 859, 1686, 68, 104, 12284], [14], [366, 44, 102, 14], [104, 163, 2071], [774, 42], [14], [27, 177, 1961], [144, 2352, 7, 1702, 146], [1195, 472, 883, 7, 88, 761], [1401], [44, 72, 7, 660, 493], [57, 2721, 205, 163, 1666, 7], [6787], [259, 1737, 1775, 688, 12285], [20, 152], [14], [10533], [95, 8367, 434, 950, 7, 166, 2688, 44], [91], [62], [12286], [166, 27, 803], [1085, 6071], [177, 111, 1279, 39, 12287, 64], [412], [245, 7, 5324], [622], [453], [1372], [794, 794], [14], [4734, 696, 968, 7801, 7, 2404], [12288, 12289, 8114, 265, 1538], [217], [0, 7, 474], [12290, 7, 1385], [58], [368, 660], [366, 12291], [10217], [50, 7, 215], [386, 27, 369, 202, 802, 1128], [985, 2468], [2885, 347, 3696], [366], [329, 7, 245], [241, 101, 2751], [14], [412], [492], [2404, 2405], [215], [27, 1144, 372, 3255, 133, 635, 272, 93, 106, 179, 472, 125], [7, 10520], [2153, 323], [3], [2811], [660], [1428, 1187, 159], [50], [740, 109, 39, 360, 895, 630, 262, 2348], [14], [296, 1180, 181, 239, 1337], [58], [245], [2566], [414], [1315, 788], [102, 528, 96, 12292], [977], [7422, 103, 2109], [352, 185, 362, 1708, 1229, 1128], [1682], [412, 166, 283, 1475, 7, 283, 284, 7, 3203], [420], [448, 15, 343, 7, 51, 1010, 5401, 7, 1174, 209, 1011, 4664, 264, 762, 163, 12293, 17, 784], [2014], [798, 259], [127, 96, 52, 412, 1834], [102], [800], [227, 12294, 1010, 7, 7, 879], [12295, 471, 808, 3530, 166, 1319, 7, 166, 322, 1319, 12296, 125, 7, 14, 120], [4383, 90, 550, 3183, 8204], [1151], [719, 1828, 104, 4532], [27], [4829, 595, 7, 3784, 821, 1070], [437, 7, 181, 43, 10], [2060], [210, 210, 210, 210, 7, 192, 44, 115], [7282], [1370, 1425, 1426], [794], [1772, 12297, 7, 1111], [12298], [6798, 6799], [474], [12299, 2122, 2731, 490, 7, 12300], [62], [62], [1537, 771], [6, 1159, 72, 256, 7, 1063, 124, 363, 148, 622, 1272, 505, 617, 7, 62], [2575, 1240, 8626, 7, 2149, 3042, 4303], [272, 489, 501], [44], [356, 12301, 7, 472, 1300, 12302], [14, 314, 104], [862, 2199, 9, 2576], [884], [0], [4], [166, 8469, 2698, 7, 12303, 37, 7965, 49], [20], [985, 2468, 12304], [62], [680, 5805, 2091, 39, 264, 6408, 12305, 7, 27, 6, 630, 12306, 111, 472], [977], [12307, 7], [710, 1471], [341, 330, 21], [78, 39, 743, 6506, 270, 264, 3749], [10310, 12308, 2266], [3561], [79, 97], [619, 7668, 862, 9037, 12309, 743, 75, 2484, 1109], [352, 2923, 74, 569, 7, 359, 352, 386, 177, 12310], [1215, 7, 12311, 472], [12312, 7, 20], [123, 528], [15, 1377], [2669, 263, 186, 104, 630, 2210, 1374, 49], [5, 1916, 5, 299, 471, 789, 49], [3328, 104, 152, 7, 12313, 19], [245, 7, 163], [1383], [27, 5571], [5116, 103, 2109, 56], [762, 21], [120], [1215], [6951, 341, 7, 985], [6116, 94, 27, 186, 7, 524, 1457, 30, 37, 3584], [934, 12314], [1899], [5709], [474], [6777, 4020, 104, 386, 125, 30, 205, 4408], [123, 3268], [3403, 285, 20, 103], [3092, 7, 27, 88, 2751], [15, 1268, 341, 7, 4401, 355, 4709], [352, 319, 1851], [262, 1275, 956, 3976, 956, 582, 2247], [185, 287, 270, 1381, 2200], [106, 352, 568, 322], [20, 49, 20, 694, 7, 45, 1422], [12315], [677, 7, 123, 513, 285], [12316, 1751, 3089, 12317, 1847], [315, 794, 3818, 205, 484, 264, 746], [5, 216, 412], [14], [62], [12318, 12319, 12320], [285, 97, 361, 434, 363, 7, 52, 71], [2068, 235, 7, 36], [260], [5, 306, 368, 40, 12321, 7, 186, 104], [245, 7, 6029], [182, 505, 7, 1242], [719, 7, 9253, 186, 104, 185, 7237, 7, 12322], [2286, 7, 10590, 7, 2036, 579, 4598, 7895, 2303, 947, 399, 2195, 9903, 6549, 9985], [1016, 622], [460, 104, 105, 205, 994, 299, 2292, 270, 160, 49], [274, 5262, 808, 37, 49, 5754, 412, 96, 929, 72, 5934, 7, 274, 2925, 37, 49, 2066, 49, 39, 1078, 72, 323, 1044, 2926, 94, 246, 2927], [634], [37, 3411, 39, 68], [12323, 7, 414, 2087, 7, 12324], [315, 515, 386, 27, 3575], [11173, 743, 352, 604, 467], [7084, 467, 630, 270, 1128], [259, 21], [26, 104, 1004, 6408, 7, 12325], [14], [893, 7, 125], [651], [245], [374, 7, 453], [660], [901, 2739, 3276], [374], [1558, 4236], [104, 163, 2539, 62], [12326], [2409, 1054, 1085, 5510], [314], [15, 4956, 7, 68, 733], [7, 12327], [6853, 51, 498, 246, 270, 69, 17, 434, 49], [58], [102], [582, 247, 965, 7, 3210, 7, 120], [192, 78, 6194], [220, 607, 1455], [270, 49], [12328], [20, 721, 7, 20], [12329], [125, 5275, 627, 7, 14], [90, 89, 7, 4177, 84, 489, 355], [20], [884, 7, 884], [106, 5, 6582, 27], [3729, 19, 659], [634, 974, 7, 1039], [245, 1401], [776, 412, 3558, 37, 17, 2046], [14, 120], [8732, 1052, 12330], [58], [91], [291], [417, 106, 104, 185, 4664, 264, 125, 361, 7, 7, 417, 45, 12331, 44, 7, 114, 12332, 51, 2859, 12333, 51, 1386, 4980, 7, 194, 4980], [160, 12334], [453, 7, 7066, 776, 144], [414, 15], [14, 120, 7, 1422, 7, 95, 1422, 7, 123, 8, 7, 581, 17, 7, 127], [1272, 69, 2720, 7, 40, 2720], [362, 49, 1828, 88, 8350], [417, 299, 37, 2243, 2091], [95, 242, 27], [884], [104, 6, 1446, 12335, 2361, 7, 743, 1205, 5, 6535, 78], [5, 94, 2757, 69, 371], [64, 1241], [12336], [12337], [102], [582, 45, 7753, 27, 7, 34, 5, 12338, 104, 265, 31, 7, 72, 3577, 37, 1684, 111, 37, 49, 7, 12339], [2079, 565], [215, 7, 2356, 7, 2646, 7170, 7171, 7, 3182, 7168, 1085, 7169, 7, 259, 612], [15, 622, 365, 7, 12340], [12341], [56, 96, 114, 103, 732], [104, 87, 7, 148, 7, 6285, 44], [0], [420, 7, 51, 2973, 352, 148, 224, 7, 291, 7, 223, 2476, 2151, 27, 1531, 12342, 7, 1866, 1851, 7, 7779, 322, 7, 270, 205, 17, 7, 368, 177, 528, 7, 12343, 264, 161], [10471, 457, 2944, 4352, 2034, 4994], [7, 1005, 39, 37, 571, 524, 262, 12344], [45, 264, 940, 90, 306, 90, 341, 1661], [374], [77], [291], [12345], [12346, 372, 1010, 12332, 166, 807, 256, 349], [660, 34, 2373, 95], [850, 7, 494], [5, 942, 663, 96, 528], [14, 120], [26, 88, 378, 1622, 166, 8240], [4637, 428, 41], [12347], [902], [761, 1219], [14, 120, 159], [264, 12348, 582, 7, 209, 777, 472, 784], [245, 7, 2273, 7, 675, 12349, 7, 561, 770, 12350], [643, 5714], [492], [470], [1744, 7, 719, 264, 123, 1375], [330, 1147], [20], [1630, 5, 1640, 185, 6063, 270, 264, 6030, 153, 9, 370, 766, 291, 12351, 7, 163, 863, 2361, 4213], [622, 12352, 72, 297, 2892, 9224, 220, 7, 51, 89, 52, 908, 87, 434, 72, 3499, 87], [268, 1766, 567, 1999, 567, 3595, 27], [15, 365], [2096], [62], [843, 49, 111, 16, 694], [69, 361, 39, 1078, 153], [811, 159, 306, 413, 39, 264, 12353, 7, 1747, 740, 372, 7, 1856, 7, 166, 12354], [14], [77, 612, 7, 310, 4546, 612, 12355], [818], [215, 947], [569, 3060], [1483], [470, 368, 52, 7, 88, 202, 12356, 9858], [428, 8, 1122], [1992], [568, 7, 4, 7, 412, 19], [123, 12357], [1540, 810, 655, 352, 386, 322], [14], [474, 1377], [370, 97, 413, 96, 2708], [3059, 744, 7, 2438, 1128], [805, 1770, 81, 194, 3485, 801, 7353, 7, 370, 7323, 7, 5, 2381, 7115, 8848, 7965, 3728], [1576, 104, 152, 7, 1833], [223, 862, 5, 299], [14], [287, 720, 9, 160, 21], [95, 1592, 34], [719, 264, 1191, 12358, 7, 12359, 12360], [62, 7, 181, 355, 235], [1369, 1370, 7, 11, 17], [62], [7317, 7, 3552], [62], [1719], [14, 120], [10078], [314, 761, 622, 24, 1057, 2435, 359, 1502], [88, 223, 352, 12361], [215], [1016, 12362], [96, 44, 78, 299], [14], [62], [181, 355, 2694, 7, 420], [1242], [898, 69, 52, 1077, 152, 27, 105, 472], [5063, 7, 341, 5063, 7, 7248], [88, 155, 7, 414, 44, 9682, 7, 12363, 7, 90, 12364, 2944, 7366], [2928], [2328, 12365], [5, 105], [7508, 7, 12366, 7, 7508, 7, 215], [117, 733, 7, 215], [62], [12367], [1527], [474], [11, 7, 1822, 413, 448], [12368, 97, 428, 91, 232], [12369], [474], [123], [1401, 7, 334], [1372, 322], [1010, 270, 2345, 7, 123, 1444], [4513, 12370], [12371], [651], [414, 971, 104, 912, 153, 965, 7, 1531, 9, 75, 465, 2022, 291], [754, 7, 6, 8, 812, 1296, 2001], [2416, 1452, 96, 264, 152, 7], [103, 12372, 7, 417, 9461, 2351], [374], [58], [1645], [542, 160, 264, 1855, 355, 49, 448], [2418, 1952], [370], [1772], [123, 12373, 122], [4], [5, 92, 27, 519, 12374, 2095, 7, 91], [20, 3025, 902], [2328, 90, 12375, 776, 7, 1086, 399, 374, 7, 1342, 12376, 7, 1033, 7, 1086, 3382, 7, 12377, 90, 4839, 776, 7, 6293, 7, 12378, 711, 1751], [374, 12379], [127, 3499], [12380, 20], [75, 7292, 270, 264, 3749, 7, 26, 16, 694, 7, 5460, 49, 270, 264, 3749, 472, 5, 185, 26, 12381, 7, 3414, 270, 893, 8, 296, 12382, 104, 1463, 7, 166, 262, 53, 72, 163, 156, 7, 1195, 16, 17, 39, 45, 472], [8096], [12383, 111, 385], [62], [5, 92, 78, 299, 722, 11238, 7, 769, 7, 102], [19], [794, 62], [6021, 8156, 2437, 8157], [977, 15, 1444], [15, 472, 974, 617], [215, 59], [6, 186, 472], [215, 120], [14, 21, 166, 428, 7, 114, 103, 7, 114, 12384], [330, 1187], [12385], [494, 235], [123, 2875], [14, 370, 2406, 719, 7, 12386, 49, 7, 300], [619, 472, 537, 1377, 153, 299, 163, 5059], [72, 263, 126, 64], [62], [15, 385, 102], [155], [2359], [26, 104, 1574], [101, 20], [1402, 352, 185, 75, 7539], [370, 7, 12387], [19, 15, 7, 2070, 7, 12388, 51, 94, 12389, 3732, 160, 49, 7, 15, 3732, 7, 15, 42], [5535, 308, 7, 2040, 3187], [44, 779], [3053], [7, 27, 177, 306, 27, 65, 763, 7, 297, 1187, 72, 117], [14], [1490, 414, 5, 341, 765, 96, 37, 1625, 3864], [14, 120, 11398, 96, 49, 299, 277, 287, 166, 263, 12390], [1205, 368, 300], [5873, 421], [826], [27, 1474, 14, 7, 27, 106, 323, 7, 2285], [3847], [120], [921, 1722], [103], [1099, 6071], [62], [215, 7, 259], [259, 952, 259], [2856], [12391, 5762, 1123], [15, 11770, 7, 127], [442], [352, 185, 362, 21, 177, 363], [245], [660], [3724, 7, 96], [524, 5, 148, 630, 78, 5, 106, 45, 255, 949], [940, 7, 127], [89, 5, 865, 37, 7216, 326, 27, 640, 1557, 37, 2010, 7, 5, 341, 52, 1385], [14], [6, 8302, 285, 1847], [58, 7, 513, 5, 94, 388, 27, 7, 322], [414], [761, 7, 209, 187], [11], [12392, 12393], [6295], [20, 12394, 7, 20, 7, 20], [20], [399, 1070, 3160, 688, 8017, 3104, 4829, 595], [14, 120], [4361, 12395], [123, 1624, 7, 660, 639], [58], [3119], [12396], [474], [58, 2382, 7, 27, 12397, 247, 160, 49], [370, 404], [660], [215], [155], [1385, 7, 12398, 7, 95, 12399, 528, 7, 166, 2740, 1361, 12400, 3026], [2285, 111, 788], [245, 7, 776, 1071], [120], [159, 7, 528, 7, 994, 1339, 30, 12401, 355, 7, 1337, 7, 12402, 345, 10111, 7, 12403, 669], [102, 2694, 7, 440, 104, 1621], [186, 52, 516, 7, 62], [102], [5, 604, 2391, 12404, 495, 148, 12405, 5, 12406], [4664, 910], [2544], [104, 12407, 96, 78], [1062, 7965, 1966, 1297, 72, 472, 2694, 7, 252], [660], [1165, 319], [296, 7, 1544, 7, 434, 7, 363], [22], [859, 7, 117, 472, 2849, 64], [15, 43, 166, 2286, 102], [8191, 270, 12408], [20, 609], [275, 10559], [88, 124, 8020], [4, 387, 6922, 16, 2095], [382, 7, 90, 228, 4445, 7, 52, 1008], [427], [120, 513], [754], [95, 435], [651], [202, 1328, 159], [1445, 2651, 7, 568, 6923, 7, 355, 7, 75], [282, 7, 69, 103, 39, 1538, 7, 99, 27, 431, 163, 64], [3], [1242, 7, 3532], [619], [14], [4910], [50, 12409, 7, 27, 210, 622], [14, 120], [349, 75, 49, 7, 179, 96], [2544], [26, 27, 12410, 166, 510, 7, 45, 95, 8, 10581, 7, 524, 2122, 2248, 765, 72, 26, 1171, 7, 262, 1077, 107, 264, 125], [1229, 12411, 12412, 12017, 7, 363, 12413], [12414, 527], [2074], [64, 361], [9171], [4487, 738, 7, 218, 7, 365, 12415, 472, 1241, 1526], [14], [940], [2204, 1062, 264, 220], [366, 537], [16, 1729], [14, 120], [12416], [102, 96, 11937], [58], [2388, 49], [20], [5354, 3146], [4083, 17], [160, 414, 5, 308, 413, 101, 20], [4009], [1422], [5312, 12182, 12417, 699, 7, 14], [58, 7, 12418, 8], [155, 7, 106, 272, 152, 524, 1863, 463], [366, 44, 365, 91], [423, 6968], [223, 386, 104], [26, 104], [4319], [1899, 7, 12419], [1116, 7, 88, 15, 956, 619], [12420, 96, 90, 440, 104, 41], [5, 341, 230, 1474, 264, 64, 7, 2881, 137, 410, 9115, 7, 407, 1304, 7, 1040], [20, 7, 43, 64], [794], [6630, 7, 12421, 12422, 4942, 7, 12423, 1230, 5570, 2108, 7, 10487, 1231, 12424], [123, 467], [423, 229], [58, 7, 743], [663, 691], [6444, 26], [5114], [454, 412, 42, 455], [474, 9548, 1039, 7, 902], [797], [52, 270, 49], [62], [1349], [75, 5805, 2091], [6, 609, 96, 37, 3142, 17, 2731], [78, 1640], [719], [104, 386, 765, 72, 412, 104, 3292], [3], [5, 743, 1980, 592], [7323], [50, 7, 50], [160, 1622], [215, 16, 17, 39, 163, 369], [160, 39, 16, 17, 7, 91, 7, 14], [51, 1063, 104, 655, 262, 1077, 115], [26], [120], [1310, 1847], [16, 510, 277, 369, 7, 95, 15, 7367], [202, 7, 4103], [104, 386, 720, 88, 12425, 3863, 1039], [45, 437, 7, 6716, 464, 72, 1274, 134], [215], [62], [211, 185, 264, 1054, 9, 112, 166, 264, 163, 774, 12426], [3633, 862, 278, 2229], [12427, 12428, 85, 39, 12427, 12428], [542, 44, 210], [305, 159, 487, 2381, 7, 211, 177, 210], [12429, 11281], [12430, 7, 634, 7, 3203], [14, 120], [245, 7, 4223, 7, 817, 104, 228, 115, 490, 326, 719], [438, 5, 1431, 69, 12431], [27, 228, 44, 472, 263], [1040], [660], [20, 15], [59], [51, 72, 859, 7, 1987, 8608, 7, 355, 166, 51, 10814, 177, 1117, 7, 166, 297, 12432, 7, 246, 2935], [14, 1028], [3381, 37, 1524, 109, 783, 9, 303], [14], [58], [14, 365, 1422], [2069, 5059], [1099, 1369], [14, 691, 7, 44, 378, 965, 2856], [62], [2825], [417, 104, 10079, 88, 2549], [492], [12433], [794, 150, 78, 1626, 1372], [12434], [2931, 37, 125, 110], [12435], [120], [167, 743, 7, 8655, 355, 12436, 166, 3566], [15, 513, 7, 410, 49, 2425, 7, 471, 21, 157, 157], [259, 7, 6839], [8562], [1225, 5, 116, 185, 926, 841, 7, 99, 17, 7365, 72, 1010, 7, 88, 5267, 7, 5, 179, 352, 6, 152, 7, 93, 179, 352, 106, 7, 719, 72, 186], [178, 1987, 929, 10320], [582, 2973, 27, 106, 46], [372, 1337, 7, 165], [2551, 510, 20, 91, 7, 62], [382, 159, 7, 106, 104, 365, 149, 7, 159, 2226], [245], [64, 7, 260, 7, 64, 7, 126, 817, 7, 64], [202, 8453, 7, 19], [719, 7, 12437, 7, 5200], [892], [215], [245], [12438], [14], [5485, 12439, 7, 14], [12440, 5843], [12441, 1724], [14, 622], [81], [884], [474], [315, 372, 7, 5, 2923, 264, 569, 5395, 5799], [217], [1645], [1428, 72, 125, 5275], [106, 27, 15, 160, 974], [448, 15, 2399, 96, 2921, 222, 62], [607, 732], [5, 2248, 12442, 630, 264, 766], [366, 44], [2849, 1319], [489, 1010, 7, 412, 365], [58], [901, 2899, 62], [460], [715], [84, 413, 177, 12443, 410], [26, 1847], [370, 1961], [163, 2033, 1542, 7522, 163, 49], [215], [3], [1116, 5, 1856, 542, 12444], [69, 10520, 239, 91], [27, 159, 386, 859, 99, 5, 341, 574, 663], [1966, 501, 12445], [630, 264, 296, 4794, 166, 1769], [1, 7, 12446], [14], [12447, 4398, 110, 37, 12448, 7, 45, 412, 7, 6215, 5251, 681], [245], [619, 5290, 888, 72, 366, 172], [9755, 361, 7, 125], [3137], [447], [20, 12449, 7, 88, 20], [62, 7, 87, 7, 96, 12450], [705, 5533, 3129], [15, 1283, 7, 163, 2830, 7, 761], [352, 106, 447, 12451, 12452, 12453, 352, 6, 447, 12454], [367, 7, 352, 640, 412, 96, 104, 294], [581], [375, 2039, 7, 2811], [1369], [245, 7, 977], [1370, 1343], [2133, 2267], [663, 2151, 264], [104, 971, 185, 2135, 1531, 714, 582], [20, 1947], [12455, 7, 438], [10, 1623, 181], [3236, 7, 3236], [5, 185, 384, 1524, 1115, 956, 27, 7, 5, 306], [51, 209, 299, 9, 256, 7, 51, 9613, 10522, 1322, 7, 524, 1490, 25, 5, 942, 227], [3614, 8670, 94, 12456, 741, 2109], [64, 114, 103], [14, 46, 7, 2087, 1541], [4196], [12457], [472, 49, 159, 106, 104, 283, 284, 264, 12458], [49, 39, 465], [232, 7, 2213], [64, 32], [51, 45, 12459, 44, 270, 153, 7, 2921, 414, 51, 604], [0, 728, 7, 38, 7, 428, 4230], [20], [14], [75, 355, 365], [291, 7, 826, 7, 826, 7, 826, 7, 164, 17, 7, 314], [12460], [14, 997], [39, 88, 20], [0, 1590, 88, 378], [12461], [717], [568, 12462], [3026], [259, 1737], [858, 216], [2931], [492], [270, 347, 2424], [14, 647, 7, 95, 46], [464, 44], [12463, 341, 2576], [10983], [20, 21, 20, 694], [20], [414, 12464], [13], [62, 7, 6, 117, 44], [215], [62], [3], [3785], [715], [12465], [4475, 370, 363, 235, 7, 12466, 7, 448], [14, 181, 239, 240], [1039], [50], [64, 7, 582], [1616], [9818, 52, 859], [12467, 7, 90, 2530, 12468], [3514, 1443, 845], [1499, 12469, 3847], [7, 513, 569, 12470, 7, 12471, 12472, 7, 265, 21, 7], [14], [2907], [12473], [1273, 37, 3133, 369, 1267], [14, 120, 7, 366, 1574], [660], [472, 3547, 721, 4157], [12474, 1999, 472, 275, 7, 487, 363, 104, 5564], [81], [12475, 49, 7, 17, 272, 747, 7, 2650, 111, 720], [0, 7, 1010, 7, 372], [14, 120], [16, 7047, 2489, 7, 227, 1106], [10217, 34, 762, 7, 4], [902], [1449, 12476, 102], [111, 8598], [95], [12477, 609, 5965, 7], [474], [474], [123, 1010, 912, 21, 7, 9757], [6512, 137, 313, 313, 10359, 12478], [1490, 1401], [7282], [120], [717], [5934, 7, 447, 365], [15, 12479, 19], [283, 284], [46], [2677, 21, 84, 12480], [12481], [231], [513, 1699, 619, 71, 7, 104, 159, 45, 89, 12482, 1624, 44, 71], [5580, 366, 3573, 7, 12483, 341], [394], [15, 515], [259], [693, 7, 2359, 7, 77], [59, 7, 517, 285, 773], [352, 247, 663], [123, 49], [705], [1163, 374], [14], [1723, 688], [14], [433, 160, 39, 414, 5, 306, 3896, 1640, 568], [20, 956, 26], [62], [20, 3176, 7, 235, 7, 88, 1946], [2034, 4094, 7, 474], [717, 2171], [1858, 7, 2997], [832, 246, 12484, 7, 4324, 1659, 1187], [305], [268, 12485, 7, 12486, 7, 12487], [11181, 362, 413], [58], [20, 584, 3176, 2091], [2405, 270, 49], [727], [14], [12488], [56, 366, 44, 19, 4579], [12489], [2225, 7, 2225], [581], [45, 1987, 284, 7, 434, 49, 19], [12490, 7, 743, 779, 7, 779, 9027, 12491, 1229, 4621, 5616], [58], [630, 718, 8110, 2285], [120], [366, 44], [3951, 630, 16, 12492, 7], [494, 7, 160, 732, 7, 372, 297, 462], [12493], [245], [12494, 7, 123, 3626, 30, 31], [3183, 1162], [58], [15, 134, 727, 3370], [291], [91], [794], [8750, 521, 854, 179], [12495, 738], [123, 3547], [88], [15, 582], [45, 8815], [14], [16, 344, 4174], [401], [245], [15, 365, 7, 622], [4159, 1107], [285, 152, 160, 49], [14], [778, 12496, 7, 1784], [44, 164, 266, 663, 7, 3170, 2635, 659], [1875, 97, 41, 7, 952], [2002, 7, 719, 68, 7426, 7, 299, 472, 21, 305, 1039], [460, 370, 1961, 7, 6369, 31, 7, 166, 630, 939], [2328, 579, 1723], [12497], [4], [519, 104, 1010, 270, 37, 517, 2738, 326, 286], [0, 7, 27, 519, 88, 164, 12498], [849, 738, 7, 91, 7, 14], [99, 93, 179, 627, 2783, 7, 627, 297, 1382, 370, 865, 96, 627, 7, 20, 3198, 407], [91], [636, 12499, 8240], [5, 6, 210, 937, 1941, 205, 1105, 303], [655, 386, 37, 1911, 4247], [37, 6002, 6003], [10472], [215, 120], [315, 5, 314], [15, 42, 7], [3580, 12500, 90, 971, 179], [410, 4431, 7, 410, 7, 609, 925], [94, 27, 283, 284], [1490, 12501], [14], [428, 8252, 125], [46], [179, 7, 835, 1471], [732, 7, 6582, 256, 7, 68, 37, 1279, 4554, 7, 5, 498, 117, 104], [6295], [884], [2528, 582, 2783], [270, 205, 485], [166, 104, 860, 16, 7965, 12502, 284, 9, 37, 1574, 5919], [44, 761], [1645], [14], [14], [702, 6131, 91, 7, 12503, 7, 1826, 1174, 777, 270, 264, 5641, 363, 7, 719, 722, 7467], [638, 186, 104, 2489, 264, 17, 472, 8864, 72, 630, 11743, 7, 410], [884], [14], [64, 2951, 7, 12504, 12505], [62], [148, 1531, 105, 655, 51, 39], [1099], [182, 458, 7, 427], [2452, 1170, 12506], [7851, 12507, 7, 7851, 12508], [20, 20], [120, 96, 205, 2056, 7, 366, 3499, 166, 527], [120], [581, 1481], [12509, 12509], [359, 37, 222, 895, 4602, 291], [811, 1346, 45, 242], [1425, 9797], [78, 39, 52, 275], [412, 42, 4481], [762, 21, 808, 627, 34, 7, 12510], [245], [104, 148, 185, 72, 1159, 72, 4937, 6260], [474, 7, 59, 7, 366, 244, 7, 743, 264, 2352], [2981, 8042], [732], [417, 124], [702, 144, 7, 798, 3982, 6119], [12511, 7, 51, 307], [350], [12512, 7, 12513], [489, 1529, 127, 7, 474], [1039], [2070, 817, 7, 7331, 6867, 474], [160, 728, 39, 40, 7, 3895], [45, 46], [1853, 7, 12514, 12515], [1756, 8209, 7, 12516], [12517, 20, 12518, 7, 581, 5033, 7, 7664, 5033, 7, 7978, 1011, 5412, 5033, 270, 16, 694], [3568], [359, 386, 93, 1077, 542, 264, 1708, 1177, 7, 26, 472, 467, 39, 1618], [12519, 7, 27, 372, 228, 38, 7, 5, 2381, 160, 39, 2942, 2366, 88, 263, 363, 1104, 7, 27, 306, 27, 106, 152], [568], [826], [3970], [215, 59], [12520], [1449, 478, 7, 253], [15, 19, 8075, 8586, 7, 544, 64], [717, 120], [12521], [15, 85, 7273, 3342], [27, 1144, 53, 7, 12522, 7, 6576, 7, 3540, 7, 6423, 7, 12523], [3582], [4318], [12524, 7, 5511], [2225], [370, 160, 39, 1229, 9221, 7, 88, 4521, 1315], [215, 582, 215, 12525], [245], [487, 49, 5, 473, 160, 1268, 1147, 268, 485], [102], [12526, 953, 12527], [12528], [16, 17], [749, 4613, 1107, 7, 12529, 264, 12530], [1040], [2666, 11650], [20, 7012, 474, 893, 1751, 7, 2470, 7, 120], [1, 7, 399, 1980, 7, 16, 12531], [242], [51, 94, 52, 38], [211, 386, 12532, 7, 942, 114, 72, 305], [362, 417, 52, 72, 8, 2631, 2132, 808, 160, 64], [62], [2757, 44, 264, 12533], [95, 46, 5, 94, 12534, 27], [15, 627, 19, 7, 242, 166, 2698, 7, 102], [216], [1502, 68, 44, 7, 1314], [259], [15, 37, 1741, 7, 366, 37, 172, 474], [123, 464], [378, 12535], [472, 7130], [1524, 1128], [794], [902], [5605, 1863, 72, 1245], [1899], [14, 120], [2014, 595, 2965, 41, 7, 1653, 798, 706], [120, 622, 233], [114, 103], [5309, 7, 574, 3787, 7, 5, 743, 472], [12536, 4909, 71], [1172, 501], [884, 7, 1346], [22], [9402, 78, 1457], [4, 7, 15, 42], [8769, 1382], [985, 1766], [12537, 7, 370, 149], [5258], [20], [89, 52, 5], [120, 582], [322, 104, 568], [14, 17], [62, 352, 52, 264, 12538], [524, 104, 15, 883, 7, 166, 1622], [14, 7, 120], [14, 20, 361], [166, 104, 2585, 743, 104, 386, 163, 859], [6787, 7, 15, 1028], [359, 27, 386, 5514, 88, 5937], [14], [1853], [431, 1349], [155], [283, 284, 19], [14], [62], [1851, 808, 2151, 802, 1661], [423, 41], [56, 96, 117, 37, 64], [15, 5843, 164, 3639], [2601], [46], [744, 7, 166, 859, 1544, 270, 1381], [9440, 5, 640, 228, 21], [12539], [104, 925, 1374, 2804, 3447], [20], [352, 247, 7, 352, 117, 681], [14], [56], [743, 19], [12540, 733, 12541, 454, 2892], [1242], [62], [414, 681, 117, 44], [1078, 72, 323], [215, 7, 46, 7, 95, 8544, 7, 448], [3029, 30, 37, 3584], [27, 247, 37, 49], [1089], [1435, 12542], [1490, 307, 308], [14, 20], [7352, 263, 7, 743, 1850, 12543], [300], [1748, 1346], [917], [2556], [15, 1892], [27, 319, 3147], [123, 361], [12544, 90, 2547, 10035, 7, 9448, 7, 4814], [4, 7, 378, 622], [901, 264, 8739], [14, 120], [59, 7, 366, 44], [95, 117, 205, 1311], [0, 7, 88, 859], [91], [414, 186, 1907, 126, 270, 177, 1119], [3293, 569, 12545], [713, 487, 1924, 7, 788, 7, 7138, 12546], [217, 7, 370, 2804, 1529, 91], [5, 306, 27, 319, 3147, 235], [62], [123], [46], [12547, 7, 334, 7], [95, 12548, 7, 948, 1767, 12549, 270], [14], [4808, 49, 177], [12550], [977], [163, 344, 7, 223, 1531, 3060, 3414, 270, 153], [368, 660], [1039], [215], [3009, 4153, 12551, 12552], [2057, 12553, 7, 10578, 7, 12554, 7, 177], [643, 223, 186, 1851, 126, 37, 12555, 1542, 363, 7, 9828, 68, 8272, 569, 9400, 812, 7, 472, 5050, 1144], [604, 37, 49], [420], [58], [412], [494, 7, 314, 16, 1047], [7, 160, 1590, 88, 147], [1899], [569, 7, 75], [3382], [12556], [64, 496], [58, 7, 41], [20, 103, 7, 3], [362], [2641, 12557, 12558, 7, 7237, 7, 236, 39, 78], [14], [13], [104, 163, 476, 604, 37, 49, 7, 1531, 524, 352, 177, 463, 507, 1722, 94, 4944, 104, 7, 472, 39, 417, 125, 104, 386, 7, 8857, 45, 1987, 284], [12559, 7, 12560, 738, 7, 125], [892, 7, 1215], [352, 4618, 42, 264, 3057, 21, 7], [91], [2881], [7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 9125, 2798, 6474], [412, 3558, 51, 12566], [762, 582], [378, 10959, 7, 89, 1851, 490], [259, 12567], [2014, 595, 2965], [14, 120], [5, 314, 11065, 9, 1859, 12568, 7, 160, 39, 163, 125], [1629], [877], [1723, 688, 5624, 7, 592, 5624, 259, 1737], [6, 1531, 487, 499, 4445, 7, 1833, 7, 341, 893, 103, 12569], [20, 1436], [2653, 44, 159, 1538, 39, 1826, 34, 863], [489, 940, 7, 901, 319, 216], [39, 14, 7, 15, 3361, 7, 5885], [14], [12570], [62, 7, 164, 1024], [123, 1422], [88, 1756], [102, 96, 412], [45, 1590, 361, 88, 465, 7, 51, 12571, 743, 264, 5942], [260, 1558, 12572, 1558, 12573], [245], [14], [123, 528], [148, 117, 622], [12574], [3415, 7, 9718, 7, 12575], [15, 229], [5, 247, 37, 49], [1997], [1215, 7, 367], [18, 413, 24, 349], [517, 49, 270, 75, 4051, 2060, 7, 12576, 4009], [1514], [494, 7, 88, 164], [215, 120], [1204], [3346], [12577], [859, 467, 12578, 7, 2541], [39, 51, 1977, 1187, 7, 5, 185, 372, 164, 12579, 7, 492], [62, 7, 370, 404, 7, 260], [634], [12580, 7, 5510], [4039, 791], [365, 148, 107, 16, 21, 862, 244], [524, 782, 319, 1556], [62], [236, 2600, 7, 166, 160, 804, 7, 937, 7, 15, 537, 365], [7, 239], [3147], [718, 7, 1751], [1645], [1774, 2532], [88, 5, 148, 105, 417, 78, 7029, 7, 315, 36, 7, 35, 39, 4701, 17, 7, 12581, 78, 2541], [59], [62], [985, 985], [62], [352, 106, 186, 472, 291], [1389], [516, 2081], [20], [12582, 7, 102], [20, 35], [262, 52, 5514, 27], [92, 352, 1011, 12583, 5889, 68], [9613, 471], [12584], [3773, 6149], [12585, 12586, 62], [4958, 1204, 4325, 149, 4066], [62, 37, 307, 1708, 7, 148, 1103], [36, 95, 347, 166, 46, 49], [5, 94, 185, 37, 2694, 104, 1057, 7, 368, 1829], [394], [1040], [717], [3], [12587], [352, 604], [14], [62], [895, 105, 417, 72, 297, 7539, 166, 181, 239], [155, 1443], [1645, 7, 62], [15, 177], [1997, 7, 2078], [14], [447, 42], [717, 937, 7, 1475], [5, 6, 1531, 242, 472, 465, 359, 5, 464, 72, 242, 7, 93, 185, 12588, 37, 9473, 111, 471], [166, 3780, 413], [14, 21], [414], [217], [1899, 7, 12589], [14], [582, 1029, 270, 779, 103, 7, 386, 104, 264, 12590, 2875], [259], [798, 1240, 374], [99, 104, 106, 12591, 7, 153, 7, 5, 185, 681], [15, 733, 365], [1899], [352, 454, 181, 355, 96, 12592], [149, 239], [1270, 7, 2328, 137, 6952], [6250, 27, 264, 1004, 189], [14], [12593, 7, 117, 12594], [494], [7, 241, 2262], [372, 895, 2406], [370, 2347, 1297], [820], [341, 247, 37, 49], [719, 186, 104, 66], [826], [1419, 104, 185, 884], [12595, 96], [370, 7, 352, 386, 45, 296], [14, 120], [4586, 7, 5576], [15, 1176], [1021], [38], [7792, 3355, 7, 1252, 1252, 7, 1804, 7, 62], [12596], [474], [12597], [2049, 149, 582, 7, 120], [524, 52, 34, 7, 524, 12598, 34, 5, 94, 323, 7, 26, 7, 5, 862, 568, 7, 5, 24, 412, 96, 3414, 7, 34, 370, 467, 412, 96, 44, 7, 37, 26], [7794, 39, 265, 465, 565, 294], [447, 4290], [420], [5831], [3, 7, 215], [738], [472, 39, 719, 16, 1795, 2973], [5, 10071, 12599, 7, 12600, 12601], [622, 21, 365], [30, 196, 51, 926, 27, 7, 817, 96, 7943, 1419], [15, 1622], [5311, 414, 27, 126, 7, 1272, 27, 185, 264, 296, 17, 7, 88, 283, 284], [216], [584, 49, 65, 7, 8, 191, 584, 119], [95, 26, 8239], [12602], [13], [420], [218, 27, 12603, 1987, 284, 7, 368, 45, 264, 49], [1040], [12188], [13], [14], [732, 7, 123, 2531], [10502, 2965, 7, 3161, 7, 4203, 6153], [62, 7, 14, 7, 370, 1556, 7, 12604], [51, 11719, 44, 802, 4408, 569, 359, 5, 325, 3259, 96, 42], [370, 45, 2900, 363], [3, 7, 719, 39, 160], [51, 12605, 2435, 7, 2225], [90, 1099, 1719], [75, 738, 489, 7, 52, 1731], [12606], [123, 812, 27, 6387], [2591, 568, 96, 719], [16, 487, 15, 1791, 68, 385], [0], [245, 740, 3129, 12012, 3130, 7, 5532, 12607, 118, 76, 414, 701, 12012, 64], [660, 14], [31, 569, 7, 12608], [746, 2721, 37, 544, 812, 111, 2422, 166, 283, 37, 26, 205, 12609], [4, 160, 1346, 7, 15, 929, 365, 7, 3245, 49], [3], [410, 569, 7, 62], [93, 386, 88, 125, 266], [719, 264, 3334, 49, 2081], [12610], [69, 1091, 12611, 3065, 5866, 663], [7352, 1977, 6731, 101, 1977], [62, 7, 5, 1470, 87, 7, 359, 27, 12612, 7, 299, 1016], [45, 12613, 3413, 27], [394], [27, 412, 44, 7, 5, 105, 7, 663, 7, 224, 35, 7, 370, 149], [1574], [1005, 2151, 3722, 7, 185, 52, 777, 929, 720, 96, 264, 1721], [977], [688, 770, 3331, 7, 137, 3331, 1588], [4223], [761, 7, 761, 7, 104], [7, 7, 7], [45, 46, 78, 5450], [231], [372, 385], [104, 148, 319, 49, 322], [12614], [12615, 12616, 12617, 12618], [20, 5033], [800, 7, 15, 527, 102], [127], [58], [52, 639, 268, 3359], [89, 27, 314, 7, 472, 7, 2221, 7, 1839], [104, 277, 164, 894], [1088, 604, 104, 160, 49, 7, 7343, 125], [3690], [64, 17], [1929, 492], [62], [581, 9262], [102], [102], [7612, 7613, 12619, 1014, 7, 776, 148, 105], [7, 2624], [120, 721, 7, 12620], [4721], [27, 859], [19, 412, 5, 455, 7, 264, 2429, 216], [2605, 355], [300], [14, 7, 15, 32], [1621], [447], [756, 366, 27, 177, 524, 447], [11854, 7, 12621, 27], [2798, 186, 52, 149], [417, 418], [102, 58], [569], [38, 52, 40], [1260, 681], [3690], [3645, 7, 181, 7, 62], [13], [772, 12622, 7, 1005, 39, 37, 12623, 111, 12624], [698, 45, 12625], [652], [901, 859, 235], [160, 1810, 8914], [26, 27, 7, 20, 21], [106, 104, 159, 15, 11501, 96, 765, 825], [186, 27, 314, 7, 811, 4808], [45, 10595], [72, 669, 166, 1187], [6446, 7, 4989], [5, 10149, 472], [892], [14, 1153], [925, 16, 344], [717], [6130, 7, 90, 1343, 776, 7, 776, 1821], [370, 372, 7, 386, 27, 194], [776, 7, 292, 293], [37, 26], [5, 1170, 160, 1783, 299, 264, 544, 1176, 3921, 956, 12626], [99, 51, 431, 429, 72, 915, 264, 4050, 5889], [2096, 163, 12627, 65], [1383], [12628, 16, 5123], [12629], [104, 159, 386, 12630, 218], [3], [102, 425], [12631], [6022, 7, 35, 118, 7, 974, 266, 7, 493], [794, 155, 7, 14], [886, 7, 1704, 7, 12632], [104, 935, 166, 12633, 447, 96, 3129], [5095], [369, 115], [78, 3541, 7, 563], [297, 1187, 97, 7, 209, 461, 1187, 160, 49], [65, 179, 127, 507, 360, 4645, 166, 2333, 7, 362, 812, 7, 5, 228, 472, 93, 94, 210], [88, 3334, 7, 177, 228, 361], [1225, 378, 385], [7836], [20, 103], [166, 274, 407, 317], [7, 5, 2076, 91], [62, 160, 1471, 7, 1826, 1471], [1831], [1590, 431, 148, 185, 264, 112], [46, 322, 7, 15, 2874], [1215, 4, 3198], [210, 111, 129, 1481, 12634], [12635], [717], [1679, 7, 5897], [64, 1219, 1490, 177], [14], [227], [12636], [850, 7, 3738], [7, 970], [5, 1107, 7, 96, 16, 12637], [1815, 1425, 6749], [12638], [1240, 1342, 822], [417, 72, 3497, 69, 10959, 7], [14], [14], [46, 12469, 4692, 12639], [14], [798, 259, 595], [1219, 39, 471], [26, 467, 499, 7, 1010], [624, 7, 12640], [5, 384, 45, 186, 12641, 125, 88, 26, 1847], [215], [62], [719, 7, 2328, 7, 12642], [420], [166, 627, 7, 5652, 2774], [14], [4162, 7, 20], [1521, 1401, 233], [20, 741], [104, 185, 181, 12643, 8020, 7, 166, 51, 39, 52, 12644, 4458], [8562], [62], [414, 52, 7, 330], [27, 89, 7, 663, 7, 299, 12645, 7, 719, 7502, 89, 27, 186, 7, 9085, 72, 445, 21, 7, 370, 7, 1430, 44], [26, 104, 788, 7, 857, 7, 463, 7, 463], [215], [7, 414, 239], [474], [448, 15, 1775, 96, 802, 264, 12646, 344, 223, 6, 8, 160, 49, 7, 91, 91, 91, 91, 12647, 91, 91, 7, 818, 5, 107, 472, 1187, 7, 5, 306, 51, 1293, 274, 1052, 1770, 1297], [15, 1574, 365, 41], [192, 256, 46], [2622, 1734, 5998, 49, 765], [474], [155], [794], [20], [62], [2495, 7, 610], [14], [227, 811, 1312, 7, 386, 369], [794, 2621], [2156], [252, 1947], [232, 7, 2921, 4942], [123, 803, 817], [412, 7, 1349], [155], [315, 7, 448, 186, 7, 5, 228, 489, 96, 898], [794, 8, 3717], [106, 104, 323], [1153], [741, 330, 72, 10751, 322, 7, 330, 72, 10751, 12648], [719], [3506], [2213], [5, 516, 7, 492], [62, 7, 160, 16, 17], [14], [1385], [14, 3204], [1961, 7, 14], [62], [45, 437], [622, 39, 1010, 2885, 4554, 6932, 30, 35], [3170, 1882, 795], [12649], [14, 120, 7, 123, 17], [14, 160, 527, 88, 163, 859, 7, 46, 365], [4778], [719, 264, 10729, 4956, 513], [366, 44], [117, 44, 1969], [1997, 7, 102, 509], [3690], [2568], [259], [12650, 3889], [62], [91], [44], [0, 619, 314], [12651], [15, 4495, 8135, 7, 544, 677], [62, 999], [472, 4752, 229, 1828, 7, 5, 4524], [12652], [12653, 7, 303], [489, 117, 166, 75, 6290, 270, 4782, 2738], [12654, 7, 52, 88, 1253, 7, 9026], [1899], [91], [5, 12655, 7, 322, 352, 106, 117, 27, 569, 119], [14], [1210, 7, 2025, 44], [12656], [568, 96, 1823, 7, 102], [14], [524, 5, 148, 12657, 804, 16, 361, 94, 1103, 177, 49], [46], [10, 76, 7, 217], [3041, 5, 431, 185, 42, 12658, 7, 245], [826, 7, 16, 12659, 88, 164], [761, 11903], [6297, 287, 273, 72, 8, 270], [62, 7, 5354], [45, 439, 2122, 4409, 1716, 7, 895, 66, 104, 185, 72, 630, 88, 6864, 7, 166, 1018], [743, 901, 372, 859, 5, 314, 42, 965, 5, 228, 75, 3637, 743, 42], [26, 27, 75], [462, 2039], [210], [16, 7693, 7, 1844, 111, 125, 7, 417, 416, 104, 7, 756, 26, 205, 1201, 7, 677], [6, 3217], [245, 245, 245], [446], [104, 319, 521, 741], [12660, 490, 39, 264, 3203, 320, 270, 16, 17], [1333, 7, 20], [985, 2468], [1294, 99, 14], [12661, 7, 5, 743, 69, 2351, 7, 1039], [14], [179, 127, 12662, 5, 185, 75, 163, 9221, 223, 242, 7, 177, 41, 7, 314, 719, 264, 163, 761, 883], [245], [62, 7, 5100, 404], [1320], [14], [14, 120], [102], [12663, 7, 1560, 104, 12664, 179, 205, 1481, 299, 12665, 7, 90, 94, 314, 8625, 110], [884, 7, 460], [634], [12666], [15, 190, 19], [5725, 7, 8077], [26, 104], [41], [104, 386, 88, 1716, 78, 4346, 32], [62, 7, 352, 447, 96, 2362], [1707, 582], [5, 971, 179, 7, 925, 44, 1721, 5, 437, 16, 49], [50], [62], [448, 412, 7, 39, 11081, 322], [62, 7, 62], [12667, 499, 4416, 948], [12668], [894, 4481, 233, 9959], [472, 39, 417, 859], [123, 1624], [12669, 12670], [1062, 7, 414, 27, 12671], [88, 417, 418, 352, 12672, 412], [474], [372], [14, 7, 5, 1640, 1557, 3234, 1047, 9682, 5, 630, 35, 7662, 7, 693, 4956, 111, 413], [2886], [14], [12673, 7, 12674, 78], [326, 37, 362], [4141, 7, 14], [12675], [701], [93, 1077, 152, 7, 192, 929, 2637, 270, 12676, 7, 5, 2653, 929, 7, 412, 7, 12677, 7, 12678], [58, 41], [16, 1117, 386, 220, 166, 12679, 7], [14], [186, 3414, 185, 55, 12680, 7, 5, 116, 52, 9242, 472, 4626, 12681, 12682], [215, 3824, 7, 2359, 7, 2640, 3250, 316], [1074, 264, 344, 5059, 7674], [20, 21], [610, 2944, 12683], [2049, 12684, 7, 5403, 12685], [977], [5, 92, 88], [892], [245], [27, 12686, 1915, 2751], [123, 464, 218, 7, 3292], [283, 37, 26, 284], [27, 159, 45, 164, 7, 99], [39, 472, 104, 7, 6965], [62, 7642], [7623], [3100, 1028, 870], [39, 160, 413, 6659], [2013, 21], [12687, 7, 27, 221, 1550, 9145, 101], [215, 91], [147, 1681], [368, 275, 695], [472, 2152], [106, 104, 159, 52], [1997], [50, 7, 102], [888, 974, 1337, 1116], [14], [1853, 7, 1853, 64], [544, 1300], [315, 1205, 34, 62], [14], [352, 386, 52, 1312, 219], [12688, 7, 40], [51, 39, 52, 1659, 1187], [1062], [2247, 352, 89, 52, 4607, 42, 7, 51, 39, 37, 747, 3310], [12689, 7, 1499, 7, 1499, 7, 817, 7, 1499], [157, 157], [102], [12690, 133, 11900], [22], [370, 12691, 19, 7, 192, 42, 330], [2303, 1737, 399, 5100, 7, 12692, 399, 12693], [370, 5, 14], [2060], [104, 1558, 3544, 101, 859, 72, 246, 12694], [245, 721], [90, 341, 1385, 1052, 111, 160, 2361, 185, 1915, 1128, 96, 363, 12695], [62], [245], [1383], [14], [95, 46], [474], [88, 386, 27], [1069, 1070], [2678, 110, 111, 1855, 2165, 39, 4690], [3378, 49], [370, 78, 299, 88, 740, 7, 5, 664, 2979, 7, 3558, 45, 322, 7, 619, 1699], [274, 12696, 72, 186, 9, 7, 417, 125, 7, 1574, 39, 7, 291], [1992, 359, 90, 1011, 370, 1117, 26, 3988], [2367, 7, 385, 7, 3], [2352, 798, 798, 12697, 1775], [14], [20, 35, 5, 630, 410, 7, 265, 20, 7, 2064, 166, 435], [58, 1219, 2132, 4319], [330], [16, 164], [14], [366, 894, 166, 1034], [96, 287, 7, 3623], [5, 6, 2637, 160, 341, 1856, 4642, 51, 39, 859], [104, 272, 516, 5580], [15], [27, 64], [420, 7, 5, 640, 1531, 228, 21, 153, 7, 160, 162, 296, 1180, 3197], [474], [15, 160, 2215, 125, 365], [14], [1856, 160, 17, 8914, 88, 465, 7, 104, 12698, 12699], [12700, 12701], [5, 2763, 96, 104], [790, 7, 663], [569], [215], [464, 2048], [22, 507, 2849, 895, 105, 51, 106, 6053], [474, 7, 14, 120, 7, 58], [1708], [2328], [96], [5949, 1999, 5239, 72, 366, 7, 1533, 2237, 9, 12702, 7, 41], [977], [1040], [5578, 7, 12703], [719, 299, 472, 239], [524, 27, 148, 283, 284, 756, 15, 27], [1682, 7, 1106], [2419], [164, 96, 256], [1174, 754, 2064, 7, 20], [6340, 205, 172, 96, 507, 1176, 7, 37, 2121, 109, 39], [14], [474], [14, 7, 7858, 44], [3633, 2537, 296], [20], [39, 264, 25, 994, 524, 7, 104, 386, 52, 53], [660], [492], [262, 621, 2050], [2048, 1180, 104, 2130, 7, 166], [58], [863, 4345, 9717, 7, 378, 528, 7, 378, 1219], [999, 609], [14], [365, 235, 323, 7, 5, 454, 78, 7, 734, 88, 155], [14], [2081, 2082], [12704], [5, 95, 21], [120, 7, 159, 7, 3377, 355], [2768, 2768], [423, 10791, 10791, 7, 12705, 7, 12706, 7, 761, 361, 4037, 7, 95, 791], [370, 87], [651], [977], [91, 7, 9751, 4408, 7, 160, 49, 7, 1529, 101, 278], [985, 2468], [7, 677, 17, 39, 52, 1544, 7, 39, 6338, 7, 817, 329, 355, 10350, 12707, 166, 774, 12426, 1330], [985, 7, 26, 1847, 1377, 934, 125], [12708, 7, 245], [93, 908, 7, 177, 8209, 68, 44], [123, 2643], [14], [1846, 27, 148, 2468, 7, 12709], [378, 172], [39, 78, 10217], [102, 7, 166, 1422], [414, 44], [59, 1662], [8801], [52, 1531, 75, 940], [717], [7363], [12710, 660], [368, 264, 12711], [125, 2382], [434, 49, 27, 349, 78, 2130, 635, 27, 925], [732, 4566, 743, 8878], [14], [1658, 44], [62, 160, 159, 1915, 12712, 177, 49, 7, 245], [78, 563, 52, 107, 97, 1180, 472], [3], [513, 64, 7, 20, 21], [12713, 20], [12714], [62], [12715, 12716, 639, 12717, 20], [15, 1949, 1039], [11877, 163, 1038], [12718, 7, 474], [1039], [14, 7, 20], [2204, 2696, 7, 11494, 7, 12719], [5, 81], [12720, 12721], [3182], [12722, 7, 1966, 2179, 2720], [100, 746], [262, 3413, 104], [3, 7, 719, 264, 1004, 18, 565, 303], [75, 2361, 247, 160, 49, 7, 527, 166, 3499], [5110, 7, 14], [794, 104, 386, 88, 64], [15, 428, 7, 39, 277, 7, 64], [474], [14, 46], [1661], [3170, 1882, 7, 2753], [7753, 607, 3047, 7, 62], [1272], [2161, 3298], [779, 2091, 2111, 152], [347, 7, 525, 738, 7, 362, 17, 1828], [3533, 738, 374], [1073], [971, 185, 247, 607, 181, 2484, 7, 524, 78, 8300, 96, 886], [64, 1471, 1106], [19, 412, 7, 794, 492], [493, 7, 474], [810, 30, 37, 677, 7, 96, 40], [57, 7, 841], [4085, 125, 7, 428, 37, 1826, 7, 901, 407, 166, 2923, 177, 16, 115], [14], [7, 440, 527], [640, 1089], [1987, 44, 37, 1726, 7, 5, 94, 46, 78, 7, 2622, 472, 264, 370, 34], [718], [489, 355, 425], [14], [5, 440, 1147], [56, 7, 262, 264, 609, 2130], [420], [370, 361, 17], [1709, 191, 1174, 777, 270, 264, 418, 363], [368, 818, 7, 46, 365, 7, 2066, 17], [1903, 2681], [15, 160, 728, 7, 369, 2292], [319, 69, 1187, 235], [12723, 1567, 12724, 7, 12725], [1048, 274, 743, 3021, 444, 72, 246, 956, 164, 956, 93, 386, 2130, 12726, 268, 1004, 444, 414, 2671, 1640, 246, 88, 231, 275, 929], [569], [412, 12727, 7, 1864, 1078, 72, 323], [27, 1661], [1708, 299, 231], [3, 14, 738], [4], [2213], [300, 582, 300, 91], [215, 7, 1106, 245, 7, 12728], [20, 609, 20, 49], [651], [3, 7, 12729, 12730], [1349], [4808], [45, 46, 160], [859, 464], [27, 463, 7, 1644], [12731, 78, 778, 19], [440, 627], [513], [474], [892, 7, 7, 95, 1422], [102], [3989, 32, 299, 101, 859, 96, 27, 5, 1560], [51, 1155, 630, 264, 12732, 45, 1195, 111, 104], [16, 17, 370, 467, 106, 285, 609, 368, 465, 72, 8, 743, 160], [3], [1314], [366, 44], [26], [62, 7, 21, 762, 111, 8500, 14], [788], [245], [20], [14], [5, 10875, 16, 12733], [2496], [1607, 39, 3206, 3893], [1195, 20], [12734], [423, 7, 123, 485, 7, 7134, 78, 19, 7, 5, 228, 26], [14, 120, 7, 12735, 21, 7, 12736, 743, 264, 5942, 7, 5, 2592, 104, 299, 1077, 285, 341, 7, 99, 37, 49, 162, 619, 7, 101, 859, 507, 1216, 39, 264, 163, 1844, 111, 125], [2928, 7, 12737, 7, 733, 7, 733], [62], [977], [7581, 7582], [3], [259, 4192], [12738, 12739], [51, 246, 859], [14], [3250, 489, 732, 7, 5, 152, 7, 12740, 7, 177, 1810, 322], [14], [799, 7, 88, 64, 17, 7, 93, 148, 1119, 7, 93, 8, 743, 125, 7, 3690], [12741], [489], [58, 41], [12742, 7, 12743, 7, 12744, 7, 12745, 7, 158, 7, 2798, 6119, 7, 12746, 12747, 7, 12748, 4385], [455], [889], [45, 72, 26, 9, 104, 794], [14], [3704], [798, 374], [754], [51, 39, 12749, 148, 366, 42], [3444], [414], [15, 7, 893, 103], [27, 163, 3350, 7, 52, 1751, 7, 41], [160, 49, 7, 39, 88, 155], [5, 66], [69, 11867, 12750, 2685, 275, 11823, 1430], [663, 5942, 7, 412, 96, 9761], [0], [754, 7, 2825], [14], [619, 7, 322, 5, 105, 414, 7, 1556, 7, 3951, 884, 7, 30, 196, 2108, 12751, 8353, 474], [2971, 39, 88, 1756], [12752], [215], [352, 152, 376, 49, 7, 794, 660, 7, 5, 630, 37, 1524, 8800, 17, 7, 808, 487, 329], [1632, 101, 2255], [14], [114, 75, 285], [470, 974, 39, 125], [1899], [1425, 505, 7, 12753], [69, 724, 39, 88, 1661, 7, 1319, 1382, 45, 163, 1089], [9506, 12754], [12755], [27, 94, 2563, 160, 375], [14, 120], [20, 4221], [27, 386, 609], [372], [51, 3489], [822, 458, 1304, 3125, 3163, 12756, 688, 4340], [17, 299, 125], [245], [148, 246, 88, 1452, 159], [0, 352, 412, 96, 104, 104, 159, 186, 160], [447, 16, 1204, 7, 761, 14], [14, 120], [2823], [20, 21], [5, 1170], [12757, 41, 7, 7317, 7318, 158], [417, 263, 5283, 5866], [149], [3146, 35, 7, 6577], [561, 821, 1070], [90], [2064, 274, 5637], [3], [2328, 1678, 579, 12758, 884], [4259, 1650, 264, 12759, 7, 39, 160, 1116], [14], [513, 27, 925, 7, 166, 126, 7, 27, 89, 1851, 35, 7, 52, 264, 7522, 2221], [39, 52, 1650, 125], [2293], [794, 26, 78, 7, 370, 361], [163, 12760, 7, 1846, 27, 4417, 693, 7, 6, 3577, 4904, 12761, 1847, 7, 12762, 4459], [102], [756, 1987, 27, 9187, 7, 330, 1128], [2060], [14], [4223], [370, 2576, 7, 3498, 355, 7, 91, 7, 12763, 7, 12764], [215], [1314, 7, 163, 7533], [5762, 365], [62, 5315], [215], [715], [492], [3527, 12765, 7, 57, 7, 12766, 12767, 7, 693], [27, 820], [4891], [5739, 7, 15, 883, 8135, 19, 7, 166, 7426], [22], [14], [1642, 1642], [627, 152, 27, 21, 465], [16, 4590, 1762, 96, 44], [215], [163, 1661, 487, 285], [507, 1952, 39, 1748, 270, 3372, 7], [215, 17], [850, 15, 622, 19], [12600, 12768, 7, 5212, 1000, 7, 12769, 7, 12770, 12771, 7, 717], [655, 89, 27, 95], [12772, 1383, 567], [474, 7, 2506, 12773, 7, 220, 110], [608, 44, 41], [1060, 1657, 37, 921], [181, 239, 372], [351, 351], [291], [18, 39, 88, 64], [14], [90, 983, 984, 7, 9000, 458, 4831, 984, 3886, 7, 5541, 3479, 3440, 2164, 5308], [5, 12774, 7, 57, 12775], [62], [14], [51, 89, 264, 859, 3787, 68, 17, 1008, 7, 104, 299, 37, 467, 5010, 7, 1542, 7, 7522, 7, 363], [62], [0, 7, 1848], [9828, 27, 247, 264, 3420], [14, 120], [14], [1206], [519, 12776, 12777], [1425, 1719], [2568], [91, 7, 427], [370, 5764, 495], [12778], [14, 120], [2994, 7, 845], [956, 524], [3595, 7, 3595, 7, 2681, 365, 7, 45, 12779, 7, 1766, 7, 106, 27, 9030, 256, 270, 1315, 365], [104, 372, 386, 1716], [45, 323], [521, 7, 2087, 925], [12780], [14], [3785, 984, 2182, 823], [718], [181, 7, 10], [123, 7, 50], [215], [177, 50], [366, 564], [12614, 7, 90, 66, 7, 1005], [43, 160, 2078, 622], [62], [14], [319, 12781], [446], [341, 7, 104, 6, 202, 256, 7, 104, 64], [1040], [14], [474], [1732], [20, 1542, 153, 372], [62], [3690], [1458, 149], [2856], [104, 1640, 568, 1969], [738], [370, 17, 2532], [57, 12782, 125, 2579, 7, 57], [420, 681], [62], [12783], [12784, 3428], [14, 7, 761, 16, 17], [14, 120], [166, 1103], [215], [14], [513, 305, 35], [4165], [1725, 7, 489, 1529], [4596, 27, 454, 2576, 7, 96, 4793], [277, 2161], [14], [277], [1607, 39, 264, 361, 7, 5, 106, 15], [660], [14, 120], [474], [581, 96, 44], [5290, 12785], [45, 264, 464], [677, 2095], [3137, 7, 217], [13], [394, 394], [15, 622], [1151], [1044, 1382], [738], [715], [581], [12786], [69, 1147, 101, 7, 1681, 7, 2244], [134, 148, 347, 699, 7, 148, 186, 78, 265], [385, 1855, 355, 3287, 7, 177, 39, 660, 7, 370, 7, 52, 1855, 7, 227, 7, 3607], [2506, 5391, 12787], [474], [14], [12788], [50], [12789, 2530, 776, 1240, 9157], [26, 104], [581, 6332], [120, 7, 163, 609], [45, 4177], [749, 4569, 39, 2135, 7, 223, 2476], [4], [217, 7, 219, 7, 374, 7, 95, 149], [13], [20, 103], [14, 120], [2381, 368, 1659, 7, 3], [88, 20], [15, 65, 96, 242], [668, 12790], [3629], [12791], [14, 7, 691], [12792, 414, 104, 1074, 1722, 235], [370, 7, 115, 363], [412, 96, 42], [12793, 7, 1369], [14], [5, 306, 390, 2562, 160], [12794, 334, 7, 3773, 252], [27, 152, 7, 57, 719, 264, 279, 8, 7, 1056, 7, 12795, 103], [58], [14, 120], [120, 732], [51, 39, 1240, 7793, 12796, 457, 2328, 90, 2336, 145, 12797, 7, 88, 448, 7, 283, 37, 26, 284], [14], [62, 7, 62], [1], [3414, 223, 79, 270, 1258, 148, 2120, 2987, 7, 52, 1531, 2346], [96, 264, 859, 49], [19], [12798], [3], [3], [1018], [46, 284, 44, 166, 37, 2022, 7, 245], [6096], [12799, 7, 630, 860], [1723, 688, 12727], [718], [4, 728, 1365, 893], [417, 37, 26, 27, 4039, 44, 1312], [62], [149, 96, 264, 1721, 159], [458], [101, 20], [2692], [300, 49], [12800, 928], [27, 185, 344, 7, 99, 101, 8110], [3763], [14, 1538, 7, 17, 7, 2346, 7, 2007, 2060], [420, 7, 14], [352, 319, 264, 2873, 1669, 893, 265, 7, 75, 1538], [20, 21], [5, 94, 3159, 27, 1454], [17, 334], [1558, 879], [850], [374, 1304], [743, 472, 352, 46, 2526, 7, 12801], [412, 75, 12802], [1369, 3621, 12803, 2225, 7], [217], [12804], [12805], [3668, 956, 619, 45, 192, 78, 46, 6948], [886, 27, 2305, 107, 87, 166, 434, 126, 12806, 489, 12807], [102], [401, 1157], [2692], [12808], [1856, 262, 765, 21, 7, 9, 12809, 7, 2044, 7, 622, 39, 720, 609, 51, 862], [166, 1908, 363], [15, 513, 365, 7, 1815], [14, 120], [718], [15, 1147], [701, 732, 7, 107, 224, 111, 205, 1311, 474, 7, 5, 862, 701, 62, 474], [818], [315, 10], [326, 463], [663, 159, 262, 264, 164, 609], [65, 12810], [1253, 448], [12811], [123, 1105, 1377], [20], [420], [300, 49], [20], [651], [10286], [6096], [1369, 1477], [120, 7, 14, 120], [106, 104, 19, 323, 37, 1122, 2731], [62], [2153, 386, 104, 1756, 239], [1272, 104, 7, 104, 105], [14], [12812, 275], [1215], [45, 46, 78], [1211], [4748], [148, 105, 749, 159], [746, 417, 563, 78, 942, 7, 72, 8, 88, 163, 164, 7, 166, 152, 37, 49, 7, 1947], [1385], [985, 2468], [242, 2437, 7, 582, 12813, 7, 0, 7, 472, 1471], [62], [370, 352, 1144, 12814], [1574, 95], [59], [619, 7, 104, 3668, 305, 7, 166, 15, 65, 7, 242], [12815], [62], [492], [915, 49, 62], [62, 12816, 285], [262, 194], [12817, 7, 268, 12818, 12819], [420], [7, 507, 1054, 39, 81, 239, 7, 352, 94, 52, 186, 1014, 166, 725, 472, 971, 12820, 264, 81, 1035], [69, 17, 640, 228, 72, 412, 467], [20, 7, 20, 7, 20], [366, 44, 7, 474], [104, 6, 1531, 9555, 189], [19, 445, 256, 7, 15, 2362, 166, 229, 7, 798, 3514, 7, 166, 93, 255, 216, 7, 4, 7, 6058], [2478, 120, 817, 7, 0, 7, 817, 69, 12821, 859], [20, 1471], [51, 862, 50], [1402, 7, 897], [12822, 12823], [12824, 7, 341, 5, 747], [277, 277, 123], [123, 1316, 177, 123, 5219, 7, 91, 7, 14], [14], [217], [4318], [366, 12825], [215], [0], [26, 160, 1638, 7, 70, 125, 7, 266], [1652, 1085, 2578, 7, 1, 7, 4546, 12826], [62, 352, 720, 1531, 341, 12827], [14], [5, 372, 2381, 51, 94, 95, 72, 69, 49, 524, 27, 148, 15, 42, 7, 622, 39, 12828], [104, 3544, 1428, 72, 15, 303, 12182, 461, 2987, 84, 112, 166, 12829, 7, 492, 166, 39, 1010, 1399, 7, 155, 119], [12830, 12831, 1831], [761, 514, 6427, 2650, 111, 12832], [5452, 7, 370, 7, 69, 17, 859, 7, 39, 52, 71], [20], [581, 21, 1314], [12833], [285, 528, 2233, 7, 97], [7206], [20], [14], [330], [1106], [232], [26, 12834], [70, 7, 10, 43, 181, 7, 27, 179, 20, 7, 474], [12835, 116, 1238, 27, 68, 21, 7, 99, 51, 2763], [8211], [5, 743, 12836, 17], [315, 0, 51, 7, 889], [259], [102], [2151, 693, 1189, 1743, 7, 5758], [1], [12837], [51, 65], [2025, 44, 96, 656, 7, 813], [7, 12838, 39, 1010, 7, 1040], [14, 120], [12839, 59, 952, 1085, 12840], [4, 7, 106, 27, 185, 97, 125], [1805], [58, 7, 4440, 12841, 8707, 3287, 7, 362, 285], [12842], [365, 7, 365, 568, 7, 51, 1187, 62, 7, 102], [330, 30, 44, 1988], [12843, 27, 1699, 413, 96], [985, 270, 863, 12844], [2014, 7280, 4630], [62], [3630], [245, 612, 215, 7, 704, 2530, 4734, 9000, 5503, 7, 90, 2128, 7, 245], [34, 1639, 104, 1640, 1624, 21], [6, 152, 88, 27, 454, 72, 6080, 78, 1018, 7, 1673, 69, 741, 103, 808, 893], [123, 7050, 7, 64], [1219], [51, 106, 3298], [14, 366, 16, 17], [8436], [21, 12845, 4196, 7, 413, 7, 489], [7, 148, 249, 5, 2637, 104], [59, 505], [470], [14], [717], [528], [12846, 1642, 12847, 2319, 12141], [41], [215, 3681], [892, 27, 370, 568, 96, 44, 7, 12848], [9, 37, 2939, 111, 376, 49, 6378, 166, 3287, 68, 507, 17, 352, 454, 12420, 1047, 72, 630, 4532], [417, 37, 26, 5, 319, 1219, 166, 1038, 7, 1062], [3690, 7, 15], [1264, 472, 108, 7, 474], [20], [219, 7, 80], [2642, 7, 2882], [77, 2087, 850, 262, 64, 884], [2848, 8547, 94, 361, 256], [104, 94, 2132, 270, 1052, 1797], [44, 64], [115, 134, 285, 801, 219], [12849, 7, 44, 4991, 3553, 1235, 12850], [1, 472, 1684], [84, 49, 1557], [370, 7, 99, 7, 160, 11, 7, 274, 370, 294, 72, 255], [719, 39, 78, 733], [9, 952, 7, 101], [12851, 12852], [412], [2641], [579, 12853, 7, 152, 1047], [1707], [3310, 148, 4399, 44], [12854], [417, 386, 27, 52, 3334, 111, 720, 2694, 12855, 7, 95, 8, 8516, 12856, 7, 200], [14], [39, 51, 1659, 1187], [20, 513], [1458, 149, 41], [26, 1274], [3514], [1342, 4383, 9635], [884], [14], [291, 7, 12857, 75, 231], [414, 51, 747], [14], [977], [701], [12858, 3038], [275, 4683, 7, 64], [62, 7, 6473, 7, 14, 334], [732, 5, 299, 10343, 96, 205, 17], [370, 568], [569], [660], [2292, 1401], [1838, 7, 59], [14, 5022], [1067, 104], [1425, 7, 4348, 12859], [1074, 12860], [1010, 12861, 7, 3681], [246, 7, 12862, 7, 493], [102], [14], [1810, 95, 31], [884], [420], [46, 21], [12863, 7, 1205, 719, 37, 12864, 4020], [6512, 7, 45, 464, 78, 7, 12865, 306, 93, 94, 6081, 104], [5, 942, 164, 96, 1453, 160, 7, 227], [90, 92, 12866, 519, 151, 72, 246, 10147], [859, 2072], [245], [14], [1263, 965, 2856, 166, 952, 1028], [9393, 299, 300], [2292, 2056, 386, 4590, 7, 62, 7, 810, 78], [352, 247, 7, 166, 264, 152, 39, 264, 152], [223, 1897, 7, 368, 205, 17], [863], [1044, 149, 19], [1333, 7, 12867, 148, 8, 270, 160, 759], [474], [37, 10464, 239, 7, 2862], [245, 7, 1219, 2169, 78], [14, 20], [352, 148, 224, 721], [14, 46], [3773, 7, 152, 1287], [46, 7, 370, 149], [20, 21], [88, 4872, 7, 0, 7, 5, 4524, 472, 743], [12868, 2013, 1410], [12522], [1385, 8950, 7, 235, 7, 91], [56, 96, 114, 2243, 21], [179, 1052, 97, 746, 7, 26, 16, 2926], [718], [120, 85, 5, 1560], [20], [3968, 472, 299, 40], [901, 264, 7224, 7, 2369], [14], [62], [417, 12869, 363, 27, 3298, 808, 929, 7, 64], [223, 247], [2721, 16, 565, 2658, 62], [163, 12870], [2204, 12871, 7, 12872, 7, 4], [1372, 8405, 44], [39, 78, 12873, 527], [1141, 1752], [20, 7, 581, 7, 62], [14], [412, 412], [2636], [5, 1791, 7, 407, 7428, 12874, 7, 68, 8625, 7, 2248, 7, 2074], [1225, 1225], [5407, 622, 743, 7695, 9753, 1751], [454, 1349], [215], [1180, 181, 3646, 12875, 7, 859, 3805], [12876, 370, 12877], [2753], [123], [12878, 808, 870, 7, 352, 604], [14], [62], [1383], [370, 719], [259], [252, 64, 341, 7, 12879], [12880, 50, 4], [259], [368, 818, 7, 453], [1383, 45, 6710, 21, 177, 49, 7, 166, 630, 1851, 7, 431, 152, 4933, 90, 12881, 7, 106, 27, 26, 1847], [1333, 746], [7353, 370, 8209], [5, 341, 609, 9, 97, 317, 1180, 2022], [315, 901, 893, 7, 62], [9, 609, 2833], [166, 88], [1891, 27, 1366, 42], [4108, 7, 51, 862], [4310, 27, 425, 7, 4908, 7, 259, 7, 776, 672, 12882, 7, 12882, 7, 3382, 7, 259, 7, 5204], [104, 185, 12883, 1040], [12835, 27, 132, 72, 950], [12884, 4946, 7, 12885, 7, 3561, 7, 14, 12886], [3], [12887, 12888], [372, 16, 361], [58], [215, 3183], [1645], [100, 78, 8095, 859], [963], [2566], [417, 7502], [521], [474], [15, 5844, 365], [14], [1966], [14], [20, 741], [6251], [7813, 2881, 12889], [186, 52, 249, 5, 179, 472, 16, 17, 39, 349, 111, 27, 7, 2753, 7, 4908, 7, 217, 7, 88, 3334, 49, 7, 46, 1253], [215, 17], [123, 87, 2050], [985, 270, 12890], [2096, 27, 64, 956, 125, 7, 4676, 912, 35, 971, 111, 445, 44], [5, 1029, 7, 166, 78, 11710, 7, 1540, 1481, 895, 381, 7], [643, 101], [20, 21], [99, 472, 101, 263], [1997, 7, 5308, 1087, 952], [7202], [985], [1334], [2269, 2164, 1130], [50], [9238], [2352, 4583, 1629], [2931], [474], [14, 7, 15, 134], [1195, 27, 159, 181, 1850], [12891], [1346, 370, 12892], [17, 1010, 7, 95, 1253, 2681], [14], [46, 365, 7, 5, 12893, 6122], [213, 6003], [99, 5, 440, 27], [20, 728, 3], [12894, 7, 1125], [719, 186, 27, 66], [447, 7, 12895], [120, 1885], [4229], [2605, 355], [12896], [2273, 7, 12897], [52, 1195, 104, 386, 859], [12898, 7, 569, 7, 307, 308], [14, 120], [15, 341], [20, 743, 16, 344], [917], [12899], [51, 39, 4177, 45, 1166], [3911, 4100], [470, 62, 7, 5, 5861, 7, 99, 12214], [14], [1425, 12900, 7, 705], [62], [14], [470], [1418, 363], [1215, 7, 1385], [300, 49], [62, 7, 120, 7890], [6985, 78, 7, 12901, 1219], [810], [14], [62, 7, 228, 12902, 7, 372, 7, 952], [222, 401, 3956, 4918, 1813, 349, 49, 7, 245, 7, 719, 264, 26, 284], [799, 177], [3172], [1590, 7, 117, 44, 365], [259, 612, 7, 3555, 259, 612], [385, 1674], [0, 15, 44, 96, 370, 1382], [12903, 50, 7, 12904], [262, 52, 2057, 72, 240], [12905], [59], [3439, 3440, 27], [718], [62, 460, 7, 6509, 1027], [37, 2207, 363, 472, 264, 791, 285, 3368, 4535, 7], [9734], [489], [630, 160, 1219, 221, 69, 17, 7, 771, 5905], [330, 68, 239], [149, 1346, 7, 149, 382, 1346, 7, 382, 64, 12906], [12907, 7, 2133, 470], [474], [956, 418, 956, 817, 12908], [14], [219, 798, 2589], [387, 1529, 435], [62, 7, 370, 467, 2476], [303, 64], [6096], [567], [2606, 77, 355], [772, 7, 12909], [1372, 5588], [716, 7, 12910, 7, 414, 32], [2823, 7, 41], [104, 386, 264, 2049, 1783], [410, 404, 5764], [2069, 46, 211, 386, 370, 12911], [166, 414, 186, 352, 224, 2204], [46, 7, 123, 49, 7, 1997], [12912], [12913], [850], [14, 120], [58], [634], [14], [12914, 268, 12915, 7, 859], [433, 472, 12916], [92, 352, 604, 472, 7, 352, 89, 8, 164], [719, 7, 3, 7, 341, 2973, 732, 2783, 8045], [835, 1316], [57], [859, 17], [263, 893], [414], [14], [2013, 7, 14], [245], [474, 7, 148, 12917], [410, 43, 77, 7, 1372, 264, 49], [688, 5497, 4727, 157, 2336, 7820, 457, 4546], [64, 513], [794, 11587, 264, 49], [50], [46], [14], [5324, 51, 216], [489, 9009], [215, 59], [2402, 369, 1283], [417, 39, 806, 111, 53, 12918, 72, 802, 774, 7, 3325], [45, 160, 12919, 12166], [372, 7, 290], [2842, 688, 11145], [3310, 788, 5964], [5770, 20, 7, 474], [27, 370, 412, 10, 44], [215, 561, 185, 779, 12920], [2569, 1704], [101, 259, 1807], [1052, 229, 5, 440, 44], [1425, 6130, 7, 12921], [465, 72, 8, 6577, 91], [26, 27, 528, 1541], [366, 41], [14, 17, 7, 732, 754], [57], [148, 15, 6610, 19], [1039], [1961, 159], [6711], [11530], [1673, 37, 114, 103], [412], [14], [1199, 8520, 7, 15, 244, 8520], [8870, 7, 1839], [20, 952], [1457], [12922], [12923, 7, 62, 7, 1204, 330, 1187], [58], [27, 372, 228, 44], [14, 3843], [12924, 4140, 7, 12925], [7105, 417, 72, 908, 341], [12926, 7768, 137, 3191, 7, 12927], [1987, 2286, 19], [12928, 1337, 1572, 7, 8977, 1337, 12929], [12930, 2652, 97, 19], [102], [378, 8632], [41], [35, 5275, 617], [6730, 7, 6730, 7, 6730], [314, 166, 104, 519, 765, 72, 1987, 284, 509], [14], [5710], [58], [463], [245], [50], [104, 185, 4562, 111, 995, 1262, 859, 724, 1856], [262, 1659], [367, 7, 805, 194, 390], [15, 7, 12931, 17, 7, 20, 21], [410, 2892], [1721, 270, 264, 163, 6303], [352, 604, 7, 2467, 242, 2673, 7, 7488, 7, 215], [51, 39, 12932], [5337, 12933], [1574, 487, 49, 7, 277, 64, 7, 1574, 7, 487, 49, 7, 277, 64], [12934], [160, 39, 37, 129, 111, 863, 103], [754], [62, 810, 417, 51, 3217, 7, 88, 164], [6304, 104, 386, 1361, 111, 12935, 7, 12936, 111, 720, 898], [362, 6580], [193, 12937, 96, 49], [120], [3], [27, 247, 21], [648, 12938, 7, 7441], [205, 12939, 39, 21, 12940], [12941], [189], [4694, 12942], [58], [859, 49, 7, 26, 472, 582], [234], [11, 49], [4175, 235], [104, 386, 37, 467, 223, 2471, 12943], [4, 7, 779, 2229, 7, 2822, 7, 160, 39, 88, 12944, 5559], [2179], [368, 275, 352, 148, 185, 465, 361], [12945], [120], [977, 7, 1370, 1369, 7, 702, 696], [12946], [51, 212], [1377, 104, 12947, 12948, 270, 1172, 11646, 7, 104, 106, 542, 263, 296, 1117, 7, 104, 604, 160, 49], [12949, 7, 1383, 434, 363], [493], [4], [1077, 8, 245], [12950, 7, 9446, 7, 1], [569, 355, 12951, 72, 10886, 12952], [352, 319, 303, 361, 269, 801, 2108], [62], [14], [215, 120], [1138], [12953, 12954, 120], [62, 7, 448, 177, 15, 5263, 7, 88, 27, 148, 630, 42, 2350, 49, 7, 434, 49, 7, 448, 15, 42, 159], [410, 3065, 6361], [715], [2419], [1531, 65, 39, 164, 7, 5, 92, 472, 9537, 12955, 12956, 299, 1791, 72, 1168, 166, 3227], [360], [14], [1457, 7, 12957, 1825, 7, 12958], [474], [14], [435, 609, 44, 19], [370, 1028, 7, 1216, 101, 12959, 7, 414, 27, 12960, 44], [474], [27, 247, 16, 2616], [944, 7, 813, 1673, 12961, 12962], [1639, 524, 205, 76, 299, 12963, 34, 264, 791], [99, 51, 106], [1997, 7, 1997], [2108, 88, 859], [524, 185, 49, 75], [155, 385], [15, 1160], [123, 3787, 11629, 44, 74, 7, 123, 909, 912], [182, 952], [3346], [5905, 17, 7, 5, 6, 179, 713], [437, 365, 7, 370, 149], [15, 513, 7, 375, 2039], [1997], [7, 2478, 7, 20], [1690], [148, 117, 44], [1523, 7, 91], [822], [14], [186, 52, 210, 61, 7, 104, 454, 72, 1060, 1669, 37, 1722], [1645], [14], [14], [14], [7, 181, 12426, 6, 95, 1669, 12964, 7], [1490, 414, 7, 104, 285, 609, 7, 186, 52, 542, 1590, 265], [14], [166, 51, 5234, 96, 21, 7, 51, 862, 756, 152, 21], [160, 4453, 205, 49], [11866, 1141, 7, 88, 125], [104, 2169, 569, 119, 7, 45, 72, 12965, 104], [2057, 4569], [3], [96, 883], [2699, 2694], [2530, 10118, 12966, 7, 12967, 399, 12968], [51, 542, 44, 6, 115, 35], [762], [27, 677, 72, 5239, 12969, 1109, 62], [956, 12970], [62], [14, 120], [850, 7, 421], [826], [474], [14, 159], [12971], [148, 8, 524, 104, 12972, 953], [262, 52, 7279], [2395, 761], [14, 7, 123, 17], [102, 2384, 12150, 528], [7651, 7651], [14], [595], [463, 940], [12973, 12974, 11, 528], [8567, 12975, 12976, 16, 1632, 1542, 12977, 1195, 1607, 2973, 78, 2373, 37, 7475, 110], [12978], [472, 6667, 1039], [363, 39, 96, 720, 7, 296, 52, 8, 524, 27, 6, 5362, 264, 859, 5585], [941, 7, 20, 1152, 350], [4], [330, 68, 5335, 7, 246, 123, 7, 414, 89, 27, 185, 72, 297, 264, 1726, 7, 476], [5, 3818, 78, 299, 1375], [1016, 72, 185, 160, 17, 12979], [366, 16, 2380, 7, 1678], [62, 104, 194, 677], [69, 12980, 69, 1574, 72, 507, 894, 7, 104, 159, 386, 70], [20, 21, 861], [4714, 12981, 7, 12982], [41], [62], [1449, 7523, 448], [12983, 898], [3137], [62], [414, 88, 12984], [14, 120], [126, 359, 52, 2135, 7, 64, 21], [2156], [4197, 186, 52, 8956], [210, 788], [21, 762], [125, 2361, 1128], [581, 21], [51, 39, 7808], [20, 150, 163, 71], [3637, 599], [20], [59, 672], [7282, 7, 7282, 7, 7282, 7, 386, 104, 747], [3423, 15, 12985, 448], [3525, 579, 1723, 2606, 7, 770, 688, 1342, 12986, 458, 3617], [1851], [2013, 244], [315, 7, 69, 3350, 463, 7, 227], [901, 3483, 4769, 607, 12987], [1317, 870, 7, 870, 870, 870, 870, 12988], [52, 372, 2247], [15, 515], [62, 7, 372], [1783, 7, 1385, 152], [14], [5770], [4390, 458, 7188], [677, 9646], [6407], [744, 64], [104, 269, 722, 1377], [5739, 111, 37, 5395, 7, 104, 163, 12989, 9, 205, 1556, 270, 16, 222, 2527, 7, 919, 246, 279, 7, 3203], [1774, 17, 7, 754], [386, 386, 1731, 111, 205, 2351], [1853], [88, 12990], [148, 192, 1326, 4481], [719, 186, 27, 66, 818], [420, 7, 5365, 7, 5332, 7, 95, 630, 3573, 528], [37, 26, 299, 472, 239], [2794, 104, 12991, 319, 12992], [12993, 239, 663, 370], [414, 1908, 363], [259], [20, 35, 153, 7, 743, 200, 7, 20], [315], [4250], [622, 817], [27, 386, 1826, 1039], [1997], [370], [492], [4381, 7, 372, 160, 17], [474], [1040], [26, 7, 160, 7, 163, 7, 12994, 12995], [728, 3147], [51, 39, 37, 272, 467, 9094, 27, 270, 37, 49, 7, 472, 166, 16, 5168, 386, 1463], [20, 4596], [14], [26, 7, 27, 7, 244, 7, 5, 94, 908, 12996, 7, 45, 68, 104, 7, 5696], [175], [62], [5, 743, 78, 4567], [12997, 7, 12998], [6332], [1225, 104, 45, 148, 105, 417, 72, 220], [1067, 27, 527], [12999], [5359], [13000, 88, 13001, 12273, 13002], [1422, 65, 902], [1062, 4303, 1273], [10432], [2783, 72, 349, 72, 13003], [581, 7, 20], [14], [14], [648, 3887, 13004, 7, 579, 1285, 2037, 13005], [5912, 7, 13006, 37, 49], [13007, 7], [14], [1751, 21], [892, 359, 5, 299, 6544, 5, 1107, 569, 119], [901, 2593], [20], [977], [1353, 3359, 270, 49, 7, 99], [215, 7, 259, 7, 259, 7, 595, 7, 136, 7, 2944, 1443], [13008, 6046], [5, 341, 64], [1300, 352, 148, 13009, 13010, 96, 104, 72, 11519, 1847, 7, 582, 202, 13011, 13012], [10865, 103], [1941, 315, 7, 934, 125, 51, 274, 569, 406, 7, 9666, 4645, 7, 315], [14, 7, 14, 120], [474], [1103, 96, 489, 3], [62, 7, 45, 46, 448], [1482], [362, 622, 1828], [1422], [13013], [365], [252, 2673], [754, 19, 7173, 7, 1610, 7, 27, 125, 65, 7, 13014], [51, 307, 308], [123, 2010, 104, 26], [13015, 11876, 3161], [3, 7, 13016, 1492], [1607, 13017, 472, 817, 13018, 7448], [5, 185, 129, 7, 13019, 2738, 72, 700], [605, 186, 27, 159, 228, 7, 56, 96, 37, 1726, 7, 186, 7011], [6035], [13020], [0], [13021, 89, 27, 3217, 72, 1229, 7, 326, 719, 7, 352, 1791, 72, 3347, 270, 13022], [616], [10905], [474], [794, 879, 738], [1039], [217, 7, 622, 765, 10578, 7, 10018], [13023], [634], [460], [315, 13024], [977], [660], [62], [62, 7, 181, 43, 489, 1731, 78], [115, 428, 3558, 37, 46], [20, 3063], [1642, 1642, 7, 13025], [182, 1775], [14], [5710], [13026], [4310, 27, 13027], [5905, 93, 2763, 27, 7, 13028], [291], [62], [367, 7, 5, 4264, 269, 1088, 330, 68, 239, 7, 12569], [27, 5506, 1262, 1756], [96], [21, 693, 4], [58], [6712], [13029], [20], [823, 7, 6114, 7, 319, 4451, 270], [58], [1099, 1719], [13030, 7, 166, 93, 228, 72, 95, 270, 7, 743, 10086, 3065], [88, 263, 910], [8, 62], [51, 39, 1149, 93, 386, 52, 1204], [62, 44, 164], [14, 120], [352, 454, 42, 72, 630, 2109], [437, 365, 7, 6444, 17], [91], [1662], [634], [262, 1650, 37, 6544, 5, 1560], [6387, 7, 202, 1650, 472], [1490, 719, 90, 862, 2242, 7, 90, 862, 14, 7, 370, 97, 2056], [14, 46, 365, 7, 8353, 111, 292, 1128], [369, 64], [14], [15, 341, 7, 19], [1461, 15, 1147, 127, 7, 2678, 355, 3250, 181, 808, 965], [719, 39, 472], [968], [934, 26], [64, 627], [1360, 1028, 27, 64], [368, 52, 1531, 300, 492], [62], [215, 7, 26, 160, 7531], [20], [7, 414], [352, 604, 1531, 68, 1686], [62, 7, 528, 40, 565], [20, 115], [420, 15, 16, 3270, 96, 1453, 7, 420, 15, 929, 1195, 5, 604, 166, 5, 925], [13031], [1725, 1605, 7, 3], [110, 487, 405], [14, 7, 20], [1899], [599, 6, 115, 746], [14], [859, 6340], [62], [26, 160, 1186, 325, 1784], [1731], [999, 44, 569, 242, 7, 414, 104, 386, 13032, 7, 44, 205, 569, 242, 7, 3130, 1729], [16, 17, 163, 2783, 7, 492, 7, 45, 743, 44], [19, 397, 6576, 7, 27, 386, 125], [90, 1987, 1855, 317, 166, 104, 790, 152, 57], [223, 2476, 2151, 205, 153, 7, 4228], [2078, 1010], [19, 15, 2175, 14, 13033], [88, 13034, 7, 2060, 7, 901, 4177, 7, 4177, 270, 669, 2720], [417, 116, 5, 630, 13035, 524, 104, 476, 192, 929, 630, 2549], [51, 640, 4602, 3626], [58], [101, 20], [114, 103], [1039], [5646, 721], [260], [3187, 7, 2199, 3187], [462, 2039, 5, 306], [13036, 13037], [88, 4708, 72, 349, 7, 7641, 10, 1623, 181, 431, 12893, 412], [270, 264, 548, 7], [414, 52, 7, 956, 85, 862, 7, 3595, 2359, 39, 163, 8350, 3276], [120, 858], [762], [3595, 3595, 3595], [884], [428, 242], [884], [5, 185, 622, 270, 1012, 7, 808, 1557], [15, 2856], [639, 101, 1617], [2478], [366, 172], [13038, 7, 691], [14], [8202, 7, 14, 974], [4404, 13039], [215], [62], [0], [1242], [14], [58], [5, 4134, 5, 185, 713, 15, 928, 7, 10, 971, 186, 37, 3787], [2395, 428], [51, 39, 1187, 4177, 7, 1640, 246, 1187, 7, 713, 408, 7, 1187, 270, 413, 75, 7, 1166, 322], [13040], [365, 13041, 320, 13042], [884], [215], [14], [51, 862, 51, 327, 78, 490, 7, 99, 2002, 655], [44, 101], [677], [62], [370], [581], [334, 7, 126, 97], [315, 7, 205, 775], [104, 7, 439, 5, 106, 117, 181], [420], [352, 116, 1624, 622, 2622, 521], [44, 326, 27, 13043, 7, 13044], [3418, 7, 845, 8264], [64], [95, 437, 262, 1010], [1022, 7202], [120], [3575, 565], [62], [5852, 7, 5611], [13045], [6, 412, 7, 16, 2379, 5010, 7, 129], [2678, 3250, 104, 7, 62], [4, 7, 3446, 244], [20, 5033], [414, 773], [368, 45, 264, 164, 2875, 7, 10, 3414, 1399, 68, 1767, 913, 6771], [160, 999, 7, 365, 15], [14], [464, 2048], [1377, 410, 181], [91], [93, 7, 2169, 96, 256, 7, 1490, 52, 7, 417, 27], [859, 725, 107, 363, 2064], [13046, 1999, 104, 45, 210, 265, 72, 44, 343, 7, 13047, 1102, 264, 564, 96, 445, 7, 13048, 104, 13049, 246, 1946], [13050, 7, 718], [117, 3840, 7, 472, 3372, 39, 24, 110, 111, 3646], [16, 2655, 7, 447, 16, 2655], [2928], [13051, 27, 5114, 16, 1382], [4656, 166, 104, 519, 1262, 1381], [6071, 557], [850, 93, 186, 7, 1574, 45, 113, 284], [10332, 7, 1941, 3370, 50], [370, 13052], [160, 1431, 7, 901, 859], [963, 7, 963], [679, 355, 9262, 7, 13053], [582, 778, 14], [1549], [182, 4054], [1320], [215, 59], [120, 159], [232, 7, 26, 7, 681, 39, 264, 788], [9864], [5673, 1240, 595, 7, 13054], [13055, 880, 1396, 13056, 13057], [15, 160, 172, 7, 14], [472, 163, 1258, 49, 7, 1047, 7, 5, 910, 177, 111, 160, 163, 1463, 7, 1346, 7, 713, 4431, 713, 7605, 7, 123, 17, 7, 352, 185, 163, 75, 609], [1365, 7, 693, 355, 1109], [13058, 1544, 365, 7, 27, 917, 7, 69, 3142, 17, 3024, 13059, 1875, 27, 7, 166, 272, 444, 27, 148, 210, 7, 39, 2631, 7, 8640, 13060, 7, 221, 69, 222, 7, 282, 3540, 322, 7, 13061, 1911, 9757], [1340, 7, 99, 352, 386], [382, 382], [8865, 2437, 13062, 3980], [62], [2856, 39, 754], [5673, 6126, 7, 227, 387, 1119, 1039], [3678, 1293], [51, 1362, 72, 95, 270, 528, 359, 2756, 274, 1105], [88], [215], [95, 437], [62], [166, 104, 106, 26, 1847, 101], [584, 7, 20], [13063, 7, 1425, 7, 458, 7, 13063, 7, 1723, 7, 776, 7, 1125], [62], [5, 341, 1187, 5087], [1422], [2921, 1401, 542, 268, 13064, 7, 2732, 7, 13065], [11498], [15, 7, 160, 1574], [13066, 101, 859], [13067, 2013, 7, 20, 7, 343], [7440], [245, 7, 14], [7, 3724, 619], [163, 13068], [1866, 859, 65, 2381, 27, 1673, 771], [474, 7, 474, 7, 216, 7, 474], [1], [407, 7, 152, 7, 569, 7], [1052, 4319, 294, 490, 235], [5, 1170, 104, 2877, 525, 3840, 30, 37, 2073, 13069], [1345, 7, 232], [3173, 145, 13070, 7, 2915], [619, 13071], [718], [1558, 849, 738], [20], [1346, 7, 164, 2033, 7, 5, 179, 5, 330, 1187, 7, 104, 45, 1018, 7, 14, 1673, 741, 7, 741], [4583], [58], [352, 386, 1289, 37, 1524, 1769, 7, 78, 7, 78, 39, 37, 3079, 326, 413, 75], [14, 7, 1422, 7, 761, 17], [8516], [13072, 1903, 8858], [102], [14], [13073, 94, 246, 97, 13074], [810, 1829], [17, 970], [62], [217], [14], [58], [13075, 7, 7598, 7, 7598, 7], [414, 89, 51, 186, 472], [800], [45, 412, 264, 2429, 4061], [127], [15, 343, 7, 37, 13076, 343], [12340, 21, 166, 255, 44, 7, 163, 13077], [217], [27, 117], [738, 7, 91], [51, 39, 216], [155], [474], [457, 259, 136, 13078, 7, 1588], [13079, 13080, 579, 13081, 12261], [3060, 7, 13082, 7, 2367], [205, 17, 429, 264, 13083], [27, 2751, 779], [1924], [148, 192, 69, 17, 210, 2731], [163, 17], [804, 7, 1207, 78], [4196], [15, 67, 19, 7], [378], [746, 45, 412, 264, 501], [6117, 7, 13084], [62], [9992], [13085, 1726], [149, 19], [51, 39, 431, 52, 4177], [638, 284, 691], [435, 39, 1853, 13086], [252, 435, 7, 27, 1867, 7, 247], [13087], [582, 274, 407, 2744, 2745, 30, 2952, 2738], [96, 44], [5, 299, 1010, 933, 13088, 13089, 13090, 13091, 13092], [412, 7, 412, 7, 386, 104, 818, 1401], [5, 971, 542, 27, 925, 16, 344], [26, 1216, 62], [1272, 39, 2395], [13093, 7, 177, 111, 1215, 7, 2081, 7, 1334, 7, 368, 45, 163, 413, 7, 934, 669, 7, 719, 7, 37, 26], [62, 7, 252], [14], [20, 7, 49], [215], [688, 2667, 7, 139, 13094], [386, 104, 96, 40], [99, 104, 718, 31], [186, 27, 440, 44, 7], [492], [13095], [89, 27, 437, 37, 11397], [5, 640, 186, 2987], [1385], [5753, 7, 1273, 1337, 1381, 13096, 1273, 474], [474, 7, 13097, 13098], [474, 7, 788], [161], [1103, 788, 97], [11684], [15, 42, 7, 13099, 13100], [13101, 671], [14, 1253, 305], [794, 189, 679, 2545, 1967, 7, 62], [474], [977], [1498, 20], [3138, 148, 13102, 69, 17], [630, 718], [719, 264, 513, 166, 883, 7, 6771, 7, 513, 584, 2243, 1847, 3572], [4141], [13103, 13104], [489, 5050, 565], [940, 13105], [901, 1187, 1977, 7, 489, 355, 326, 88], [619], [104, 105, 719, 5, 372, 228, 72, 15, 160, 125], [1532], [412, 365], [13106, 13107, 4196], [788], [14], [20, 49, 817], [14], [100], [88, 300, 99, 88, 8350, 7, 515, 7, 41], [14], [12952, 7, 2125], [13108], [5, 1560, 7, 95, 413, 762], [62], [13109], [13110, 7, 13111], [245, 7, 884], [58], [474], [297, 5906], [1331, 1010], [4599, 1337, 843, 1529, 72, 349], [8747, 13112, 7, 62, 7, 472, 1316, 7, 667], [1899], [14, 4973, 44], [3858, 528], [719, 264, 1457, 565], [88, 521], [0], [215], [370, 239], [1039], [64, 17, 7, 470, 192, 44, 210, 7, 859, 3139], [215, 219, 7, 5027, 6723], [20, 1590], [4778], [494], [581, 13113], [134, 462, 2039], [14], [58], [11004], [75, 1674, 913, 7, 604, 743, 125, 7, 2251, 49, 1365], [163, 7675], [1899], [148, 323, 44, 13114, 7, 90, 4919, 1070, 7, 3797, 1085, 13115, 7, 13116, 2606, 137, 13117, 7, 2366, 13118, 139, 13119, 7, 5, 66, 7, 4563, 7, 90, 7, 968, 7, 968, 7, 90, 7, 3635, 7, 394], [719, 186, 27, 159, 7, 306, 111, 11256, 13089], [1018], [470, 14], [884], [4521, 96, 3840], [374], [717], [472, 39, 264, 4172, 517, 79, 2247, 62], [470, 1116], [160, 134, 1292, 8358], [4, 7, 13120, 953], [5933, 8057], [95], [14, 120], [14], [412], [1272, 5, 163, 13121, 929], [1574, 361, 160, 49], [7822], [5359, 1070], [474], [9096, 7, 39, 40], [5244, 5279], [26, 7, 581, 7, 21, 91], [5, 1063, 104, 7, 13122, 7, 26, 104], [5, 2002], [88, 27, 1470, 472, 607, 2739], [5, 1444, 719, 39, 16, 571], [13123], [910, 69, 2378, 233], [160, 65, 13124, 3990, 2987, 7, 901, 13125, 956, 26], [634], [20, 507, 21], [123, 381], [5, 6], [1875, 8546, 239], [120, 7, 160, 841, 88, 64, 474], [14], [826], [45, 148, 242, 264, 3505, 5381, 434, 363], [14], [13126, 229], [20, 1909, 7, 1018], [942, 114], [1856, 360, 89, 619], [701], [62], [2174], [223, 1897, 159], [14], [5652, 111, 1538], [366, 974], [8747], [1215], [352, 386, 13127], [15, 564, 365, 7, 51, 39, 163, 1191, 7, 564, 1103, 177, 49, 418, 7, 27, 148, 228, 42, 68, 205, 17, 434, 363], [50, 50, 7, 13128, 612, 13129, 7374], [474, 7, 352, 94, 314, 7, 12009], [15, 564, 96, 471, 365], [447, 365], [88, 296, 192, 256, 152], [104, 45, 743, 220, 68, 3414, 7, 88, 13130], [489, 2060], [88, 1756], [3637], [4], [62, 120], [13131], [37, 40, 64, 39, 4961], [20], [524, 104, 3699, 270, 413, 104, 386, 1259, 72, 465, 695], [1538, 3864], [10393, 13132, 13133], [20, 21], [46], [660], [26, 1847, 9, 205, 1330, 125], [62], [37, 352, 105, 104, 94, 210, 1977, 368, 13134], [668, 11, 1304], [374, 947, 1588], [3776, 7, 13135, 44, 505], [3210, 431, 2382, 1541], [62], [660, 7, 3641, 111, 428], [939], [27, 386, 7, 27, 454, 7, 2057, 3738, 2057, 64], [58, 7, 1240, 4851, 7, 26, 1847, 72, 205, 7959, 103, 127], [4831, 13136, 13137], [513, 2873], [10, 642, 91], [163, 361, 160, 13138, 26, 3361], [14], [505, 30, 196, 2076], [62], [35, 13139, 7, 13140, 6932, 7, 1219], [6109, 7, 1774], [166, 5, 1331], [51, 862, 895, 228, 72, 8, 713, 97, 7, 166, 72, 192, 104, 152, 7, 895, 908, 303], [5, 185, 264, 153, 371, 101, 7, 88, 794, 7, 4297], [13141, 7, 719], [108], [88, 20], [8, 13142, 4177], [761, 148, 126], [2213], [5, 21], [37, 7862], [62], [4, 582], [4408, 1121, 2359, 355, 270, 6771], [390, 7, 6361, 284, 7, 492], [38], [1458], [4036], [10768], [14], [77, 2484, 928, 72, 297, 69, 298], [72, 246, 8673], [13143], [14, 1883], [90, 186, 52, 743, 749, 4972, 659], [414, 1640, 90, 743, 104], [52, 2927, 7, 10983], [492, 7, 215, 7, 859, 1544, 270, 37, 434, 467], [143, 612, 1370, 10078, 2352], [5, 162, 221, 78, 62, 7, 368, 660, 7, 37, 7941, 1011, 1767, 49], [1175], [4345, 4227], [414, 370, 6750], [245], [297, 112, 111, 12333, 72, 1031, 948, 1297], [253, 7, 2787], [315, 104, 519, 859], [13144, 6699], [13145], [1374, 467, 185, 1374, 7966, 7, 192, 42, 8, 743, 51, 306, 51, 106], [717], [944], [3398, 20], [166, 69, 2379], [13146], [1855], [58], [622, 319, 749, 13147, 13148], [663, 96, 1743], [1349, 7, 102], [474], [14, 46, 159], [215, 7, 13149, 7, 259], [51, 372, 1010], [2303, 12047, 11943, 1070, 7, 14], [24, 2074, 27, 1640, 1987, 284, 413, 7, 166, 8, 6482], [20, 7, 21, 7, 13150, 7, 370, 7, 1961, 7, 51, 268, 88, 125], [127, 96, 2243, 788], [1458, 149, 7, 62, 7, 127, 627, 7, 69, 16, 1150], [13151, 7, 2753], [14], [13046, 1999, 105, 8726, 1144, 5051, 429, 279, 7, 288, 45, 247, 1195, 111, 205, 3547, 99, 104, 8, 743, 1538, 268], [14], [14], [13152, 4785, 7, 13153, 246, 418], [675, 13154], [111, 1661, 1885, 4009], [2096], [8645], [370, 7, 414, 148, 1987, 44, 264, 405], [2531, 44, 365], [14, 1010, 194, 7, 11379, 21, 6667], [16, 344], [474], [5585, 9423], [253], [14], [88, 277, 277, 13155, 49], [476], [268, 7, 88, 2292], [877, 7, 20, 9193, 1039], [8567, 1204, 132, 72, 27], [51, 319, 354], [219, 7, 217, 7, 2946, 2946], [1247, 7, 104, 386, 765, 74, 2285], [14], [13156, 13157, 210], [660], [62], [1040], [931], [9, 749, 370, 13158, 2472, 485], [1385, 330, 347, 3696], [418, 363, 1109], [34, 7, 10, 13159], [323], [62, 7, 123, 464], [16, 103, 779, 7, 26], [91], [1645], [13160], [412], [120, 341, 13161, 1999, 948], [763, 619, 14], [13000, 13162, 7035], [13155, 152], [794, 735, 49, 7, 0, 1353, 1471, 7, 111, 37, 49], [6, 3217], [813, 105, 42, 7, 326, 265], [1732, 898], [4034], [474], [56], [884, 7, 13163], [895, 2406], [375, 6777, 7, 10972, 1751], [13164], [13165, 7, 11455], [215, 7, 215, 7, 366, 599, 166, 2380], [8100], [6268], [420], [164], [259, 505], [62], [59, 1638], [68, 7, 370, 365, 7, 370, 365, 7, 37, 537, 370, 7, 6168, 5, 210], [255, 363], [5, 3841, 910, 2849], [13166, 7, 663, 13167], [474, 7, 9171], [494], [58], [2432], [810, 30, 527, 166, 13168], [20], [62, 7, 13169], [410, 7, 27, 925], [104, 818], [886, 179, 27, 177, 64], [3042], [163, 3738, 565, 1541], [96, 719, 1169, 2551, 166, 965, 2579, 1337, 370, 609, 7, 362, 285, 1229, 7, 2551, 212, 166, 162, 1169, 7, 743, 4], [4293], [474, 7, 474, 7, 474], [447, 940, 7, 50, 102], [5274, 1737, 270, 37, 49], [4607, 37, 272, 489, 223, 8, 859, 7, 123], [800, 7, 102], [1383], [232], [1449, 2262, 1568, 1722], [4596, 39, 798, 1756, 7, 5296], [7617, 7, 399, 1980, 13170], [20, 7, 252], [228, 13171], [5765, 370, 2465], [0, 7, 68, 2660, 13172], [2260], [474], [2279], [474, 7, 39, 1775, 194], [58], [26, 746], [127], [2352], [5210], [229, 9262, 7, 728, 77], [148, 5239, 72, 15, 301], [13173, 798, 5278, 13174], [90, 440, 205, 1383, 13175, 7, 104, 185, 123, 112], [1383, 103], [245], [166, 1628, 272, 463, 96, 264, 8831], [382, 655, 89, 177, 205, 1722, 95, 7, 4364], [634], [341, 27, 106, 149], [414, 1431, 34], [5, 4285, 491, 239, 7, 62], [14], [762, 31], [75, 1240, 1635, 7, 223, 37, 26, 13176, 96, 75, 355], [13177], [215, 13178], [1731, 78], [490, 7, 62, 7, 2839, 7322], [719, 386, 104, 1463, 1650, 7, 91], [470, 7, 15, 44, 1272, 5, 247, 16, 153, 99, 1615, 242, 7, 470], [4586], [168], [14], [16, 17, 1457], [62], [58], [2226, 68, 7, 448, 7, 13179, 2229], [1766, 7, 252, 11084], [2098, 469, 1216, 929, 519, 1716], [4675, 7, 472, 13180, 7, 123], [341, 605], [245, 1775], [96, 908], [412, 264, 940, 2108, 1010], [14, 2846, 3450, 7, 209, 1717, 87, 166, 431, 274, 264, 693, 940, 2892, 7, 1833, 7, 719, 264, 125], [1645], [14], [1018, 2048, 3042], [5045, 365], [330, 1028], [120], [13181], [4581], [13182], [14, 2541], [59, 6520, 7, 798, 13183, 7, 90, 2810, 1033], [582, 719, 27, 862], [62], [648, 13184], [14], [352, 106, 185, 2022, 743, 472], [26, 104, 341, 7, 148, 192, 44, 314, 104, 30, 6414, 7, 163, 219, 4180, 7, 20, 152], [667, 7, 1105, 96, 44, 7, 3, 7, 1422, 7, 16, 17, 39, 13185], [88, 1372], [69, 68, 205, 13186], [3170, 1882], [58], [1826, 65, 5, 1828, 777], [44, 185, 64, 17, 7, 75, 103, 7, 223], [474], [717], [78, 299, 9355], [1708, 64], [7770, 13187, 7318, 7, 7317], [2373, 412, 75, 355, 97, 7, 34, 95], [13], [215, 46, 322], [6745], [13188], [447], [798, 5641, 1369, 7, 1, 7, 489, 13189], [582, 414, 104, 88, 859, 270, 21, 7, 622, 1103, 7, 738], [215], [368, 264, 548], [0], [277, 20, 49], [1645], [474], [888, 44, 472, 13190], [64, 1241, 7, 64, 17, 727, 7, 64, 8], [370, 7, 370, 7, 1616, 7, 5, 1107, 264, 1458, 239], [414, 88, 13191, 72, 117, 44, 80], [215], [315], [7012, 104, 386, 264, 277, 859, 266], [14, 7, 102, 434, 7, 524, 104, 192, 256, 305, 6399, 1253, 352, 106, 46, 30, 355, 2605, 7, 352, 469, 106, 186, 2310], [120, 1147], [4085, 52, 1531, 1259, 814], [46, 1253, 448, 7, 46, 7, 6222, 7, 117, 44], [4961, 13192, 13193], [3196], [2299, 7, 14, 7, 1723, 776], [262, 264, 164, 609], [104, 1756], [95], [619, 186, 27, 314, 44, 490], [1846, 655, 39, 160, 13194], [1855, 501, 949, 112, 4621], [13195], [62, 7, 1122], [14], [14, 7, 89, 52, 46, 956, 1253, 956, 5, 92, 78, 8585], [166, 27, 6, 202, 16, 115, 7, 1346], [314, 7, 229, 101, 378, 7, 51, 106, 656, 44, 7, 1762, 96, 1863, 72, 2025, 44], [39, 13196, 96, 870, 326, 286, 7, 1272], [330, 68, 159], [14], [7, 370, 287, 13197, 4177, 7, 88, 3334], [147, 956, 669], [3350], [127, 1216], [1997, 7, 5956, 1188], [648, 3025, 4203, 612], [1186, 39, 1187, 13198], [4637], [13199], [493], [2753], [2753], [660], [581, 96, 9254], [1558], [1062, 513], [62], [13200, 7, 186, 27, 159, 185, 264, 5181, 68, 69, 17, 7, 1195, 352, 186, 166, 51, 39, 264, 1756, 467], [51, 13201, 743, 51, 299, 1077, 1103, 359, 1147, 299, 99, 163, 42, 35], [13202, 246, 13203, 901, 1204], [2096], [3236], [149, 7, 149], [940], [794, 44, 75, 7, 5], [20], [51, 39, 7023], [474], [3561, 2010], [56, 2788, 7, 260], [88, 103, 13204], [8178, 9, 69, 1091, 660, 738], [148, 1987, 78, 72, 204], [88, 2740], [45, 1762, 96, 3075, 72, 630, 87], [859, 493, 2483, 7, 5, 94, 865, 27], [88, 1262, 3332], [62], [3041, 393, 1678, 13205, 13206, 7, 9848, 798, 9849], [69, 37, 64, 1128], [26, 205, 1201, 1639], [310], [453, 7, 160, 163, 953, 7, 11331, 8908], [1645], [799], [69, 1204], [330, 656, 64], [715], [1240, 822, 7, 96, 537], [262, 3662, 472, 527, 274, 264, 296, 2423, 1180, 582, 7, 7390, 7, 3761], [7, 370, 5407, 365], [88, 378, 5561], [1661, 1247, 189], [322, 51, 8022, 1039], [58], [13], [20, 21, 101], [163, 1346, 437, 166, 1490, 78], [7, 5, 341, 2071], [193, 1091], [715], [474], [320, 68, 1048, 39, 743, 669, 7, 361, 860, 284], [1365], [91, 7, 3920], [192, 44, 46, 13207, 7, 5, 185, 72, 95], [7, 478, 479, 7, 13208, 479, 7, 5420, 437, 322], [590, 823, 39, 2899, 13209], [62], [64], [934, 26, 160, 39, 10520], [20, 4250, 1010], [58], [14], [3], [963, 7, 4202, 26], [2811], [2096, 13210], [13211], [14, 120], [181, 239], [14], [818, 2384], [13212], [2468], [245, 776, 1817, 1070, 7659, 13213, 7, 2190, 1775, 1342, 612, 7, 1085, 505, 13214, 7, 1358, 7, 6454, 702, 2965, 7, 1817, 4735, 579, 1670, 6589], [2050, 39, 2081], [58, 7, 370, 305, 7, 3], [235, 454, 3458], [215], [14, 7, 366, 44], [51, 39, 1856, 7, 604, 256, 2310, 1124], [1385, 27, 148, 2335, 412], [177, 39, 13215, 1381], [13216, 7, 14, 120], [630, 13217], [1899], [13218, 743, 264, 378, 99, 24, 210, 6, 1531, 117, 264, 7522, 13219], [977], [13220], [20], [1018, 326, 1987], [1402, 62, 7, 11203, 894], [3447], [14], [62], [4, 7, 10984, 7, 232, 7, 437, 78, 2681], [30, 196, 90, 185, 115], [1449, 144, 448], [349, 99, 1756], [5, 255, 2242, 51, 299, 125], [705, 2944, 13221], [368, 1915, 13222], [3761, 7, 9623], [13223, 7, 2921, 489, 2006], [762, 21], [1425, 13224, 13225, 13226], [941], [215], [38], [30, 196, 6174], [366, 44], [252, 7, 850], [660], [123, 1177, 1035], [1980, 5004, 1676], [1219, 1010], [1144, 13227], [2437, 622], [14, 4410], [8003], [283, 284, 8199], [20], [489, 363], [20, 4250, 6617], [41], [581, 773, 20, 49], [13228, 7, 1422, 7, 5424, 21, 166, 599, 7, 166, 13229, 7, 75, 677, 7, 13230, 1241, 96, 13231, 39, 13232, 7, 4239, 7, 370, 2892, 7, 39, 64, 2720], [474], [427], [4239], [11291], [5580], [166, 160, 299, 52, 1531, 16, 13233, 10468], [1044, 78, 499, 104], [14], [160, 13234, 1524, 7, 334, 7, 217, 7, 743, 27, 7, 431, 2335, 265, 21, 7, 217], [870], [46, 322, 7, 4, 7, 365], [239, 7, 13235], [205, 177, 1756, 322, 7, 13236, 224, 359, 732, 803], [370, 3139], [412], [260], [2087, 21], [14], [14], [330, 98, 19, 7, 5770, 7, 5, 454, 1150, 492], [1531, 1366, 507, 2382], [1815, 1425, 7577], [582, 2470, 819, 1267, 68, 2661, 7, 27, 94, 630, 42, 270, 434, 49, 1275, 7, 166, 78, 498, 246, 13237, 956, 78, 3678, 322, 7, 88, 15, 42], [20, 21], [13238, 13239, 101, 2204, 1062, 7, 14, 120], [46, 448], [2753], [370, 7, 865, 3762], [352, 314, 27, 64], [64, 17], [13240, 7, 4098, 8788], [13241, 7, 182, 7, 4205], [723, 205, 264, 1858, 2545, 1967, 8964, 1783, 270, 749, 517, 2545, 111, 13242, 7, 8562], [5719, 489], [634], [454, 13243, 7, 13244, 6408], [1263], [10, 43, 181, 7, 166, 149, 13245, 355, 7, 521], [123, 115], [10826, 27, 6, 246, 361, 7, 472, 414, 349], [14], [69, 125, 233], [12275], [1837, 7, 13246, 96, 1312], [510, 89, 5, 499, 177, 111, 12782, 326, 45], [62, 7, 660], [13], [123, 12553], [26, 160], [106, 352, 45, 46], [439, 51, 39, 743, 125], [58], [2137], [123, 13247], [14, 120], [15, 4596, 7, 2219, 6979, 2892], [56, 7, 615, 7, 5, 13248, 7, 265, 49, 7, 166, 13249, 7, 548, 2361], [91], [817, 330, 46, 21, 1028], [14, 46, 1253, 448], [4598, 13250, 458, 7, 1605], [1187, 72, 1538, 5, 306, 7, 1915, 720, 413, 2389], [474], [45, 2025, 75, 2484], [3261, 13251, 7, 5, 491, 7, 13252], [62, 3198, 284, 72, 630, 4572, 7, 88, 163, 13253], [2014, 7293], [14], [62], [58], [12325], [794, 322, 205, 3577, 3201], [75, 355], [9963], [13254], [423, 582], [5, 228, 264, 10595, 7, 656, 801], [125], [5, 148, 1366, 472], [14], [166, 160, 2673, 7, 1292, 7, 3717, 413], [252], [14, 2333], [3210, 7, 13255], [362, 21, 177, 363], [67, 2537, 472], [474, 414], [399, 3331], [370, 117, 44], [20], [20, 21, 7, 1574], [414], [95, 46], [217, 7, 13256, 7, 2014, 6726], [489, 43, 10, 270, 21], [14, 120, 159, 7, 300, 49], [20], [3173, 3963, 8204], [4560, 7, 4706], [3], [1558], [448, 15, 622], [14, 120], [3], [2125, 7, 1625], [215, 59], [26, 7, 219], [937], [5438, 7, 75, 3075, 181], [13257, 12014, 13258, 13259, 13260], [1410], [13261, 8990, 13262, 7, 2404, 2965], [102], [487, 285, 1304, 7, 91], [507, 515, 39, 369, 7, 51, 499, 37, 2740], [14], [13263], [46], [45, 205, 13264], [8747, 7, 453], [366, 5267, 902], [368, 96, 27, 3310, 7, 96, 6610], [859, 285, 1775, 1039], [88], [2014, 13265, 131, 7, 1425, 1838, 1815], [99, 5, 178, 179, 78, 7, 205, 2351, 7, 2973, 78, 177], [2921, 371], [370, 1382, 761, 7, 417, 186, 104, 1478, 44, 72, 314, 524, 5096, 386, 1659], [14], [14], [10286], [260, 7, 13266, 6867], [14], [14, 7, 700], [352, 319, 722, 1010], [99, 5953, 7278, 51, 1640, 185, 2135, 784, 13267, 284], [5, 212, 78, 51, 13268, 264, 961], [64], [14], [370, 4423, 8367], [58, 7, 93, 386, 101, 4325, 68, 3121], [14, 120], [9967, 96, 264, 1054, 7, 13269, 7, 1402, 723, 13270, 7, 26, 160, 163, 7090, 189, 7, 2153, 341, 90, 30, 160, 163, 103], [13271, 2859, 37, 17], [123, 6777, 218], [1961, 7, 14, 7, 95, 305, 448, 7, 3203, 1775, 166, 194, 1904, 7600, 7, 790, 152, 7, 14], [14, 1247], [13272], [1314], [5, 314, 1572], [370, 1117, 7, 166, 27, 319, 13273], [14, 159], [13274], [123, 222], [5578], [210, 270, 3802, 64, 1304], [453], [798, 1086, 895, 4481], [12123], [427, 4205], [472, 39, 719, 5, 13275, 179, 359, 5, 925, 6260], [51, 94, 330, 1187, 45, 447], [414], [5, 604, 16, 539, 7, 262, 6242], [366, 44, 159, 7, 253], [12, 7, 95, 46, 13276, 129, 125], [13277], [13278, 13279, 13280, 7, 13281, 7, 13282, 13283, 7, 13284, 13285, 13286, 50, 6512, 13287], [215], [660, 255, 13288], [494], [1499, 1188], [13289, 72, 179, 7, 69, 125, 69, 1574, 39, 125, 7, 368, 177, 1915, 862], [13290], [163, 604, 9, 2162, 17, 57], [175, 7, 472, 299, 2121], [4921], [62, 1062, 7, 655, 1144, 27, 13291], [4191], [423], [13292, 3276, 808, 2454], [3744], [382], [660, 56], [13293, 7193, 131], [297, 7605], [368, 155, 72, 8, 37, 49, 472, 352, 604, 30, 501, 181], [155], [14, 1312], [14, 120], [1853, 7, 20, 21], [93, 13294, 44], [3690], [859, 49, 619, 1699], [931], [596, 1370], [474], [908, 622], [370, 1315], [818], [160, 39, 49, 39, 264, 1908, 111, 363], [366, 44], [2478], [1240, 947], [668, 761], [474, 7, 769], [13295, 3183, 13296, 5170, 947, 7, 456, 13297, 1723, 776, 13298, 7220, 2944, 13299, 9707, 7, 9730], [521], [315, 88, 4416, 414, 27, 269, 886, 270, 487, 285], [160, 159], [14, 120], [16, 17, 24, 270, 479, 115], [14], [26, 104, 64], [14], [106, 27, 4521, 2561], [702, 1838, 7, 4694, 131], [414], [62], [1040, 715], [14], [215], [619], [1240, 12161, 7, 1337, 7, 1342, 13300, 3889, 7, 6119], [3778, 582], [13301, 10959, 454, 2043], [7516, 7, 5539], [62], [2753], [2247, 160, 163, 564, 209, 908, 1430, 7, 569, 119, 8463, 44, 370, 1430, 7, 125, 564], [26, 472, 299, 11864], [412, 365], [365, 4314], [20, 791], [790, 115, 31, 7, 808, 841], [62, 177, 472, 166, 104, 519, 13302, 6854, 72, 186, 78], [51, 94, 330, 7, 412, 365], [65, 1903, 2005], [370, 571, 1481, 7, 974, 4101, 37, 371], [14, 120, 15, 65, 96, 53, 1669, 1892], [62], [5, 92, 51, 463, 110, 111, 37, 4856], [14], [13303, 7, 1210], [6657, 7, 11298, 7, 163, 378, 8], [2373, 2851, 72, 13304, 166, 2816, 51, 13305], [14], [1151], [277, 13306], [50], [15, 160, 627, 365], [259, 1730, 219], [252, 435, 91], [90, 13307, 7, 4698, 7, 4694, 7, 668, 1457, 7, 13308, 270, 16, 694, 7, 3784, 770, 13309, 8257, 7, 136, 648, 649], [470, 95, 104, 13310, 125], [942, 88, 859], [719, 103, 386, 352, 270], [5112, 7639, 68, 5485, 7], [20], [3], [14], [89, 352, 152], [1147, 148, 1124, 1147, 365, 7, 13311], [13312, 7, 352, 177, 15, 13312], [13313], [179, 957, 322], [262, 5304, 239], [1074, 750], [2068, 68, 7426, 365], [7], [291], [5106, 13314], [2328, 137, 6119], [2994, 7, 5, 1320, 7, 5, 148, 105, 414, 51, 148, 1124, 7, 352, 106, 152, 1124, 166, 305, 7, 1524], [102, 177], [794, 2529, 2056], [2440, 565], [863, 134, 3206, 5930, 1669, 2108], [291, 7, 5698], [13315, 7, 104, 106, 8, 134], [330, 7, 13316], [892, 27, 370, 149], [952], [291, 132, 125, 166, 34, 53], [715], [51, 3668, 246, 9, 104, 270, 434, 49], [95, 1728], [1947, 106, 27, 1822, 69, 462, 365], [192, 44, 1010, 115, 270, 2068, 19], [5624, 316, 7, 845, 316], [474], [13317], [123, 13318], [482], [2568], [366, 44], [1422, 365], [160, 125, 17, 7, 262, 3773, 2831], [7, 1756], [892, 27, 13319, 177, 31], [4114, 3184], [492], [21, 101, 762, 1997], [13320, 75, 2568], [13321, 3152], [172, 803, 27], [794, 5, 341], [51, 274, 939], [366, 44], [51, 1010], [1067, 104], [62], [1211, 13322, 4923], [3346], [58], [9621, 3525, 5598], [13323, 13323], [4134, 507, 2286, 166, 1219, 2592, 417, 72, 8], [884, 7, 884], [120, 32, 99, 774, 775], [1353, 499, 948, 39, 264, 919], [13324, 7, 1422], [718], [177, 111, 929, 7, 884], [14, 120], [13], [13325], [940, 448], [732, 7, 314], [977], [14, 7, 474], [5, 928, 78, 490], [2811], [2770], [106, 104, 568, 270, 3290, 642, 7, 5608, 4100, 7, 136, 137, 13326], [465], [179, 102, 72, 2971], [13327, 808, 507, 2022], [863, 103], [634], [91, 7, 619, 1625], [262, 1531, 7225], [15, 622], [3681, 399, 1342, 5308, 5673], [13328, 3661], [13329, 13330], [62, 644], [977], [1813], [754, 436, 7, 102], [14], [88, 20, 31, 153], [14], [20, 912, 35], [58, 7, 1458, 149], [16, 10652, 39, 164], [1987, 115, 13331, 349], [453], [467, 5905, 106, 349, 264, 49], [305, 1457], [315, 850, 27, 94], [51, 39, 677], [232, 7, 369], [20], [13332, 7, 1548, 702, 4202, 7, 4954, 4955, 7, 13333, 6163, 7, 1240, 4954, 13334], [3414, 7, 743, 719, 37, 26, 186, 1531, 186, 7, 9, 3414, 743, 160], [801, 1542, 1124, 352, 1386, 5258, 2346, 221, 37, 1168, 13335, 7, 790, 152, 359, 3414, 306, 37, 49, 39, 604, 80], [215, 13336], [859, 68, 42], [7563], [27, 13337, 160, 7, 27, 125, 7, 2096, 7, 13338, 13339], [1731, 693], [137], [13340], [212], [88], [513, 2973, 51, 39, 52, 264, 361, 245, 7, 2081], [22, 7, 2359, 728, 7, 15, 365], [1653, 52, 13341, 917], [20], [743, 3350, 13342], [470], [95, 13343, 7, 13344, 7, 264, 72, 13345, 7, 950, 7, 410], [99, 37, 13346], [14], [368, 14, 1308], [4688, 343, 1229, 7, 362], [20, 7, 215, 7, 215, 59, 7, 20, 35], [14, 120, 7, 385, 410, 1316, 268], [215], [5, 306, 14], [705, 91], [2352], [365], [693, 6872, 2373, 95], [2147, 27, 159, 45, 880, 10203, 7, 365, 7, 1073, 160, 125], [7, 7], [13347, 414, 16, 17, 39, 88, 163, 369, 7, 2153, 1987, 284, 7, 282, 789, 7, 8090, 49, 39, 1262, 1531], [88, 378], [62], [58], [13348, 27, 159, 46], [610, 2338, 13349], [100], [2921, 5074], [13350, 181, 2503, 1576, 2359], [2839, 39, 164, 7, 13351], [2666, 6518], [15, 1219], [368, 660, 233, 262, 68, 13352], [5932], [262, 52], [102], [106, 5, 4314], [625], [14, 120], [5, 15, 894, 7, 366, 44], [2360, 13353, 91], [2478], [13354, 3619, 13355], [766, 3178, 7, 1107], [2135], [50], [123, 5302, 7, 420], [62], [1365], [163, 3042, 189], [804, 12182, 319, 13356, 326, 749, 87], [9765, 3093, 91, 7, 3, 7, 790, 126, 101, 2049, 96, 1215, 7, 104, 386, 231, 1180, 44], [13357, 41], [4923, 7, 438], [2666, 1088], [14], [245], [13358, 3547, 111, 13359], [13360, 7, 3525, 7], [52, 1531, 1435], [367, 368, 521], [5943, 7, 13361, 7, 739], [2454, 1659], [13362, 13363], [14, 120, 974], [2199, 370, 445, 177, 49, 99, 160, 163, 115, 94, 117, 104], [1040, 7, 1172, 2484, 111, 115, 96], [13364], [160, 13365, 246, 4906], [46], [129, 917, 153], [13366], [634], [8090, 39, 472, 3666], [3135, 268, 264, 3187, 413, 39, 264, 17, 49, 34, 4596], [977, 1655], [1343, 13367], [106, 104, 15, 160, 13368, 88, 472, 51, 106, 2688, 749, 728, 1204, 1454], [2296], [20, 103], [27, 2414], [474], [1040], [746, 7, 5, 926, 42], [292, 1747, 476], [64, 898], [794], [5, 3370, 727, 779, 103], [10972, 413], [370, 4773], [5673], [13369, 13370, 7, 52, 114, 96, 177, 7, 524, 104, 4708, 7, 956, 27, 743, 7, 956, 27, 186], [472, 1353, 501, 1124], [91], [315, 619, 20, 55, 30, 196], [2360, 13353], [14, 120], [719], [776, 3161], [13371, 13372, 13373], [41], [794, 78, 274, 1915, 7, 104, 386, 2121, 956, 2133], [14], [96, 7, 319, 314, 1147, 222], [5, 11648, 1999, 1699, 270, 743, 569, 4051], [106, 5, 1366], [701], [59], [459, 776, 770, 137, 4591, 13374, 2807, 458], [13375, 13376], [13377, 2132, 72, 1334, 239], [826, 7, 2921, 1147, 222], [1752, 7, 27, 1107, 270, 502, 1180, 569, 2227, 7, 27, 194, 13378], [1640, 1644, 41], [5, 926, 78], [414, 27, 47, 6194, 7, 368, 660, 51, 1349], [761], [382, 2655, 417, 418, 363], [2931], [8933], [3, 7, 1752], [104, 105, 104, 185, 101, 263, 361], [13379], [216, 7, 489, 8831], [13380, 7, 15, 13381, 7, 1010], [13382, 13383], [6053, 10145, 153, 365, 64, 1684, 7, 270, 766, 371], [3891], [15, 9411, 2684, 7, 96, 802, 264, 189, 7, 3582], [634], [7559, 13384], [365, 437, 7, 368, 465, 9, 569, 761], [123, 13228], [423, 7, 205, 1549], [37, 26], [2633], [160, 460, 7, 15, 448, 7, 738], [13385], [64, 4495, 8135, 1828, 1386], [370], [160, 435, 39, 264, 1965, 13386, 5, 4524, 7, 54, 2359, 4779, 96, 435], [61], [14, 120], [1069, 458, 13387, 7, 13388, 13389], [106, 27, 45, 323, 65, 5953, 1847, 448], [372], [14, 7, 3203, 17], [719, 386, 104, 1077, 186, 9, 264, 3287, 27, 163, 761], [123, 6905, 7, 371], [27, 519, 4325, 9195, 44, 270, 517, 693, 2484], [136, 13390, 7, 2413, 7, 6029], [1172], [420], [417, 418], [1334, 235, 7, 205, 3121, 39, 264, 2429, 13391], [474, 7, 148, 149, 365], [149], [901, 163, 2529], [14, 120], [12], [11517], [14], [474], [420], [444, 2437], [13392, 1360], [120], [810, 30, 16, 13393, 7, 366, 78], [59, 215, 7, 26, 13394, 7, 245], [0], [474], [283, 284, 761], [120, 1122], [51, 640, 630, 7, 21], [884], [3, 7, 215], [14], [3595], [7, 11085], [90, 1856, 89, 125, 472, 49], [401], [639, 1010, 537], [794, 1275], [120], [474], [1651, 330], [412, 697, 571], [120], [410, 1121], [202, 205, 1201], [1731], [1449, 7, 622, 7, 863, 3042], [433, 5, 341, 81, 294, 7, 1714], [62], [215], [50], [5, 1560, 27, 148], [14, 7, 95, 46], [1215, 7, 352, 8118, 571, 1666], [1088, 39, 2292, 1669, 507, 3198, 284], [45, 1378, 929, 148, 79, 1028, 7, 101, 64], [513, 862, 78, 39, 660, 72, 1897], [1242], [107, 694, 489, 10288, 30, 264, 363, 7, 464, 12681, 6399, 205, 9291], [11314, 5423, 166, 8973, 754], [88, 160, 17, 6, 186, 264, 125, 1296, 44, 7, 3], [489], [638, 472, 1949, 1039], [88, 414, 7, 1648], [58], [13395, 91, 91], [2944, 12102, 7, 1070, 1818, 2944, 2326, 7, 12102, 7, 776, 310, 6623, 702, 7, 2303, 597, 4383, 776, 2336, 3797, 13396, 2606, 2303, 947, 884, 7, 1085, 1980, 13397, 136, 672, 139, 776, 7, 62], [414, 148, 27, 2489, 110, 72, 2689, 5245, 110], [1016, 3350], [253], [800, 7, 259], [5710, 510, 39, 2899], [447, 7, 4, 39, 816, 1128, 7, 3498, 355], [14], [20, 9150, 355], [663], [352, 1011, 75, 1346, 9, 750], [90, 341, 13398, 72, 412, 264, 4050, 2738, 2650, 111, 1762, 1855, 97, 72, 630, 221, 2310, 49], [2928], [62], [88, 7, 67, 1011, 164, 49], [1016], [1629], [27, 159, 454, 72, 13399, 13400, 413], [13], [5653, 1316], [13401], [1572, 1572], [13402, 5306, 4223], [694, 2783, 13403], [20], [166, 782, 7, 934, 189, 7, 104, 386, 3350, 125, 956, 619, 513, 7, 5, 341, 13404, 607, 37, 3766, 5, 1011, 72, 8, 9, 104], [2154, 720, 743, 472, 7, 1490, 417], [88, 283, 284, 7, 7853], [133, 1465, 4149, 1622, 2895], [365, 15, 898, 88, 263, 163, 64], [15, 841, 19], [88, 64], [2132, 1241, 13405, 886], [58, 7, 366], [91], [26], [740, 472, 569, 894, 13406, 2973, 472], [1383, 50], [299, 90, 300], [410, 436, 410, 7, 410, 87, 7, 417, 39, 160, 6579, 7, 2997, 7, 79, 7, 723], [45, 242, 7, 116, 27, 365, 7, 15, 1219], [99, 51, 64], [4381], [62], [492], [0, 1490, 13407, 284], [489, 1010], [884], [472, 13408, 13409, 7, 743, 264, 13410, 528], [27, 13411, 8353], [1548, 7, 1548], [14], [14], [329, 7, 13245], [2096, 7, 104, 862, 472, 177, 49, 7, 2069, 8], [537, 9, 7045, 9938, 5897], [5, 163, 216, 7, 148, 1319, 7, 85], [1524], [368, 13412, 368, 2927, 788], [13413, 13414], [120, 17], [13415], [489, 355], [581], [5045, 205, 2694], [22], [11454, 7, 148, 445], [12726, 299, 1717, 13416, 264, 363], [474, 7, 794], [370, 6659, 96, 160, 13417], [52, 524, 1034, 3368, 1725, 2049], [62], [366, 44], [14, 120], [8450, 3674, 11013, 78], [359, 5, 106, 314, 16, 5283, 7, 27, 70, 163, 677], [1010], [1507, 6, 186, 2987], [62], [0, 474], [155], [859, 7057], [3147], [205, 1201, 39, 521], [5, 491, 96, 527, 7, 319, 485, 3853, 7, 4125, 971, 330, 1454], [417, 185, 5, 1107, 7, 569, 119], [14, 937, 7, 14, 120, 7, 2002], [719, 386, 104, 132], [439, 5, 148, 185, 7950], [467, 2738, 7, 19, 7, 102], [414, 386, 27, 1531, 11097], [17, 88, 1358], [90, 178, 285, 229, 229, 13418, 16, 4085, 495], [120], [14], [166, 104, 386, 5318, 53, 30, 1022], [474], [14], [1205, 2151, 2395, 13419, 93, 1144, 45, 11], [743, 16, 344, 13420], [215, 7, 2904], [1639, 1472, 110], [26, 104], [3497, 2048], [870], [12233, 2944, 13421], [14, 1286], [37, 11229, 111, 2684, 274, 5983], [2811], [677, 721], [1732, 7, 5, 431, 228, 103], [2014, 10587, 2036, 1085, 2036], [59, 2627, 7, 59], [164, 6610, 7, 1087, 6500, 7, 1085, 696, 1071], [4034], [106, 27, 323, 448, 166, 1875, 256, 363, 902], [51, 274, 693], [45, 13422, 948, 7, 13423, 177, 5, 1366], [1385], [850], [701], [58], [215], [13424], [20, 21], [892, 2887], [330, 68, 7, 823, 10296, 431, 1010], [15, 599, 365], [62, 7, 46, 78, 7, 46, 19], [259, 7, 259], [884, 7, 5, 13425, 166, 5, 105, 78, 7, 884], [739, 361, 7, 120, 7, 15, 1054], [352, 247], [0], [370, 489, 5704, 7], [1102, 287, 732], [7125], [27, 1385], [1340], [370, 1544, 7, 45, 279], [14, 120], [185, 264, 123, 1375, 952], [378], [27, 185, 72, 13426, 2057, 3738], [245], [370], [27, 13427, 7, 362, 111, 4590, 854, 179], [1607, 39, 1716, 7, 992], [842], [3236, 7, 1997, 7, 10983, 7, 4039, 44, 262, 45, 609], [1383], [1147], [13428, 1308], [366, 44], [794, 20, 117, 436, 7, 120, 436, 7, 125, 1377], [62], [2328, 137, 6589], [13429], [62, 7, 3664], [13430, 595], [102, 7, 120], [90, 45, 1303, 7, 368, 14], [14], [10266], [102], [352, 247], [423], [91], [1639, 52, 9242, 88, 300, 34], [20, 21], [5, 1011, 72, 265, 1721, 811, 3065, 640, 11709, 5, 45, 319, 37, 1726], [14], [5390, 44, 68, 13431, 5, 185, 2049, 9915, 101], [13432, 20], [91], [299, 1856, 1262, 740], [126, 2151, 16, 804, 1300], [277, 369, 1035], [215], [163, 13433, 17], [160, 189, 4575, 101], [315, 1372, 264, 3547], [790, 13434, 7, 677, 17], [1383], [663], [14, 7, 1010, 75, 7, 863, 103, 7, 2006, 7, 8966, 125], [366], [242], [1681], [1471, 35], [127, 96, 1411], [2347, 5585], [3], [5559, 582], [717], [1310, 7, 163, 2856], [892], [2154, 5941], [101, 378], [14], [386, 104, 1385, 7, 474], [2691], [259, 139, 2944, 1443, 7, 10733], [3310], [62], [20], [62], [64], [494], [245], [13435], [1625], [412, 1028], [2060], [104, 6250, 7, 1531, 740, 7, 202, 1259, 88, 465], [1524], [123, 1219, 850, 7, 378, 1219], [374, 3141], [62, 13436, 7, 907], [474, 7, 5116, 499], [894, 104, 66], [738], [850], [1121, 1121], [14], [1385], [64, 7, 27, 64, 8198], [120, 858, 7, 20, 2856], [1383, 5, 15], [36], [120, 6264, 7, 3858, 6264], [15, 582], [62], [163, 841], [106, 352, 95, 322], [417, 124, 1381, 6841, 27, 159, 928, 7, 352, 46, 69, 6122], [13437, 13438, 7, 13439], [4905, 7, 505], [487, 1047, 681], [4381], [95, 1422, 1907], [2955], [13440, 7, 164, 49, 13441], [4374, 205, 1155], [3785], [26, 27], [2915, 7, 370, 1308, 7, 7220, 158, 7, 4881, 7, 13442, 7, 2575, 5672, 1088, 7, 1, 399, 702], [177, 913, 604], [4717, 4717, 4717], [14, 303, 7, 3, 7, 1264, 1264, 1264], [14], [215, 7, 215, 7, 259, 21], [857], [467, 1375], [563, 51, 185, 2010, 7, 1616, 7, 1], [13443, 7, 14, 762, 21], [20, 49, 7, 435, 27, 1474, 14], [1487, 516], [843, 49, 111, 16, 694], [374], [7630], [14], [164, 13444], [255, 363, 7, 14, 691], [3172, 184], [800], [106, 27, 283, 37, 26, 284, 27, 18], [14], [817, 13445], [20], [14, 7, 13446, 1292, 1454], [794, 1011, 779, 2229, 96, 264, 859, 693, 2738, 569, 111, 256, 89, 7, 1262, 13447], [3854], [663, 2262, 410], [215], [14], [3], [3784, 3167, 10035, 7, 7138], [104, 319, 2074, 7], [155], [717], [15, 365, 3765], [166, 51, 319, 7255, 7, 91], [370, 7, 15, 428, 7, 96, 64], [794, 1969, 7, 544, 630, 147], [963, 7, 13448, 6895], [898, 378, 7, 13449], [155, 7, 255, 363], [14], [185, 3280, 7, 185, 264, 2890, 2891], [622, 52, 749, 3359, 7, 435, 299, 372, 859], [732, 3805], [820], [693, 8964, 7], [489, 68, 181, 7, 95], [702, 13450, 7, 4881, 7, 1, 13451, 702, 13452], [49, 39, 275, 7, 322, 5, 148, 185, 72, 8, 9, 761, 435], [264, 163, 761, 7, 5, 45, 888, 1052, 287, 7, 262, 68, 743, 264, 10, 1453, 5498, 13453, 582, 7, 58], [1490, 2673, 126, 517], [2601, 7, 3645], [826], [11, 743, 50, 7, 8961], [4], [1816, 1558, 849, 7, 1044, 363], [13454, 166, 303, 1010], [385, 7, 3624, 404, 7, 95, 528, 7, 166, 937, 567], [13455, 788, 7, 372, 788], [14], [3196], [56], [123, 242, 7, 14], [62], [152, 6246, 7, 622], [8699], [95, 219, 7, 12131, 322], [474], [253, 16, 235, 94, 5348, 270, 9761], [95, 115, 521, 3198, 732], [925, 16, 4212], [3], [245, 7, 1723], [417, 299, 21, 513], [123, 950], [27, 3544, 45, 53, 363], [5, 24, 306, 8413, 7, 467, 1375, 7, 294], [106, 27, 26, 1847], [15, 160, 5905], [6825, 262, 1458], [120, 1574, 9164], [68, 733], [1726, 701], [105, 417, 72, 4076, 99, 148, 105, 417, 72, 8], [434, 3250], [255, 49, 229, 489, 9027], [123, 87], [2199, 117], [1465, 7, 604, 808, 4256, 7, 1465], [15, 160, 438, 448, 7, 1540, 817], [99, 90, 178, 246, 231], [267, 268, 2179], [794, 7, 5, 2381, 352, 2688, 1454], [91], [90, 392, 3118, 457, 13456, 8822, 688, 7, 90, 5038, 7, 6454, 90, 689, 688, 798, 11902, 10783], [15, 2856, 64, 21], [14], [3645], [732, 13457, 104], [2823, 7, 2096, 7, 13458, 152, 5498, 9, 229], [4, 7, 160, 39, 256], [1040, 7, 1040], [62], [2668], [10922, 343, 101, 64, 7, 859, 49, 2730], [10063, 7, 11527, 44, 322, 7, 13459], [5, 440, 13460], [5, 92, 2856, 604, 21, 7, 1927], [1472, 486, 629, 7, 88, 45, 1187, 1847], [7056, 13461, 13462, 41, 7, 7, 13463], [2544], [884, 7, 96, 1385, 160, 363, 7, 352, 13464, 13465, 5, 862], [794], [7204, 7, 20], [850, 102, 7, 8567, 13466, 7, 277, 3703], [202, 149], [2373, 308], [13467, 7, 718], [315, 62, 7, 69, 5168, 7, 62, 7, 315, 62], [884], [14], [62, 7, 13468], [2464, 7, 8, 3717, 159], [2519, 190, 1947, 7, 5533], [123, 87, 7, 6713], [13469, 584, 7, 527, 218, 7, 45, 4398, 221, 974], [743, 27], [14], [51, 216, 7, 14, 870], [215], [20], [412, 746], [849, 738], [2373, 412], [1999, 892], [1731, 78, 952], [2528], [6461, 1934, 7467], [102], [291, 7, 850, 51, 39], [186, 104], [160, 13470], [474], [13], [14], [4881], [14], [636], [1629], [14], [5580, 7, 4], [104, 1201, 1681], [13471], [13472, 13473], [368, 37, 2804, 1529], [1422], [1992], [754], [1258, 1387, 761], [569, 3075], [13474, 153, 9, 115, 134], [13475], [160, 17, 714, 1180, 472, 467], [705], [365], [62, 7, 5, 94, 202, 720, 1122], [2682], [245, 7, 5, 744, 42], [215], [3525, 1786], [62], [977, 7, 38], [13476, 13477, 472, 7, 27, 89, 1203], [3281, 4075, 7, 6, 412], [4], [272, 524, 104, 15, 773, 96, 52, 13478, 417, 37, 26, 72, 7353], [13479, 9, 1538, 462, 850, 14, 7, 462, 2535, 743, 6315], [6585, 597, 6761, 7, 13480, 7, 1], [370, 93, 519, 859, 23], [13481], [9, 13482, 7471, 7, 13483, 13484, 6791, 1033, 136, 1696, 1723, 7, 99, 749, 3988], [14], [104, 3544, 177, 859, 3414], [8579, 7, 210], [262, 1208, 7, 35, 7, 181, 355], [474], [420, 7, 245], [412, 13485, 13486, 7, 3203], [1147, 1897], [1648, 7, 13487, 7, 705], [4228, 1916, 223, 37, 669, 9029, 4961], [26, 11084, 7, 394], [11564, 7, 123, 1716], [677, 861, 7, 1774, 2532, 7, 13488, 13489, 7, 20], [62, 7, 352, 604, 7, 476, 7, 2848], [5027, 219], [5, 2335, 8], [447, 7, 1659, 13490, 7, 1977], [71, 7, 262, 52], [8330], [370, 1508, 3372, 7, 352, 1077, 15, 27, 7, 51, 1530, 1010, 7, 13491, 445, 51, 305], [13465], [13492], [719, 264, 870, 266], [58], [88], [1342, 1369, 26, 27, 177], [2074, 8678], [104, 11635], [661, 1987, 104, 13493, 13494], [166, 242, 622], [27, 185, 264, 3057, 1572, 7, 1436], [159, 447, 448], [27, 10556, 221, 1573, 849, 295, 7, 1556, 37, 1574, 7, 8120, 8120, 7, 104, 860, 7, 123, 13495], [13496], [159], [1490, 743, 3995, 7, 5, 718, 264, 5644, 1752, 7, 693, 119], [884, 7, 160, 4016, 65, 166, 7173, 152, 160, 125], [487, 499], [101, 20], [1365, 438], [414, 24, 35, 7, 95, 21, 166, 1624, 841, 901, 2549], [14], [524, 27, 15, 42, 5, 283, 284, 7, 45, 365, 1120, 37, 4528, 1534], [14, 7, 366, 1810], [1151], [14, 20], [794, 2161, 746], [215], [1073, 1934], [58, 159, 7, 299, 287], [5661], [14], [14, 7, 216], [102], [352, 604, 7, 4596, 895, 4907, 7138], [62], [366, 44, 376, 49, 102, 7, 1899], [630, 16, 2754, 7, 13497, 7, 2754, 7, 732, 88, 231], [492], [663, 159, 368, 7694, 1637, 268, 1843, 363], [2669, 186, 27, 942, 7, 230, 860, 284, 607, 1273, 737, 599, 7, 420], [968, 1941], [259, 7, 1863, 1107], [215, 7, 13498], [718, 7, 4787], [1136], [315], [3248, 548, 7, 10, 1268, 2361], [4157], [20], [13499], [352, 319, 37, 487, 1260, 3951], [1490, 177], [14], [762, 9921], [1057, 272, 7, 474], [62, 7, 120, 7, 974, 4904, 210], [282, 1016, 7, 368, 6188, 7, 69, 1582, 1542, 153, 7, 13500, 472, 639], [0], [120, 2541], [39, 78, 2660, 3815, 5, 1560, 7, 3498], [2921, 1283, 2423], [322, 262, 2091], [368, 660, 69, 14], [120], [763, 660], [1215, 974, 7, 2041, 7, 7430, 51, 862, 517], [21, 20], [245], [62, 58], [1016, 1414, 1649], [13501], [13502, 13503], [2568, 472, 13504], [62], [4404, 1679, 4404, 391, 3635, 849, 391, 157, 137], [794, 527, 89, 325, 7, 352, 3922, 177, 111, 929, 233, 7, 1147, 166, 65], [102], [13505, 104, 105, 13506, 27, 3699, 166, 27, 349, 72, 609, 13507, 7, 1490, 45, 417, 37, 13508, 13509], [179, 7, 1499], [8474], [2359, 103, 7, 272, 160, 363, 7, 13510], [0, 5, 117, 97, 1180, 622, 80], [14, 20], [51, 2076, 619], [93, 386, 52, 132, 9586, 7, 604, 111, 52, 7, 88], [366, 361, 7, 474], [7, 417], [1225, 7, 2434, 2639, 1435, 6645], [688, 13511, 741, 7, 3336, 7, 13512, 515, 166, 4170, 13513, 13513], [1481, 463], [20], [13514, 7, 6827, 111, 37, 13515, 8918, 3382, 7, 8548, 13516], [314, 524, 27, 106, 95, 74, 96, 20], [5108], [51, 94, 630, 742, 270, 6340, 7, 985, 1574], [14], [215], [997, 13517], [13518, 7, 62], [62, 386, 27, 3575, 898], [8662, 7, 13519], [2096, 3023, 166, 1018, 37, 125], [884, 7, 6474, 2798, 9125, 13520, 7, 6474, 2798, 9125, 13520, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 7156, 12561, 648, 2646, 12562, 5606, 2646, 12563, 12564, 12565, 7, 9123, 137, 6474, 2798, 9125], [27, 517], [10, 1855, 7, 569, 1858, 7, 4401, 317, 7, 889, 3278, 2243, 7, 13521, 2243, 7, 569, 1117, 7, 3366], [13112, 4692, 13522], [1016, 16, 485, 27, 13523, 8], [62, 7, 102], [58, 7, 942, 114, 72, 437, 7, 68, 21], [104, 386, 1262, 6025, 239], [37, 49], [420], [1540, 160, 3730, 299, 1650, 88, 619], [370, 7, 270, 413], [297, 1187, 859, 7], [863, 832, 104, 13524, 270, 779], [11574, 702], [718], [415, 1029, 1353, 1028], [13525], [215], [215], [369, 2087, 7, 884], [160, 343, 5401, 1418, 1615], [123, 3044, 1247], [20, 3063], [12463, 7, 472, 299, 1661, 7, 9682, 7, 24, 44], [1062, 78], [668, 482, 270, 870, 34, 70, 3065], [382, 1122, 7, 39, 69, 87, 284], [46], [15, 385, 56], [14], [263, 3353], [2014, 7366], [382, 7, 365], [2359, 7, 22, 7, 227], [1490, 1474, 1217], [11804, 111, 32, 104, 2549, 7, 62], [14], [4, 898, 806], [581, 1737], [2531], [1422], [259, 612], [89, 27, 3267, 286, 7, 761, 7, 368, 52, 12943, 239], [13526], [13527, 205, 1091, 7, 262, 1077, 186, 125], [4, 39, 387, 9, 27], [62, 5, 233, 205, 765, 72, 528, 44, 3, 7, 20, 13521, 96, 428, 7, 978, 3653, 1066], [956, 524, 134, 21, 39, 713, 296], [4091, 7, 13528, 355, 12101], [215, 91], [6358, 2204, 971, 209, 210, 72, 472], [58], [1385, 7, 104, 859, 266], [21, 7, 1267, 7, 368, 1261, 7, 1151, 564, 7, 454, 27, 1128], [761, 17], [20], [215, 59, 4824], [62], [27, 185, 1851, 296, 72, 186, 7, 34, 3800, 44, 722, 34, 210], [319, 3573, 8573], [5, 148, 228, 72, 412, 96, 4664, 264, 164, 17, 7, 1179, 78, 246, 275, 2734, 2247], [14], [806], [58], [7, 315], [524, 1016], [245, 90, 13529, 688, 7, 148, 126, 30, 177, 7, 19, 7, 166, 262, 264, 79, 266], [101, 20], [2292, 7, 2433, 268, 1430, 3024, 110, 1916], [262, 272, 609, 235], [51, 4453, 1659, 1187], [5798, 2285], [14], [315, 125, 1300], [453, 7, 229, 7, 453], [177, 528, 2361], [215], [1147], [14], [414], [93, 163, 64, 474, 7, 581, 98], [64, 43, 152], [1034, 1010, 95, 437, 17], [159, 7, 5, 3226, 27], [259], [14], [1259], [10221, 413], [2751], [235, 7, 88, 418], [26, 104, 788], [892], [104, 106, 152, 322], [62, 90, 247, 21, 677], [51, 299, 1010], [3703, 361], [374, 1088], [52, 741], [1822, 413, 365], [2025, 44, 7, 655, 104, 7, 7, 123, 746], [4021], [2347], [11750, 13530, 44, 88, 465, 80], [215], [3841, 360, 7, 15, 177], [15, 5263], [62], [219, 13531, 458], [2402], [608, 44, 193, 166, 219], [102], [13532, 270, 10454, 849], [2892, 39, 722, 1241], [549, 830], [971, 27, 1825, 261, 44], [414, 89, 5, 2010, 1187, 524, 13533, 765, 72, 186, 472], [57, 7, 414], [42, 216, 7, 663, 159], [13534, 1417], [1385, 349, 7, 10773, 7, 3292], [1172, 13535], [50, 7, 163, 7, 50], [13536], [157, 157], [62], [13537, 13538], [412], [13505, 7, 160, 435], [705, 7, 1588, 9621], [447, 728, 365], [45, 15, 160, 7], [370, 1245], [2892, 7, 474, 7, 369, 2361], [16, 1204, 1396, 13539, 228, 205, 973, 462, 524, 104, 148, 1825], [104, 519, 163, 2529, 2130], [26, 160, 64, 886, 7, 51, 790, 908, 7, 489, 543, 7, 68, 1034], [58], [3532], [4, 4170, 13540], [5, 4014, 5, 361], [447, 365], [314, 5, 148, 107, 1172, 355, 72, 5934, 743, 27, 163, 2395, 7941], [5, 185, 732, 68, 5391, 1013, 7, 125, 266], [14], [368, 660, 368, 660, 7, 262, 81], [166, 51, 212], [20, 1486], [58], [5, 341, 1458, 1916, 7, 2568, 7, 245, 1304], [111, 8598, 746, 7, 62], [52, 956, 123, 956, 27, 7], [13541], [493, 1549, 527], [111, 719], [2468], [6787], [91], [407, 5704, 410, 317, 4401, 355, 5496], [3137], [6, 2637, 5, 13542, 750], [7285, 20, 1436], [8141, 2243, 431, 6, 152, 884], [362, 1219], [5934], [27, 159], [474], [413, 489, 7, 3], [2367], [423], [102], [89, 104, 8, 13543, 413, 7, 4977, 13544], [91], [13545, 264, 13546], [62], [181, 8167, 20], [2173], [2542], [2670, 7, 13547, 7, 50, 227], [1088], [850, 7, 78, 368, 7, 78, 39], [102, 96, 370, 1382, 7652], [13548, 14], [14, 120], [14, 120], [890, 1848, 39, 40], [857], [410, 1241, 859, 7, 859, 493], [884], [13549, 2406, 7, 691], [14], [262, 194, 677, 227], [1884, 21], [10317], [2137], [581], [215, 7, 13550, 7, 13551], [7068, 6487], [291], [474, 7, 97, 2916], [581], [2096, 27, 125, 7, 95, 7581, 7, 181, 812, 7, 68, 44], [57], [12940], [99, 341, 1362, 72, 1875, 37, 1375], [448, 8, 65, 1454], [370, 125], [11456, 158], [95, 46], [120], [5, 105, 11301, 64], [17, 1119, 448], [64, 244], [104, 369, 2138, 13552], [215], [13553, 185, 72, 1320, 9, 949], [62], [467, 1375, 39, 329, 13554, 442], [1829, 2229, 779, 58], [95, 242], [977, 7, 1369, 1477], [2489, 1661, 322, 365, 7, 2173], [123, 7, 14, 7, 366], [7390], [215], [155], [4, 7, 315, 125, 5045], [622, 11], [245], [894], [12117, 1], [10332, 341, 5, 9486, 72, 10332, 1052, 6129], [62], [93, 177, 185, 222, 431, 210, 7, 1324, 17], [1116], [215, 1638, 64], [51, 39, 1623, 378], [634], [62], [4809], [6407, 49, 582, 247, 7, 12], [13555, 830], [14], [540], [99, 13556], [7], [3681, 11591, 8143], [13557, 51], [970, 110, 453], [900, 13558, 13559], [660, 7, 13560], [884], [651], [125], [91, 7, 88, 147], [14], [474, 7, 3195, 7, 795], [1560, 5, 299, 13561], [13134, 235], [13562], [102, 96, 2632, 2243], [5945, 115], [2125], [1039], [20], [10773], [13563], [95, 31, 7, 519, 52, 1659, 1187], [14], [352, 1651, 7, 330], [120, 7, 728, 7, 728, 841, 152, 13564, 96, 27], [1039], [13565, 11067, 898, 13566], [62, 51, 319, 27, 490, 270, 37, 517, 4031], [64, 17], [3561], [818], [62], [245], [414, 386, 104, 88, 1756], [7], [62], [1941, 294], [62], [394], [62], [14], [13567, 7, 13567, 7, 13567], [13568, 1804], [7, 489, 97, 355, 448, 7, 95, 270, 569, 7, 75, 7, 489, 7], [393, 13569, 13569, 13569, 7, 1719, 13570, 145, 579, 4283], [2816, 102, 96, 378, 17, 7, 1454, 7, 527, 166, 817, 13571, 7, 1855], [884], [2199, 39, 7, 361, 27, 70, 125, 91], [14, 20], [892, 88, 806, 229, 80], [202, 819, 44, 7, 365], [153, 21, 859, 49, 7, 62], [13572], [368, 660], [26, 1699], [90, 209, 319, 72, 185, 264, 13573, 9, 435], [1927], [51, 39, 4177, 99, 431, 52, 455], [20, 1624], [78, 5318, 1469], [549], [51, 39, 52, 88, 5304], [7204], [1575], [884], [50], [2161, 2162, 7, 13574], [2133, 69, 1201], [14], [3122, 11, 1859, 7, 16, 2204], [865, 104, 510], [20, 428], [1487, 255, 2454, 7, 51, 39, 45, 1650, 749, 3787], [20, 1169], [2839, 7322], [1532, 7, 1532, 3483, 52, 3245, 476], [414], [1005], [64, 13575, 7, 102, 1638], [316, 99, 604, 153, 72, 264, 265, 13576], [2135], [352, 604], [569, 7, 75, 7, 489, 7, 6686, 365], [9668], [474], [177, 341, 7, 120, 341], [259, 13577, 1106], [1422, 7], [2262, 77, 2165], [420], [62], [13106], [26, 27], [13578, 2483], [6032, 15, 582, 6424], [4686], [51, 4613, 13579, 7, 45, 568, 78, 94, 246, 743, 75, 2484], [1215, 3949, 13580, 7, 91, 7, 13581, 27, 743], [423], [13582], [936, 7, 91], [352, 148, 149], [420, 7, 51, 274, 370, 3988], [14, 120], [3530], [20, 21, 7, 64], [362, 13576, 68, 4054, 2836], [513, 1826, 266], [2402, 69, 3142, 17], [26, 27], [205, 517, 363, 72, 152], [326, 366, 37, 3897], [474], [13583, 13584], [64], [13], [1120], [62], [701, 858, 7, 93, 386, 490, 7, 120], [62, 7, 58], [8666, 2243, 72, 117, 2511, 7, 175, 7, 2860], [1357], [104, 106, 1124, 4793, 104, 185, 722, 219], [14, 2087, 1743, 7, 15, 365, 7, 64, 272, 106, 1743, 7, 314, 7, 13585], [45, 192, 78, 46], [216, 7, 412], [75, 2292, 285, 96, 507, 2583], [15, 1219], [330, 341, 7, 5, 440, 104], [414, 719], [13586, 64, 761, 1216], [14], [5386, 4946, 111, 279, 4175, 67], [104, 106, 437, 78], [227, 235], [160, 513, 39, 714], [14, 120], [62, 7, 88, 13587], [215, 13588, 7, 215, 156], [4563], [291], [428, 179, 894, 64, 330, 656, 42], [296, 186, 15, 42, 101, 12388, 27, 94, 630, 13589, 284, 9, 42], [2175], [20, 741], [1383], [15, 622, 7, 51, 1107], [6, 10748, 90, 9692, 472], [20, 7, 732, 569, 499, 7, 750, 7, 732, 7, 245, 7, 750], [619, 181, 39, 11], [581], [1853, 7, 62, 89, 5, 45, 10102, 5043, 7, 417, 39, 472, 264, 109], [5753], [1941, 1941], [1649], [390, 2122, 264, 917], [902], [239, 7, 414, 27, 186, 160, 7, 92, 2382, 2708, 386, 275], [262, 264, 2951], [944, 13590], [985, 434], [14], [305, 264, 153], [465], [200, 7, 4342, 7358, 1077, 186], [1353, 285, 1401, 492], [14], [1225], [710, 6028, 68, 347], [519, 1102, 264, 574, 49], [259], [9151, 72, 91], [14, 46], [13591], [884], [717], [217, 7, 7689, 7, 217], [1642, 1642, 7, 474], [13592], [3137, 7, 13593], [2965, 1425, 10587, 2182], [20], [13594, 7899], [1, 3948], [117, 42], [8374, 166, 13595, 166, 13596, 7, 1365, 123], [718], [719, 994, 386, 27], [62], [88, 27, 148, 224, 524, 490, 39, 722, 4673, 326, 52], [902, 7, 78, 2923, 37, 2206, 3826, 72, 117, 104, 62], [13597], [26, 27, 235], [166, 369, 622, 994], [370], [370, 27, 1308], [239, 7, 177, 205, 1469, 7, 13598, 264, 991, 13599, 7, 2133, 37, 3404], [14], [6877, 13600, 947, 7, 569, 4703, 7, 1815, 12938], [62], [13601, 20, 7, 62], [940, 455], [14, 3292], [414, 13459, 27, 13602, 16, 1556], [51, 1674, 527], [1719], [472, 1018], [2322, 39, 1650, 78], [14], [397, 1826, 413, 266, 1828, 12459, 975, 1538, 11, 51, 1686, 487, 49, 85, 801, 114, 115, 51, 3368, 13603, 166, 1483, 166, 322, 5919], [15, 229], [4778, 7, 4778, 7, 4778], [6876], [362, 609], [14, 46], [13604, 10578, 7, 127], [22], [27, 2118, 264, 2057, 17], [46], [205, 2285, 39, 37, 13605, 270, 1127, 10, 205, 13233, 1526, 39, 72, 117, 42, 326, 4800, 37, 13606], [13607, 13608, 11522], [715], [3132, 1054, 13609], [13610], [412, 4690, 7, 13611, 8068, 8114, 244, 7, 13612, 8114, 1684, 7, 489, 355, 7, 474], [20, 7, 800], [260, 7, 148, 46], [14, 7, 102, 7, 3], [2060], [95, 1422, 7, 17, 106, 1999, 8, 160, 49], [62, 7, 374], [1875, 160, 49], [4165, 4312, 7332], [120], [14, 7, 20], [648, 11138, 670], [5, 209, 349, 72, 2706, 7, 1333], [123, 7271], [13613, 247, 524, 1219, 89, 727], [19, 46], [5, 971, 8, 5283, 7, 95], [8003], [521], [62, 7, 228, 516], [13614, 352, 412, 96, 272, 489, 501], [1215], [5, 307, 308], [717], [352, 4399, 352, 910, 166, 352, 210, 9, 13615], [445, 568, 773], [91], [13616], [10, 1623, 407], [58, 2333], [158], [719, 749, 2179, 30], [850, 262, 1661], [1275, 132, 263, 125, 150, 13617], [1645], [13618], [13619], [7, 45, 323], [1016, 7, 245], [58], [104, 588, 62, 7, 352, 228, 99, 417], [4586], [453], [3250, 2359, 3951, 2081, 2082], [810, 30, 177, 929, 13620, 13621], [985], [2829, 181, 355], [1225, 7, 622, 39, 1203], [1490, 177, 104, 106, 179, 322, 2045, 474], [20, 21], [215], [245], [91, 7, 14, 7, 13622], [14, 15, 841], [186, 52, 8986, 264, 378], [3845, 7, 13623, 7, 442], [14], [489, 97, 355], [4039, 582, 7, 52, 44], [5710], [14], [58], [202, 322, 7, 368, 155], [2536, 45, 46, 10209, 7, 160, 39, 264, 2875], [2137], [62], [13624], [2025, 44, 68, 13625], [2079], [2389, 355, 431, 370, 2576], [4687, 7, 6, 27, 9555], [341, 148], [3437, 7740, 13626, 370, 13627], [2160, 968, 1425, 10431], [9102], [15], [123, 1961], [90, 6893, 270, 1172, 492], [980, 149, 7, 104, 349, 7, 2811], [977], [13628, 463], [516, 788], [390, 2395, 2060], [102], [58], [14, 7, 20, 21], [13629, 436, 7, 97], [2944, 3748, 399, 3887, 13630], [14], [20, 7, 38, 39, 40, 7, 334], [977], [91, 7, 91, 7, 13631, 7, 91, 7, 91, 7, 91, 7, 91], [973, 13632, 8699, 2406, 795, 6898, 472], [14], [6085, 68, 7, 931, 2135], [978, 64, 21], [58], [5673, 1076], [773, 87, 13633, 10363, 1063, 256, 7, 382, 4259, 765, 270], [4103, 17, 7, 69, 177, 88, 5559, 7, 472, 125], [13634, 7, 219, 9157], [64, 17], [14], [13635, 7, 13636], [563, 51, 3024, 1187, 7], [55, 9224, 7, 127, 2384, 7, 120, 172, 7, 272, 489, 1699, 1203, 7, 172, 166, 390, 7, 1615, 744, 7, 95, 2681, 365], [26, 7, 14, 120, 366, 102], [719, 783], [51, 39, 2899], [1731, 78], [95, 21], [1225, 7, 51, 13498], [20], [62, 7, 64], [13637, 2243, 7, 3519], [417, 124, 119, 89, 27, 1105, 7, 272, 44, 7, 474, 13638], [15, 2262, 365], [12926, 3173, 7, 13639, 13640, 7, 1240, 2034, 1070, 7, 9950, 7, 688, 687, 6851, 2944, 5643], [1891, 13641, 7, 13642, 859, 78, 340], [2946, 7220, 952], [14], [1638, 95, 21, 7, 4], [454, 97, 2940], [14], [3], [26], [14], [458, 3209, 7, 3537], [370, 17, 7, 215], [14], [62], [1205, 7, 93, 148, 117, 564, 1377, 7, 99, 3044, 229, 32, 7, 1721, 469, 111, 27, 3413], [3525], [414, 27, 88, 1756, 158], [370, 1770, 32], [1707, 10751, 5737], [123], [3756], [474, 7, 120, 1219], [414, 386, 507, 1722, 471, 104, 159, 7, 160, 39, 88, 1460], [7, 2594, 7], [386, 93, 13643, 13644], [5, 1471, 64, 227], [123, 2162], [431, 330, 347, 3696], [102, 95], [283, 37, 26, 284, 372], [192, 44, 105, 359, 104, 386, 270, 16, 4408, 7, 2025, 44, 524, 104, 228, 13645], [1723, 776], [2013, 5033], [90], [315, 88, 2079], [166, 34, 27, 803, 7, 88, 303, 106, 789, 750], [102, 7, 4903, 7, 1436], [14], [5, 7775, 27], [524, 78, 39, 749, 408, 51, 10499, 78], [417, 7, 89, 27, 220], [1074, 16, 125], [20], [499, 370, 1041, 630, 473, 2730, 13646], [412, 365], [59], [369, 435, 7, 634, 7, 13647], [679, 2484, 13648], [524, 5, 185, 72, 692, 2310, 408, 270, 160, 49, 5, 341, 1747, 2248, 765, 72, 10531, 8625, 270, 37, 907], [1103, 4600, 68], [243, 701, 88, 1458, 582], [51, 39, 1930, 956, 37, 13649, 11217, 7, 4297, 636, 13650, 4297, 636, 13651], [634], [1542, 3815, 39, 2660, 3815], [54, 746, 30, 680, 2484, 537, 13652], [1219], [6194, 7, 370, 2467], [451, 825], [102, 378], [940, 3584], [1645], [1490, 52, 277, 123, 72, 179, 96, 13653, 472, 223, 1856, 10280, 96, 205, 463, 525, 489], [102, 2242], [14], [12868], [62], [36, 7, 62, 7, 26, 104], [1610], [75, 205, 344, 7, 5, 162, 72, 13654], [622, 1366, 44, 1372, 39, 1624, 66], [1062, 385, 939, 7, 2057, 3738], [11], [13655, 1558, 458], [365, 15, 1377], [2345, 9717, 7, 648, 13656], [26, 104, 13657, 7, 414, 44], [537, 3080, 7, 412, 13658], [5, 910, 505, 7, 4, 7, 370, 1319], [95, 1665, 30, 1050, 13659], [270, 49, 7, 487, 569, 355, 7, 218], [1102, 859, 2056, 4448, 7, 52, 67, 106, 8, 2583], [1899], [352, 247], [90, 971, 52, 372, 2637, 104], [13660, 9422, 7, 13661, 779], [14], [420], [14], [19, 46, 7, 3135, 39, 275], [6216, 3625], [13662, 7, 3575, 3580, 2174], [15, 582, 96, 471, 7, 166, 1012, 42], [2050, 39, 7522, 13663, 13664, 205, 159, 270, 160, 49], [5290], [245], [127], [205, 1598, 264, 13665], [1039], [1262, 5059, 622], [102], [412, 19], [738], [7056, 7, 4966, 1617, 7, 719, 264, 266], [10984, 7, 977], [1969], [1863, 13666, 472, 125, 166, 3457, 72, 8578], [985, 2468, 7, 90, 13667], [270, 37, 7, 1229], [14, 120], [4198], [5, 314, 27, 185, 264, 13668, 111, 1047, 9, 1147, 27, 6, 152, 1296, 1617, 565], [90, 523, 5861, 101], [49], [14], [3420, 52, 164], [619], [0, 7, 0, 693], [58], [13669, 7, 776, 4546, 7, 1815, 95, 1010, 7, 1346], [10346], [1723, 4340], [1486], [46, 13670], [521, 31], [472, 7862, 1916], [216], [13671], [2886, 7, 13672, 467, 7, 2782, 13673, 7, 886, 1300], [239, 229, 2122, 1911, 1716, 826], [20], [1425, 2944, 13674, 947], [13675, 72, 3989, 32, 7, 4593, 44, 115, 21, 153], [64], [1538, 266, 1686, 1122, 359, 90, 862, 5, 299, 3989, 1538, 266, 1686, 1122, 359, 352, 476, 185, 264, 3989, 55, 7, 1490, 694], [14], [120], [517, 285, 460], [14, 7, 8884, 27, 13676], [1398], [314, 519, 177, 540], [14, 7, 3], [14], [93, 148, 105, 417, 72, 17, 8], [414, 37, 26, 186, 104, 8, 68, 1229, 5485], [56], [13638], [245], [420, 7, 2971, 5872, 7, 474], [13677, 7, 102], [2133, 44], [372, 7, 148, 7644], [14], [756, 26, 42, 284, 7, 370, 1529], [41, 7, 460], [14, 120, 16, 13678], [660, 961, 1263], [51, 39, 1166, 7, 314], [474], [14, 385], [14], [2060], [940, 264, 1560], [746, 7, 455], [45, 264, 1908, 111, 363, 159], [884], [185, 104, 3914, 44, 179, 264, 1924], [2025, 75, 2484, 7, 6686], [14, 7, 14], [88, 719, 62, 7, 13679], [6, 3298, 160, 13680], [262, 621, 166, 13681, 190, 166, 1622], [569, 74, 91], [102], [10524], [13682], [4250], [414, 27, 1471, 101, 1253], [177, 50], [50], [186, 104, 431, 454, 72, 568], [2285, 13683, 1600, 75, 6378], [14, 120], [20], [19, 15, 929, 177], [13684, 7, 262, 3224, 9, 811, 13685, 7, 4228], [215, 7, 215], [11058], [368, 307, 308], [14, 20], [474], [474], [315, 13686, 849], [1487, 7, 157, 157, 7, 27, 101, 13687], [901, 270, 49, 7, 10658, 246, 418], [14], [4854, 655, 96, 12622, 282, 211, 148, 1987, 264, 13688, 2151, 5835, 659], [215], [14, 865], [14], [20, 479, 104, 66], [434, 363, 7, 2025, 44, 7, 262, 1847, 322], [223, 2537, 7, 5, 744, 42, 7, 544, 11], [123, 1471, 1274, 385], [163, 11, 1650, 1851, 3142, 49], [581], [15, 1035, 19], [3561], [13689, 160, 564, 372, 185, 1851, 270, 1430], [6777], [619, 104, 319, 13690], [252, 1481], [11672], [12916, 1915, 747, 177, 49], [680, 677, 862, 738, 1826, 17, 7, 5580, 7, 3898, 1353, 1241, 3523, 7, 13691], [64, 52, 179, 10330], [420], [20, 3802, 1089], [46], [20, 21], [715], [20, 7, 160, 13692, 7, 390], [13693], [14, 120], [45, 46], [177, 265, 2968, 2022, 7, 11881, 2433], [2122, 101, 859, 436], [660], [50, 46, 7, 1253, 7, 365, 7, 892], [21, 97, 7, 5594, 3350], [1, 219, 7, 4840, 2575], [262, 8547, 810, 44, 284, 104, 319, 8547, 68, 361], [14, 120], [2856], [58, 622], [13694], [5, 159, 386, 1650, 574, 7, 619, 1699, 7, 125], [114, 103, 7, 26, 472, 13695, 103], [51, 39, 270, 49], [27, 105, 7, 75, 13696, 270, 6590], [6877, 1588], [37, 8517, 5095, 7, 4664, 264, 49, 53, 9304], [51, 319, 13697], [680, 3060], [13698], [2064, 7, 5, 3226, 7, 330, 21], [14], [366, 44], [26, 104, 3470], [64, 1590, 7, 517, 98], [1853], [798, 259], [3976, 2437], [64], [14], [1210], [489, 39, 762], [5, 319, 1016, 795], [14, 20], [743, 5423], [1961, 85], [1422, 7, 1147, 2078], [2096, 2856, 27, 630, 370, 1969, 636], [794, 45, 454, 5378], [493, 7, 474, 259], [62], [1486, 13699, 7, 660, 7, 412], [13700], [89, 5, 499, 27], [160, 428], [1342, 13094, 7, 13701, 3104, 6248, 7, 310, 12080, 5690, 458, 7, 374], [315, 91], [45, 46, 159], [3250, 489, 65, 513, 3250, 569], [474, 7, 826], [120, 2541], [117, 44, 31, 7, 64, 1219], [719, 264, 859, 1783], [423, 390], [467, 1375, 7, 13702, 27, 7, 177, 111, 27], [88, 164], [368, 1659], [15, 7, 15], [192, 78, 95, 68, 45, 72, 630, 1052, 1117, 7, 20, 1292], [15, 11084], [245], [474], [1927, 7, 157, 157, 7, 2367], [3], [5, 5696, 13703, 902, 7, 13704, 387], [5, 185, 72, 95, 72, 1843], [12], [15, 1219], [13705], [20, 21], [1039, 7, 15, 894, 127], [259, 21], [4, 447], [492], [20, 3847], [5, 2076], [490, 299, 722, 13706, 2611, 13707, 200], [5, 349, 181, 1047, 495], [13], [4228, 811, 281], [160, 163, 2108, 7, 410, 1382, 3142, 49], [75, 97, 2484], [13708], [215], [363, 7, 39, 7, 1572], [1242], [743, 4, 17], [26, 160, 45, 95, 5, 604, 88, 263, 103, 1272, 184, 743, 160, 45, 95, 46], [91], [4, 677], [69, 13709, 39, 743, 75, 1797, 3413], [370, 5407, 365], [985, 434], [1992, 75], [91], [513, 7, 6, 412], [20], [13710, 252], [5426, 2151, 370, 104, 369, 3178], [901, 81], [20, 177], [64, 13711], [4676, 111, 13712, 270, 264, 12447], [14], [13], [1645], [64, 2007, 7, 474], [27, 177, 2783], [5696, 72, 13713, 37, 13714, 13715, 30, 13716, 3721], [370, 13717, 72, 149, 7, 474], [2137], [102, 1147, 7, 440, 27], [51, 274, 75, 2738, 784, 51, 3368, 749, 13718], [120, 13719], [62, 7, 64], [262, 7, 88, 859], [627, 104, 660, 235], [795], [1723, 7, 776], [4310, 104, 68, 37, 11231], [3561, 7, 13720], [378], [1385, 7, 26], [862], [10625], [14, 120], [62, 1731], [58], [299, 209, 1454], [13721, 7, 561, 770, 13722], [9960], [474, 7, 13723, 7, 20], [3], [20, 741, 2298], [137, 1770, 13724, 13725, 116, 4944, 811, 159, 91, 7, 58], [5914, 1349], [362, 2613], [414, 386, 104, 132], [20, 617], [152, 177, 7, 62], [439, 262, 490], [166, 44], [13726], [366, 13727, 7, 378], [1820, 90, 1545], [5, 13728, 1999, 777, 264, 12619, 13729, 96, 418, 363, 1109], [1076, 845], [62], [569], [2999], [14, 120], [3485, 7, 330, 68], [14], [368, 177, 1810, 7, 13730, 7, 13731], [155, 694], [3], [420, 7, 622, 7, 15, 622, 7, 622, 935], [58], [2125], [859, 1544, 185, 3595, 8176], [5, 942, 96, 104, 627]]\n",
            "[[6], [6], [6, 5, 2, 2, 2], [3], [2], [2, 4, 2], [2, 4, 2, 3], [2], [3, 8, 5, 2], [2, 4, 5, 6, 8, 2], [2], [4, 2, 2, 4, 2, 2], [4, 2, 6, 2, 4, 4, 2, 2, 2], [8, 3, 2], [6], [2, 2], [2], [2, 2, 4, 4, 2], [2], [6], [4, 2], [6, 8, 2, 6, 5, 2, 2, 2], [2, 2, 5, 2, 2, 2, 4, 2, 2, 2, 4], [2, 5, 6], [2, 6], [2, 2], [2, 2, 2, 2, 2], [6, 2], [2], [2, 7], [4, 2, 2, 2, 8, 2], [2, 6, 8], [7, 2], [4, 2, 4], [4, 2, 2, 2, 2, 2], [3, 2, 4, 2, 2, 4, 5, 2, 2, 4, 2, 2], [2, 2, 2, 2], [2], [2, 5, 2, 5, 4, 6], [2, 5, 2], [6], [4, 2, 2, 2], [2, 2], [6], [2], [4, 2, 2, 2, 2], [2, 5, 2, 4, 5, 2, 2, 5, 6, 2, 5, 2, 2, 5, 2, 5, 2, 2, 2, 7, 5, 2, 2], [2], [3, 8], [6, 6, 5, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2, 5, 2, 4, 2, 5, 2, 2, 2, 5, 2], [4, 4, 2], [2, 5, 3, 2, 5, 2, 5, 2, 2], [4, 2, 2, 8, 5, 2], [2, 2, 2, 4, 3, 2, 4, 2], [2, 6], [2], [2, 2, 3], [2, 4, 2, 4, 5, 2, 4, 2, 4, 2, 8, 5, 2], [6], [4, 2, 4, 6, 8, 2], [2], [2], [2, 2, 5, 4, 2, 2, 4, 2, 2, 6], [3], [2, 4, 2, 4, 2, 2, 6, 2, 2], [2], [6, 8, 5, 2, 2, 5, 4, 6, 5, 6, 2], [4, 6, 2, 2, 2, 2, 2], [2, 8], [2, 2], [6, 4, 2], [2], [2], [2, 4, 2, 8, 8, 5, 4, 2, 2, 5, 2, 4, 2, 2, 2, 3, 2, 5, 8, 2, 2, 2, 2, 5, 2, 4, 2, 2, 2, 3, 2], [2], [2], [2, 2, 5, 4, 3, 2, 6, 5, 3, 5, 3, 5, 3, 5, 4, 2, 7, 4], [6, 5, 4, 2, 2, 2, 2, 2, 2], [6], [2, 2, 5, 2], [2], [2, 4, 2, 5, 4, 3, 5, 2], [2, 5, 2], [2, 4, 5, 3], [2, 5, 2, 5, 2], [6, 4, 3], [7], [2], [2, 2], [4, 2, 2, 2, 2, 3], [2, 8, 2], [2, 4, 2, 4, 2, 2], [2], [2], [6], [2], [3], [2, 2, 2, 2, 2, 2], [6, 8], [6], [2, 4, 2, 3], [6, 8], [4, 2], [2, 2, 4, 2, 6, 5, 2], [6], [2], [2, 5, 4, 2, 8, 2, 4, 2, 5, 6], [6], [2], [2, 2, 4, 2, 2, 4], [6, 6, 8, 6], [6], [2, 5, 2], [4, 2, 2, 5, 2, 2, 2, 5, 2], [6, 6, 5, 2], [2], [6, 4], [2, 4], [2, 5, 2, 2, 6, 5, 2, 3], [4, 2, 4, 2], [6], [2, 2], [4, 5, 3, 5, 3, 3, 5, 4, 2, 2, 3], [2], [2], [2, 2], [2], [6, 2, 2, 2], [2, 2, 2, 2], [2, 2, 4, 2, 2, 2, 3, 2, 4, 2, 5, 5, 2, 2, 4], [2, 4, 2, 2, 2, 4, 2], [2, 2, 2, 3, 5, 2, 2, 2, 2, 2, 6, 5, 2, 5, 6, 5, 2, 5, 2], [6], [2, 2], [2], [2, 8, 2], [2, 3], [6, 5, 2, 2], [2, 2, 6, 5, 8], [2, 3, 5, 8, 2, 4, 2, 4, 2], [3], [2], [2, 8, 6, 4, 2, 5, 4, 2, 2, 4, 2], [2, 6], [4, 2, 4], [2], [2, 2, 5, 3, 5, 2, 2], [6], [6, 2, 5, 2, 2], [6], [4, 2, 2], [2, 2], [2, 2], [3, 4, 2, 2], [2, 4, 2, 4, 2, 2], [2], [2, 8], [2], [2, 6], [2], [6], [2, 6, 6, 2], [2, 4, 2, 4, 2, 2, 2, 4], [3, 2], [6, 6], [4, 2, 2, 2, 5, 2], [4, 2, 5, 4, 2, 2, 5, 2, 2, 2, 2, 5, 2, 2], [4, 2, 2, 2], [2, 2], [6], [4, 2, 2, 6, 2, 2, 2, 2, 2, 6, 5, 2, 2, 4, 2, 2, 2, 2, 6, 2, 6, 4, 2, 2, 2], [3, 8, 5, 6], [2, 4, 2, 2], [2], [3], [2, 2], [4, 2, 8, 5, 2], [6], [4, 7, 2], [2], [2, 2, 2, 5, 4, 2, 2, 2, 5, 2], [4, 2, 2], [2], [2], [4, 2, 5, 2, 4, 2, 2, 2], [2, 2, 5, 2], [2], [2, 2, 5, 2, 5, 8], [4, 2, 2, 2, 8, 6, 5, 2], [2], [8], [2], [6, 8, 2, 5, 2, 2, 2, 2, 4, 2, 4, 2, 6, 2, 5, 2, 4, 5, 2], [2, 2, 2, 5, 2], [2, 4, 2, 4, 2], [8, 2], [2, 3, 2, 2], [2, 2, 2, 5, 4, 2, 2, 5, 2], [6], [8, 2, 3], [8, 2, 8], [2, 2], [2, 8], [4, 2, 5, 2, 2, 2], [2, 5, 2], [4, 2, 2, 2, 4, 2], [4, 2, 2, 2, 7, 2, 2, 4, 2], [8, 2, 2], [2, 2, 2, 2, 2], [2, 2], [2, 5, 2], [2], [4, 2], [4, 2, 2, 6, 2, 2, 4, 2, 2, 2, 2, 2], [2], [6, 3, 5, 6, 2, 6, 3], [2], [2], [4, 2, 2, 2, 2], [6, 3, 2, 5, 2, 2, 2, 2, 6], [6], [6], [2, 4], [4, 2, 2, 2], [2, 4, 2, 2, 2, 8], [2, 2], [2], [2, 5, 2, 2, 2, 2, 2, 4], [2, 2, 2], [2], [2], [6], [2, 2, 2, 4], [2], [6, 6], [2, 2, 2, 2, 2], [2, 2], [2, 5, 2], [2], [2, 5, 2, 2], [3], [2], [2], [4, 4, 2, 2], [3], [2, 8], [2, 6], [6, 6], [2], [2], [2, 2, 6, 2, 2, 2], [2, 2], [2], [3, 2], [6], [6], [2, 2, 6, 6], [2], [6, 5, 3, 8], [2], [2, 5, 2, 2], [2], [2, 4, 2], [2, 2], [2], [6, 5, 6, 6, 5, 4, 8, 5, 4, 2, 2, 5, 2], [2, 2, 5, 2], [2, 5, 2, 2], [2, 4, 2, 2, 2, 5, 2, 2], [6, 6], [2], [3, 2, 5, 4, 7, 2, 5, 4, 2, 5, 2], [2, 4, 2, 4, 2], [2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 5, 2, 4, 2, 2, 3, 2], [2, 2], [4, 2], [6], [8, 7], [3, 4], [4, 2, 2], [6, 6], [2, 2, 2, 2, 2, 5, 6, 2, 5, 2, 8, 2, 2, 5, 4, 8, 2], [2], [4, 2], [2, 5, 2, 5, 2, 5, 8, 5, 2, 5, 2], [6, 8, 2], [6], [2], [2], [2, 2, 6], [2], [2, 2, 2], [2, 4, 2, 2], [2], [2], [2, 2], [2, 8, 5, 6, 8], [2, 2], [2, 4, 4, 2, 4, 8, 2, 2, 5, 4, 2, 2, 8, 2], [4, 2, 4, 2, 2, 5, 6, 2, 7, 2], [6, 5, 6, 5, 6], [2], [2, 2], [3, 4, 2], [6], [2, 3], [6, 6], [2, 4, 2, 2, 5, 2, 2, 3, 2], [2, 6], [6, 5, 2, 3, 2, 4, 8], [2, 3], [4, 4, 2], [2], [2], [2, 2, 2, 4, 6, 5, 2, 2, 4, 6], [2, 2, 2, 2], [2, 2, 3], [2], [2], [2, 8], [2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 5, 2, 2, 8, 2, 4, 2], [2, 4, 2], [6], [6], [4, 2, 5, 2], [3, 2, 2, 2], [2, 8, 2, 2, 6, 3, 5, 2, 6], [8], [2, 8], [2, 5, 2], [2, 4, 2, 2, 2], [6], [4, 2, 2, 5, 4, 2, 2, 2], [6, 5, 2, 2], [3], [4, 3], [2, 2], [3, 2, 2], [2], [2, 5, 4, 2, 4, 5, 4], [4, 8], [4, 2, 4, 2, 2, 2], [2], [6, 6], [2, 2], [8, 2, 2, 2], [6], [3, 3, 5, 2, 2, 2, 2, 2, 2], [6], [2], [2], [2], [2], [2, 4, 2, 2, 2], [6, 6], [4, 2, 2, 2, 6], [2, 3, 2, 2, 2, 6, 2], [6, 8, 5, 2, 5, 2, 2, 2, 2, 5, 3], [2, 2, 2, 2, 2, 2], [2, 2, 2, 3, 2], [3, 2, 2, 6, 8], [6, 6, 4, 2, 2, 2, 2, 2], [6], [6, 5, 2, 2, 5, 2, 3], [4, 4], [2, 8, 5, 2, 2, 4, 2, 4, 2], [6, 5, 2, 2], [2, 2, 5, 2, 2], [2], [2, 4, 4, 2, 2, 2, 6], [2], [8, 3, 5, 3, 2], [2, 6, 2, 6, 8], [2], [4, 2, 2, 2, 4, 2], [6, 6, 5, 6], [2], [2, 5, 8], [2, 2, 5, 2], [2], [2, 5, 2, 5, 2], [8, 5, 3], [6, 2, 2], [2], [2], [2, 2, 2, 4, 2], [8, 2, 2, 2, 2, 5, 3, 4], [3, 4], [2, 2], [2, 5, 4, 2], [2], [2, 2, 2, 5, 2, 5, 2, 5, 2, 5, 2], [2], [3, 2], [6], [2], [2, 2, 2, 7], [2, 2, 2], [6, 4, 2], [2, 8], [2, 2], [2], [2, 2, 4, 3, 2, 2, 2, 2, 2, 2, 5, 2, 2, 3, 6], [2, 6, 2, 4, 8], [2], [2, 2, 2, 2], [6], [2], [6], [6, 4, 8, 5, 3, 2, 2, 3], [2, 5, 6], [2], [3, 4, 8, 3], [6, 6], [6, 6], [2, 2, 8], [8, 2, 5, 6], [4, 2, 8], [2, 2, 5, 2, 2, 2], [8, 2], [2, 2], [3, 6, 8], [2], [6], [6], [2, 2, 2, 2, 2], [2, 4, 2, 5, 6], [2, 4, 4, 2, 2, 2], [2, 8, 2], [2], [2], [8, 2, 6, 2, 5, 2], [4, 2, 2, 2, 2], [2, 2, 2], [2, 2], [2, 2], [6, 6], [4, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2], [2, 2, 5, 2, 5, 2], [2, 8, 4, 2, 2, 6, 4, 2, 5, 2, 2, 5, 2], [2, 4, 7, 2, 2, 4, 2, 2, 4], [2], [2], [2, 5, 4, 8, 2, 2, 4, 2, 5, 2, 8, 5, 2, 4, 2, 5, 6], [6, 4], [2, 5, 2], [3], [2], [2, 2, 4, 2, 2, 4, 2, 4], [2, 2], [2], [2, 5, 2], [6, 6], [2, 4, 2, 5, 3, 4], [2, 2, 2], [6], [2, 2], [2, 5, 4, 2], [2, 2, 2, 2], [2, 2, 6, 2, 5, 2], [2], [6, 8], [8, 3, 5, 2, 4, 6, 5, 4, 2, 4, 7, 2, 2], [6], [2], [2], [2], [2], [6], [2], [2], [2, 5, 4, 8], [2], [2, 2, 2, 2, 2, 8], [2], [6, 8], [6, 4, 2], [2, 6, 2], [6, 2, 5, 4, 2, 7, 2, 5, 6, 5, 2, 5, 2, 6], [6, 2, 5, 2, 2], [2, 5, 6, 7], [5], [2, 5, 2], [2, 2], [6], [2], [2, 2, 6, 2, 2, 3], [6], [6, 8], [4, 3], [2, 5, 2, 2], [2, 5, 2, 2, 4, 2], [2, 2], [2], [8], [4, 2, 5, 6, 2], [6, 2], [6], [3], [6], [2, 7], [2], [2], [4, 4], [2, 2], [8, 5, 2, 2], [2], [6, 5, 6, 4, 3], [2, 2, 2, 2, 2, 8], [2, 7], [3], [6], [2, 5, 4, 2, 3], [6], [2, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2, 2, 5, 2, 2, 4, 2, 5, 2], [2, 2, 2, 2], [2, 4], [3, 2, 2, 2, 2, 2], [2, 5, 3], [2], [2, 5, 3, 5, 8, 2, 4, 2, 5, 2, 2], [2], [3, 5, 2, 2, 5, 6], [6, 6, 5, 3, 8], [6, 2], [2], [2, 4, 2, 2, 4], [2], [2, 2, 2, 2, 2, 2], [2, 7], [3], [8, 2, 4], [4, 4], [2, 2], [4, 4, 2, 2, 6, 5, 2], [2, 8, 5, 8, 5, 2, 2, 2], [4, 2, 2, 2, 2, 2, 2], [2], [4, 2, 2, 6, 2, 2, 2], [2, 2, 7, 2, 4, 8, 2, 5, 2], [2, 2], [2, 8], [2], [2, 2, 5, 2, 2, 5, 4, 8, 2, 2], [2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2], [4, 6, 8], [2, 2], [2, 2], [6], [6], [2, 6], [2, 5, 4, 2, 4, 2, 2], [6], [2, 4, 2, 2, 6, 2], [2, 5, 4, 5, 2, 2, 6, 4, 4, 2], [2], [2, 8, 2], [2], [2, 8, 2, 2, 6], [2, 5, 6, 2], [2], [2, 2, 2, 2, 5, 4], [2], [8, 2, 2, 2, 5], [2], [2, 5, 2], [6, 6], [3, 4, 2, 2, 2, 4, 2], [2, 6], [7, 2, 2, 2, 5, 2, 8, 2, 2, 2], [4, 2, 4, 2, 2, 7], [6], [2], [4, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2], [2, 2, 2], [3], [2, 2, 4, 4], [4, 2, 2], [6], [2], [6, 6], [2, 2], [7], [6, 6], [6, 6], [2, 2, 4, 3, 4, 2, 2, 3, 2, 4, 2, 2], [6, 2], [6, 8], [2, 2], [6, 8, 2], [4, 2, 6, 2, 3, 2], [2], [2, 2, 2], [2], [2, 2], [4, 8], [2, 2, 2, 2, 5, 2], [6], [2, 3], [6], [2, 2], [8, 6], [4, 2], [2, 5, 2, 2, 5, 2, 5, 2, 5, 2], [2, 3, 2], [2, 5, 2, 5, 2], [5, 2, 2, 5, 6, 5, 2, 2, 2, 8, 5, 4, 2, 2], [2, 5, 2, 5, 2, 7], [2, 5, 6, 2, 6], [2], [2], [2, 5, 2], [6, 2], [2, 2], [8, 2], [6], [2], [8, 6, 2, 8, 6], [4, 2, 2, 5, 8, 2, 5, 2, 5, 2, 2, 2], [2], [6, 5, 6, 8], [2, 4, 2], [2], [2, 2, 4, 3, 2, 2], [2, 2], [2, 2, 4, 2, 2], [6, 5, 6], [4, 2, 2, 2, 2, 2, 8, 3, 2], [3, 4, 2, 2], [2, 2], [2, 6, 2], [6], [2, 2, 5, 3, 2, 5, 2], [2, 2], [2, 4], [4, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2], [2], [2, 2], [2], [2], [4, 2, 2, 7, 2, 2, 2], [6, 5, 2, 5, 2], [6, 2], [2, 2, 2, 5, 2], [2, 6, 2, 4, 2, 2, 2, 5, 2, 5, 4, 8, 5, 2, 4, 2, 2, 2, 2, 2], [2, 2, 2, 5, 8, 8], [4, 2, 2, 4], [6], [4, 2, 2, 2, 2, 2], [4, 2, 2, 2, 2], [3, 2], [2, 5, 2, 5, 2, 5, 2, 5, 2], [6], [3], [2, 2, 2], [2], [6, 2], [2, 5, 2, 2], [2, 2, 5, 4, 6, 2, 2, 2, 5, 2, 2], [2, 2, 2, 2], [2], [2, 2], [2], [2, 2, 4, 2], [2, 2], [2, 2, 2, 8, 2, 2], [6], [2], [6], [3, 5, 4, 2, 2, 5, 3], [2, 2, 2, 2], [2], [2, 5, 2], [2, 2, 2, 8, 6, 5, 2], [2, 6], [4, 2, 2], [8, 2, 2, 2, 2, 2, 8], [2, 5, 2, 5, 2], [2, 5, 2, 5, 6], [2, 2, 2], [6, 6, 5, 2], [6], [6, 2, 2], [2, 2, 2, 2, 2], [8], [4, 6, 2, 5, 6, 6, 5, 2, 6, 8], [6], [2, 2], [2, 2, 4, 2, 2], [6], [4, 2, 2, 4, 6], [6], [2], [4], [3, 8, 2, 5, 2], [2, 4, 2, 2, 2, 2], [4, 2], [6], [2, 4, 2, 2, 5, 2, 4, 2, 2, 5], [6], [2, 2, 5, 2, 5, 2, 2, 2], [2, 5, 2, 2, 2, 2], [2], [2, 2, 2], [2, 5, 2], [6], [2, 2, 2], [2, 2, 5, 4, 8, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2], [2, 8, 2, 2], [6], [8, 2, 2, 2, 2, 7, 6, 2], [2], [3, 3, 2], [2, 3], [3, 5, 2], [2, 4, 2], [2, 2, 2, 2, 5, 3], [6], [2, 2, 2], [5, 2, 5, 6, 2, 6, 2], [4, 2, 8, 5, 2, 5, 2, 2, 5, 2, 4, 2], [2, 2, 6, 5, 2, 6], [2, 2], [2, 2, 2, 2, 2, 2, 5, 2, 3, 2], [3], [2], [2, 2], [4, 2, 2], [2, 2, 2, 6], [2, 3, 4, 2], [6], [2, 2, 2, 6, 5, 2, 2], [2, 3, 2], [2], [4, 2, 2, 2], [2, 4, 8, 6], [6, 5, 4], [2, 2, 5, 2, 2], [2, 2, 2, 6], [2], [2, 2, 8, 4, 2, 5, 4, 2, 2, 2], [6, 6], [2], [6], [3], [3], [6], [2, 8], [2, 2, 4, 2, 6, 2, 2, 5, 2, 2, 2, 5, 3, 3, 2, 3], [3, 5, 2, 4, 2, 2, 5, 4, 4, 2, 2, 5, 2, 2], [2, 3, 2, 5, 2], [2, 5, 2], [2, 2, 4, 4], [2], [2, 2], [2], [4, 2, 3, 5, 2], [2], [2, 2], [2, 2, 2, 5, 2, 7, 2, 5, 4, 2, 4, 2, 4, 5, 2, 3], [2], [6], [2, 7, 2, 2, 2, 2], [6], [2, 2, 4, 2, 2], [2], [2, 2, 2, 2, 2, 5, 2, 4, 2, 4, 5, 2, 2, 5, 3, 2, 5, 2, 6, 2, 4, 2], [6], [4, 2], [6, 6], [2], [2, 2], [6], [2, 3, 2, 5, 3, 5, 2], [6], [5, 2, 5, 5, 2, 5, 6, 5, 2, 2], [3, 2, 2, 4, 2], [2, 2, 4, 3, 6], [6, 6], [2, 2, 2, 4], [2, 4, 6], [2], [3, 2, 2, 2], [4, 2, 2, 2, 2, 2, 2, 2], [2], [6], [2, 2], [6, 5, 6, 5, 3, 3, 4, 2], [3, 2, 3], [2, 5, 4, 4, 2, 2], [4, 2, 2, 2, 2, 2, 6], [2], [6], [6], [4, 2, 2, 2], [8, 5, 2, 5, 2, 5, 2, 4, 2, 2, 4, 2], [6, 6], [2, 5, 8, 2, 5, 4, 2, 2, 7, 5, 2, 4, 6, 2], [6], [2, 8, 2, 5, 2, 4], [6, 5, 2, 6, 5, 2, 2, 5, 6, 2, 5, 2, 2, 2, 6, 2, 2], [2], [2, 6, 2], [2, 6, 2, 2, 2, 5, 2, 5, 8, 6], [8, 2, 2, 2, 5, 2], [2, 4, 3, 2], [2], [2], [2, 2], [2, 4, 2, 2], [2, 2, 2, 2], [2], [4, 2, 2, 2, 2, 4, 2, 4, 3, 2], [4, 2, 2, 4, 2], [2, 6, 2, 5, 4, 2, 2, 3], [2], [4, 2, 5, 4, 6, 4], [6, 2, 2, 2, 3, 5, 3, 8], [4, 2, 2, 5, 2, 2, 4, 2, 5, 2, 5, 4, 2, 2, 2, 2, 2, 2, 5, 2, 2, 4], [2, 2], [3], [2, 2, 3], [4, 2], [2], [4, 6, 5, 4, 2], [2], [7, 2], [4, 2, 5, 2, 5, 2, 3, 2, 5, 6, 4, 2, 4, 5, 2, 2, 2, 4, 2, 5, 2, 3, 2, 4, 2, 4], [2, 4], [2, 3], [2, 2, 2, 5, 2], [2], [3, 4, 8], [6], [4, 6, 5, 2], [2], [2, 2, 2, 2, 2, 2], [6], [6], [2, 4, 4, 8, 2], [2, 5, 8, 3, 6], [2, 4], [6, 2, 5, 2, 3, 5, 2, 2, 8, 5, 2, 2, 5, 2, 2, 8, 5, 2], [4, 2, 4, 4, 2], [2, 5, 2, 5, 2], [6], [3, 2, 4, 2, 2], [2, 4, 2, 5, 2], [5, 8, 2, 5, 6, 8, 2], [2, 6], [2, 4, 2, 2, 2, 2], [7], [5, 2], [4, 2, 5, 2, 2], [2], [4, 2, 4, 3, 2, 4, 2, 2, 2, 4, 2, 5, 2, 4, 2, 2, 2, 5, 2], [2, 2], [8, 2, 2, 2, 5, 2, 4, 2], [6, 3, 2], [2, 2], [2], [2, 2, 5, 2, 2, 4, 8, 2, 2, 5, 4, 2, 4, 2, 2, 2, 4, 2, 2], [6], [7], [6, 8], [2], [2], [3, 2, 2, 5, 6, 2, 2, 2], [2], [4, 3, 4], [6], [2, 5, 6], [4, 2, 4, 2], [6], [2], [2, 5, 2, 2, 2, 2, 2, 2, 5, 2, 4, 5, 2, 2, 8], [2, 3, 2, 2], [6, 6], [2, 5, 2, 2, 5, 2], [6], [2, 5, 4, 2, 4, 5, 2], [3], [6, 2], [2, 2, 2, 2], [2, 5, 2], [2, 4, 2, 2, 5, 3, 5, 2, 4, 2, 8, 2, 6, 5, 3, 3, 5, 2, 2, 2, 3], [2, 5, 2, 5, 2, 5, 2, 2, 5, 2], [6, 8, 5, 2, 2], [2, 2], [4, 2, 2, 2, 4], [2], [2, 2, 2, 2, 5, 2], [4, 2, 2, 2, 4, 2], [2, 5, 2, 2, 7], [6, 2, 2, 2], [2], [2, 2, 2], [2], [2, 2], [2, 2, 5, 2], [8, 2], [6, 5, 6], [2, 8], [4, 2, 4], [6], [6], [4, 8, 2, 4, 8, 2, 2, 2], [2, 2, 7, 2, 5, 2, 2], [8, 4, 2, 4, 2, 2, 2, 2], [4, 2, 4, 2, 8, 5, 4, 2, 5, 3, 4, 2, 5, 3, 4, 5, 4, 2, 4, 2, 5, 4, 3, 3], [4, 8, 2, 2, 2, 2, 4, 8, 2, 2, 2, 2, 3, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2], [6], [8, 6], [2, 2], [8, 5, 6, 6], [2, 5, 2, 2, 4, 2, 2], [2, 4, 8], [2, 6], [2], [2, 2], [4, 2, 2, 3, 2], [2], [2, 2, 2, 2, 2, 5, 2, 5, 2, 2, 5, 2, 2, 2, 6, 5, 6, 2, 8], [2, 5, 2], [6, 8, 2, 5, 2], [2, 2, 8, 2, 8, 2, 3], [2, 5, 2], [2], [2, 2], [2, 2], [4, 2], [2, 2, 2], [2, 2, 5, 2, 3, 2, 5, 2, 4, 2, 2, 2, 2, 4, 2, 4], [2], [7], [2], [2], [2], [8, 2, 2], [3], [2], [6], [3, 6, 8], [2], [2], [2, 4, 2, 2, 2], [3, 3], [4, 4], [6, 2, 8], [2], [2, 2], [6, 8, 2], [6], [2, 2, 2], [2, 2], [6], [6], [2, 2, 2], [4, 2, 4, 2, 2, 5, 2, 4, 4, 2, 2], [2, 8, 5, 2, 2], [6, 2, 2, 2, 2, 2, 2, 5, 2], [8, 7, 5, 4], [4, 2, 3], [2, 4, 2, 2, 2, 2, 2], [2, 5, 2], [2, 5, 2, 2, 2, 5, 2, 4, 2], [8, 5, 7, 5, 2, 2], [2], [6], [2, 2, 8], [6], [2], [2, 4, 2, 2], [2], [3, 4, 8], [2, 2, 2], [2, 2, 2, 2, 2, 5, 2, 2, 2, 2], [2, 5, 2], [2, 2, 7, 2, 2, 2], [2], [4, 2, 4, 2, 2, 5, 4, 2, 2, 2], [2], [6], [8, 2, 2, 2], [2, 2, 2], [6, 5, 8, 2, 2], [2, 2, 3], [6, 2, 5, 6, 2], [2, 2, 2], [2, 2], [6], [8, 7, 2, 2], [2, 8, 2, 3], [3, 4], [2, 5, 2, 2], [3, 8], [2, 2, 8], [3], [2, 2, 5, 4, 8, 5, 2, 2, 2, 5, 6, 2], [2, 5, 4, 2, 2, 4, 4], [2], [2], [2], [6], [2], [4, 6, 2], [6], [4, 2], [2], [2, 2, 2, 2], [2], [2, 4, 2, 2, 5, 4, 2, 2, 4, 2], [2], [4, 2, 2, 2], [8, 2, 2], [4, 2, 2, 5, 2, 2, 5, 6, 6, 5, 4, 2, 2, 2], [4, 2, 2, 2, 2], [6], [2, 3], [2, 2, 2, 5, 3, 3, 8, 6, 2, 5, 3, 3, 5, 6, 2, 5, 2, 4, 2, 2, 2, 7, 5, 2, 3, 5, 2, 3], [2, 5, 2], [2], [4, 2, 2, 3, 2, 2], [4, 2, 6, 5, 2], [3], [2, 8], [6, 3], [2], [2, 5, 3, 2], [2], [6, 4, 3, 8], [2, 7], [4, 2, 2], [2], [2, 2, 5, 2, 5, 2, 2, 8], [6, 2, 8], [2, 2, 4, 2, 2, 8, 5, 2, 4, 2, 2, 2, 4, 2, 3, 5, 2, 2, 5, 2, 2, 4, 2, 2, 2], [6], [5, 2, 8, 4, 2], [2, 2, 5, 8, 2], [2, 2, 8, 2, 2, 2, 4], [2, 2, 4, 2, 2, 4, 4, 2, 2], [8, 2, 2, 4], [2, 3, 2], [4, 2, 2], [2, 8, 2], [2, 5, 2, 2], [6, 5, 6], [2], [2], [2, 2, 2, 2, 5, 2, 2], [2, 4, 2, 5, 2, 4, 2, 4, 5, 2, 2], [2], [2, 6, 2], [6], [6, 2], [6], [6, 5, 4, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2, 2, 2], [6], [6, 5, 2, 8], [2, 2, 5, 2, 2, 2, 4], [4, 2, 4, 2], [6, 2], [2], [4, 2, 2, 2, 2, 2], [2], [2], [6, 5, 8], [2, 8, 2, 8], [2], [2, 3], [6], [2, 2, 2, 4], [2], [3, 8], [6], [2, 2, 3, 2, 2], [2], [3, 2, 3], [2], [6, 8, 2], [2, 8, 3, 2, 5, 3, 2, 4, 4, 2, 4, 2, 4, 2, 3], [2, 5, 2, 2], [3], [2], [2, 5, 2, 2, 4, 2, 6, 5, 2, 2, 2], [2, 6, 5, 6], [2, 2], [2, 6], [2, 5, 8, 2, 2, 4, 5, 2], [2, 2], [2, 6, 5, 8, 5, 4, 2, 2], [2, 4, 2, 2, 2, 3, 5, 2, 4], [6], [4, 2, 4, 2, 2, 5, 2, 2, 2], [6, 5, 3], [3], [2, 2], [2], [2, 5, 4, 2], [2], [2], [2, 6, 5, 6, 6, 5, 6, 2], [2, 2, 4, 2], [2, 2], [2, 2], [2], [4, 2, 2, 2, 2, 6], [2], [2], [2, 2], [2, 2], [2, 8], [6, 5, 3, 4], [2], [2], [2], [2, 2, 2, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 2, 4, 2], [4, 2, 2, 3], [2], [2, 2, 2, 5, 2, 5, 2, 5, 3], [6, 2], [2], [2, 3, 2, 4, 8, 2], [2, 2, 8], [5], [2, 2, 4, 2, 3], [6, 6], [2, 2], [2, 5, 4, 2, 8], [6, 5, 6, 5, 8, 5, 2], [6], [6, 5, 2, 5, 6, 8], [2], [2], [2], [2, 5, 4, 2, 2, 2, 2, 5, 2], [2, 2, 2], [6, 2, 6], [6, 2, 5, 3, 8], [6], [2, 4, 2, 2, 2, 4], [3, 2], [2, 4], [6, 7, 2, 7], [2, 2, 4, 2, 6, 5, 2, 5, 4, 2], [2, 5, 2, 2, 5, 4, 2], [4, 2, 6, 4], [2, 2], [2, 2, 5, 6, 4], [2, 2, 4, 5, 2, 2], [8, 6, 2, 2, 6, 2, 5, 2], [8, 2, 3, 5, 2, 6], [2, 5, 2], [2, 5, 5, 2, 5, 2, 4, 2, 5, 6, 5, 4, 2, 2, 2, 2, 3], [3, 2], [6, 5, 4, 2, 5, 2, 6], [2], [6], [2], [2], [6], [2], [2], [2, 2, 2, 4, 2, 2, 2, 5, 2, 2, 2], [2, 8, 2, 2, 2, 3], [2], [6, 4, 2], [2, 5, 8, 5, 2, 2, 6, 5, 2, 2, 2, 2, 5, 2, 8, 2, 2], [2], [2], [2, 2, 4, 8], [2], [2, 6], [6, 5, 2, 6], [5, 7, 5, 7, 5, 7, 5, 3], [2], [6, 5, 2, 2, 3], [2, 4, 2, 2, 2, 2], [3, 2, 2, 5, 4, 4, 5, 3, 4], [2, 2, 7, 2, 3], [2, 5, 3, 2], [2, 3], [2, 2], [6], [3, 4, 8], [8, 2, 3], [6, 6], [6, 2, 2], [2, 2], [2, 2, 8, 5, 2, 4, 4, 4, 2, 5, 8, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2], [2], [4, 2, 2], [2], [2, 4, 2, 5, 2, 4, 2, 5, 2, 8, 5, 4, 2, 4, 2, 2, 2], [2, 2, 2, 5, 2, 2, 4, 2, 4, 2, 5, 2, 2], [2, 5, 8, 2], [3, 2, 4, 2, 2, 4, 2, 2, 2, 8, 2], [4, 2], [2, 5, 4, 2, 5, 2, 2], [2], [2, 3, 2, 5, 6, 6, 2, 8], [2, 4, 2, 2, 2, 2, 4], [2, 2, 5, 6], [4, 2, 2, 4, 2], [2, 2], [8, 2, 2], [2, 5, 2, 3, 5, 2, 2, 2, 5, 2], [6, 6], [6], [6, 6], [4, 2, 2, 6], [2], [7, 2, 2], [2, 2, 2], [2, 2, 8, 3], [2, 2], [6], [6, 3, 5, 2, 8, 5, 2], [4, 2, 2, 5, 4, 2, 2, 2, 2, 3], [4, 2, 2, 2, 2], [2, 4, 2, 2, 2, 2, 4, 5, 2, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2, 2, 8], [4, 2, 2], [2, 8], [4, 8, 2, 2, 2], [2, 8, 5, 2, 6], [2, 5, 4, 2, 2, 2], [8], [3, 5, 2, 5, 3, 5, 2], [2], [2], [5, 2, 8, 5, 2, 4, 2, 2, 4], [2, 2, 2, 6], [2], [6], [2], [2, 2, 2, 2, 2, 2, 2], [2], [2, 3, 2, 2], [2, 8], [2, 6], [6], [8, 2, 4, 2, 7, 5, 2, 2, 2], [2, 4, 7, 8], [2, 5, 2], [2, 8, 5, 2, 8], [2, 2, 2, 2, 4, 2, 2, 2], [2, 2, 2], [2], [4, 2, 3, 2], [2], [6], [2], [2, 2], [6, 5, 6], [4, 4, 6, 6], [2, 2, 6, 2], [2, 4, 2], [2, 8], [6], [2, 4, 4, 2, 4, 2, 2, 2, 2], [3, 5, 2], [2], [6, 5, 3, 2], [8, 2, 5, 2], [2, 5, 2, 2, 2, 2], [4, 2], [2], [2, 5, 2], [2], [6], [4, 2, 2, 4, 4, 2, 2, 2, 4, 6, 5, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 3, 4, 6, 5, 2, 6, 2, 2, 3], [2], [2, 8, 5, 2], [4, 2, 2, 2, 2, 2, 4, 3], [6, 5, 2, 2, 4, 5, 3], [2], [2], [2, 5, 2, 5, 2, 6], [2], [4, 2, 4], [6], [2], [2, 2], [2, 4, 2], [2, 3], [2, 2, 2, 2, 2], [4, 2, 2, 2, 2, 2, 8, 5, 4, 2, 4, 5, 6, 5, 4, 2, 4], [2, 2, 3, 5, 2, 5, 2, 2, 2], [2], [2, 2, 8], [7, 2, 7, 2], [3, 5, 8, 3], [4, 2, 5, 4, 2], [2, 5, 2, 2, 2, 2], [2, 8], [6], [6, 3], [2, 8, 5, 2], [6, 8, 5, 6], [6, 7, 2, 4], [2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 5, 6, 4, 2, 3, 2, 5, 4, 6], [2, 2, 2, 4], [2], [3, 6, 6], [4, 2, 2, 4, 2, 2, 4], [2, 2, 2, 2, 2], [4, 2, 2, 2, 6], [3], [4, 2, 3, 2], [2, 2, 2, 2, 2, 5, 2], [6], [3, 2], [2, 2, 4, 6], [2, 2], [6], [2, 2], [6, 6], [3], [2, 2, 2], [2], [4, 2, 2], [4, 2, 8, 2], [6], [2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2], [2, 5, 4, 2, 2, 5, 2, 2], [3], [4, 2, 5, 2, 4], [2, 2, 4, 4, 5, 2, 2, 2, 2], [6], [2, 5, 4, 2, 2], [6], [2, 5, 8], [6, 2], [4, 2, 2, 2, 6, 2, 5, 2, 8], [2, 6, 2], [2, 2], [6, 2], [6, 4, 2, 2, 5, 2, 5, 8, 2, 2, 5, 8, 2, 6, 2, 2, 4, 6, 2, 2, 4, 2, 5, 8, 2, 2, 6, 2, 4, 2, 5, 2, 2, 5, 2, 2, 2, 2, 3], [2, 2, 5, 2], [8, 5, 2], [2], [6], [2, 5, 2], [4, 2, 6, 2, 2, 4, 2, 2], [7, 5, 4, 2, 2, 2], [2, 2, 4, 2, 5, 2, 2, 4], [3], [2, 6], [2, 8, 5, 7, 5, 7], [2], [2, 5, 2, 2, 2], [6], [2, 4, 2, 2, 2, 4, 2, 2, 4, 3, 4, 2, 2, 4], [2, 8], [2], [2, 8], [6, 4, 2], [2], [3], [2], [4, 2, 2, 6, 2, 2, 2], [2, 2, 2], [3, 4, 5, 3], [6, 2, 6, 2, 2, 2, 2], [2, 2, 3, 2], [4, 2, 6, 2], [3, 2, 8], [2, 6, 2], [2, 4, 2, 4], [2], [2, 4, 2], [2, 2], [2], [2, 2, 2, 6], [2, 2, 4, 8, 2, 2, 5, 2, 2, 4, 2, 2], [3, 5, 2], [2, 2, 2, 2, 2], [2], [6], [2], [2, 2, 2], [2, 2, 8], [6], [2, 2, 3], [2, 8], [2, 4, 2, 2, 6, 4, 2], [2], [8, 2, 2], [2, 8], [2, 7, 2], [2], [2, 4, 2, 2, 2], [3, 5, 4, 2, 2], [4, 2, 2, 6, 2, 2, 2, 4, 2], [2, 5, 3], [2, 8, 2, 5, 2, 2], [2], [6, 6], [6, 2], [6, 5, 6, 8, 5, 2, 2, 5, 2, 5, 4, 2, 2, 5, 6, 8, 2, 5, 3], [2, 4, 2, 3, 5, 2, 5, 2], [2], [2, 4, 2, 2, 2, 2, 5, 6, 8], [2, 2], [2, 2, 2, 2, 4, 3, 2], [2], [2], [2], [6], [4, 2, 2], [2, 2, 5, 2, 3], [2, 6], [2], [6, 5, 2, 2], [4, 2, 2, 2, 4, 2, 2, 5, 3], [2, 2], [3], [2, 5, 2, 2, 4], [2], [2, 5, 2, 2, 2], [3, 5, 2, 2, 2, 4, 5, 8, 5, 4, 3, 2, 4, 2, 4, 2, 3, 2, 4], [2], [2], [6, 6, 5, 6, 2, 6, 5, 2], [2, 8, 5], [4, 2, 2, 5, 6], [2, 2], [2, 2, 4, 2, 2, 6, 2, 4, 2, 2, 2, 6, 4], [2, 5, 2], [2, 2], [4, 2, 3, 2], [4, 3, 8, 6, 5, 2], [2], [2, 2, 2], [2, 2, 2, 2, 2, 2], [2, 5, 3], [8, 2, 4, 2, 2], [2, 4, 2, 2, 2, 2, 2], [6], [6], [2], [2, 4, 3, 2, 4, 2, 2, 2, 2, 2, 2], [2], [2, 2, 2], [2], [2, 6], [2, 2, 2, 4], [2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 5, 8, 2], [2, 2], [2, 2], [2], [2], [2, 3, 5, 8, 4, 3], [2, 2, 6, 2, 2], [2, 4, 2], [6], [2, 8, 6], [2, 2], [6], [2], [4], [6], [2, 2, 2], [2], [2, 2, 5, 2, 5, 3, 5, 2, 5, 2, 3], [4, 2, 2, 4, 2, 2, 2], [2, 2, 4, 2], [2], [6, 4], [2, 2, 2], [2, 8], [2], [2, 6], [2, 2, 2, 2, 2], [2, 4, 2, 2, 7, 7, 2], [2], [2, 5, 2], [3, 5, 2, 6, 5, 2, 2, 5, 6], [2, 2, 4, 3], [2, 2, 5, 2, 2], [2, 8], [2], [2], [2, 2, 4], [6], [6, 2], [2, 8], [2, 2, 2, 7, 2, 3, 2], [4, 2, 2, 2, 2], [2, 8, 2, 5, 2, 2, 2, 5, 2, 4, 2, 2, 4, 2, 3, 2, 5, 2, 4, 2], [6, 5, 6, 8], [2, 2, 4, 2], [6], [2, 2, 2], [2], [6, 5, 4], [6], [4, 8, 3, 3], [6, 2], [2, 2, 2], [4, 2, 5, 4, 2, 4, 2], [2], [2], [2, 2, 2, 2, 4, 6, 5, 8, 2, 4, 2, 2], [2], [2, 2], [2, 4, 2], [6], [2, 2, 2], [4, 2, 3, 4, 2, 2], [2], [2, 8], [4, 2, 3], [4, 2], [2], [3, 2, 5, 6], [3, 5, 6], [2, 2, 5, 2], [2, 2, 5, 2, 5, 2, 2, 2, 5, 2, 2, 2, 5, 2], [2], [4, 2, 3], [2], [2], [2], [2], [4, 2, 2], [3], [2, 2, 2, 2], [8, 2, 5, 2], [2, 5, 2, 3], [2, 7], [2, 6], [2, 4, 2, 6], [3], [3], [8, 2, 2, 2], [2], [2, 6, 6, 5, 2, 5, 3], [2, 6, 6, 5, 2], [2], [5, 2], [4, 2, 4, 2], [2, 8], [2], [2, 2, 2, 4, 2, 8, 2, 2], [2, 2], [6], [3], [6], [2, 5, 8, 2, 2], [2], [2, 4, 2, 2, 2, 4, 4, 2], [2], [2, 4, 6], [6, 2], [3], [4, 2, 3, 5, 2, 3, 2], [2, 2, 2], [4, 2, 5, 2, 2], [3, 4, 8, 2, 8, 5, 4, 2], [2, 2], [5, 6, 8], [4], [6], [2, 2, 8], [4, 2], [8], [4, 2, 2, 2, 2, 2, 2, 4], [2, 2], [2, 2, 3, 2, 2, 6, 5, 2, 2, 2], [2], [2], [2, 4, 5, 2], [2], [2, 3, 2], [2, 4, 2, 2, 2, 8, 4, 2, 2], [6], [2, 6, 5, 6], [6], [2], [2, 6, 4, 5, 2, 6, 4], [6, 6], [4, 2, 2], [2, 2, 3, 5, 2, 2], [4, 2], [4, 8, 2, 2, 2, 2, 2], [2], [2, 5, 2, 2, 2, 5, 2, 4, 2, 2, 4, 6], [6], [2, 2], [2], [4, 2, 8], [2], [2, 2], [2, 2, 4, 3, 2], [8, 2], [2], [2, 5, 2], [8, 3, 5, 6, 8], [6], [2, 5, 3], [2, 6, 2, 5, 2], [5, 2, 2], [4, 2, 2, 2, 2, 2, 3, 2, 2, 2, 4, 6, 2, 2, 6], [2], [2, 4, 2], [2, 6, 2, 3, 6], [4, 2, 2, 6, 4, 5, 2, 5, 2, 4, 2], [6, 8, 5, 2, 2, 2, 2, 2], [6, 7, 5, 2, 2, 2], [2, 2], [2], [2, 2, 8, 5, 2, 5, 2, 2, 5, 2, 5, 2, 2, 5, 6, 4], [2, 2, 3], [6], [6], [6], [2, 4, 2], [4, 2, 2], [6, 5, 2, 2, 6], [2], [2, 5, 2], [2, 2, 4, 8], [2], [2, 3], [6], [6], [2], [2, 6, 6], [3, 5, 8, 5, 2, 5, 2, 5, 2, 2, 2, 5, 2], [3], [2, 7, 5, 2, 3], [2, 4, 3], [2, 5, 8], [2, 2, 4], [2, 5, 8, 2, 5, 2, 5, 2, 2, 2], [2], [2, 2], [2], [2], [2], [4, 2, 2, 4, 7, 2, 4, 5, 2], [2], [4, 2, 2, 2, 2], [2], [2], [6], [4, 2, 2], [2], [4, 2, 2, 2], [2], [2, 2], [2, 7, 2, 8], [2], [6, 2], [2, 5, 2], [2, 2], [6], [2, 8, 2], [2], [6, 5, 6, 5, 6, 5, 6, 5, 6], [2, 2], [6], [6], [2, 2, 5, 2, 4, 2, 4], [2, 2, 4, 2, 5, 2, 6, 4], [2], [8, 6, 2], [2], [2, 4, 2, 6, 2, 4], [3, 3], [2], [2], [2, 2, 2], [4, 8], [7, 2, 2, 4, 2, 2, 2], [4, 8, 5, 2, 4, 6, 5, 2, 2], [4, 2, 4, 4, 2, 8], [2, 4, 6], [2], [2], [2], [8, 6, 5, 2, 8, 2, 5, 2], [2, 2, 4, 2, 2], [2, 2], [6, 8, 5, 2], [2], [4, 2, 4, 5, 2, 2], [8, 2, 2, 2, 4, 6], [2], [4, 2, 2, 8], [3, 6], [2, 3, 2], [2, 5, 2, 2, 5, 2, 2, 3], [2, 2, 5, 2], [2, 2, 5, 4, 2, 5, 4, 2, 2, 2, 2, 2], [6, 6, 8], [2], [6, 6], [2], [6], [2, 8, 2], [2, 4, 2], [2], [2], [2, 8], [2, 4], [4, 2, 5, 2, 2], [2, 2], [2], [2, 2, 5, 4, 2, 2, 2], [2, 2], [2, 4, 2, 4, 2], [6, 6], [2], [2, 7], [2, 4, 3], [2, 4], [2, 4, 4, 2, 2, 4, 2, 2], [2, 5, 3, 2], [4, 2, 2, 2], [2, 2, 5, 4, 2], [2], [3], [8, 4, 2, 2, 2, 5, 4, 2, 5, 2, 5, 2, 2, 2], [6], [2], [8, 2, 3], [3, 2, 2, 6], [2], [2, 2, 7], [2, 2, 5, 2], [2], [3, 5], [2], [2], [2], [6], [4, 2, 2, 2], [6], [4, 2, 2, 5, 2, 2], [2, 2, 8, 3, 2], [4, 2, 2, 2, 2, 4, 2, 2, 2, 4], [2, 4, 2, 2, 3], [4, 2, 2], [6], [2, 7, 8], [6, 2, 4], [4, 6, 8, 2, 3], [2, 4, 3, 2, 2], [2], [2, 4, 2], [6], [2, 4, 2, 2, 4, 2, 5, 2, 5, 2, 2, 2], [2], [2], [2], [2, 2], [8, 2, 2, 2, 5, 2, 2, 2, 3], [6, 6], [2, 7, 5, 6], [2, 2, 2, 4, 2, 2, 2, 7], [8, 5, 6, 6, 5, 4, 2, 7, 5, 2, 2, 2, 2, 2, 3, 5, 2], [2], [2, 8], [4, 2, 2, 2], [2], [2], [4, 2, 2, 2, 2, 2, 6, 5, 2, 2, 2, 2, 2, 2], [4, 2, 3, 2], [2, 2, 2, 4, 2, 8, 5, 2, 2], [4, 2, 2, 2, 4, 5, 4, 2, 4, 2], [2], [2], [3, 2, 2, 2], [4, 8, 5, 2, 3], [6, 6, 6], [6], [2, 8, 2, 4, 6, 2], [2, 2], [2, 2, 4, 2, 2], [2, 5, 2, 4], [2], [4, 2], [8, 4, 4, 2, 3], [2, 2, 7, 2, 2], [2, 5, 4, 8, 2, 2, 2, 2, 2, 5, 2, 2, 4, 5, 2, 2, 2], [4, 8, 2, 2, 5, 2, 3], [2, 2, 2, 5, 4, 2, 3], [2, 4, 2, 3, 3], [2], [2, 2, 2, 8], [2], [6], [2, 7], [2, 5, 4, 8, 2, 7, 2, 5, 2], [2, 2, 2, 2], [2, 4, 2, 5, 3, 3], [2], [2], [2, 2], [2, 2, 2, 5, 2], [2], [2, 6], [2, 6], [2, 5, 8, 5, 2, 2], [6, 2, 2, 2, 5, 2, 6, 2, 2, 2], [6], [3, 5, 8], [4, 2, 2, 2, 4, 3, 2, 2], [3, 4, 2, 5, 2, 2, 5, 2, 2, 2, 4, 6, 2, 2], [2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 5, 4, 2, 2, 2, 2], [6, 6, 5, 2, 8, 2], [5], [6], [4, 5, 2, 2, 3, 2, 2, 2, 4, 7], [2, 2, 8], [2, 2, 2, 2, 4, 3, 2, 2, 2, 2, 5, 2, 4, 2], [6, 6], [2], [2], [6], [6], [2], [6, 2, 2, 6, 2], [3, 3, 2], [4, 5, 8, 5, 5, 8, 4, 2, 4, 2], [2, 2, 2, 4, 2, 2, 2], [3], [4, 2], [2, 5, 2], [2, 8, 2], [2, 2], [2], [2, 2], [6], [2], [8, 5, 4, 3, 5, 2, 2, 4, 2, 4], [2], [6], [2, 2, 7, 5, 2, 2, 4, 2, 2], [4, 2, 4], [2], [4, 2, 2, 4, 4], [2], [6], [2], [2, 3], [2, 2, 2, 4, 2, 2], [8, 5, 4, 2, 4, 5, 2], [2, 8, 2, 2, 2, 2, 5, 2, 8, 5, 2, 2, 2, 2, 5, 4, 2, 2], [6, 6], [4, 2, 2, 4, 4, 2, 4], [5, 4, 2, 6, 4, 4, 2, 5, 2, 4, 2, 4, 2, 6], [6, 4, 5, 2, 2], [2, 3, 5, 2], [6, 6], [2], [2, 2, 2, 4, 2, 2], [2], [2, 2, 3, 5, 6], [2, 2, 4, 2, 2, 5, 3], [4, 6], [4, 2, 2], [2], [3, 4], [2], [4, 2, 2, 2, 5, 2, 2, 2, 2, 3, 2], [2, 4, 2, 3], [2, 2, 2, 2, 7], [6], [2, 2, 4, 2], [4, 2, 2, 2], [4, 2, 2, 2, 6], [2, 4, 8], [3, 5, 2, 2], [5, 2, 4, 3], [2, 2, 4, 2, 2, 6, 4, 2], [6], [6, 5, 6, 8], [7, 4], [4, 2, 2, 2], [2, 2], [6], [4, 2, 2, 5, 2, 2, 2], [6], [2], [2, 2, 5, 2, 2, 2], [6, 2, 5, 2, 2, 2, 5, 2, 2, 3, 5, 2, 5, 2], [6, 6], [6], [6], [2, 5, 2], [2], [2, 5, 2, 2, 8, 2], [2, 4, 2, 5, 4, 2, 2, 4, 2], [3], [2], [2, 6], [2, 8], [2], [2], [6], [6, 8, 2, 8, 2], [2], [2, 2, 2, 2, 2, 6], [8, 6], [2, 2, 8, 8], [6], [2], [3, 8, 5, 2, 2, 2, 8, 5, 2, 2, 2, 2, 2, 3, 2, 2], [2], [2, 2, 2, 2, 3], [4, 6, 8, 2, 3], [2, 2], [2], [6], [8, 3, 4, 2, 2, 5, 2, 4, 2], [6], [2], [2, 2, 2], [2, 6, 2], [2, 8, 5, 2, 6], [6, 6], [2, 2, 6], [6, 2], [5, 2, 2, 5, 2, 5, 8, 5, 2, 4], [4, 2, 2, 4, 2, 5, 2, 2, 2, 2], [2], [8, 2, 2], [4, 2, 2, 8], [2, 8], [2], [2], [2], [3, 2, 2], [4, 2, 2, 4, 2, 5, 2, 2, 7, 5, 4, 2, 6], [2, 4, 2, 2, 8, 3], [2, 4, 2, 2, 2], [2, 2, 2], [4, 2], [6, 5, 4, 3, 6], [2], [2], [2, 2, 2, 8, 2, 2, 5, 4, 2, 2, 2, 2, 5, 8, 2, 8, 5, 2], [2], [2, 2, 2], [6, 8], [6, 8], [2], [8, 5, 2, 2, 4, 2], [2], [2, 2, 2, 8, 2], [2], [2, 6], [2, 2, 2, 2, 2, 5, 3], [8, 2, 2, 2], [2, 5, 2], [2, 5, 2, 2, 2], [2, 2], [3, 5, 3], [2], [2, 8, 4], [4, 2, 2], [3, 2, 3, 2], [6, 2, 4, 2], [2], [6, 8, 2], [2], [4, 2], [3, 5, 8], [2, 2], [2, 5, 2], [4, 2], [2, 2], [5, 5], [2, 2], [4, 4, 2, 2, 6, 4, 2, 4, 2], [3], [3, 2, 2], [6], [2, 2, 2, 3, 2, 4, 2], [8, 2, 3, 2, 6, 2], [2, 2, 8, 5, 2, 5, 2, 2, 2], [4, 2, 2, 4, 4, 2, 5, 2, 4, 2, 2, 2, 2, 7], [2], [2, 3], [8, 2, 2, 4], [6, 8, 2], [2, 3, 2], [6], [6, 6], [6], [2, 5, 2, 4, 2, 6], [2, 2, 5, 2, 2], [2, 2, 2, 6, 2, 8], [2, 2], [2], [3], [4, 2, 8, 5, 2, 2, 4], [4, 2, 2, 2, 2, 5, 2, 5, 2, 2, 2], [6], [2, 6], [2], [6], [2, 2, 2, 2, 2, 5, 2], [2], [2, 4, 2, 2, 2], [2, 2], [2, 4, 2, 6, 4, 2, 4, 2, 2, 2, 4, 2, 6, 4, 2, 2, 5, 2, 2, 2, 5, 4, 2, 2], [6], [6, 4], [2], [6, 2], [2, 2], [6, 5, 6, 2, 5, 4, 6, 5, 2, 5, 2, 6], [2], [2, 5, 2], [2, 5, 2], [4, 2], [2, 4, 2], [2], [2, 8, 2], [2, 4, 2], [4, 2], [2], [2, 4, 4, 2, 2, 2, 4, 2, 4], [2, 5, 2], [6, 6], [6, 5, 8, 2], [8, 2], [2], [2], [2, 2, 3, 6], [2, 6, 3, 5, 2, 8, 5, 6, 3], [2], [3, 5, 2, 2, 2, 4, 2, 3, 5, 4, 2], [2, 5, 2], [6], [2, 2, 2, 2, 8, 2, 2, 2], [6, 5, 6], [6], [6, 6], [2, 2, 2, 3], [2], [8, 5, 8, 2, 5, 2], [6], [2], [2, 2, 2], [2, 4, 2], [4, 2, 2, 2, 4, 3], [8, 2, 2, 2, 6, 7], [2, 2, 2], [2, 5, 2], [2, 4, 2, 2, 2, 2], [2, 2, 6, 5, 2], [2, 8, 2, 2], [2], [4, 2, 4, 2], [2, 4, 3, 8, 2, 5, 2, 4, 2, 2, 2, 8, 2, 2, 4, 2, 5, 4, 3, 3, 5, 2, 4, 2, 5, 4, 2], [2, 2], [6, 5, 6, 8, 5, 2, 5, 2, 2], [2], [2], [6], [2, 8], [2, 2, 8], [2, 2, 4, 2, 4], [2, 2, 5, 2], [2], [8, 2, 4, 2, 2, 4, 2, 6, 2, 5, 2, 6], [6], [6, 5, 2, 2, 6, 2, 6, 5, 2, 2, 2], [6], [2, 2, 5, 2, 2, 5, 2, 2], [2], [6], [6, 8, 5, 2, 6], [6], [2, 2], [2, 2, 6, 2, 8, 5, 2, 2, 2, 2, 2, 5, 2], [6, 2, 6, 2], [6], [2, 2, 4, 4, 2, 8], [2], [2], [2], [6, 2], [2, 2, 6, 8], [2, 2, 2], [2, 2], [2, 2], [2], [6], [2], [6], [4, 2, 5, 2, 2], [8, 2, 2, 2, 2, 2, 5, 8, 6, 2, 2], [6], [2, 4], [2], [2], [2, 2, 7, 2, 2], [6, 4, 4, 5, 2], [2], [2], [6], [6, 2, 6, 2], [6, 6, 5, 2], [2, 2, 7, 5, 2, 6], [2], [8], [2], [6, 5, 2, 2], [2], [2, 5, 2, 2, 2], [6, 6], [2], [3], [2], [2, 2, 2], [3, 2, 2, 5, 6, 2, 2, 2, 2], [3, 6, 8], [2], [2], [3], [6], [2, 6, 5, 2], [2], [2, 2], [2], [4, 4, 2, 5, 2, 4, 2], [2, 2], [2, 2], [6, 5, 2, 6], [2, 2], [4, 2, 2, 3], [2, 4, 2, 4], [8], [6], [2, 4, 2, 2, 2, 2, 2, 3, 2], [2, 5, 2], [2], [6], [2], [2, 5, 2, 8], [2], [2, 4, 3, 2], [6], [2], [5, 6], [6], [2, 2, 2, 5, 2, 2, 5, 2, 2], [4, 2], [6, 2, 2, 2, 2], [2, 2, 8], [4, 2, 2, 2, 2, 2, 5, 2, 5, 4, 2], [2, 2, 2, 8, 5, 4, 2, 2, 2, 4, 4], [2], [2, 8], [2, 4, 2, 8, 4, 2, 2, 2], [6], [4, 2, 2, 2, 4, 2], [6, 5, 2, 5, 6, 4], [2, 3], [6], [2, 2], [2], [2, 2, 8, 2, 5, 3, 2], [2, 8], [2, 2, 4, 2, 2, 5, 4, 7, 2, 4, 8, 2], [2], [6], [2, 4, 2, 6, 5, 2], [2, 4, 2, 4, 2, 4, 2], [8, 5, 2, 2, 2], [2, 5, 2, 5, 2, 2, 4], [2], [6], [2, 4, 2], [4, 2, 2], [6, 5, 2], [2, 2], [3, 5, 6, 2, 2, 5, 2, 6, 6], [6, 2, 2, 5, 6], [2, 2, 2, 8, 2, 2, 4, 2], [2, 8, 2, 2, 2, 2, 2], [2, 5, 2, 2], [2, 2, 2], [2, 5, 4, 8], [6, 3, 8], [4, 2, 2, 2, 2], [2, 2], [2], [6], [2], [6, 8, 5, 2, 5, 4, 2, 6], [8, 2], [2, 4, 2, 2, 2, 4, 2], [2, 5, 2, 2], [6, 2, 5, 8], [8, 5, 2, 2, 5, 3], [4, 2, 2], [6, 2, 2, 2], [3, 5, 8], [2, 5, 2, 2, 2, 2], [2, 5, 2, 2], [2, 5, 2, 2, 2], [2, 4, 2, 4, 2, 5, 2, 2], [2, 5, 2, 5, 2], [6, 2, 2], [6], [2, 6, 5, 4, 2, 2, 4], [2, 4, 2, 2, 4, 2, 3, 2, 5, 2, 2], [2], [2], [2], [4, 2], [6], [2, 6], [6, 5, 6], [2, 5, 3, 5, 2, 2, 4], [6], [2], [2], [2], [2, 5, 2, 2, 5, 8, 2, 5, 2], [2], [2, 4, 6, 2, 6, 2, 2, 5, 2], [2, 2], [2, 2, 2, 4, 2, 4, 2], [6, 5, 2, 4, 2, 2], [2], [4, 2], [6], [2, 2, 6], [2, 2], [6, 6], [6, 6], [4, 2, 8, 4, 2, 5, 2], [2, 8, 2, 5, 4, 2, 2, 2, 2, 8, 5, 2, 4, 2], [2, 5, 2], [2, 6], [4, 2, 4, 2, 5, 2], [2, 4, 5, 2, 6, 4, 5, 2], [2], [2], [4, 2, 2, 2, 4, 2], [2, 4, 2, 7, 2], [2, 2, 5, 4, 6], [2, 2, 5, 2, 2], [6], [3, 2, 5, 4, 3, 4, 7], [2, 5, 6, 5, 2], [2], [4, 6], [2, 2], [6], [3], [2, 3], [2, 3], [3, 4, 8, 2, 5, 2, 4, 2, 4], [4, 2, 2, 4, 6, 2, 5, 2, 2], [2, 5, 2], [4, 2, 8], [2, 2], [3, 2], [6], [2], [2, 2], [6], [4, 2, 4, 2, 8, 5], [6, 6], [2, 6, 8, 5], [2], [2, 2], [2, 2], [2, 2, 5, 8, 5, 7, 7], [2, 2, 5, 2, 8], [8, 5, 2, 2, 2, 2], [2, 2, 4], [6, 5, 2, 5, 6, 5, 2, 4, 5, 6], [2, 5, 6, 5, 2, 2], [2, 2, 2, 4, 6, 5, 2, 2], [6, 4, 5, 2], [2, 4, 2, 6, 8], [2, 2, 2, 2, 2, 2, 2], [2, 2], [4, 4, 2, 3, 2, 6], [4], [2], [6, 5, 2, 2, 5, 3, 2, 5, 2], [2, 8, 2, 2, 2], [6], [4, 6, 2], [2], [2, 2], [2, 3], [2], [6], [4, 2, 2, 2, 2, 2, 2], [2, 4, 5, 4, 2], [2], [6, 5, 2], [4, 6], [2], [2, 6, 6, 2, 2, 8], [2], [2, 2], [2, 2, 4, 2, 2, 4, 2, 5, 2, 2, 2, 2], [6, 2], [2, 6], [6], [6, 5, 6], [6, 8, 5, 3, 2, 5, 2, 8], [3, 2, 5, 3, 2, 3], [2], [8, 7, 7], [2], [6, 7], [4, 2, 2, 2], [2, 2], [2], [2, 5, 2], [2], [2, 2, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2, 5, 2], [2, 4, 2], [2, 4, 2, 4, 3, 8, 2], [2, 5, 2, 2, 2, 5, 3], [6, 8, 5, 2], [6], [2, 4, 2, 2, 2, 2, 2, 2], [2, 5, 2], [6], [2, 2, 2, 4, 2, 2, 5, 3], [2], [2], [2, 8], [2, 2, 8, 2, 2, 2], [2], [2, 2, 2], [2], [2, 2, 2], [2], [4, 2], [6, 6], [2, 5, 2, 5, 2, 8], [6], [3], [2], [2], [2, 8, 4, 3], [2, 3], [2, 5, 2], [6], [2], [6, 2], [4, 2, 4, 2, 2, 5, 2, 2, 6, 2, 5, 4, 5, 2, 6, 4, 2, 2], [2], [2], [2], [2], [2], [2], [2, 2], [6, 8, 6, 6], [2], [2, 2, 2, 2], [2], [2, 5, 3], [3, 2], [6, 8], [6, 5, 6, 5, 6], [2, 6, 2, 8, 4, 2, 2, 4], [6, 8], [2, 2], [2, 2, 2], [2, 5, 8], [2, 5, 2, 2], [6, 5, 2], [2, 2, 2, 2, 3, 2], [4, 8], [2, 4, 2, 4, 4, 2, 2, 2], [2], [2, 5, 2, 2], [2, 2, 2, 8, 2], [2, 2, 2], [6, 8], [4, 2, 6], [6], [3], [7, 2], [2, 8], [3, 2, 4, 2], [2, 5, 2, 2, 5, 2, 8, 5, 6], [6], [2, 2, 2, 2, 2, 5, 3, 5, 2, 2], [4, 2, 2, 4], [6], [2], [2], [6], [2, 2, 2, 2, 2], [6, 3, 2], [2], [2], [8, 2, 2, 2, 5, 2, 2], [3], [2, 7, 2, 2], [2], [2], [4, 2, 3], [2], [2, 2, 2, 2], [6], [2], [2, 5, 8], [6], [4, 2, 2, 3], [4, 2, 4, 3, 4], [4, 2, 6, 5, 2], [6, 4], [2, 8, 2, 5, 2, 2], [2, 2, 3], [6], [2, 4, 2, 5, 2, 6, 2], [6, 6, 5, 6, 8], [2, 2], [2, 2, 8], [2, 5, 2, 2, 4, 2], [2], [2, 2, 2, 2, 2, 7, 2], [2, 4, 2, 4, 2], [2], [2], [2], [2], [4, 2, 2, 2], [8, 2, 5, 8, 2], [2, 2, 7], [6], [2], [4, 8, 2, 2, 2, 5, 2], [2], [2], [3, 4, 7, 8, 5, 2, 2, 2], [2, 6, 2, 4, 5, 5, 2, 2, 2, 4], [2, 2, 4, 2, 2, 2, 2, 2], [6], [2], [8, 2, 4, 2, 3, 2, 2, 4, 2, 2, 6, 4, 2, 2, 2, 5, 4, 2, 2, 2, 2], [4, 2], [4, 8, 2, 2, 5, 2], [6, 6], [2, 4, 5, 2, 5, 2, 8], [2, 4, 2, 4, 3, 4, 2, 2, 5, 2], [2], [4, 2, 2, 4, 2], [2], [2], [2], [4, 8, 2, 4, 2, 2], [6], [2, 8, 5, 2], [2, 2, 2, 8, 2, 4, 2, 2, 2, 8, 6, 5, 2, 4, 2, 8, 6, 4, 2], [2], [4, 6, 2, 4, 2, 4, 6], [2], [6, 2], [2], [2, 4, 2], [2, 5, 2, 5, 3, 5, 3, 5, 8, 2, 6, 5, 6], [6, 8, 4, 2, 2, 4, 2], [2, 2, 2, 2, 2], [8, 5, 8, 2, 5, 2, 7, 2, 2], [3], [4, 2, 2], [3, 5, 2, 2], [2, 2, 2], [6], [2], [2, 2, 4, 6, 2, 8], [5], [6], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 4, 2, 2], [4, 2, 4, 2, 2, 5, 2, 5, 2, 4], [2], [4, 2], [2], [6, 8, 4, 2, 2, 4, 5, 2], [6], [2, 2, 2, 2, 2, 4, 2, 2, 5, 4, 4, 2, 3], [2], [6], [2], [2], [2, 5, 8, 2, 2, 2, 2, 5, 4, 2, 2, 4, 2, 2, 4, 5, 3, 2, 2, 2, 7, 2, 2, 2], [2, 5, 4, 2, 2], [4, 2, 2, 2], [3, 8], [4, 2, 2], [6, 8], [4], [4, 2, 4, 4, 2], [2, 2, 5, 2, 6, 5, 2, 2, 2, 5, 2], [4, 2, 2, 5, 2, 4, 2], [4, 2, 8], [2, 5, 6], [2, 2], [2, 2], [6, 2, 2, 2], [6], [2, 2, 5, 4, 2, 2, 5, 2, 5, 2, 4], [2, 2, 4, 2], [6], [2, 2, 7], [2, 5, 2], [4, 2, 2], [2, 2, 2, 4], [6, 5, 2, 2], [2], [2], [7, 8], [6], [2], [2], [2, 2], [6, 6], [2, 2], [6, 8], [2, 6], [5, 4, 2, 5, 2, 4], [2, 5, 2], [2], [2, 2], [2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 8, 5, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 8], [6, 5, 2, 2], [8], [2, 2, 2, 2, 2, 4, 2, 5, 6, 4, 2], [2, 2, 2, 6], [2], [2], [2, 2, 4, 2, 2, 2, 2], [2, 2, 8], [4, 2], [2], [8, 5, 2, 2, 4], [2], [2], [2, 2, 4, 5, 2, 5, 2, 8, 5, 4, 2, 2, 2, 2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2], [2, 4], [2, 4], [2, 8, 2], [4, 2, 2], [2, 5, 2, 3, 8, 5, 6, 3, 4, 2, 5, 6, 6], [4], [6], [6, 6, 5, 2, 7, 5, 3], [2, 5, 4, 2, 3, 5, 2], [3, 2], [2], [2, 2], [2], [4, 3, 4, 2], [6], [2], [2, 2, 2, 3, 8, 2], [4, 4, 7, 4, 5, 2], [6], [2, 4, 8, 3], [3, 5, 3], [2], [2, 4], [2], [2], [2, 2, 8, 2, 2, 6, 2, 2, 2], [6], [2], [6, 6], [6], [2], [6, 2], [2, 2, 2], [2], [2], [2, 2, 5, 2, 4, 2], [2, 6, 8, 5, 4, 2, 5, 6, 2, 2, 2], [2, 6], [6], [2], [8, 5, 6, 5, 2], [4, 2, 2, 2], [2, 5, 2, 8, 5, 4, 2, 2, 2, 2, 4], [6], [4, 4, 5, 2, 2], [6], [2], [6, 5, 2, 4, 2], [2, 5, 2, 2, 2, 5, 2, 2, 2], [2], [2, 2], [2, 8, 2, 4], [2], [2, 4, 5, 2], [4, 2, 4, 2, 8], [2, 4, 2], [2, 2], [2], [4, 2, 2], [2], [2], [2, 2], [4, 2, 7, 2, 7, 2, 8], [2], [3], [2], [8, 2, 2], [2], [2, 3, 7, 8, 5, 6], [6], [2, 5, 2], [2, 2, 2, 2], [2, 2], [2], [4, 3], [2], [2, 2, 2, 2, 3, 2, 5, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 7], [6], [7, 7], [2, 5, 4, 2, 4, 2], [3], [6], [2, 4, 2, 5, 2, 5, 2, 8, 2], [2, 2, 2, 2, 2, 2, 6, 2, 7, 7, 2, 2, 2, 2, 2, 5, 2, 2, 2, 5, 8, 2, 2, 2, 2, 4, 2], [2], [2, 2], [2, 5, 2, 5, 4, 2, 3, 4, 6], [2, 2], [2, 6], [3, 2], [2, 5, 2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [4, 3], [2], [8, 6], [6, 2], [7, 3], [2], [2, 2, 6], [6, 5, 6], [2], [3, 2], [2, 2, 3, 5, 4, 2, 2, 2], [2], [8, 6, 6], [2, 2, 5, 2], [6, 8], [2, 2, 7], [6, 8], [3, 5, 2, 2, 2, 2], [2, 8, 2, 5, 2], [6, 5, 2, 8], [8], [4, 2, 2, 4, 2, 2, 6, 5, 4, 2, 2, 4, 2, 2], [2], [2], [3, 8, 5, 2, 2, 6, 2, 2, 5, 2], [2], [6], [6, 6, 6, 2, 8, 2], [5, 4, 3, 2], [2], [3], [2, 2], [2, 2, 2], [2, 2, 2], [2, 5, 2], [2, 2, 2, 4, 2], [6], [6, 5, 2, 2, 5, 2], [2, 4, 6, 8, 5], [2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 2, 2], [6], [2, 5, 4, 5, 2, 2], [2, 5, 4, 2, 4, 4, 2, 2, 2, 2, 2, 5, 2, 5, 4, 2], [4, 2, 2, 2, 2, 6, 2, 2], [2], [2], [2], [2, 2, 4, 2, 3], [2, 2, 2, 2, 2], [2, 6, 6, 2, 2], [4, 2, 5, 4, 2, 2, 5, 2, 2, 2], [2, 5, 3], [2, 3, 2, 8], [2], [6, 8, 2, 2, 5, 6, 4, 2, 2, 2], [2], [4, 2, 6, 6, 2, 2, 5, 3, 4, 8], [6], [4, 2, 2, 4, 2], [2, 5, 2], [2, 3, 8, 2], [6], [2, 5, 6], [2, 7, 2, 5, 2, 2, 2, 5, 7, 2, 2], [2, 5, 2], [2, 2, 2], [4, 7], [4, 5, 6, 5, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2, 2], [4, 2, 2], [4, 2], [4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2], [6], [2, 2, 5, 6], [2, 5, 2], [6, 6, 6], [2], [2, 4, 2], [2], [6], [6], [2], [2], [2, 5, 6], [8, 4, 2, 2], [2], [2, 5, 2, 2, 2, 5, 3, 2, 4], [2, 2, 2, 4, 2, 2], [6, 5, 6, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 8, 8], [2, 5, 2, 5, 2, 2, 6, 5, 2, 6, 5, 2], [2, 4, 2, 2, 5, 2, 2, 5, 4, 7], [2, 4], [2, 3], [2, 5, 2], [2, 2, 2, 4, 2], [2], [2, 4, 2], [6], [4, 2, 2, 8], [4, 2, 2], [4, 2, 5, 2], [2, 2, 4, 5, 2, 5, 2, 4, 2, 2, 4, 2, 5, 2], [6], [2], [2], [6, 5, 6], [6, 2], [2], [2], [3, 4, 4, 2, 2, 2, 6, 2, 4, 2, 2, 4, 3, 4], [2, 2, 4, 7], [2, 5, 6], [8, 3, 7, 5, 2, 8], [2, 2, 2, 5, 4, 2], [4, 2, 7, 4], [4, 2, 2, 2, 2, 2, 2, 2, 2, 8], [4, 2, 3, 6, 5, 2], [2, 8, 5, 2, 6], [2], [4, 6, 2], [4, 2, 2, 6, 4, 2, 6, 4, 2, 6, 2], [2], [8, 5, 6, 5, 6], [6], [2, 4], [2, 4, 2, 2], [6, 4, 2], [4, 2, 2, 4], [2], [6], [6, 4], [4, 6, 7], [2, 2, 2, 5, 4, 2, 2], [2, 5, 2, 2, 5, 4, 2, 2, 8, 5, 2, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 4, 4, 2, 4, 5, 2, 3, 4, 6, 5, 2, 2, 2, 2, 2], [2, 2, 2], [2, 5, 3], [4, 4, 2, 2, 4, 3, 5, 2, 2, 5, 2], [2, 2, 2], [2], [2, 3, 2], [6, 5, 2, 5, 2], [2, 8], [6], [6], [6, 5, 6, 8], [3, 2, 2, 3], [2, 3], [8, 2, 2], [6], [2, 4], [6], [2, 4, 5, 2, 5, 3, 8], [2], [2, 6], [2, 2, 4], [2, 4, 2, 2, 2, 2], [2, 2, 2, 2, 2], [5, 4, 2, 8, 2], [6, 5, 4, 2, 2], [2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2], [6], [2], [2], [2], [2, 4, 8], [2, 4, 2, 2], [6, 5, 6], [8], [2, 5, 2], [8, 2, 6, 4, 6, 5, 4, 2, 2, 4], [4, 2], [6], [6], [2, 5, 4, 2, 2, 2, 4, 3, 2, 2, 2, 5, 2], [2], [2], [6], [6], [6], [2, 2, 5, 2, 2, 5, 2], [2, 4], [2], [4, 2, 6], [6, 5, 6, 5, 8, 2, 5, 3, 5, 2, 2], [2, 5, 2, 2], [2, 5, 2], [2], [7], [2], [2, 4, 2, 2, 2, 4, 2, 2], [6], [6], [8], [2, 3, 5, 2], [2, 2, 2], [2], [2], [2, 2], [2], [4, 4, 6, 2, 2, 5, 2, 2], [6], [2], [8, 5, 2, 4, 2, 4, 2, 4, 5, 6], [8, 2, 2, 2, 5, 8, 2, 2, 2, 4, 5, 2, 2], [6], [2, 5, 2, 5, 4, 2, 2, 2, 2, 2, 2], [2, 2], [6], [2, 2, 4, 2, 2, 2, 4, 2], [6], [2, 4, 2, 6], [4, 3, 2], [2, 4], [6], [4, 4, 8], [8, 2, 5, 6, 8], [2, 4, 8, 5, 2, 3], [2], [4, 2, 5, 2, 2], [2, 2, 4, 3, 2, 5], [2], [6, 7, 8, 4, 2], [6, 2], [6], [2], [6, 2, 2, 8, 5, 2, 2, 4], [2], [2], [2], [2, 4, 2], [2, 2], [4, 2, 2, 2, 2, 3], [2], [2, 5, 2], [8], [2], [2], [2, 2], [6], [2, 8, 2, 2, 5, 6], [2, 2, 2, 6, 2], [2], [2, 5, 2], [2, 5, 2], [6], [4, 2], [2, 2], [2], [2, 5, 6], [2, 4, 3, 2, 2, 2], [6, 2], [2, 6, 8], [2], [2, 5, 2], [2, 2, 2], [6], [2], [2], [6, 2], [6], [4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 3], [5, 2], [2, 2], [2], [2], [2], [2, 6, 4], [2], [2, 2, 2, 8, 2, 2, 2, 2], [6], [2, 2, 2, 4, 2], [6], [2], [2], [2], [2, 3], [2, 8, 2, 2], [6], [2, 7, 2], [4, 2, 2, 8, 2, 2], [2], [2, 2, 2, 2, 5, 2, 2, 5, 3], [6], [2, 6, 8, 5, 4, 6, 2, 5, 2, 2, 2, 4, 2, 2, 3, 2, 2, 2], [2], [2, 6], [2, 2, 2, 2, 2], [2], [2], [2, 2, 6, 5, 5, 2], [2, 6, 2, 2, 2, 8, 5, 2, 2, 8, 2, 3, 5, 6, 6], [2, 4, 2, 6, 3], [4], [4, 2, 4, 2], [4], [2, 2, 5, 4, 2, 4], [2, 5, 2, 2, 2], [2], [2, 2, 2, 2, 5, 2, 4, 6], [2], [2, 6, 8], [2], [2, 2, 5, 2], [2], [2, 2], [2], [2, 2, 2, 4, 5, 2], [2], [2], [2, 2], [2, 2, 2, 4, 5, 2, 4, 2, 2, 8, 4, 8, 8, 5, 2], [7, 3, 7, 5, 2, 2, 2], [2, 2, 2], [4], [4, 2, 5, 4, 3, 2], [6, 2, 4], [2, 8, 2, 2], [2], [2], [3], [2, 2, 3, 5, 2, 2, 2, 2], [6], [6, 2, 2], [2], [2, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 4], [6], [6, 5], [2, 3], [8, 2, 6], [4, 2, 2, 2, 2, 2, 2], [2, 2, 6], [2], [2, 2], [2, 8, 2, 2, 2, 2, 2, 2, 2], [4, 2, 2, 2, 5, 2, 4, 2, 4, 2], [2, 5, 2, 4], [2, 5, 6], [2, 8], [6, 8], [2, 2, 2, 4, 2, 2, 4, 2], [4, 2, 4, 2, 6, 2, 2], [2, 4, 2, 5, 2, 2], [2, 5, 3], [2], [4, 2], [2, 7, 2, 2], [2, 6], [6], [2], [2, 8, 5, 6], [2, 2, 4, 2, 5, 2, 3, 2, 2, 2], [2, 2], [2], [2], [2], [2, 2, 4, 2, 3, 2, 4, 2], [2, 2], [2, 2, 6, 7], [8, 5, 4, 2, 2], [6, 3, 8, 5, 2, 2, 2], [4, 2, 4], [2, 2, 4, 2, 4, 8, 2], [2, 2, 2, 2, 2], [2, 4, 2, 2], [6, 2, 6, 2, 5, 2, 6], [2], [3, 5, 2, 8, 2], [3, 2, 2, 2, 6], [2, 2, 2, 4, 2, 2, 4], [4, 2, 2], [6], [2], [2, 2, 2], [2, 2, 6, 2, 2, 5, 2, 4], [2, 4, 5, 2], [2], [4, 2, 4, 2, 2, 5, 2, 4], [2, 5, 2], [2, 8, 5, 2], [4, 5, 8, 2, 4, 2, 7, 5, 2], [8, 5, 8, 5, 6, 2, 6, 2, 4, 2, 2, 2, 2, 2, 2], [2, 8], [2, 4, 2, 4, 2, 2, 2, 2, 4, 2], [2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 5, 2, 2, 2, 2, 4, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2], [2], [2, 2, 2, 2], [2, 5, 2, 8, 5, 2], [2, 8, 2, 4, 2], [2, 2, 4, 2, 4], [2, 4, 2, 2, 2], [6, 6], [3, 4, 2, 2, 5, 3], [6], [2, 5, 3], [6], [2], [3, 5, 2], [2], [2, 2, 2], [3], [2, 2], [4, 3, 2, 2], [2], [3, 8, 2, 8], [2], [6, 3, 5, 2, 8], [5, 2], [2, 4, 2, 2, 2, 4, 2, 2, 2], [6], [2], [8, 2, 6, 5, 2, 5, 6], [2, 4, 2], [7, 2, 2], [2, 2], [2], [6, 8, 5, 6], [2], [3, 2, 8, 5, 6], [4, 2, 5, 2, 2, 2, 2], [6], [2, 5, 2], [2, 4, 2, 4], [2, 2, 2], [2, 8, 5, 2], [2, 2], [4, 2, 2, 2, 2, 2], [6, 6], [2, 4, 2], [6], [2], [2], [2, 2, 4, 2, 4, 2, 3, 6, 5, 5, 2, 2, 2, 4, 5, 2, 2, 4, 2, 2, 4, 2, 2, 5, 2, 2], [4, 2], [2, 5, 2, 4, 8], [2, 6], [6, 6, 5, 6, 5, 6, 6, 5, 2, 2, 5, 6, 2, 5, 2], [4, 4, 4, 5, 2, 4], [2, 2, 2, 2, 2], [2, 2, 2, 2, 2], [6, 7, 4], [2], [4, 2, 2, 2, 2, 5, 2, 2, 4, 2, 4], [4, 2, 2, 4, 6], [3, 2], [2], [3], [2], [8, 2, 2, 4, 5, 2, 4, 2, 4, 6, 6, 5, 2, 2, 2, 8, 2, 2, 2, 5, 2], [2, 2], [6, 5, 2, 5, 2, 2, 2, 5, 2, 8, 2, 8, 5, 6, 6], [6, 8, 2, 5, 2], [2], [2, 2, 2, 7, 8], [4, 6, 5, 2, 5, 2, 4], [2], [6, 5, 4, 2, 4, 2, 6, 5, 2, 5, 4, 6, 2, 4, 2, 2, 5, 2, 4, 5, 2, 2, 5, 2, 4, 2, 5, 4, 4, 8, 5, 2, 2, 3], [2, 2, 4, 2, 2, 2], [5, 4, 2, 2, 2, 2, 2, 3], [2, 2, 2, 4, 2, 4, 8, 3], [3], [2], [2], [2], [2, 2, 6, 2, 2, 2, 4, 2], [2, 2, 2, 6], [2, 5, 2], [4, 2, 2, 2, 8], [6, 6], [3, 2, 2, 8, 2, 2], [2, 8, 2], [2], [2], [3, 8], [6, 6, 4], [2, 2, 8, 5, 2, 2, 4, 2], [2, 5, 2, 5, 4, 2, 5, 4, 2, 2], [4, 2], [2], [2], [2, 5, 4, 2, 2, 2], [2, 8], [6], [2, 4, 2, 2, 7, 2, 2, 2, 6, 2, 2, 6, 2, 2, 5, 3, 2, 2, 2], [8, 2, 2, 2, 7, 7, 7, 5, 4, 2, 2, 2, 6, 2, 2, 8, 6], [2, 2, 2, 2, 2, 2, 4], [6, 2], [3], [2], [2, 2, 2, 4, 2], [4, 6, 2, 6, 6], [4, 4, 2, 7, 2, 2, 2, 5, 2, 2, 2, 5, 2, 5, 2, 2], [6], [2, 6, 5, 2, 2, 6, 2], [2], [6, 2], [2, 2], [7], [2, 4, 2, 5, 2, 2, 2, 3], [8, 2, 8], [2], [2, 5, 3, 5, 2, 2], [2, 2], [2, 2, 4, 4, 2, 2], [6], [2, 8], [2, 2, 7, 2, 2], [2, 2, 5, 2, 2], [2, 2, 3, 2, 2, 2, 2, 5, 2, 2, 5, 4, 2, 2, 3, 2, 2], [2, 4, 2, 5, 3], [4, 2, 4, 2], [6], [2, 2, 2, 4, 6], [6, 2, 2], [4, 2, 2, 2, 5, 2, 2], [2, 5, 2, 2, 4], [2, 2, 5, 2, 2], [2], [2, 5, 2], [2], [6], [6, 6], [2], [2, 3, 8, 2, 2, 3, 2, 2], [2, 4, 4, 2], [6], [2, 2], [2, 4, 4, 2], [6], [2], [2, 2, 6, 5, 6], [2], [8, 4, 2, 2, 2, 4, 2, 4], [2, 5, 8, 2, 5, 2], [2, 2, 5, 2, 4, 2, 5, 3, 5, 4, 2, 4, 6], [6], [4, 2], [4, 2], [6, 5, 6, 5, 6, 5, 6], [2, 8, 5, 6], [2], [8], [2], [2], [2, 5, 2, 7, 2], [2, 2, 8, 2, 2], [2], [2], [2], [2, 5, 3], [2, 2], [6, 2, 6, 5, 2, 8], [2, 2], [2], [6], [2, 2, 4, 2, 6, 6, 5, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2, 2, 2, 6], [2, 2, 2, 2, 2, 5], [7, 2, 5, 2, 2, 2], [3], [6], [2], [2, 4, 2, 2, 2, 2, 2], [2, 7], [2], [2], [2, 2, 2], [3], [4, 2, 4, 2, 2, 8, 5, 2], [6, 3, 2], [4, 4, 2, 4, 5, 4, 2, 3, 5, 2, 2, 5, 4, 5, 4, 2, 5, 2, 4, 2, 4, 5, 8, 5, 2, 2, 2], [3, 2], [2, 8], [2, 6], [2, 2, 2, 2, 2, 5, 3, 4, 2, 5, 2, 2, 2, 2, 2, 4, 4, 2, 3, 2, 5, 2, 2, 2, 2, 2, 2, 4, 3, 5, 2, 2, 2, 2, 3, 6, 5, 2, 4, 2, 2, 2, 4], [2], [2, 2, 8], [2], [4, 2, 4, 2, 2, 2, 5, 2, 5, 2], [2], [2, 2], [2, 2, 2, 2], [6, 6, 8], [6, 4, 8, 8], [6, 6], [2, 2, 4], [6, 6], [6, 6, 2, 8, 5, 2, 7, 5, 2, 2], [2, 6], [2], [2, 4], [2, 2], [6, 2, 2, 4, 5, 2, 2, 5, 2], [2, 4, 8, 8, 6, 2, 3, 2], [2, 2, 2, 3], [2], [6, 8, 2], [2], [2], [3, 4, 8], [2, 6], [2, 4, 2, 2, 7], [2, 5, 2], [2, 6, 5, 8, 5, 2, 4, 2, 2, 2, 4, 2, 5, 6, 2, 5, 6, 4], [2, 2, 5, 2, 2], [4, 2], [3], [5, 4, 4, 2, 4, 8, 2, 5, 2, 6, 2, 2], [6], [4, 2, 4, 8, 2, 2, 2, 2, 2], [6, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 4, 2], [2, 2], [2], [4, 2, 6, 5, 4, 2, 2, 5, 2], [2], [6], [2, 6], [7], [6, 2], [2], [6, 5, 6], [6, 8, 6], [8], [6, 8, 2], [6, 8, 5, 2], [2], [4, 2, 2, 6, 4, 2], [2], [2], [2, 5, 2], [2, 4, 2, 2, 4, 4, 2, 2, 2, 2], [2, 5, 2], [2, 4, 6, 2, 7, 2, 4, 2, 2, 2, 6, 5, 4, 8, 2, 2], [6], [2, 2, 2, 6], [6, 5, 8, 4, 2, 2, 4, 5, 2], [2], [3, 5, 2, 6], [2], [2, 2], [2], [6, 2, 5, 6, 5, 6], [6], [2, 4, 2, 4, 2, 4, 2, 2], [6, 6], [2, 2], [2, 6, 5, 2, 8], [6], [6], [2], [2], [6, 8, 5, 4, 2, 2, 4, 2], [2, 6], [2], [6], [2], [2, 5, 2, 5, 6, 2, 8, 5, 2, 6, 2, 2, 2], [2, 2, 3], [2, 5, 4, 2], [6], [4, 5, 8, 5, 2, 7, 2, 2, 2, 5, 2, 5, 2, 7, 2, 5, 2, 2], [2, 6, 5, 2, 4, 2], [2, 2, 2, 5, 2], [2], [4, 2, 2, 2, 2, 2, 2, 4, 2], [4, 2], [2], [4, 2, 2, 4], [2, 2, 2, 2, 2, 4, 6, 5, 6], [2], [2, 2], [2, 5, 2, 5, 2, 5, 2], [2], [2, 5, 2, 4, 2, 3], [6, 2, 2, 8, 2], [8, 2, 2], [6, 6], [2, 2], [2, 4, 2], [3, 2, 2, 4, 8], [2, 5, 4, 2, 6, 5, 2, 2], [2], [6, 8], [2], [6, 8], [6], [2, 2, 4], [2, 2, 5, 2, 2, 5, 2, 5, 2], [2, 5, 4, 7, 2, 2, 5, 2, 4, 2, 3, 3], [2], [2, 5, 2], [2], [6], [2], [2, 2, 5, 4, 2, 8], [6, 6], [2, 2, 2, 5, 2, 2], [2], [3, 4, 2, 2, 8, 5, 2, 6, 2, 2, 5, 2, 2, 2, 2, 2, 3, 2, 5, 2, 2, 6, 2, 3], [2, 2, 2, 2, 5, 2, 2], [2, 8], [2], [3, 6], [2], [2, 2, 5, 2, 5, 2, 2, 4, 2, 2], [6], [2], [2, 2, 2, 7], [2, 8], [4, 2], [6, 6], [2], [2, 2, 2], [6], [2, 2], [6], [2, 2], [2, 2], [4, 2, 4, 2, 7, 2, 6], [2], [6], [2, 2, 2, 2, 5, 6], [6, 5, 2, 2], [2, 5, 2, 2, 2, 2, 4, 2], [2, 4, 2, 2], [2, 2], [4, 2, 4], [3, 4], [2], [2, 5, 2], [2, 5, 2, 6, 4, 2], [2, 2, 4, 2, 4, 2], [4, 8, 2, 2, 2, 3, 5, 2, 2, 2, 6, 5, 2, 7, 5, 6], [6, 5, 2, 3], [2], [2, 5, 2, 2, 3, 5, 2, 2, 2, 8, 5, 2, 2, 2], [2, 4], [2, 8], [6, 5, 2], [2, 2], [3, 3], [2], [2, 2, 4, 2], [2, 8, 2, 5, 2], [2], [2, 2, 2], [2], [2], [2, 2, 2], [2, 6, 2, 2, 2, 2, 2], [4, 2], [4], [4, 2, 2, 2, 2, 4, 3], [2], [4, 2, 4, 2], [2], [2, 5, 2], [4, 8], [6, 4, 2, 2, 3, 3], [4, 2, 4, 2, 5, 2, 5, 6], [4, 2, 4, 4, 2, 2, 6], [3], [6], [3, 6], [4, 8, 2, 3, 5, 6, 6, 2], [2, 5, 2], [4, 2, 2, 2, 2, 2, 2], [2, 2, 5, 2, 2, 2, 6, 8], [6], [2], [4, 2, 2, 8, 2, 7, 2, 2, 3, 2, 2], [4, 2, 2, 2], [2, 2, 8, 2, 2, 2], [2, 4, 2], [6, 4, 2, 2, 5, 4, 4, 2], [2, 2], [2, 5, 2, 5, 3], [6, 6], [2, 5, 2, 5, 8, 4, 2, 6, 4, 2, 4], [8, 4, 2, 4, 2], [4, 2, 4, 4, 2], [6], [2], [6, 6], [6], [4, 2, 2, 5, 2, 2, 5, 2, 2, 4, 2, 4, 2, 5, 2, 2, 6, 5, 2, 2], [6, 2], [2, 2, 2, 2, 2, 2, 8], [6], [6], [6, 2, 6], [2, 2], [6, 2], [6, 2, 5, 4, 2, 6, 8], [2], [2], [2, 4, 2, 2, 3], [2], [2], [2, 2, 4, 2, 2], [2], [2, 2, 3, 2], [2], [6], [8, 2, 5, 2, 2, 2, 2, 7], [6, 8, 5, 2, 2, 2, 5, 6, 6, 2, 2], [6, 5, 2], [2], [2, 4, 2, 2, 2, 8, 5, 2, 2, 2, 2, 6, 5, 2, 2, 5, 4, 2, 4, 2, 2, 5, 4, 2, 4, 2, 5, 4, 2, 2], [2, 2, 4, 2], [8, 2, 4, 2, 2], [2, 2, 5, 8], [2, 8, 6, 2, 5, 2], [2, 4, 5, 2, 4, 2, 2, 5, 4, 2], [2], [3, 5, 2, 5, 3, 5, 2, 8, 5, 3], [2, 2, 5, 2], [4, 5, 2, 5, 2], [2], [6], [2], [2], [6], [2, 2, 5, 6], [2, 8], [2, 2], [6, 8], [3], [2], [2], [2, 2, 5, 4, 2, 2, 2, 2, 2], [2], [2], [2, 2, 3, 2], [2, 4, 6, 4, 8], [2, 6, 8, 2, 2, 6, 2], [2, 8], [4, 2, 2, 2, 2, 6], [2, 4], [2, 8], [2, 6, 5, 2, 2], [6], [2, 2, 2], [2], [2], [2, 7, 4, 2, 2], [3, 6], [2, 8], [3, 2, 2, 2, 3, 2], [6], [2], [2, 4, 2, 2, 8], [4, 2, 4, 2], [4, 4, 2, 2, 2, 4, 8, 2, 2], [2, 2, 2], [2, 2, 2, 2, 2, 2], [3, 5, 2], [6], [2, 2, 2, 2, 2, 5, 2, 2, 5, 2, 2, 8], [2], [2, 8, 2, 2, 2, 8], [2, 6, 5, 3], [2], [2], [6, 2, 5, 2, 6], [2, 5, 6, 5, 2, 2], [2, 2, 8], [6, 8, 5, 3, 2, 5, 3], [4, 2, 2, 2, 2, 2, 4, 2, 2, 2], [2, 5, 4, 2, 2, 2, 4, 2], [6], [2, 2, 5, 2], [2], [2, 5, 6], [2, 2], [2, 2], [2, 2, 2], [4, 2, 2, 2, 2, 2, 8], [6, 8], [2, 5, 8], [2, 2, 2], [2, 5, 2], [4, 2, 2, 2, 6, 4, 4, 5, 4, 2], [4, 2, 2, 2, 4, 5, 4, 2, 2, 2, 5, 2, 4, 2, 4, 2, 2], [2, 2, 2, 2, 2, 2], [3, 2, 7], [6, 2, 5, 8, 2], [2], [2], [4, 2, 4, 2, 4, 2, 2, 2, 2], [2, 2, 2], [2, 5, 2], [3, 7], [4, 2, 2, 4, 2, 6, 5, 2, 2, 4, 2], [2, 8, 5, 2, 5, 8, 2], [6], [6], [2, 2, 2], [2, 5, 2, 5, 2, 5, 2, 5, 2, 2, 5, 2], [2], [6, 2], [2, 2, 6], [2, 8, 2, 2], [3], [6], [2, 2], [2], [6, 7], [2, 2], [2], [2], [2, 6, 2], [6, 2, 5, 6, 2], [2, 4], [2, 8, 2], [2], [6, 6, 6, 2], [6], [2, 2], [2], [2, 5, 2, 2, 4], [6], [2], [2], [2], [2], [2], [2, 2, 2, 4, 5, 2, 5, 2], [6, 2, 4, 2], [2], [2], [3, 5, 8], [2], [2, 2, 2], [2, 5, 4, 2, 2], [2, 2, 8], [2, 2, 2], [5, 8, 2, 2, 5, 2, 2, 5, 6, 6, 5], [6], [2], [2], [2, 2, 4, 3, 2], [6, 6, 5, 2, 8], [2], [4, 2, 8, 2], [2, 2, 4, 2, 5, 2, 2, 4, 2], [3], [2, 2, 5, 2, 2, 2, 5, 2, 2, 2], [2, 5, 6, 5, 2], [6, 6], [4, 2, 2, 5, 2, 2], [2, 2, 2, 5, 3], [2], [6, 2, 2], [2, 2], [6], [2, 6, 2, 5], [2], [2], [2, 6, 2, 6, 5, 2], [2, 2, 2, 2, 2, 2], [4, 2], [2], [6], [6], [2, 5, 2, 2], [6, 8, 2], [2, 2], [2], [2, 6, 2, 2], [2], [2], [8, 2, 2, 4, 5, 4, 4, 2, 2, 2, 6, 4, 4], [2, 2, 2, 5, 2, 8], [2], [6, 8], [6], [2, 5, 2, 5, 2], [6, 5, 2, 2, 2], [4, 2, 2], [2, 2], [2], [8, 3], [6], [3, 4], [6], [2, 4, 2, 2, 4, 2, 4, 2, 2], [6, 4, 3], [2], [6, 2, 5, 4, 5, 2, 2], [2, 3, 5, 2], [6, 2], [2, 5, 2], [2, 2, 3, 5, 2, 2, 6], [6], [2, 2, 5, 2, 5, 2], [2, 2, 7], [6], [6, 2, 2, 2], [2, 2, 2], [2], [6], [2], [2, 2, 4, 2, 2], [2], [2, 5, 2], [6], [2, 2, 2, 5, 2, 2, 2], [2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2], [6], [2, 2, 2, 2], [6], [2, 4], [8, 2, 4, 3, 5], [2, 5, 4, 8, 5, 2, 2, 2], [2], [2], [2, 5, 2, 2, 2, 6], [6, 2], [6], [6, 8, 2, 2], [2], [2], [2], [2, 2, 2, 2], [2, 2], [2, 2], [2], [6, 8], [2, 6], [6], [4, 3, 2], [2], [2], [6, 2, 5, 8], [2, 2], [2, 2, 4, 2], [6], [2, 2, 5, 2], [4, 2, 2, 2, 5, 2, 2, 2], [2, 2, 2, 5, 8], [2, 5, 4, 2, 2, 5, 2, 4, 6, 6, 2], [2, 2, 8, 5, 2, 6, 5, 2, 2, 7], [4, 2, 3], [2], [3], [2, 4, 6, 2, 2, 2, 2, 2, 4], [2, 5, 4, 2, 2, 2, 6], [2, 2, 5, 2, 5, 6], [2, 4, 2, 8, 3, 5, 8, 2, 6, 2, 6, 2, 8, 5, 6, 2, 2], [2], [2, 2, 2], [4, 2, 2, 2, 2, 4, 6, 8], [4, 2, 2, 3, 2], [2, 2, 2], [2], [6, 6], [2, 4, 2], [6, 4, 5], [2, 2, 4, 2, 2], [2, 2, 5, 2, 5, 6, 3], [2, 4, 2, 2], [4, 3], [6], [8, 2, 3], [2], [2, 5, 2, 3], [8, 5, 2, 4, 5, 2, 2, 2, 2, 5, 4, 2, 2, 4], [2], [2], [2, 8, 3], [2, 4, 3], [2, 4, 3, 4, 2, 2, 2, 2, 2, 8, 2], [4, 3], [2], [6], [6], [4, 8, 2, 5, 2, 5, 2, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2], [4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 5, 2], [2], [6], [3, 2, 5, 2, 2], [2], [2, 2, 2, 4, 4, 2], [6], [2, 4, 5, 2], [2, 2, 2], [2, 2, 5, 2, 2], [6, 6], [6, 2, 4, 6, 5, 2, 8, 2, 8], [6], [6, 2], [8, 8], [2, 2, 6, 2, 2, 2], [4, 3, 2, 7], [6, 8], [4, 2, 2, 2], [2, 4, 2], [2, 6, 2, 8, 2, 5, 2], [2], [4, 2, 2, 2, 2, 2, 2, 2], [2, 5, 6, 5, 2, 8, 5, 2, 2, 2], [3, 2], [8], [2, 4], [4, 8, 5, 2, 2, 2], [2, 5, 4, 7], [2], [2, 5, 2], [2, 2, 2, 5, 2], [2], [8, 8, 5, 3, 2, 2], [4, 8, 2, 2, 5, 2], [2, 2], [2, 5, 2, 2], [2, 6, 5, 2], [2, 6, 2, 5, 6, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 4, 2], [2], [2, 2, 4, 2, 2, 2, 8, 2, 5, 3, 4, 4, 2, 2], [2, 5, 4, 2, 2, 2, 5, 4, 2, 4, 2, 2, 2, 2, 2, 2, 3, 5, 4, 2, 4, 2, 2], [2], [2], [2], [6, 6], [2], [6, 8, 5, 2], [6, 2, 2, 2, 5, 3, 3], [6, 6], [2], [6, 8, 2, 2], [4, 2, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2], [2], [2], [2, 5, 2], [2], [2, 4, 2, 2, 2, 5, 2, 2, 2], [6, 8, 6, 6], [2], [2, 2, 4, 2, 4, 3, 8, 2, 3], [2], [2, 2, 2], [2], [4, 2], [4, 2, 2, 5, 2, 2, 2], [6], [2, 2], [6, 8, 2, 2, 2, 5, 6, 5, 6], [3, 5, 2, 4, 5, 4, 3], [7], [4, 2, 2, 2], [4, 2, 2, 5, 2, 2, 2, 6], [2, 2, 2, 2, 2, 8, 2, 2, 4, 3], [2], [2, 4, 2, 2], [6, 2, 4, 2, 2, 4], [6, 8, 2, 5, 7, 2, 3, 5, 2], [2], [2, 2, 4, 5, 6], [6], [6, 2, 8, 5, 2, 2, 8, 2], [2, 2], [2, 2], [4, 2], [2, 2], [2], [2], [2, 4, 2, 7], [2], [6, 6], [2, 2, 4, 2, 5, 2, 2, 2], [6, 8, 2], [2, 7], [2, 5, 2, 2, 5, 4, 2, 4], [2, 2, 4], [2, 2], [2, 5, 3], [2], [2, 4, 3], [3, 5, 6, 4], [2, 6], [6, 2], [2, 5, 2, 2], [2], [6], [2, 2, 4], [6, 8], [2, 4, 2], [6, 2], [2, 4, 2, 2, 2], [2, 4, 6, 8, 5, 2, 8], [6, 5, 6], [6, 6, 6], [2, 4, 2, 2, 4, 2, 3, 2], [2, 5, 6, 2], [2, 4, 2, 2, 2, 2], [6], [2], [2, 2], [2], [2, 2, 2], [6], [2], [4, 2, 2, 2, 3], [2, 2], [2, 2, 2, 2, 3], [6, 8, 2, 2], [2], [2], [2, 5, 2, 2, 2, 2, 2], [2, 4, 2, 2, 6], [2], [4, 3, 4, 4, 3], [6], [4, 2, 5, 4, 2, 8], [6], [2], [2, 2], [2, 8, 2, 2, 7], [2], [2], [2, 8, 2, 4], [6, 2, 2], [6, 5, 2, 5, 6, 2, 5, 2], [2, 2, 2, 2], [4, 2, 2, 2], [3], [7, 2], [4, 7, 2], [6, 6], [2, 2, 5, 2, 2, 6], [2], [2, 3], [3], [2], [6, 8], [4, 2, 2], [2, 6], [2, 4, 2, 7, 5, 2, 5, 6], [3, 5, 2, 8], [2, 2, 3], [6, 6], [6, 5, 2, 4], [6, 2, 4, 2], [2, 5, 2, 2], [2], [2, 2, 3, 2, 2, 4, 2], [2, 2, 2], [4, 2, 2, 5, 3, 5, 6, 2], [2, 5, 2, 4, 2, 2], [4, 2, 4, 2, 2, 4], [2], [2], [2], [2, 5, 3, 5], [6, 8, 5, 2, 4, 2, 2], [6], [2, 2, 4], [2], [6], [3, 3, 5, 4, 2, 2, 2, 2, 6], [4, 2], [2], [6], [2, 2, 2, 2], [2, 2, 5, 7, 5, 6, 5, 4], [4, 4, 2, 4, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2], [2, 2, 2], [6], [6], [2], [2, 5, 2, 4, 2], [5, 4, 8, 2, 2], [2], [2, 5, 2], [2], [8], [3, 8], [6, 5, 2], [6, 7, 5, 2], [2], [2, 7, 2, 5, 7, 5, 2, 2, 4], [6], [2], [4, 3, 2, 2, 2, 2, 5, 2, 2, 4, 4, 2, 4, 6, 2, 2, 4, 5, 4, 2, 2, 3, 4, 2, 5, 2, 2, 2, 2], [2, 5, 2, 2, 5, 3], [2, 5, 2], [4, 6, 4, 2, 2, 6, 5], [2], [2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 8, 2, 8], [2, 2, 4, 2], [2, 8], [2, 2, 5, 2, 4, 4], [6, 2], [2, 2, 4], [6, 6], [4, 2, 2, 2, 2, 2, 5, 4, 2, 3, 3], [2], [2], [3, 4, 8, 5, 2, 8, 6, 7], [2, 2, 2, 2, 6, 5, 3, 5, 8, 2, 7, 3], [6, 6], [2, 4, 4, 2, 2, 2, 2, 2], [2, 2, 5, 2, 2, 2], [2, 6, 5, 6, 8, 5, 3], [6], [2], [2, 5, 2, 2], [2, 6], [2, 2], [2, 2, 2], [2, 8, 6, 2, 2, 5, 4, 2, 2, 2, 2], [2, 2, 2, 2, 2], [2], [6], [2, 8], [2, 2, 8], [2], [2, 5, 2, 5, 2], [6, 8], [4, 2, 2, 2], [2], [2, 5, 2], [6, 7, 2, 2], [2, 2, 2, 2, 2, 2, 5, 2, 2], [2], [2, 5, 2, 2], [6, 6], [2], [2], [3], [2, 4, 2, 5, 2], [2, 4, 2, 6, 5, 4, 2, 2, 2, 2, 5, 2], [2, 5, 2, 6, 5, 2], [2], [2, 5, 8], [2, 2], [2, 2, 6, 4, 6, 2, 8], [2, 8, 2, 7], [2], [2, 2, 5, 2, 4, 2, 5, 2, 5, 6, 8, 2], [5, 4], [2], [2, 5, 2], [2], [3, 7], [2, 4, 2, 2, 2, 4, 2, 5, 2, 2, 5, 6, 2, 6, 2, 5, 2, 4, 2], [6], [2], [6, 6], [2], [4, 2, 2, 4, 2], [2], [2, 2], [6], [2, 5, 2], [6, 6], [2, 2, 2, 4], [2, 4, 2, 2, 6, 2], [2, 6], [2], [2, 2], [2, 2, 2], [4, 2, 2, 2, 2], [2, 2, 7, 8, 5, 2, 2], [2, 6, 6, 2, 2, 2], [4, 2, 2, 2, 6, 4, 2, 5, 4, 4], [2], [6], [6], [2], [2], [4, 2], [6], [2], [2, 2, 2, 2, 2, 7, 2, 2, 4], [2, 2], [2, 5, 2], [6, 4], [2, 5, 2], [6], [2, 4], [6, 2, 5, 2], [4, 2, 2, 7, 4, 2, 2, 4, 2, 2, 7, 5, 4, 2, 2, 2, 2, 2, 6], [2, 2, 7], [6, 6], [2], [2], [2, 5, 2], [6], [8, 7, 2, 2, 7, 5, 2, 4, 2, 3, 2], [6], [2, 3, 3], [2, 4, 2, 6, 5, 6, 5, 4, 2, 8], [6, 8, 2], [2], [4, 2, 2, 2, 2, 7], [2, 4], [2, 5, 4, 2, 3], [2, 4, 2, 2, 3], [6], [2, 5, 2, 2], [2], [5, 2, 8], [2, 2, 2], [2, 2, 2], [2], [8, 2, 2, 2], [4, 2, 4, 2], [2], [2, 4, 2, 2], [2, 2], [2, 5, 4, 2, 2, 2], [6, 6], [2, 5, 2], [6, 8], [2], [2], [2, 2, 5, 2, 2, 5, 2, 5, 2], [2], [2], [2], [2, 2, 8, 5, 6], [2, 2, 2, 5, 2, 2, 2, 4, 2, 2, 5, 3, 5, 4, 2, 2, 5, 4, 2, 2, 2, 2, 5, 2, 2, 4, 2, 2, 4, 5, 2, 3], [8, 2, 6, 2, 2, 2], [2, 2], [6], [2], [2, 5, 6], [2], [4, 2, 4, 4, 2, 2], [4, 2, 2, 5, 2, 2], [8, 6, 2], [2, 2, 4, 2, 4, 5, 8, 2, 2, 2], [6, 8], [2, 2, 4, 2, 5, 4, 4, 2, 2, 2, 2, 5, 2, 2, 2], [2], [2, 2, 8, 5, 2, 8, 2, 2], [6, 3, 4], [2], [2], [6], [2, 4, 2, 2, 2, 5, 4, 2, 2, 2], [6], [6], [2], [6], [8, 5, 2, 2], [4, 4, 5, 3, 5, 2, 2], [2, 5, 6, 5, 2, 7, 5, 3], [4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4], [2, 2, 2, 2], [2, 5, 4, 2, 4], [4, 2, 3, 5, 2], [4, 6, 6], [2, 2, 2, 5, 2, 2], [2], [2, 2, 4, 3], [2, 2, 2, 4], [4, 2, 6, 2, 2, 8], [2], [2, 2, 8, 2, 2, 5, 2, 2, 2, 2, 2, 6, 2, 3], [2, 6], [6, 2, 5, 2], [4, 2, 2, 3, 2, 2, 4, 2, 2, 2, 3, 4, 2], [3, 4, 3, 5, 6, 4, 2, 5, 2, 2], [2], [2, 2, 5, 2], [4, 2, 2, 3, 2], [4, 2, 2, 2, 2], [2], [4, 7, 2, 3, 2, 2], [2, 2, 4, 2, 2], [2, 5, 4, 2, 6, 5, 2, 4, 2, 5, 2, 2], [2, 2, 2, 4], [2], [4, 2, 4, 5, 4, 2, 5, 2, 5, 6, 6, 5, 2, 2], [8], [4, 2, 2, 5, 2, 2, 2, 4, 2, 2, 2, 2], [6], [4, 2, 2, 5, 2, 2, 3], [2], [3, 5, 3, 5, 4], [5, 5, 5], [2, 2, 4, 2], [2], [2, 8], [4, 2, 2, 2, 2], [6], [2, 8, 2, 7], [6, 2], [2, 5, 6, 8, 2], [2], [6], [2, 8, 2, 2], [2, 4, 2, 5, 4, 5, 7, 5, 2], [4, 2, 2, 2], [8, 2, 4, 4, 2, 5, 2, 3], [3], [3, 2], [2, 2], [2], [6, 2], [2], [2], [2, 2, 2, 2, 5, 4, 2, 2], [5, 2], [6, 8, 5, 2], [2], [4, 2], [2, 2, 4, 2, 5, 2, 2, 2], [2, 2], [2], [6, 5, 6, 7], [2], [2], [2, 2, 4, 4, 2, 2], [7, 5, 2, 4], [2, 2, 2, 2], [2, 2], [2, 6], [2], [2, 2, 2], [2, 8], [3], [2, 5, 2, 5, 2], [2], [2, 2, 5, 4, 2, 2, 2, 2, 2], [2, 2, 2], [2], [2, 2, 4], [4, 8, 2], [3, 4, 5, 6, 6], [2, 4, 4, 6, 8, 2, 2, 6], [2, 4, 2, 5, 4, 2], [2, 2], [2, 2, 2, 6], [2, 5, 6], [4, 2, 4], [2], [6, 2], [3, 4, 3], [6], [8, 5, 4, 2, 4, 5, 4, 2], [2, 2, 5, 2, 4, 2], [4, 5, 2, 2], [2, 3], [4, 2, 4, 4, 2, 2, 3, 8, 2, 4, 2], [2, 4, 2, 2, 2, 2, 2, 4, 6], [3, 3, 2, 8], [2], [2, 4, 2], [6], [4, 4, 2, 2, 2], [2], [2, 2], [2], [7, 5, 6, 2, 5, 8, 2, 5, 2], [2, 2, 5, 6], [8, 5, 8, 5, 2], [4, 2, 2, 2, 2, 2, 8], [2], [3, 6], [4, 2, 5, 2], [2, 6, 2, 5, 2, 2, 6, 4, 2], [8, 2, 2, 4, 8, 8, 2, 8, 5, 2, 2, 5, 4, 2, 4, 4, 2, 2], [2, 2, 5, 4, 2, 6], [2, 2, 8], [2], [6, 7], [2, 2, 2, 2], [5, 4, 2, 2], [2, 4, 3, 5, 2, 3], [3], [8, 2, 2, 2, 2, 7], [2, 2, 5, 6, 8], [2, 3, 2], [2, 2, 6, 2, 2], [2], [6], [2, 5, 2], [3, 8, 4, 4], [6], [2], [2], [2, 5, 2], [5, 6], [4, 2, 5, 2, 4, 2], [2, 6, 8], [2], [3, 2, 2], [2, 2, 2, 4, 2, 5], [6], [6], [2, 2, 2, 2], [6], [2, 6, 2], [8, 2, 6], [3, 4, 2, 5, 6], [2, 5, 2], [4, 2, 2, 2, 2, 3, 2, 3, 6], [6], [2], [4, 5, 4, 5, 2], [6], [2, 8, 5, 2, 2], [6], [2, 5, 6], [4, 2, 2], [6, 2], [4, 2, 2, 2, 2, 5, 2, 4, 2, 2, 2, 2], [2], [2], [2, 2, 5, 2], [4, 2, 5, 2, 5, 2, 2, 5, 4, 2, 2, 4, 2, 5, 2, 2, 6, 6, 5, 2, 5, 2, 4], [3, 4, 3, 5, 2, 5, 2, 5, 2], [6], [5, 2, 4], [2], [2, 6, 8, 2, 2, 2, 2, 3, 4, 2, 2, 4, 2, 5, 2, 2, 2, 2, 2, 2, 2, 5, 2, 4, 6, 4, 6, 5, 4, 2, 4, 2, 2, 4, 2, 2], [6, 8, 2, 2], [2, 4, 2], [2, 2, 4, 2, 2], [2], [2], [2], [6], [2], [2, 5, 2], [6], [2, 4, 2, 5, 2, 3], [2, 2], [2], [6, 8], [2, 5, 2, 3], [2, 2, 8], [2, 5, 2], [2], [2, 5, 2, 2, 5, 4, 2, 2, 2, 8], [2, 2, 2], [2, 4, 2], [2], [2, 2, 2, 2, 2, 5, 2, 2, 2, 2], [4], [2], [2], [4, 2, 5, 2], [2, 5, 4, 4, 2], [6], [2], [6, 8], [8, 5, 6], [2], [2, 2], [8, 2, 6, 2, 2, 2, 2, 6], [2, 2, 2], [2], [6, 6, 5, 2, 2], [6, 4, 8, 2, 3, 2, 5, 2, 2], [3], [4, 2, 2, 3, 8], [2, 4], [2, 4, 3], [2, 5, 2, 8], [3], [2], [6], [2, 7], [2], [2], [4], [2, 2, 2], [2], [6, 2, 2, 5, 3, 3], [2, 8], [4, 3, 8, 2, 5, 4, 2], [6], [2, 5, 8], [2, 2, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2, 2, 5, 3], [2], [2], [4, 2, 5, 2, 4, 2, 2, 4, 2, 2], [6], [2, 5, 2, 4], [8], [2, 2, 2, 5, 2], [6], [2, 4, 2, 2, 2, 4, 6, 2, 2, 4, 2], [2], [2, 2, 5, 2], [2, 4, 2, 2, 4, 2, 5, 2], [2, 5, 4, 2, 2, 2], [3, 2], [4, 2, 2, 2, 2, 2], [2, 5, 2], [2, 2, 2, 2, 3, 5, 2, 2, 4, 2, 2, 2, 2, 2, 5, 2, 2], [2, 2, 2, 2, 4, 2, 4, 6, 4, 2, 2, 2, 2, 4], [3, 4, 2], [2, 2], [2], [4, 2, 5, 2, 2, 3, 5, 2, 2, 4, 5, 2, 3, 4, 8, 5, 3], [2, 2], [2, 2, 2], [2], [4, 2, 2, 2], [2, 4, 2, 2, 3, 6, 2, 4, 2], [2, 5, 6], [6, 2], [4, 2, 6], [8, 5, 4, 2, 4, 2, 5, 2], [6], [2, 2, 2, 4, 2, 2, 3, 2, 4, 7, 5, 4, 2, 5, 2, 4, 2, 3, 3, 8], [2], [2, 5, 2, 6], [2], [6], [6, 6], [2], [2, 5, 2, 4, 2, 2, 4, 2, 2, 2, 5, 4, 2, 2, 4, 2], [2, 5, 2], [2], [2], [6, 8, 2], [2, 5, 2], [3, 4], [2], [4, 2, 2, 3, 4, 2, 7], [2, 5, 4, 2, 2, 8], [3, 8], [4, 2, 2, 5, 3, 4, 2, 4, 2, 4, 2], [2], [2], [2, 2, 5, 2, 2, 2], [2, 5, 2], [2, 2, 2, 2], [2], [2, 2, 2, 2], [4, 2, 2, 2], [2, 6], [2, 2], [2, 5, 2, 4, 2], [2, 2, 2, 4, 2, 2], [2], [2], [6, 5, 4, 2, 2, 2, 2, 2, 4, 2, 6, 2, 5, 2, 3, 2, 7], [2], [6], [2, 5, 2, 4], [2, 2, 2], [2, 5, 6], [2], [6], [4, 2, 2, 5, 2, 4, 2, 2, 4, 5, 4, 2, 4, 5, 2, 5, 2, 5, 2], [6, 2], [4, 2, 2, 7, 2, 2, 5], [6], [2, 2, 2, 8, 2, 5, 4, 2, 2, 2, 4, 2, 2, 2], [6, 8, 5, 2, 5, 2, 2, 2], [2, 2, 3, 2, 3], [6, 6], [2, 4, 2], [2, 2, 5, 2, 2], [6], [4, 2, 2], [2], [2], [4, 2, 2, 2], [2, 2, 2, 5, 3], [2, 2, 3, 2], [4, 4, 2, 2, 5, 2], [2, 4, 4, 5, 2], [2, 2], [2], [2, 2, 3], [2, 4, 7, 2], [2, 6], [2, 5, 4, 2, 2, 2, 2], [6, 2], [2, 3], [4, 2, 2], [4, 2], [2, 4, 4, 2], [2], [2, 5, 2], [2, 8, 2, 2], [6], [2, 5, 2, 3], [3, 3], [2, 2, 2, 2], [6], [4, 2, 2, 2, 8], [2, 5, 2], [4, 2, 2, 2, 6], [2], [2, 4, 2, 2, 2, 4, 5, 4, 2, 2, 2, 2], [2, 5, 2, 5, 2, 5, 8, 5, 2], [2, 2], [2], [2, 2, 2], [2], [2, 2, 2, 5, 2, 4, 2], [4, 7, 2, 2, 5, 4, 2, 2], [2, 4, 6], [2], [4, 2, 2, 2, 2, 2, 2, 2], [2, 8], [4, 8, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2], [2], [2], [2], [6], [6, 2], [2], [2, 2, 4], [6, 4], [2, 2, 2, 2, 8, 2, 2], [2, 2], [2, 4, 2, 2, 2, 5, 4, 2, 2, 5, 2, 2, 2, 5, 2, 2], [2, 2, 2, 2, 2, 5, 2, 3, 5, 8, 2, 5, 2], [2, 2, 4, 2, 2, 2, 3, 2], [2, 5, 8, 5, 2], [2, 2, 2, 2, 8], [6], [6, 6, 4, 2, 2, 5, 6, 6, 5, 8, 2, 8], [6, 8, 2, 2], [2], [4, 2], [6], [2, 2, 2, 8], [2, 2, 5, 2], [4, 2, 2, 4, 8, 2, 2, 4, 2, 2], [4, 2, 2, 2], [6], [4, 3], [6, 5, 4, 2, 2, 2, 6, 6, 5, 4, 2, 2, 2, 2], [2], [6, 4, 2, 3, 2], [6], [2, 4, 2, 2, 2, 2, 5, 4, 2, 2], [2, 3], [4, 2, 2, 4], [2, 5, 2], [2], [6], [2, 2], [2, 4, 2, 2, 2, 4, 2, 2], [2, 5, 6, 6, 5, 6], [8], [4], [2], [2, 2, 2, 2, 2, 5, 2, 8, 2, 2, 5, 2], [6], [6], [2, 5, 2], [4, 2, 4, 4], [2, 4, 2, 2, 2, 2, 6, 4], [2, 5, 2], [2], [2, 2, 4], [2, 2, 8, 5, 6], [2, 4, 8, 2, 4, 8, 5, 2, 2, 2, 2], [6], [2], [6, 5, 2, 4], [4, 2, 2], [6], [2, 2, 2, 2, 2, 5, 4, 2, 2, 2], [2], [2], [2, 2, 2], [2, 2, 4, 2, 5, 2], [6], [2, 2, 2, 5, 2, 8, 5, 2, 8], [8, 6], [6], [2, 4, 2, 5, 4, 2, 4, 5, 2, 2, 2], [6], [2, 2], [2], [4, 6, 6], [6, 5, 4, 5, 2, 2], [2, 2], [2, 2, 2, 5, 2, 5, 2, 5, 3, 6, 8, 5, 6, 2], [2, 6], [6], [6], [2, 5, 2, 2, 5, 4, 2, 5, 2, 2, 2], [6, 2], [5, 3, 2, 2, 2, 2, 5, 2, 2, 5, 8, 2, 2, 2, 2, 2, 2, 2, 7], [6, 5, 3, 6, 8, 2, 3], [2, 5, 2], [4, 2, 5, 4, 6, 2, 4], [2, 2], [6], [3, 4, 2, 2, 5, 2], [2, 8], [2, 4, 2], [2, 5, 2, 6], [2, 4], [6, 8], [2], [2, 2, 2, 2], [6], [4], [2, 2], [4, 2, 2], [3, 8], [2, 2, 4, 2, 4, 2, 2, 4, 3], [8, 2, 2, 6], [6], [2, 4], [2, 4, 4, 2, 2, 4, 2, 5, 2], [4, 2, 2, 6, 2, 2, 4], [2], [8, 3, 5, 6, 6], [2, 6], [2], [2], [2, 2, 8, 2, 6], [6, 8, 2], [2, 3, 2], [2, 5, 2], [2], [6, 5, 6], [2, 2, 5, 2, 5, 2], [4, 3], [2, 2], [2], [2, 5, 2, 2, 4], [4, 4], [2, 2, 4], [2, 5, 4, 2, 2, 6, 2, 8], [2, 2, 2, 4, 2, 5, 8, 2, 8], [2, 5, 6], [2, 4, 2, 2, 3], [6, 8, 5, 2, 2, 5, 3], [2], [6, 2], [3], [2, 2, 5, 2], [2, 2, 7, 5, 2], [4], [2, 2], [2, 2, 2, 2], [6, 5, 2, 2, 5, 2, 2, 2], [2, 2, 3], [2], [2, 2, 2, 2, 2, 2, 5, 2, 4, 2, 2, 8], [3, 3, 2], [2, 2, 5, 2, 2], [2, 5, 2], [2, 2, 2, 3, 5, 2, 2], [2, 5, 8], [2, 3, 5, 8, 2, 2, 5, 2, 2, 2, 2, 4, 4, 6], [6], [5, 2, 8], [2, 3], [2, 4, 2, 7, 5, 4, 2, 2, 4, 5, 2, 4, 2, 2, 2], [2], [2, 2, 2], [6], [4, 2, 8], [2, 5, 2, 2, 6, 2], [6], [2, 6, 2], [2, 8, 2, 2, 2, 2, 2, 2], [4, 2, 5, 2, 2, 5, 4, 2], [2, 6], [6, 4, 8, 5, 3, 2], [2, 4, 6, 4], [2, 2, 2, 5, 2], [2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4], [2], [2, 8, 5, 2, 6, 2, 2], [4, 3], [8, 2, 2], [2, 6, 2], [3], [2], [2, 8, 2, 2], [6, 5, 2, 2, 5, 2], [6, 6, 6, 2], [6], [2, 5, 2, 2], [2], [2], [2, 2, 4], [2, 2], [4, 2, 5, 2], [6, 4, 2, 2], [2, 8], [8], [2], [2, 5, 5, 6, 6], [2], [2, 7, 2, 2, 2, 2, 4, 4, 2], [4, 2, 2, 2, 2, 2, 2, 2, 4], [4, 2, 2, 4, 2, 2, 6, 4, 2, 2, 2, 2, 4], [2], [6], [2, 4], [3], [2, 5, 6, 2, 2, 2, 6], [3], [2], [6], [6], [4, 2, 4, 2], [2], [4, 2, 2, 7], [2, 6], [2], [2, 5, 2, 3, 5, 2, 4, 2, 5, 4, 2, 3], [6, 6, 5, 2, 6, 5, 2, 2, 2, 2, 5, 4, 2, 4, 2, 2, 2, 8, 5, 2, 2, 2, 2, 2, 5, 2, 2, 4, 8, 2, 2, 3, 2, 2, 3], [6, 5, 8, 5, 8, 5, 8], [2], [6], [2, 2], [2], [6, 8], [2, 2], [4, 2, 2], [6], [2, 2, 8, 5, 4, 2, 5, 2, 5, 4, 8, 2], [6], [6, 5, 2, 3, 2, 5, 4, 2, 2, 5, 4, 2, 2, 3, 5, 3], [2], [2], [6, 2], [2, 5, 2, 5, 2, 5, 2, 5, 8, 5, 2, 2, 5, 2, 6, 5, 2, 2], [2], [2], [2, 2, 3, 2, 4, 2], [6], [2], [2, 3], [2], [4, 2, 2, 2, 2, 4], [2], [2], [6, 5, 2, 7], [4, 3, 2, 5, 2, 2, 5, 2], [4, 2, 5, 2, 2, 2], [4, 2], [4, 2, 2, 2, 2, 2, 2], [2, 2, 5, 2, 2, 2], [2], [2, 5, 2], [6], [2, 5, 2, 4, 2, 2, 5, 7, 5, 8, 2, 5, 2, 2, 8, 2, 2, 2], [8, 2, 2, 2], [2], [6], [4, 2, 2, 2, 5, 2, 2, 5, 4, 2, 2, 2, 2, 2, 5, 2, 2, 2], [3, 2, 2], [6], [2, 2, 2], [2, 8, 2, 3], [2], [6, 8, 5, 2], [4, 2, 2, 2, 3, 5, 8, 6, 2, 3, 3], [2, 2], [2], [4, 2, 2, 4, 2], [6, 6], [6, 2], [4, 2, 6], [2], [4, 2], [2, 4, 7, 2, 2, 3, 4, 6], [2, 2, 3], [2], [2, 2, 2, 2, 4], [2, 4, 2, 2, 4, 4, 4, 2, 4], [2, 4, 2, 5, 3, 6], [6, 6], [2], [6, 6], [4, 2], [2, 2, 5, 2, 2, 8], [2, 2, 6, 2], [2], [2, 6, 5, 2], [4, 2, 4], [4], [8, 2, 2], [2], [4, 2, 2, 2, 2], [4, 2, 2, 2, 5, 2, 4, 2], [6], [8, 4, 3, 5, 2, 2, 5, 4, 2, 4, 6, 5, 2, 2, 2, 7], [2, 2, 2, 3], [2], [2, 3, 4, 5, 2, 6], [3, 2, 5, 3, 4, 2, 2, 5, 2, 2, 2, 2, 6, 5, 2, 3], [2], [2, 2, 4, 3, 5, 2, 2], [2], [6], [2], [2, 2, 5, 2, 2, 5, 2, 5, 2, 5, 2], [6], [6, 5, 3, 2], [8, 2], [2, 2], [6], [2], [2], [2, 2, 5, 2, 5, 2, 2, 5, 2], [4, 2], [2], [2, 5, 6, 8, 2, 2, 5, 2, 2], [2], [6], [2, 2], [8, 2, 4, 6, 2], [4, 2, 2, 2, 4], [6], [3, 3, 2, 2], [4, 7, 2, 2, 2, 2, 5], [6, 2], [2, 6, 8, 2], [2, 2, 5, 2, 2, 5, 2, 5, 2, 2, 5, 6], [4, 2, 4, 6], [2, 2, 2], [2, 5, 7, 2, 5, 7, 2], [2, 4, 2], [2, 2, 2, 2], [2, 4, 2], [2, 2], [2], [6, 2, 2, 3], [6], [4, 2, 2, 5, 6, 4, 2, 2, 2, 5, 2, 8, 2, 2, 2], [4, 2, 5, 2, 2], [2], [6], [4, 2, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2, 4, 2, 5, 2, 5, 2, 5, 2], [2], [2, 5, 2], [2, 4, 2, 2, 2], [6, 6], [6], [2], [2, 2, 3], [6, 6], [2], [2, 5, 2], [2, 2, 2], [2], [6, 6], [3, 5, 8], [4, 2], [2, 5, 2, 5, 6, 2, 5, 2, 2, 5, 2, 5, 2, 4, 2, 4, 2, 2, 2], [4, 2, 2, 3], [2, 2], [2, 5, 8, 3], [2], [6], [2, 2, 2, 8], [2], [2, 5, 2], [2, 5, 2], [6], [4, 2], [2, 8], [6, 5, 4, 2, 5, 4], [2, 4, 2, 8], [2], [6], [2, 2], [2], [8, 5, 4, 2, 2, 4, 5, 4, 3], [6], [6], [2], [2], [6, 2, 6, 2], [2], [3], [2, 2], [8], [4, 2, 2, 3], [2], [2, 2, 7], [2, 2, 3, 8, 5, 2], [6, 8], [2], [2], [2, 2], [6, 5, 3, 4, 2], [6, 6], [2, 2], [6], [6], [8, 6, 6], [2], [2, 5, 2, 2], [8, 4, 2, 2, 5, 2, 2], [2, 2], [6], [2], [4, 2, 2, 6, 5, 4, 2, 6], [2], [6, 6], [2], [6, 2, 4], [8, 2], [2, 2, 2], [3, 8], [2, 5, 2], [2], [2, 2], [6, 8], [4], [2, 6], [2], [2], [6], [2], [4, 8, 2, 5, 3, 5, 2], [8, 2, 6, 2, 5, 2, 2, 4, 6], [8, 2, 2, 7, 5, 4, 2, 2, 5, 2, 5, 2, 2, 5, 2, 5, 2], [7, 2, 2], [2], [6], [2], [2], [2, 2, 4, 3, 6], [3, 4], [6, 2], [6, 5, 3, 6], [2, 2], [4, 2, 2, 2, 5, 4, 6], [3], [2, 5, 8, 5, 3, 5, 6, 2], [2], [6, 7], [6, 6], [2, 4, 2, 5, 2], [2, 6], [6, 8, 2, 7], [3, 2], [2], [2], [6, 5, 2], [2, 2, 4, 2, 6, 4], [2, 5, 6, 2], [2, 2, 4], [2, 5, 2], [6], [4, 2, 8, 2, 4], [2, 3, 5, 2, 6], [4, 2, 5, 2, 4, 2, 6, 2, 5, 2, 5, 2, 7], [6], [6, 6], [6, 8], [4, 2, 3, 2, 2, 2, 4, 4, 2, 2, 2, 5, 2, 2, 5, 2, 2, 3, 2], [6], [2, 5, 2], [3], [2, 4, 2, 2, 2, 2, 2, 4, 5, 2, 2, 2], [2, 2, 2, 2], [2], [2], [2], [2], [2], [2, 2, 4, 2, 2, 2, 5, 2], [6], [2, 5, 2, 3], [3, 4, 8], [2], [3, 8, 2, 2], [2, 2, 3, 4, 2, 4, 2], [2], [2, 2, 2, 2, 4], [4], [2, 6], [2], [2, 2], [2, 2], [4, 2, 3, 5, 2, 2, 2], [2], [6, 2, 5, 2, 5, 2, 5, 2, 2], [6, 5, 6], [4, 2, 2, 2, 2, 2, 6, 5, 2, 2], [6, 6], [4, 2, 2, 4, 2], [2, 3], [2, 2], [2], [3, 7], [2, 4, 4, 2, 2, 5, 2], [2, 2, 2], [2, 2, 2, 2, 5], [2], [2], [2], [2, 4, 2, 2, 2, 4, 2, 2], [8, 4, 2, 6, 6, 2, 2, 2, 2, 2, 2], [2], [2, 8], [2], [2], [2, 2, 2, 6, 5, 2, 8, 5, 8, 5, 8, 2, 2, 6, 4, 2], [2, 2, 2], [6, 8, 2, 5, 2], [6, 6], [2], [6, 8], [6, 8, 5, 6, 6, 2, 4, 2, 2, 5, 4, 2, 6, 2, 2], [2], [2, 2], [2, 2], [2, 4, 2, 2, 2, 6], [8, 2], [2, 2], [2], [2, 6, 8], [6], [6], [2, 2], [6], [6], [2], [6], [2, 2], [6, 5, 6, 6], [2, 4, 2, 2, 2, 8, 2], [2], [2, 2, 4, 2, 4], [4, 4, 5, 4, 2], [6], [2, 2], [2], [2, 2, 4], [2], [2], [2, 2, 4, 4], [4, 2, 2, 4, 2, 5, 2, 2, 2, 3, 2, 5, 2, 2, 2, 2, 5, 8], [2], [6, 2], [7, 2, 5, 8, 2, 5, 2, 5, 4, 3], [2], [2, 4, 2, 8], [8, 6], [6], [2, 5, 4, 2, 6, 5, 2, 6, 8, 5, 7], [2], [2], [2], [2, 2, 2], [2, 8, 2], [2, 2], [2, 5, 2, 2, 2], [6], [5, 4, 8, 2, 3, 4, 5, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 3, 2], [4, 2, 2, 2, 2, 2, 4], [6, 5, 6, 5, 6], [2, 4, 5, 2], [4, 2, 2, 2, 3], [2, 6, 4, 5, 6, 8, 2, 8, 5, 2, 2, 5, 2, 4, 2, 2, 5, 3, 5, 2], [2, 6, 8, 5, 2, 5, 8, 4, 2, 2], [6, 3], [4, 2, 2], [2, 5, 2], [2, 2], [2, 5, 8, 4, 2], [2, 2, 2], [2, 2, 4, 2, 4, 5, 2, 5, 6], [6], [2], [2], [2, 2], [6], [2], [3, 4, 8, 5, 3, 3, 5, 2], [2, 2, 6, 5, 3, 5, 2, 2], [2, 4, 2, 2, 8, 2], [6], [4, 2, 2, 4, 2, 6, 2, 4, 2, 2, 4, 2, 6, 4, 5, 8, 2, 2], [4, 2, 2, 2, 6, 8, 2, 2, 4, 2, 7, 2, 2, 5, 2, 2, 2, 6, 6, 5, 2, 2], [2, 2, 3], [3, 2, 7, 2, 2, 7], [2, 5, 2, 5, 4, 2, 2, 5, 2, 2, 4], [6], [6, 6, 6], [3], [2, 8, 2, 5, 2], [2], [6], [6], [2], [2], [2], [3, 2], [3, 5, 2, 2, 2, 5, 4, 2, 6, 5, 2], [4, 2, 2, 4, 2, 6, 5, 2, 4, 2], [2], [4, 2, 2, 2], [2, 2, 4, 5, 2], [6], [2], [2, 2, 2, 6, 5, 2], [3], [6], [4, 8], [2, 4, 2, 2, 5, 4], [5, 2, 2, 6, 5, 6], [6, 6], [2, 6, 8, 2, 2], [3, 5, 2, 4, 2, 2, 3], [2], [6, 5, 8, 2, 2, 7, 5, 2, 2], [2], [2, 5, 2, 2, 5, 4, 6, 2, 5, 2], [2, 2, 4, 2], [2, 4, 2, 7, 2], [6, 2, 2, 2], [2, 2, 8], [2], [2], [2, 6, 6, 5, 8, 2, 2, 6, 2, 5, 4, 2, 5, 2], [2, 2, 4, 2, 6, 6], [2, 2, 2, 4, 2, 2, 7, 4, 2, 5, 2, 4, 2, 7, 2, 2], [2, 2, 5, 3], [8], [4, 2, 2], [6, 2, 4, 2], [2], [6, 8, 2, 5, 7, 5, 2], [5, 2, 2, 4, 2, 4], [6, 8], [2], [6], [6], [8], [2, 2, 2, 2, 2], [2], [6, 8], [2, 4, 2, 2, 2, 4, 5, 2], [2, 2, 2, 2, 2, 2, 6, 2, 7, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2], [2, 2, 3, 4, 2, 8, 2, 2, 5, 2], [3, 5, 6], [2, 4, 6, 5, 2], [6], [8, 5, 2], [2, 5, 3], [2, 8, 2, 2, 3, 2], [2, 2, 2, 6, 4], [4, 2, 2, 2, 4, 2], [4, 3], [6, 8, 2, 2, 8], [2, 5, 4, 2, 2, 2, 2], [3, 4, 8], [2, 2, 2], [2, 5, 2, 5, 4, 2, 5, 2, 2, 2, 2, 2], [4, 2, 4, 8], [2, 8, 5, 2], [2, 2], [2], [2], [2, 2, 5, 2, 2], [3], [2, 2, 2, 4], [2], [2, 2, 4, 2, 2, 2, 2, 6, 2, 5, 6, 2, 2, 2, 5, 3], [6], [2, 4, 2, 6], [6, 8], [2, 2, 2], [3, 6], [2], [2, 2, 3], [2], [6], [2, 5, 2, 2, 2], [2, 4, 2], [6], [6], [6], [2, 2], [2, 2, 5, 3], [2, 5, 2, 5, 6, 3], [8, 4, 2, 2, 2, 4, 2], [2, 2], [2], [2], [2, 2], [8, 5, 6], [6, 2], [2, 4], [6, 5, 2, 2], [2, 2], [6, 2, 5, 8], [2, 5, 8, 5, 2], [2], [6], [8, 6, 6], [2], [6], [2, 6], [2, 5, 2, 4, 2, 2, 2], [2, 5, 2, 2, 4, 5, 2, 2, 4, 2, 2, 4], [4, 2, 2, 2, 2, 4, 5, 2], [4, 2, 2, 2, 2, 2, 2, 2], [2, 2], [2], [6], [2, 6, 8, 2, 8, 2], [2, 2, 2], [2, 6, 2, 2, 5, 2, 5, 2, 4], [4, 2, 5, 2, 2, 2, 2, 2, 2], [4, 2, 5, 4, 4, 2], [2], [2, 2, 2], [2, 5, 2, 2, 2, 2, 4, 2], [2], [2, 2, 4, 5, 2], [2, 5, 8, 2, 4], [6, 6], [4, 2, 6, 8], [6, 2], [2, 5, 2, 2], [2, 5, 2, 2], [6, 6], [2, 2, 5, 2, 5, 4, 2, 4, 2], [2, 2, 2], [2], [2, 2, 5, 4, 5, 2], [2, 2, 2, 2, 6], [2, 4, 2, 4, 5, 3, 4, 2], [2], [6, 8, 4, 2], [6], [2, 4, 2, 2], [2, 2, 2, 5, 2], [6], [2], [2, 2, 2, 4, 2, 2, 4, 5, 3], [4, 2], [2, 4, 2, 2, 2], [3, 2], [2, 3, 5, 2, 5, 3], [2, 2, 4], [2, 4, 2, 8], [2, 6], [6, 5, 6, 5, 2], [6], [2, 2], [2], [4, 2, 5, 2, 7, 2, 5, 2, 4, 5, 2, 5, 2], [2, 2], [2, 8, 2, 2, 2, 2], [2, 2], [6], [2, 2, 2, 8, 5, 2, 2], [2, 2, 2], [2], [2], [2, 2, 3, 5, 4, 2], [6], [2], [2], [2, 4], [6], [6, 3, 8, 5, 3], [2, 2, 3], [6], [4, 2, 5, 2], [2, 2, 2, 6, 4, 2, 5, 2, 2, 4, 5, 2, 2, 2, 4, 2, 5, 2, 4, 3, 6], [2, 4], [2, 2, 6], [4, 8, 6, 2, 2, 2, 2, 2], [2, 2, 2, 5, 2], [2, 6, 8], [2, 2], [2, 4, 2, 4], [2, 5, 4, 2], [2, 4, 2, 5, 2, 5, 6, 5, 4, 4, 2, 5, 2, 5, 2, 5, 6, 5, 2], [4, 2, 7, 6], [4, 4, 2, 2, 8], [2, 2, 5, 2, 5, 2, 5, 6, 2], [2], [2, 2], [2, 4, 6], [6], [6, 6], [2], [4, 4, 2, 2], [2], [2], [2, 2], [2], [2], [6, 8, 2], [6], [2], [6], [6, 2], [2], [3, 2, 2], [2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 5, 2, 5, 2, 5, 2, 5, 2, 2, 2, 5, 2, 2], [6, 2], [2, 6, 2], [6, 2, 2], [3, 4, 3, 4, 3, 5, 2, 2, 6, 2, 2, 6, 4], [4, 7, 5, 2, 4, 2, 5, 2, 2, 2, 7, 5], [4, 2], [6, 6], [2, 4, 2, 2], [2, 5, 2, 2, 8], [2], [6], [2], [6, 2, 8], [2], [2], [2, 8, 2], [2], [2], [6, 5, 6, 8], [2, 4, 4, 2, 2], [2], [3, 2, 6], [2, 6, 5, 6, 2, 6], [6], [2, 2, 5, 4, 2, 2], [2, 2], [2, 4, 2, 4], [6, 8, 2], [2, 5, 8], [4, 2, 4, 2], [2, 5, 2], [6, 8], [2], [2, 2], [2], [2, 5, 3], [2, 2, 4, 2, 2], [2, 5, 2, 5, 7, 2], [6, 6], [6, 8], [6, 2, 4, 3], [3], [2], [4, 2, 2, 2, 2], [4, 3], [2, 2, 5, 4, 2, 5, 2, 2], [6], [6, 8, 5, 2], [2], [6], [2], [2, 2], [2, 5, 2], [2, 2], [2, 5, 6, 8], [2, 4, 5, 2, 8], [2], [6], [2, 5, 2, 2, 5, 2, 5, 8], [6, 2, 2, 2, 7, 2, 2, 5, 2, 5, 4, 2, 3, 2], [6, 4], [2], [8, 5, 2, 4, 2], [6, 6, 5, 2, 6, 6], [8, 2], [2, 6, 4, 2, 2, 6], [2, 2, 5, 2], [2, 2, 2, 2, 2], [2], [6], [2, 2, 4], [2], [2, 2, 5, 2, 8], [2, 2, 2, 4, 2, 2, 2, 2, 2, 5], [8], [2], [2, 4, 8, 2, 4, 2, 5, 2, 3], [2, 2, 4], [2, 3, 5, 2, 2, 3, 5, 2, 3, 2], [2, 5, 2, 2], [2], [4, 2, 4, 8, 2], [6], [8, 2, 3], [2, 2, 8], [2, 5, 2, 4, 6], [8, 3], [6], [2], [2, 2, 2], [2, 5, 2], [2, 2], [2, 5, 2, 5, 2, 7], [2, 5, 2], [4, 2, 2, 2, 4], [2, 6, 2], [2, 2, 4, 2, 2, 2], [2, 2, 2, 4, 6, 2], [2, 5, 2, 2, 5, 2], [2], [2], [2], [6, 6], [6], [2], [6], [2, 2, 2, 5, 2], [2, 4, 8], [2, 4, 2, 4, 5, 4, 2, 2, 2], [4, 5, 2, 5, 8, 2, 8, 3, 2], [2, 2], [2], [2, 2], [2, 2], [2], [6], [2, 5, 6], [2], [2, 5, 2, 2], [2, 2, 2, 5, 2, 2, 2], [4, 2, 2, 2, 2, 2, 2, 2], [3, 8], [2, 2, 2, 2], [2], [2], [6], [2, 4, 2], [2, 2], [6, 6], [2, 3, 8], [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2], [2, 4, 2, 2], [2, 5, 2], [2, 4, 2], [2, 3, 2], [2, 6, 5, 2], [4, 2, 2, 2, 4], [6, 4, 2, 2, 2], [2, 8], [2, 6, 6], [4, 8, 4, 2, 4], [6, 8, 5, 2], [2, 2, 2, 2, 2], [3, 4, 8, 2], [2, 2], [6, 2, 5, 8, 2], [2], [2, 6, 2, 2], [2], [8, 4], [2], [6], [2, 2, 2, 7], [2], [6], [6, 2, 5, 6, 8, 2], [2, 5, 2], [6, 8], [3], [2], [2, 5, 2, 5, 2, 2, 6], [6], [4, 2, 2, 4], [6, 2], [2, 2, 5, 2], [2, 2, 2, 2, 8], [2, 4, 2, 3, 5, 8], [2, 8, 2], [8, 2, 2, 5, 8, 2, 2], [2, 7, 2, 2], [2], [2, 2], [2], [6, 2, 8], [2, 5, 2, 5, 2], [2, 2, 4, 2, 2, 2, 2, 2, 8], [6], [2], [6], [2], [2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2], [2, 5, 2, 2, 8], [6, 5, 2, 2, 5, 6, 6], [2, 7], [2, 2, 2, 3, 6], [4, 2, 5, 8, 7, 8, 5, 2, 5, 6], [4, 2, 6], [2, 2], [8, 2, 2, 5, 2, 3, 5, 8, 5, 2, 2, 5, 2, 3], [3], [4, 2, 2, 6, 2, 2, 7], [2], [2, 2, 2, 4, 2, 5, 2, 2], [2, 4, 2, 2, 2, 4, 5, 2, 2, 2, 8], [2, 2], [2, 2, 2, 2], [6], [2], [4, 2, 6], [2, 2, 5, 2], [4, 2, 2, 6, 2], [2], [3], [2, 2], [6], [2, 2, 5, 3, 4, 8], [2], [2, 2], [2, 4], [4, 2, 2, 4, 4, 2, 2], [3, 5, 2, 2, 5, 2, 5, 4, 2, 2, 2, 2], [2], [4, 2, 4, 2, 2, 2, 6], [2], [6], [6, 5, 2, 2, 5, 4, 8], [2], [4, 2], [8, 4, 2, 7, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2, 5, 4, 2, 4, 2], [2, 5, 2, 2, 2], [2], [3], [2, 2, 2], [2, 5, 2, 5, 3], [2, 2, 2, 2, 3, 2], [4, 2, 8, 6, 2, 2, 8], [2], [6], [6, 6], [3], [2, 6, 6], [2, 5, 2, 4, 6, 2, 5, 2, 4, 2, 2, 4, 6, 2, 5, 2, 2, 5, 2, 6, 4, 4], [2, 3, 2], [2], [2], [2, 8, 2, 2, 5, 4, 2, 4, 7, 2, 7, 2, 2, 2, 2, 2, 2], [8], [6], [3, 5, 2, 2, 5, 2], [2], [6], [8, 6, 4, 2], [2, 2, 5, 8, 2, 2, 5, 2, 4, 2, 4], [2], [4, 2, 4, 7], [2, 5, 4, 2, 2, 2], [2, 2, 4, 2, 2, 2, 2, 2, 2], [2, 4, 2], [2, 5, 2], [8, 2, 2], [2, 2, 2, 2], [2, 8], [6, 4], [2, 2, 2, 4, 2, 5, 2, 6, 2], [2, 8], [2], [3, 2, 5, 4, 2, 2, 4], [2, 2, 5, 2, 2], [6, 8, 5, 2, 2], [2], [5, 2, 5, 6], [2], [2, 2, 4], [2, 5, 2], [2], [6], [2, 2, 2, 2, 5, 4, 2, 2, 2, 2, 2, 6], [2], [6], [6], [6], [5, 2, 2, 2, 6, 2, 2, 5], [4, 2, 5, 4, 2, 6, 5, 2, 2, 2, 8, 6], [6], [2, 4, 2, 2, 6, 5, 4, 2, 2, 2, 6], [4, 2, 4, 2], [2, 2, 5, 2, 3], [4, 2, 2, 2, 5, 2, 2, 2, 4], [2, 2], [2], [2, 8], [2, 6], [2, 2, 7, 5, 2, 2, 2], [4, 2, 4, 2, 6, 6], [2], [4, 3, 2, 2, 2, 2, 2], [4, 2], [2], [6, 6], [2, 5, 2], [2], [2], [6, 4], [2], [2, 2, 2, 4, 2, 2], [2, 2, 2], [2, 3], [6, 5, 2, 2], [2, 2, 2, 8], [2, 2], [6], [2], [2, 2], [2, 2, 2, 8], [4, 2, 2, 4, 3, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2], [2], [4, 2, 2], [2, 2, 2, 2, 5, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2], [2, 5, 6, 2, 2], [3], [2, 2, 2, 5, 2, 2, 5, 2, 2, 4, 2, 2, 2, 2, 7, 5, 2], [4, 2, 4, 2, 2], [2, 2, 2, 4, 2, 2], [2, 4, 7, 5, 2], [2, 4, 2, 3], [4, 2, 4, 8, 2, 4, 2, 5, 4, 4, 2, 3], [6, 6, 8], [2, 2, 5, 2], [2], [2], [6, 8, 2], [2, 8], [2], [2], [2, 2, 2], [6, 6], [2, 2, 2, 2, 5, 3, 6], [2], [2, 2, 2, 2], [2, 3], [6, 2], [3, 2, 2], [6, 6], [4, 2, 2], [6, 2, 3, 4], [2, 8], [6], [6, 4], [2, 5, 2, 5, 2, 5, 2, 4, 2], [4, 6, 2, 2], [2, 2, 3, 2, 5, 2, 4, 2, 2, 4, 2], [4], [2, 8], [2, 5, 4, 2, 2, 5, 2], [2, 2, 2, 2, 2], [2, 3, 5, 3, 3, 3, 3, 2], [2, 2, 2], [6, 8], [2, 5, 2], [4, 5, 2, 2], [6], [2], [2, 4, 6], [3, 2], [2], [2, 3], [4, 2, 2, 8], [2, 2, 2, 2, 5, 4, 3, 2, 2, 4, 7, 2, 4, 6, 2, 5, 2, 2, 6, 5, 3], [3, 2, 5, 2], [2, 2, 2, 2, 4, 2], [2], [2, 2], [2, 2, 4, 2], [4, 2, 4, 2, 2], [6, 5, 6, 5, 2, 5, 6, 2, 2, 8], [2, 3, 2, 4, 4], [8, 4, 2, 2, 2], [2, 4, 2, 2], [2, 2, 2], [6], [6, 6, 6, 5, 2, 3, 5, 6], [2], [2], [8, 8], [4, 2, 2, 2], [2], [2], [2], [2, 5, 2, 4, 2], [2], [6], [3, 5, 4, 5, 3, 5, 2, 2], [8, 2], [4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 5, 4, 2, 4, 2, 2, 3], [6, 8], [6], [3, 5, 4, 5, 8, 5, 4, 2, 2, 2, 5, 2, 2, 4, 5, 2], [3], [2], [4, 2, 4, 2], [2, 5, 2], [2], [2, 4, 2, 2, 2, 2, 2, 7], [2, 4, 8], [2], [2], [2, 2, 2, 2, 2], [6, 8, 2], [2, 2, 2], [2], [3, 2, 2, 2, 2], [6, 5, 6], [6], [6], [2, 2, 2, 5, 2, 2, 2, 2], [2, 5, 2, 2, 2], [2, 5], [6], [2, 6], [2, 2, 4, 2, 2, 4, 2, 2, 2], [2, 2], [6], [6], [2, 2, 2, 2, 5, 2], [6, 5, 6, 5, 6, 5, 2, 5, 2, 5, 4, 2], [3, 3], [4, 8, 3], [3, 4, 2, 2, 2, 2, 4, 2, 2, 6, 5, 8, 2, 2, 2], [2, 7], [2, 2, 5, 2, 3, 4, 2, 2, 7, 5, 2, 8, 5, 2], [6, 5, 6, 6], [2], [2, 2, 2, 2], [2, 5, 2, 2, 2], [2], [2, 8, 2], [6], [2], [2], [6, 8], [2, 2, 8, 5, 2, 5, 4, 3, 8, 5, 2], [4, 7, 2], [2, 6, 4, 3], [2, 2, 3], [2, 5, 2, 2], [4, 2, 4, 8, 2, 2], [4, 2, 6, 5, 2, 2, 2, 2], [2, 2, 4, 4, 2, 5, 2, 2, 2, 7, 5, 2, 2], [6], [2], [2], [2, 2, 4, 2, 2, 2, 5, 2, 4, 5, 4, 2, 2, 2, 2, 2], [3], [2], [2], [2, 2, 2], [2], [2, 5, 8, 2, 7, 5, 2], [2], [2], [2], [2, 2], [6], [2], [2], [2, 5, 2, 2, 2, 2, 4], [6, 8, 2, 2, 2], [6, 2], [2, 2, 5, 2], [2, 8], [6], [2], [2], [2, 4, 2], [3, 4, 2, 4, 5, 2], [2], [2], [2, 5, 4, 2, 2, 8, 2, 2, 4, 5, 3], [4, 2, 2, 2], [2], [6, 2, 3], [6], [2], [2], [6], [8, 5, 2, 5, 2, 2, 2], [6], [6, 6], [2, 5, 2, 4, 2, 2, 6, 2, 5, 2, 2, 3], [2, 2, 2], [2, 2], [4, 2, 2, 4, 2, 2, 2], [2, 4, 2], [6, 6], [4, 2, 4, 2, 2, 2], [2, 2, 5, 3, 2], [2], [8], [2], [2, 2, 2, 2, 4, 2], [3, 5, 2, 2, 4], [4, 4, 4, 2, 8, 5, 4, 2, 6, 5, 2, 2, 6], [6, 2, 2, 5, 2, 2, 2, 2], [3, 3], [6], [6, 8, 5, 2], [2, 6, 8, 2, 5, 2, 2, 2, 2, 2, 6], [4, 2, 4], [2], [2, 3], [3, 8], [2, 2, 4, 3], [4, 2, 2, 2, 2], [2], [6, 5, 3, 4, 8], [6], [5, 2], [4, 2, 2, 2, 2], [2, 5, 8, 2, 2], [6, 6], [6, 6, 4, 2, 2, 2, 5, 6, 6, 4, 2, 4, 2, 2, 4, 3], [2], [2, 2, 5, 2], [2, 2, 2], [6, 5, 6], [2], [8, 2, 6, 4], [6], [2, 2], [2], [3, 4, 2, 2, 2], [2], [8, 4, 2, 7, 5, 2, 4, 2, 2, 5, 4, 4, 2, 7, 5, 2, 2], [4, 2, 3, 3, 5, 2, 5, 2, 2, 4], [2, 8, 2, 5, 4, 2, 3], [4, 2, 2, 2, 2, 4, 2, 2, 2], [4, 6, 2, 4, 6, 5, 2], [2, 6], [2, 6, 8, 6, 2], [2, 2, 5, 2, 5, 2, 2, 5, 2, 2, 2, 4], [2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 3], [4, 2, 2, 2], [6], [2, 6], [2, 7], [2], [2, 8], [2], [2, 5, 8, 2], [2, 2, 4, 2], [2, 2], [2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 5], [2, 2, 5, 4, 8, 2, 5, 2, 2, 2, 3, 2, 2], [6, 2], [2], [2, 2, 2], [2], [8, 7], [2], [4, 2, 8, 2, 2, 5, 2, 2], [6, 8], [8, 2, 2], [2], [2, 8], [2, 5, 2], [6], [2, 5, 6, 8], [2, 2], [6], [2], [2], [2], [6], [6], [4, 2, 4, 2, 4, 6, 2, 5, 2, 2, 2, 2, 2], [2, 8], [4, 2, 6, 2, 5, 2, 2, 6, 5, 4, 2, 5, 6, 2, 7, 2, 5, 2, 2], [2], [2, 2, 6, 2], [2], [6], [6], [4, 2, 4, 2, 4, 4, 5, 2, 2, 4], [4, 2], [3], [2], [2], [6], [3, 5, 2, 2], [2, 5, 4, 2], [4, 5, 2, 4, 2, 2, 2], [6], [4, 2, 6, 8, 2, 2], [4, 2, 4, 2, 5, 8], [2, 5, 8, 2], [3], [6, 2, 2, 6], [2, 2], [6], [2, 2], [2], [2, 5, 2], [2], [2, 2, 5, 4, 4, 2, 5, 6], [2, 2, 4, 5, 2], [3, 5, 7, 8], [6, 2], [2, 2], [4, 2, 2, 2, 2, 5, 2, 2, 6, 2, 4, 6, 2], [4, 8, 5, 2, 6], [6], [2, 2], [8, 2, 2], [2], [4, 5, 2, 2, 4, 5, 4, 2, 5, 2, 4], [2, 2, 6, 2, 8], [2, 2, 4, 2, 2, 6, 2, 4, 8, 5, 2, 2, 2, 8, 2, 6, 5, 2, 4, 2, 2, 2], [2, 5, 2], [2, 4, 5, 4, 2, 2, 2, 2, 2, 2], [4, 4, 5, 2, 4, 4], [6], [2, 4, 2, 4, 6], [2, 2, 4, 2, 2, 2], [2, 8], [2, 4, 2, 5, 8, 2, 2, 2], [2, 5, 2, 2, 2], [2, 2], [4, 2, 5, 2, 2], [2, 5, 2], [2, 2, 2, 5, 7], [8, 2, 6], [2], [2, 4], [2], [6, 6], [6, 4], [2, 5, 3, 5, 8, 2, 2, 3], [2], [2, 3, 2, 5, 2], [2, 2, 2, 2, 2], [6, 4, 8, 5, 6], [4, 3, 2, 2, 5, 2, 5, 4, 2, 4, 2, 4, 3, 3, 5, 3, 5, 4, 2, 4, 7, 5, 2, 2, 5, 4, 2, 3, 2, 6], [2, 5, 2, 2, 2], [2, 2, 2, 5, 4, 3, 5, 4, 2, 2, 2, 2, 2, 4, 5, 2, 2, 2, 4, 2, 2, 5, 2, 8, 5, 2, 2, 5, 2, 4, 6, 5, 2, 2, 2, 5, 2, 3, 2], [2, 5, 2, 4, 2], [2, 2], [2, 2, 2, 2], [2], [8, 2, 2], [2, 2, 5, 2, 2, 2, 2], [2, 2], [4, 2, 2, 6, 2, 8, 2, 8, 2, 6], [2], [6], [6, 2], [2], [2, 4, 2, 3, 6, 2], [2, 5, 6], [2, 5, 6, 5, 4, 5, 2, 5, 3, 5, 4, 5, 8], [2], [4, 8, 6, 4], [6], [2, 2, 2, 2, 2, 5, 3, 5, 2], [2], [6, 5, 4, 8], [2, 2, 2], [2, 2, 5, 6, 5, 8], [8], [2, 5, 6], [5, 2, 2], [3, 2], [2, 2, 8, 2, 4, 2, 2], [2, 5, 2, 5, 2, 5, 2], [3], [2, 5, 2, 5, 2, 5], [4, 2, 2, 4, 4], [4, 2, 4, 3, 2, 4, 2, 2, 2, 2], [2, 5, 2], [2, 2, 2, 5, 2], [2, 2], [2], [2, 2, 2], [6], [3, 5, 2, 2, 5, 4, 2, 4, 2, 6, 5, 4, 2, 2, 5, 6, 2, 2, 5, 2], [8], [6], [4, 2, 2, 2, 2, 2, 5, 4, 5, 4, 2, 2, 2, 2, 7, 2], [6, 5, 6, 5, 3, 2], [2], [8, 2, 2], [2], [6], [3, 2, 2, 2, 2], [2, 4], [2, 6], [2], [2], [6], [6], [2, 5, 2, 5, 2, 5], [2, 2, 4, 2, 4], [2], [2, 2, 2, 2, 2], [2], [6, 8, 5, 2, 2, 8], [2, 6, 2, 2, 4, 5, 3, 2], [2], [4, 2], [2, 5, 2], [4, 2, 2], [2], [2], [2, 6, 2, 6, 5, 3], [2, 2, 2, 4, 2], [2, 5, 2, 5, 2], [4, 2, 2, 2, 2], [4, 2, 2], [2], [2, 2, 4, 2, 2, 2], [3, 2], [2, 5, 2, 4], [2], [6, 4, 2, 5], [2], [4, 2, 2, 2, 2], [2, 5, 6], [2], [2], [2, 7], [2, 2], [4, 2, 2, 2, 2], [4, 2, 2], [8, 2, 2, 2], [6, 8, 5, 4, 2, 5, 2], [2], [8, 2, 2, 2, 2, 2, 2, 2], [2, 4], [4, 2, 6, 2, 2, 2, 2, 2, 2], [2, 5, 2, 5, 2, 4, 2, 2], [4, 2, 2, 4, 3, 4, 3], [3, 8, 2], [4, 2, 2], [2, 5, 4, 2, 2, 5, 2, 5, 2, 5, 4, 2, 3, 7, 5, 2, 2, 5, 4, 5, 2, 3], [2, 5, 6], [6], [6, 5, 2], [6], [4, 2, 5, 2, 2], [2, 4, 2, 2], [2, 4, 2, 6], [2, 4, 2, 4, 5], [2], [2], [2, 4, 2, 2, 2], [4, 2, 2, 4], [2], [2, 5, 2, 2, 2, 2, 2, 2], [2, 5, 2, 2], [2, 5, 3], [3], [2, 3, 2], [2], [6, 4, 5, 2, 2], [8, 2], [6, 2, 6], [2, 3, 2, 2, 2, 5, 2], [2], [6], [2, 6], [2, 2, 2, 4, 2], [2, 2], [4, 2, 8, 2, 8, 5, 2, 5, 8, 2, 2, 6, 7], [2], [2, 2], [2, 2, 2], [2, 2], [2, 6, 2, 5, 2, 2, 2, 2], [2], [4, 2, 4, 4, 2, 2, 2, 6, 4, 3], [2], [2, 2], [2, 2, 2], [3], [6], [6, 2, 8], [6], [4], [2, 2, 2, 2, 2, 5, 8, 5, 2], [6], [2, 5, 2], [2], [4, 2, 5, 6, 7, 2], [2], [2], [2, 5, 2], [2, 5, 2], [6], [2], [2, 2], [6, 6], [2, 2, 2, 2, 2, 2], [3, 2, 5, 2, 5, 4, 2, 5, 2], [2], [6, 2, 4], [2, 8], [4, 2, 3, 2], [2, 2], [2], [6], [2, 4], [2], [3, 2, 5, 2, 2, 4, 2, 5, 2, 2], [6, 8, 5, 6, 2], [6, 8], [3], [2], [6, 2], [8, 2, 2], [6], [6], [2], [2, 2, 6, 5, 2, 2, 3, 5, 2, 2, 2], [3, 6], [2], [2, 2, 4, 2, 5, 4, 2, 4, 5, 8, 2, 2, 5, 2, 2, 2, 2, 5, 2, 2, 2, 2, 5, 4, 2, 5, 2, 5, 4, 5, 2, 5, 2, 5, 4, 5, 2, 5, 2], [4, 2, 4, 4, 5, 2, 2, 2, 2], [2], [2, 6], [2], [2, 2, 4], [3], [6], [4, 2, 2, 2, 2, 2, 2, 2], [2, 2], [4, 8, 2, 2], [3, 5, 2, 2], [2, 2], [6], [6, 6], [6], [2], [4, 4, 3, 2, 4], [8, 6, 4, 2], [2], [2, 4], [2], [2, 5, 2, 2], [2, 6], [3, 5, 6, 5, 6, 2], [4, 2, 4, 5, 2, 5, 3, 4], [4, 2], [2, 4, 2, 4, 2, 2], [4, 8, 4, 2, 4, 2], [2], [2, 4, 2, 2], [4, 8, 2, 2, 4, 5, 2, 2, 4, 3], [2], [6, 4, 6], [2, 7], [4, 2], [2, 2, 4], [6, 5, 4, 8, 2, 3, 2], [6], [2], [2, 2, 7, 2, 2, 2, 2, 2], [6], [2, 8], [6, 2, 5, 2], [2, 2], [2, 8, 2, 2], [6], [2], [2], [4, 2, 4], [6], [2, 2, 2], [2, 8], [3], [2], [4, 2, 2], [6, 8, 2, 5, 4, 2, 3, 2, 5, 8, 2, 4, 2, 2, 5, 4, 2, 2, 4, 2, 4, 2, 2, 2], [2, 2, 5, 2, 6, 2, 2], [2, 5, 4, 2, 2, 5, 3], [6, 8, 2, 6, 2], [2, 2], [2, 2, 2, 4, 2], [4, 2, 2, 7, 2, 2, 5, 2, 2], [2, 2], [2, 2], [2], [3], [2, 6], [2], [2, 2, 3, 2, 8], [6], [2, 4, 2, 2, 7, 4, 2, 2, 2, 2, 2], [2, 2], [2, 2, 2], [6, 6], [2], [2], [3, 6, 2, 4, 7, 3], [2], [2, 4, 2, 4, 2, 2, 2, 4, 2], [3, 2, 7], [3, 2, 3], [2, 5, 2, 4, 8], [2, 2, 8, 2], [2], [2, 5, 2, 2, 8], [7], [4, 2, 5, 4, 2, 5, 2, 2, 2, 3], [6, 5, 3, 3, 5, 3, 6, 2, 4, 2, 7, 2], [2, 2, 2], [8, 2], [2, 2, 2], [3, 6, 4, 2, 3, 8], [6], [8, 2, 2, 2], [2], [6, 2, 5, 2, 2, 5, 8], [3, 5, 3], [2, 4, 6], [4, 2, 2, 2, 2, 2, 4, 2, 5, 2, 2, 2, 4, 2, 5, 2, 2, 8], [4, 2, 2, 6, 6, 2, 5, 2, 2, 5, 2], [6, 5, 4], [6], [2, 6], [2, 2, 2], [3, 2, 2], [2], [4, 6], [2, 7], [2], [3, 8], [2, 2, 2, 2, 2, 2], [8, 5, 2, 2, 5, 2], [2], [2], [2], [2], [6], [2, 2, 2, 2, 2, 4, 2], [2, 2, 2], [2], [6, 2], [4, 2, 2, 2, 4, 2, 2], [2, 2, 4, 2, 4], [2, 2, 5, 2], [2, 5, 6, 5, 2, 2, 2, 2, 2, 4], [2, 6, 2, 2, 2], [4, 2, 2, 4, 2, 5, 4, 2, 5, 2, 2, 2, 4, 2], [2], [2, 2], [2, 2, 2], [2], [2, 7, 2, 2, 2, 2, 2, 2], [2, 5, 2], [2, 4, 2, 2], [2, 2], [2], [4, 4, 2, 4, 2, 5, 2, 4, 2, 2, 4, 2, 4, 2], [6], [2], [3, 6], [2, 4, 4], [2], [2], [6], [8, 2, 4, 2, 2], [2, 2, 6], [2, 5, 2], [2], [6, 2, 4], [6, 5, 2, 5, 6], [4, 2, 6], [4, 6, 2, 4, 5, 6], [2, 2, 4, 2, 2, 2, 7, 5, 2, 2, 2], [6, 5, 6, 5, 2, 5, 2, 5, 8, 5, 4, 2, 2, 3], [2, 2, 2, 3], [2, 2, 5, 2, 5, 2, 8, 5, 4, 4, 2], [2, 5, 2], [6], [2, 2, 2, 2, 2, 2, 2, 6, 5, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2], [6], [6], [2, 2, 5, 2, 2, 2], [4, 2], [2, 3, 8, 2], [3], [2], [2, 5, 2, 2, 2, 4, 2, 2], [2, 4, 2], [6, 6, 2, 5, 2, 6, 2], [4, 3], [2], [2, 2], [2], [6], [2, 2, 2, 2, 2], [2], [2, 5, 2, 2], [2, 5, 6, 2, 2], [4, 2, 2, 2, 4], [4, 2, 2], [8, 5, 2, 5, 2, 2], [8, 5, 4, 2, 2, 2, 2], [6], [2, 2, 2], [2], [2], [6], [2], [2, 4, 2, 2, 2, 3], [2, 2, 6, 8], [2, 2, 2], [2, 5, 2, 2], [2], [2, 5, 2, 2], [4, 7, 2, 5, 3], [2], [2], [2], [2], [6, 8, 2, 2, 2], [2, 2, 6], [2, 2, 2], [2, 2], [2, 2, 2, 5, 2, 2, 3, 5, 2, 2, 2], [2, 2], [4, 2, 4, 5, 2, 6], [2, 8], [3], [2], [2], [2, 5, 2], [2, 2], [2, 2, 5, 6, 2], [2], [2, 5, 2], [6, 5, 6, 5, 2, 8, 2, 7], [2], [2], [6], [2], [6, 8], [2], [6, 8], [2, 5, 2, 2, 5, 2, 2, 5, 2, 8, 2, 5, 2, 4, 2], [2, 2], [4, 2, 2, 2], [3, 5, 2, 3], [2, 5, 2], [2], [6], [3], [2, 2, 8, 2, 2], [6], [2, 5, 2], [2, 5, 4, 3], [4, 2], [8, 2, 4, 4, 3], [2], [3, 2, 2, 2], [2, 4, 6, 2, 2, 6, 8, 2, 2, 6, 5, 2, 2, 2, 5, 2, 2, 2, 2, 6, 5, 2, 3], [2], [2, 5, 2, 5, 2], [2, 2, 5, 2, 2], [2, 7, 2, 2, 2], [2, 2, 2, 2, 4, 2, 2, 5, 2], [2, 5, 2], [2], [2], [6, 8, 2, 6], [8, 2, 2, 2, 5, 2], [2, 5, 2, 4, 2], [6, 5, 6], [2, 3], [2, 2, 2], [2, 5, 2, 2, 2], [2], [2], [6], [2, 5, 2, 8, 2], [6], [3, 4], [2], [2], [2], [8, 2, 5, 8, 2], [2, 2, 2, 6, 8], [8, 2, 2, 2], [4, 2, 4, 2, 2, 5, 4, 2, 2, 7], [2, 7], [2], [2, 8, 2, 2, 2, 2, 2], [2, 4, 2, 4, 4, 6, 6, 5, 2], [2], [8, 4, 2, 2], [2, 2, 2], [4, 2, 2, 4, 5, 2], [6], [2, 6], [2, 3, 2, 5, 4, 2, 3, 2, 2, 2, 2], [2], [6, 2], [2, 4], [4, 5, 2, 5, 4, 2], [4, 2, 4, 3, 2, 5, 2], [2, 5, 6, 4, 4, 4, 2, 4, 6, 2, 4, 7, 5, 2], [2], [2], [6], [4, 2, 3], [2], [6], [2, 2, 5, 2, 5, 2, 2], [2, 5, 6, 2], [2, 4, 8, 4, 2, 3], [2, 5, 4, 2, 5, 2], [8, 2], [2, 8], [2, 2], [2, 2, 2, 8, 6], [6, 2, 8, 5, 2, 2, 6, 2, 2, 2, 2, 2, 2, 7, 5, 3, 5, 4, 2, 3], [2], [6], [2, 2, 2], [6, 2], [2, 2], [6], [2], [2], [2], [6, 2], [6, 8, 5, 2, 2, 5, 4, 2, 4], [8, 4, 4, 2], [2], [2, 2], [6], [4, 2, 2, 2, 2, 4], [3, 4, 8, 5, 2, 2, 4, 2, 4, 2, 2, 5, 3, 8, 2, 5, 6, 2], [2, 5, 6, 2, 4, 5, 2, 5, 6, 5, 4, 2, 2, 3], [2, 2], [4, 2, 4, 3], [2, 2], [6], [2, 8, 4, 2, 2], [4, 2, 3, 2, 5, 2, 7, 5, 4], [2], [6], [4, 2, 2], [8, 3], [8, 2, 2, 5, 2], [2, 2, 2, 2, 2, 5, 2, 6], [2], [6, 2, 2], [2], [2], [2], [2, 2, 2, 5, 3, 5, 2, 2], [8, 2, 4, 2, 2, 2, 6, 5, 8, 2, 5, 2], [6], [4, 2, 2], [2], [2, 6, 2], [2], [2], [2, 4, 4, 2], [3, 2, 5, 3, 2, 2, 5, 3, 2], [2, 5, 2, 5, 2, 5, 4, 2, 2, 2, 4], [2, 2, 2, 2, 2, 4, 2], [6], [2], [8, 4, 2, 2, 2, 2, 2], [6, 5, 2, 2, 5, 2, 4, 2, 4, 6, 2, 2, 4, 2, 2, 2, 2, 2, 5, 4, 4, 2, 2, 4], [6, 8], [2, 2, 2, 2, 2], [2, 2, 2, 5, 2, 5, 2, 5, 2, 4], [8, 2, 2], [2], [2, 5, 6, 5, 3, 4], [2, 2, 2, 6], [4, 2], [6], [2, 2, 4, 2, 4, 4], [3, 4, 2, 4, 2], [2, 2, 2, 7, 2], [2], [2, 5, 8], [6], [6, 5, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2], [2, 4, 2, 2, 4, 6, 5, 3], [2, 5, 8, 2, 2, 5, 4, 2, 2, 4, 5, 2, 2, 4, 2, 2, 4], [2, 2, 2, 3, 2, 4, 5, 4], [2, 2, 4], [6], [5, 2, 2, 2, 2, 5, 2, 2], [2, 4, 2], [2], [2, 8], [2, 5, 2, 2], [2, 3, 2, 6], [2, 2, 6, 2], [2], [2], [2], [2], [2], [2], [6, 2, 8], [2], [2, 8], [2], [2, 5, 2, 4, 4, 2, 2, 2, 2, 4, 2, 5, 2, 4, 2, 2, 4, 2, 2, 2, 4], [4, 2, 2, 4, 2, 2, 2, 2, 8, 2, 2, 3, 4, 6], [2, 2, 2, 2, 2], [3], [2], [2, 5, 2], [2], [2, 4, 2, 5, 4], [6], [4, 2, 2], [2], [2, 6], [2, 7, 5, 2], [2, 7, 2], [2, 2, 4, 7, 2, 2], [2, 2, 4, 2, 2], [2, 6], [2, 2, 2, 2, 2, 2, 6], [2, 2, 8, 5, 4, 2, 6, 4], [2, 2, 3], [2], [2, 2, 2, 2, 2, 5, 2, 2, 2], [4, 2, 3, 2], [3, 4, 8, 2], [2], [2, 5, 4, 3, 2, 5, 2, 4], [2], [6], [4, 2], [2, 2, 3], [2], [3, 2, 5, 2, 8], [2, 2, 4, 8, 2, 2, 2, 2, 2, 8, 5, 2, 5, 2], [5, 2, 2, 2], [2, 2, 2], [3, 8, 3], [2, 4, 2, 2], [6], [2], [6, 6, 2], [3, 3, 2, 2, 4, 4], [5, 4, 8, 2], [2, 7], [2], [2], [6, 2, 2, 2, 2, 2, 5, 6, 3, 2], [2], [2, 5, 2], [2, 4, 2, 2, 5, 4, 2, 2, 6], [5, 8, 6, 5, 2, 6, 5, 6, 2, 2], [2, 8, 2, 2, 2], [2], [3], [2, 3, 4, 2, 2], [6, 2, 6], [6], [6], [2], [2, 5, 8, 3], [2], [3, 2], [2], [6, 6], [2, 4], [6], [2, 2], [2], [2], [2, 4, 2, 4, 2, 2, 5, 2, 8, 2, 6, 5, 2, 8, 6, 5, 3, 5, 2, 4, 4, 5, 2, 4, 2, 2, 2], [2, 2, 2], [6, 5, 2, 6, 5, 2], [4, 2, 2], [6], [6, 5, 2, 4], [4, 2, 2, 5, 2, 4, 4, 2], [2, 4, 2, 2, 2], [4, 2, 2, 2], [2, 5, 6, 6], [2, 2], [2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [6], [2], [6], [2, 2, 2], [2, 2, 5, 2, 2], [3], [6], [2], [3, 5, 2, 5, 2, 5, 2, 4, 6], [2, 2, 4, 2, 6], [6, 8, 2], [2, 2, 2], [4, 2, 8, 4, 2, 3], [2, 4, 2], [4, 2, 2], [2, 5, 2], [2, 5, 2, 2, 2], [2, 6], [6, 2, 2, 2], [2], [6], [2], [2, 2, 2], [2, 4], [6, 5, 2], [2], [2, 2, 2], [4, 2, 2], [8, 6], [2, 2], [2, 8], [6, 2], [2], [2, 2, 2], [6], [2, 2], [6, 2, 2], [2], [6, 2, 6, 2], [6, 5, 6, 5, 2, 6, 2, 8, 5, 2, 2, 5, 2, 3, 5, 2, 2, 2, 2, 2, 2, 5, 2, 5, 2, 7, 5, 2, 3, 4], [2], [2], [2], [2], [2], [2, 4, 2, 2, 2, 4, 2, 2], [2, 4, 2, 4], [6], [4, 2, 2, 5, 3, 5, 2, 5, 2, 4, 5, 2, 2, 6, 6, 5, 2], [3], [2, 2, 5, 3, 5, 2], [4, 5, 2], [4, 4, 2, 2, 5, 2, 6, 2, 8, 2], [2, 2], [2], [2], [8, 6], [6], [6], [2, 6, 2, 5, 2, 5, 4, 2, 2, 2], [2, 2, 4, 8], [2, 6, 8], [8, 6, 2, 2, 2, 2, 5, 4, 2, 2, 4, 2, 2, 2, 2, 5, 2, 4, 2, 2, 2, 4, 4, 2, 2, 5, 2, 6, 4], [6, 6], [2, 2, 2, 2, 2, 5, 6, 6], [2, 2], [2], [2, 5, 6, 2], [4, 2, 4, 3], [3, 2], [2, 5, 2, 2], [2, 5, 2, 5, 8], [2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 5, 2], [2, 2], [2], [2, 2, 5, 2, 2], [2], [2, 2, 2, 5, 2, 2, 2, 2, 5, 2], [2, 6], [2, 4, 2, 2, 6, 5, 4, 2, 2], [6], [4, 3, 2], [2], [7, 5, 2, 2, 2], [8, 2, 4, 2, 4, 2, 2, 2, 2], [2, 5, 2], [2], [2, 2], [3, 4], [2, 4, 2, 2], [2, 4, 2, 2, 3], [6], [6], [2, 2], [6, 6], [6, 8, 5, 2, 2, 7], [2, 5, 2, 5, 4, 2, 5, 6, 2, 5, 2, 2, 5, 2, 2], [2], [8, 2, 2, 6, 2], [6, 2, 2, 2], [6, 2, 4, 5, 2], [6, 2, 2, 4, 2, 5, 2, 2, 7, 2], [2], [2, 2, 2, 2], [2, 2, 5, 4, 2, 5, 2], [2, 2, 2, 2, 2, 7, 5, 2, 3, 2], [2, 6], [6], [2], [6], [3], [2, 2, 4, 2, 2], [2, 2], [2], [2], [2, 8], [4, 2, 2, 2, 5, 2, 2], [3], [4, 2, 2, 4], [6], [2, 4, 8, 5, 2, 5, 2, 7], [6], [6, 8], [2, 5, 2], [2, 6, 4, 2], [4, 2, 4], [2, 2], [2, 2], [2, 2, 4], [6], [6, 6, 5, 8], [2], [6, 2], [2, 5, 8, 5, 2, 4], [2, 2, 2, 2, 6], [6, 6, 4, 5, 2, 2], [6], [2, 2, 3], [2, 5, 2], [2], [2], [2, 6, 8], [6, 6], [2], [2, 5, 2], [6, 6], [3, 5, 8], [2], [6, 5, 2, 2, 2], [2, 2, 2, 2, 2], [2], [2, 2, 2, 5, 6, 4], [2], [2, 2, 7, 5, 2], [4, 8, 2, 3, 5, 4, 2, 2, 6], [6], [2], [2], [2, 4, 2], [3, 5, 2], [2, 2, 2], [4, 2, 4, 2, 5, 2, 2], [2, 2, 8, 2], [2], [2, 7, 3, 5, 6, 8, 2], [2, 4, 2, 2, 4, 5, 4, 2, 5, 2, 4, 4], [2, 6], [2, 6, 3, 5, 2, 2, 4, 2, 4, 2, 2, 2, 6, 2, 2], [6], [6], [2], [2, 5, 2, 2], [6], [6, 5, 2], [4, 2, 2, 6], [2, 3, 2, 4, 2, 2, 2, 2, 2, 2], [4, 2, 4, 4, 2, 2, 2], [3], [6], [2, 2, 2], [6, 5, 4, 2, 2, 2, 2, 2], [6, 6], [6, 2, 2, 8, 5, 2, 5, 2, 2, 2, 5, 3, 4, 3, 2, 3, 5, 2, 8, 4, 2, 4, 3, 7], [2, 2, 2, 2], [2, 2, 2], [8, 5, 6, 5, 6, 6, 2, 5, 3, 8, 2, 2, 8, 2, 5, 2, 2, 5, 6], [6, 8], [2], [6], [4, 2, 2], [2, 2, 5, 2, 4, 2, 2], [6, 4], [2], [2, 6], [2], [2, 2, 6, 3, 7], [2], [2, 4, 2, 2], [2], [2, 8], [4, 2, 4, 4, 2, 2, 2, 4, 3, 2], [4, 2, 2, 6, 2, 2], [2], [4, 2, 4, 2, 5, 2, 2], [2, 4, 4, 5, 2], [2, 5, 6, 2, 2, 6, 3], [2], [2, 2, 2, 5, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2, 2], [6], [2, 2, 2], [2], [2, 2], [2, 2, 2, 5, 4, 3, 4, 8, 2, 3, 5, 4, 4, 2, 2], [2], [3, 2, 2, 2, 2, 2], [3, 5, 4, 2, 2], [2], [2, 2, 5, 4, 2, 4, 2], [2], [2], [2, 2, 2, 2], [6], [2], [2, 2], [2, 2, 3], [2, 7], [4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2], [2], [6, 2], [6, 6], [2, 5, 6, 6], [4, 2, 4], [3], [2, 2, 2, 2], [2], [7, 2], [2], [2, 8], [2, 2], [2], [4, 2, 2, 2, 2, 2, 2, 2], [2, 4], [2], [3, 2], [3, 3], [2, 5, 2], [4, 6, 2, 4, 2, 5, 2, 2, 3, 4, 2, 2, 4, 2, 7, 5, 3], [2], [2, 2, 2, 2, 4, 2, 8, 2, 2, 2], [4, 4], [6, 6], [4, 2, 2, 2, 6, 6], [6], [3, 4, 3], [6], [2, 4, 2, 2], [4, 8, 5, 2, 3], [2], [2], [6, 2], [6], [6], [2], [3, 2, 5, 2, 5, 2, 2, 7, 5, 2], [2, 8], [2, 2, 2, 2], [2, 5, 2], [2], [2], [2, 4, 3, 8, 2, 2, 2, 5, 2, 2, 2, 4, 2, 2, 5, 3, 8], [3, 4, 2, 2], [2, 2], [2, 2], [6, 2], [2, 6, 6, 5, 2, 8], [2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4], [4, 2, 2, 5, 2, 2], [8, 2, 2], [2, 2, 2, 5, 8, 2, 2, 6], [6, 6, 6, 8, 2, 2, 2, 8], [2], [4, 2, 4, 2, 2, 2, 2, 2], [6], [2, 5, 2], [2, 5, 2, 5, 3, 2, 2], [2, 2, 2, 2, 2, 2, 4, 2], [6], [4], [2, 2], [2], [6, 4, 8, 2], [6, 6, 8], [6, 8, 2], [4, 2, 5, 2, 5, 2, 5, 3, 3, 5, 2, 2, 4, 2, 5, 4, 2, 2, 2, 5, 2, 2, 2], [2, 6, 4, 2, 3], [2, 2, 2], [4, 7, 2, 4, 2], [2, 2, 2, 2, 5], [6], [2], [6], [2, 4, 2], [8, 2, 2, 8, 2, 5, 4], [2, 5, 4, 4, 6, 2], [2], [2, 2, 2], [2, 2, 4], [2, 7], [2, 2, 2, 2], [5], [2], [2, 2], [4, 2, 2], [3, 5, 4, 2, 5, 4, 2, 2, 2, 4, 2, 2, 5, 4, 2, 2, 2, 2, 6, 5, 2], [2, 4], [2, 2, 6], [2, 2], [2, 8, 2, 7, 2, 8], [2, 5, 2], [2, 5, 4, 2, 2, 8], [2, 5, 2], [2, 4, 2, 2], [8], [2, 2, 3, 2, 2, 2], [2], [4, 2, 2, 2, 4, 2, 2, 2], [6, 2], [8, 2, 4, 2, 4, 2, 2], [2, 4, 6, 6, 2, 2, 2], [8, 2, 5, 8, 2], [2], [2], [2, 7], [2], [2], [2, 4], [6, 2], [4, 3, 2, 5, 2, 2, 2], [5, 2], [2, 4, 3, 4, 6], [2, 2], [2], [6, 2, 2, 2], [2, 2, 2], [2, 3], [8, 2, 4], [2, 4, 8], [4, 2, 7], [2, 4], [4, 6], [2, 4], [2], [2, 2, 2], [2], [6], [8, 2, 2], [2, 2], [2, 4, 8, 2, 8, 2, 2, 2, 2], [2, 5, 2], [6, 7, 2, 2, 2], [2, 2, 2, 2, 2, 2], [2, 5, 6], [2], [4, 2, 4, 5, 2], [6, 6], [2], [8], [2, 2], [8, 5, 2], [6], [6, 5, 2], [4, 2, 4, 4], [2], [2], [2, 4, 2, 2, 2, 2, 5, 2, 3, 5, 2, 2, 2], [2], [2, 2, 2, 8], [2, 2, 4, 2], [2, 7], [2], [2, 5, 2, 2], [2, 2, 2], [6, 8], [8, 2, 2, 2, 2], [2, 8], [2, 2], [2, 2], [6], [7], [2, 8, 5, 2], [6], [2, 6, 6, 6], [6], [6, 2, 6], [6, 5, 2, 2], [4, 2, 2, 2], [2, 6, 2, 2], [2], [4, 3, 2, 2, 2, 2], [6, 3], [2, 2, 4, 2], [4, 2, 3], [2, 5, 3], [6], [2, 5, 4, 4, 8, 5, 2, 2, 5, 2, 3, 5, 3, 2, 2], [2, 5, 2, 4, 2, 3, 2, 2, 2, 5, 2, 2, 2, 4], [2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [6, 2], [2, 2, 4], [2], [4, 2, 4, 5, 4, 3, 5, 3, 5, 6, 2], [2, 2], [2], [2], [2], [2], [8, 2, 4, 2, 2, 2, 6, 2, 5, 2], [2, 5, 2, 8, 5, 6, 2], [2, 2, 2, 3], [6], [2, 2, 2], [2], [6, 2, 5, 2, 5, 2, 2, 2, 5, 8, 5, 2], [2, 2, 2], [6], [4, 6, 7], [2, 8, 2, 5, 2], [6, 5, 6, 5, 6, 6, 5, 6, 6], [6, 6, 5, 8, 2, 2, 2], [6], [4, 2, 6], [2, 2], [2], [2], [2, 2, 2, 6], [2, 4, 4, 2, 2, 2, 5, 2, 5, 2, 4, 3], [5, 5], [2, 2, 4, 2, 2, 2, 3, 3, 5, 2, 2, 2, 5, 2, 2, 5, 2, 2, 2, 2, 2], [2, 2], [2], [6], [2, 4, 4, 2], [2, 2, 2], [4], [2, 7], [2, 2, 2, 2, 2], [4, 2, 2, 5, 2], [2, 2], [6, 8], [4, 2, 2, 2, 2, 2], [2], [2, 2], [2], [2, 4, 2], [2], [6, 6], [4, 6, 2, 5, 2, 4], [2, 2, 2], [2], [2, 2, 2], [6, 3, 5, 2], [2], [2], [2, 2, 5, 6], [2], [2], [3, 2, 3], [2, 2, 2, 7, 2, 4, 6], [2, 4, 2, 5, 2, 5, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2, 2, 4], [2, 2], [2, 5, 8], [2, 8], [6], [2], [2, 2, 2, 2], [2, 5, 2, 5], [2, 2, 7], [2, 4, 2], [2, 5, 2, 5, 8], [2, 2], [2, 2], [6, 6, 8], [8, 2, 6, 4, 2, 2, 4, 3, 6, 2, 2, 4], [6, 5, 2, 2, 2, 6, 2], [2], [4, 2, 2, 2], [2], [6, 3, 6], [2], [2], [2, 2, 4, 2], [4, 2, 2, 2, 7, 2, 2, 2, 2, 2, 8], [6, 2], [2, 2], [2, 4, 6, 4, 2, 2, 4, 4, 2, 2, 4, 8, 2, 2], [2], [6, 7], [4, 2], [2], [6], [4, 5, 4, 2, 4], [2, 2, 2], [3, 8], [2], [4, 2, 2, 2, 7], [6, 7], [2, 2], [2], [2, 8, 5, 2, 2, 2, 4, 5, 2, 4, 2, 5, 4, 4, 2, 5, 4, 4, 2], [4, 2, 2, 2], [2], [2, 2, 6, 8, 2, 2], [2, 2], [6, 6], [4], [4, 3], [6, 2, 2], [2], [2, 4, 2, 2, 5, 4, 2, 2, 4, 2], [6], [2, 5, 2, 2, 8, 6], [4, 2, 2, 2, 2, 2, 2, 2], [2, 4, 2], [6], [6], [2, 4, 2, 2, 2, 2, 2, 4], [2, 2], [3, 2, 2, 2, 4], [2, 5, 2, 8, 6], [6, 5, 4, 2, 2, 2, 2, 2, 2, 5, 4, 2, 2], [2, 2, 2], [4, 2, 4], [2, 4, 2, 2, 5, 4, 2, 4, 2], [3], [2, 4, 2, 2, 2], [2], [2], [2, 5, 6], [4, 2, 4, 2, 2, 2, 6], [2], [2, 5, 2, 2], [2, 5, 6, 2, 5, 6], [2, 2], [2, 2, 6, 2, 3, 8, 5, 2, 6, 6], [2], [6, 8, 8, 5, 2, 2, 2, 3, 5, 2], [2], [2, 2], [2, 2, 5, 4, 2, 2, 2, 3], [2, 6], [2, 5, 4, 2], [2, 3], [2], [4, 2, 5, 6, 2, 5, 2], [2], [3, 2, 2, 2, 2], [2], [4, 8, 2, 2, 2, 2, 4, 2, 5, 2, 2, 6, 2, 8], [2], [6, 6], [6, 4, 2, 5, 2, 2], [2, 4, 2, 2, 8, 3, 6, 2], [2], [6, 5, 3, 2], [4, 2, 4, 2, 2, 2, 2, 7, 4, 3, 3], [2, 6, 5, 6], [4, 2, 2, 2, 4, 2, 2, 2, 2], [2, 2, 5, 2, 5, 2], [2], [6], [2, 2], [2, 4, 5, 4, 2, 2, 2, 2, 3], [2, 5, 2, 2, 2], [2], [2, 3, 2], [6, 6], [2], [2], [6], [2], [6], [2, 2], [2, 2], [6], [2, 2, 4, 2, 5, 2, 4], [6, 6, 5, 3, 3, 5, 2], [2], [2], [2, 2, 3], [6, 8], [4, 2, 2, 5, 6], [2], [2, 5, 6], [6], [2], [5, 2], [4, 2, 2, 3, 4, 2], [2], [8, 6, 8], [2, 2], [6], [2], [2, 2], [2, 2, 2], [6], [2, 2], [2, 4, 8], [2], [6, 5, 8, 5, 2, 2], [2, 4, 8, 3, 2, 5, 2], [2], [6], [2], [4, 2, 4, 2], [6, 5, 6, 2], [2, 5, 4, 2, 2, 2], [8, 2, 2, 2, 4, 2, 2], [2, 2, 4, 2, 2, 2, 5, 2, 3], [8, 2, 4, 2, 2, 2, 2], [2], [6, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 4, 2], [8, 8, 2, 8, 2], [2, 4, 2, 2, 2, 2, 3, 2, 4, 5, 2], [2], [4, 4, 8, 2], [2, 2, 5, 2], [6], [2, 2, 2], [4, 8, 5, 4, 2, 4, 2, 5, 8, 5, 4, 2, 2, 4, 5, 4, 2, 2, 4, 2, 8, 2, 2, 4, 2, 2, 5, 2, 4, 2, 2, 4, 2, 4, 5, 2], [2, 2, 4, 2, 2, 2, 2, 2, 2], [2, 2], [2], [2, 5, 6], [2, 8, 2, 2], [2, 5, 3, 2, 2, 2, 5, 2, 2], [6], [6, 2, 2], [2], [4, 2, 2, 3, 2, 7], [4, 8, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2], [6], [2], [2, 5, 4, 2, 2, 2], [2], [2], [4, 4, 2, 2, 2, 2, 7], [2], [3, 2], [3], [2, 2], [7, 8, 2], [2, 3, 2], [6], [2, 8, 5, 2, 3, 5, 4, 2, 2, 3, 4, 2, 8, 5, 4, 8, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4], [2, 2, 2, 4, 5, 4, 2], [2, 2, 2, 5, 2], [2, 2, 2, 8, 2], [2, 6, 8, 2, 2, 3, 3], [6, 8, 2], [2, 3], [2, 2, 2, 8], [6, 5, 2], [2], [3], [2, 4, 2, 2, 2, 2, 4], [2, 2], [2, 4, 2], [2, 8, 2, 5, 2, 6, 5, 2, 2, 4, 2, 5, 2, 5, 2, 5, 2], [2, 7, 5, 2, 4, 2, 5, 6, 8], [2, 4, 3], [2], [2], [2], [2, 4, 2, 2], [2, 6], [2], [4, 2, 2, 5, 2, 2, 2, 8], [4, 2, 2], [4, 5, 4], [6], [6], [2, 5, 2], [3, 5, 4, 2, 4, 4, 2, 5, 2, 2], [8, 2, 2, 2, 2], [4, 3, 2, 5, 2, 8, 5, 8], [2], [4, 2, 4, 2, 3], [2, 2], [6, 2], [2], [2, 2], [6], [6, 4, 6], [2], [7, 5, 2, 6], [4, 2, 2, 2, 2, 2], [2, 5, 2], [2, 2, 2, 4, 2], [2, 2, 8, 2, 2, 2], [2], [2, 4], [6, 6], [3, 2, 2, 4], [2, 4, 2, 2, 4, 6, 5, 4, 3, 3, 3], [6], [2, 2, 2, 4], [2], [2, 2], [2], [2, 2], [2], [4, 8, 2, 2], [4, 2, 2, 8, 5, 2, 3, 2, 5, 2, 2, 2, 2], [2, 2, 4, 2, 5, 2, 2], [6, 2, 5, 6, 6, 5, 2], [4, 2, 4, 2], [2, 4, 2, 2, 2], [4, 2, 5, 2, 5, 2], [2, 2, 4, 2, 2], [2, 2, 3], [4, 2, 2, 8, 8, 2, 4, 2, 2], [6], [6], [2, 4, 2, 2, 2, 2, 2], [2], [6], [2, 2, 2, 2, 4, 2, 2, 2], [2, 4, 3, 2], [6, 5, 2], [2, 3, 2], [3, 4], [2, 2], [3], [8, 4, 2], [6, 8], [2, 2, 2, 8, 2, 2], [2], [3, 8], [2, 5, 4, 2, 2, 7], [2, 8, 6, 2, 6], [6, 8, 5, 6], [2, 2, 5, 2, 2, 5, 2, 8, 2], [3], [2, 4, 2, 2, 2, 2, 4, 2, 2], [4, 2, 2], [2, 2, 2, 5, 2, 4, 4, 2], [2], [2], [6], [6], [6], [2], [6, 6], [2, 2], [2, 2, 5, 8, 2, 2, 6], [6, 8, 2], [2, 5, 2, 4, 5, 2, 2], [6, 5, 6], [2, 5, 4, 2, 2, 4, 2, 4, 5, 2], [8, 6, 5, 6, 5, 6, 8], [4, 2], [2], [2, 2, 2, 5], [2, 2, 8], [2], [4, 2], [2], [2, 2, 5, 2, 6], [6, 6], [2, 2, 2, 2, 8], [2], [4, 2, 2, 2, 2, 2], [2], [2], [4, 2, 5, 2, 2, 2, 2, 2], [4, 2, 3, 5, 2], [2], [2, 5, 2, 5, 2, 5, 2, 4, 2, 2, 6], [2], [8], [2, 7], [2, 4], [2, 6, 2, 8, 5, 6, 8, 5, 3, 8], [2], [4, 2, 2], [2], [2, 5, 6], [2, 2], [2, 5, 6], [4, 2, 2, 5, 4, 6], [6], [2], [2], [4, 2], [2], [2], [2, 2, 2, 2, 2, 2], [6, 6], [4, 2, 2, 6, 2, 4, 3, 2, 2, 4, 2, 2, 2, 7], [6], [2, 4, 2, 2, 4, 2, 2, 3, 2], [2, 6], [2], [2, 2, 2, 2], [2, 2, 4, 2, 3], [2, 3, 2], [6], [3, 2, 2], [4, 3, 2, 2], [2, 2, 2, 2], [2, 2, 5, 3, 2], [2], [2], [6, 5, 6, 2, 5, 2, 7, 5, 2, 5, 2, 3], [2], [7], [3], [3, 6], [2, 2, 6], [2, 2], [2], [2, 8], [6], [3, 5, 3, 8], [2], [2, 2], [2, 2], [6], [2, 4, 2, 5, 2], [2], [6, 2, 4, 2, 5, 6], [2], [2], [6], [2], [3], [2], [2], [2], [2], [2, 2], [2], [4, 2, 5, 2, 2, 5, 2, 2, 2, 2], [2], [2, 8, 2, 5, 2, 8], [3, 3], [2, 2, 5, 3], [2, 5, 2, 2], [2, 4, 2], [2], [2], [2, 2], [6], [2], [3, 5, 4, 3, 8], [6, 2, 5, 6, 8], [2, 4, 6], [2], [6, 8, 5, 2, 8], [6, 8], [2], [3, 8], [2, 4, 6, 2], [2, 4, 2, 2, 4, 4, 2, 5, 4, 2, 4, 2], [2, 2, 5, 2], [7, 5, 8], [2, 2, 8], [2], [6, 6, 3], [2], [2, 5, 2, 2, 2], [2, 4, 2], [2], [3, 4], [2, 5, 2, 7, 5, 2, 8, 5, 2, 5, 2, 5, 7, 2, 8, 5, 3, 2, 4], [4, 6, 2], [2, 2, 2], [6, 8, 5, 2, 5, 2, 2, 2], [6], [6, 5, 6, 5, 6, 6], [2], [4, 2], [2, 4, 2, 6, 5, 2, 5, 3], [2, 5, 6, 2, 6], [6, 2, 5, 8, 4, 2, 6], [2, 2], [2, 2, 2, 4, 2], [3], [2], [6], [2, 2], [2, 2, 5, 6, 2], [2, 3], [2], [2, 4, 2, 2, 3, 2, 4, 6], [6], [8, 2], [6], [6, 5, 2, 2, 2], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 5, 2, 2], [2], [2, 8, 2], [6], [6], [2], [4, 2, 7, 5, 6], [4, 2, 2, 5], [2], [6], [6, 2, 2], [2, 4, 2, 7, 5, 2], [2, 5, 6, 8, 5, 2, 3], [2, 3, 5, 3, 2, 2], [2, 5, 2, 2], [8, 2, 5, 2], [2, 5, 2, 2], [6], [2, 2, 5, 2, 2, 2, 2], [8, 2, 4, 2, 5, 8, 2, 2, 2], [8, 2], [2], [2, 2, 5], [2, 2, 2, 5, 6], [4, 2, 5, 2, 5, 3, 2, 4, 2], [2, 2, 2, 5, 2, 4, 2, 2, 2, 2, 2, 3, 8], [2, 3, 3, 5, 4, 2, 2, 4, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 8, 5, 6], [4, 8, 2, 2], [2, 5, 2], [2], [2, 2, 2, 5, 2], [3], [2, 2, 2, 5, 2, 2], [2, 2, 8, 6], [8, 5, 2, 6, 5, 6, 8, 5, 2, 2, 2], [2, 3, 5, 2, 3], [6], [2], [2], [2, 7, 5, 6], [2], [2, 2, 5, 8], [2], [6, 8, 5, 6, 2], [2], [2, 4, 4, 2, 2, 2, 2], [6, 6, 2, 2, 8], [3, 4, 3], [2], [2, 5, 3], [2, 2, 6, 8], [2, 8], [4, 2, 2, 2, 2], [4, 2, 2, 2, 5, 4, 2, 5, 2], [2, 4, 3, 6], [6, 4, 3], [2, 2, 2], [6, 8, 2], [2, 8], [7, 6], [2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2], [2, 2, 8, 2, 2], [2, 6], [8, 2], [2, 5, 2, 2, 2, 5, 2], [6, 4, 8, 2, 5, 2, 8], [2, 4, 2, 2, 2], [4, 2, 2], [2, 5, 4, 2, 4, 2, 2], [2], [4, 2, 2, 2, 3, 3, 4, 5, 4, 2, 5, 2, 4, 2, 4, 2, 2, 2], [6, 8, 3, 6], [6], [2], [8, 2, 4], [2, 5, 3, 5, 2, 2, 2, 2, 8], [3, 5, 4, 2, 4], [6, 5, 6], [2], [2], [2, 8, 2, 3, 5, 2, 2, 2], [2, 5, 2, 4, 2, 5, 2], [4, 2, 2], [4, 2, 8, 2, 6, 5, 2], [3, 3, 2, 5, 2, 2, 6, 6], [2, 2, 2, 2, 5, 5, 2], [2], [2, 5, 2, 2, 4, 2, 5, 4, 2, 2, 4, 2], [2], [2, 5, 6], [2, 2, 5, 4, 2, 5, 2, 2], [2, 2], [2, 2], [2, 5, 2], [2, 2, 5, 4, 2, 5, 2, 5, 2, 2], [2], [6], [2, 5, 2], [2, 5, 2, 2, 4], [2, 8, 8, 5, 2], [2, 6, 5, 2], [2, 2, 5, 8, 2, 5, 2, 2, 2, 8], [2, 4], [6], [4, 2, 5, 6, 3], [6], [6], [2, 4], [2, 2], [2, 2], [2, 2], [2, 4, 8], [2], [2, 2, 2], [2], [2, 5, 2, 4, 2], [2, 4], [4, 8], [2], [2], [6], [2], [6], [2], [2], [6], [2, 5, 3], [4, 8, 3], [3], [2, 2], [4, 2, 4, 2], [6], [2], [2], [2, 2, 3], [2, 2], [6, 6, 2, 6, 8], [2], [4, 2, 2, 2, 4, 4], [2], [2], [2, 5, 4, 2, 2, 2, 8], [2], [2, 5, 4, 2, 4], [6], [2, 4], [2], [6, 5, 2], [4, 2, 4, 5, 4, 2, 2], [2, 2, 5, 2, 2], [3], [2, 2, 4, 6, 2, 2, 2, 2, 2, 2, 3, 2, 2], [2, 2, 2, 2, 2, 6, 5, 2, 2, 2, 2], [2, 2, 6, 5, 2, 5, 3], [2, 4, 2, 2, 2], [2], [2, 2, 2, 5, 2, 2, 2, 4, 2, 2, 3, 5, 2, 4, 2], [6], [4, 2, 4, 2, 2], [2, 5, 2], [2, 2, 5, 6, 5, 2, 2], [2], [6, 5, 2], [2, 2, 2, 5, 3], [8, 2], [2, 5, 8, 5, 2], [2, 2, 4, 2, 2, 2, 8], [3, 2, 5, 2], [2, 5, 2, 3], [3, 8, 5, 3, 7, 5, 2, 2, 5, 6], [2, 5, 4, 2, 5, 2, 5, 2], [6, 8], [4, 2, 2], [2, 5, 2, 2, 5, 2], [4, 5, 2, 2], [2], [2, 3, 2, 5, 4, 2, 6, 4, 5, 4, 2, 6, 5, 2, 6, 4, 6], [2], [2], [4, 2, 3, 2], [6], [2], [2, 2, 3, 4, 4], [2, 2], [4, 2], [2, 2, 4, 2, 2], [2, 7, 8], [4, 2, 2, 2, 2, 5, 6], [4, 2, 2], [4, 2, 2, 8, 2, 2, 5, 7, 2, 8, 5, 2, 2, 5, 4, 3, 5, 2, 2], [2], [4], [4, 2, 2, 5, 4, 2, 2, 2, 6, 5, 2, 2], [2, 5, 4, 2, 8, 2, 8, 2, 4, 3], [2, 2], [2, 6], [2, 8], [2, 2, 6, 5, 6, 6, 2, 6, 8, 2, 3], [6], [2, 4, 6, 4, 4, 2, 2, 5, 2, 2, 2, 2, 2, 2], [6, 5, 2, 8], [4], [6, 6], [2, 2, 4], [6], [2, 2], [6, 4, 5, 2, 2], [6], [6], [6, 5, 2], [2], [4, 2, 5, 8, 2, 3, 6], [2], [2, 4, 2, 2, 2, 5, 2], [2, 4, 7, 5, 2, 5, 7, 5, 8, 2, 2], [2], [2, 4, 4, 2, 2, 2, 2, 2], [2, 2, 4, 2, 5, 2, 3, 2, 2, 2, 3, 8, 5, 6], [2, 2], [6, 5, 4, 2], [6, 5, 2], [2, 5, 2], [6], [2], [2, 2, 5, 2, 3, 2], [2], [6], [2], [4, 2, 2, 2, 2, 8], [4, 4], [6], [2, 2], [2, 2, 5, 2], [2, 5, 6, 5, 8, 2, 2], [2, 2, 5, 4, 2, 5, 4, 2, 2, 6, 5, 2, 4, 8], [2], [6, 2], [2, 4, 2, 2, 4, 2, 5, 2], [2, 8, 2], [2, 2, 2], [4, 2, 4, 6], [6], [2, 2], [2, 8, 5, 6, 5, 8, 4, 2, 2], [6, 6], [2], [2, 6], [2, 2, 2], [2], [2, 2], [2, 4, 2], [2], [2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 8, 2, 2, 5, 4, 2, 4, 2, 4, 2, 5, 8, 2, 8], [2], [2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 6, 8, 5, 4, 2, 2, 2, 2, 2], [2, 5, 2], [2], [2, 7, 5, 2, 4, 2, 5, 2], [2, 4, 2, 2, 2, 8, 2], [6, 6], [4, 2, 2], [4, 2, 2, 2, 2, 5, 2, 2, 2, 5, 2], [2, 6, 5, 2], [5, 2], [2, 5, 2, 2, 7, 2], [4, 2, 2, 5, 2, 5, 2, 8, 2, 8, 2, 2], [2, 2], [6], [2, 5, 2, 2, 2, 2, 2, 2, 5, 2, 2], [2, 2, 4, 2, 6, 2, 2, 6], [2], [4, 2, 2, 2, 2, 2, 5, 6, 8], [6], [6], [2, 2], [2, 5, 2], [2, 2, 4, 2, 8], [2, 5, 2], [3, 8, 2, 2, 2, 3], [2, 5, 8, 2, 8, 2, 5, 8, 2, 8, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 8, 2, 8], [4, 2], [2, 2, 5, 2, 2, 5, 2, 2, 5, 2, 2, 2, 5, 2, 2, 5, 2, 2, 5, 2], [2, 2, 2], [2, 4, 3, 4, 2, 2], [2, 5, 2], [6, 5, 2, 2, 2, 2, 5, 2, 6], [4, 2, 2, 2, 4], [2, 2], [6], [2, 4, 6, 2, 2, 2, 2], [2, 5, 2, 7], [2, 6, 2, 5], [2, 2, 4, 2, 2, 2], [4, 4], [2], [2, 7, 2, 2], [2], [6], [6], [3, 8, 5, 2], [4, 8, 2, 2, 4], [2, 2, 8], [6, 2], [2, 5, 4, 2, 3, 5, 2, 5, 2, 4], [2, 4], [3, 2, 2, 3, 2, 3, 3], [2, 8, 5, 2, 4, 6, 2], [2], [6, 8, 2], [6], [2, 2], [2, 6], [2, 5, 2], [2, 5, 2, 5, 2], [4, 2, 2], [2, 2, 7, 4, 3, 5, 2], [6], [3, 8, 2], [6, 7], [2], [6], [6, 6], [2, 4, 2, 4, 5, 3, 5, 4, 2, 2, 4], [2], [2, 4, 7, 5, 2, 2, 2, 3], [3, 2, 2, 2, 4], [2, 4, 2, 4, 2, 2, 8, 4, 2, 5, 6, 2, 2, 8, 5, 2, 2, 2], [4, 2, 8, 6, 2, 4, 2], [2, 5, 2, 2, 2], [6, 2], [2, 2, 2, 2, 2, 2, 4], [6], [2, 5, 4, 2, 2], [6, 5, 2, 5, 4, 2, 5, 4, 8, 5, 2, 4, 2], [3, 2], [6], [6, 6, 2], [2], [4, 2, 4, 2, 2, 2, 5, 2, 2, 4, 2, 2, 2], [2, 2, 2], [4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 5, 2, 4, 2, 2, 2, 2], [6], [2], [6], [5, 2], [2, 2], [2, 4, 2, 4, 5, 2, 2, 2, 4, 5, 2, 5, 2, 2, 2, 2, 2], [2, 6], [2, 5, 2, 2, 2, 2, 2, 2], [2, 2, 6, 4], [4, 2, 2, 6], [2, 2], [6], [2, 3, 3], [2, 5, 8, 5, 2], [4, 8, 2], [6], [8], [6], [2], [4, 3, 3, 2, 5, 6, 6], [3, 2, 2], [8, 6, 6, 2, 2], [4, 5, 4, 2, 4], [6], [6], [2], [2, 7], [2], [4, 5, 2, 2], [3, 4, 3], [2], [4, 2, 2, 2], [2, 4, 2, 6, 3], [4, 2, 6], [2, 6], [3, 8], [2, 2], [2, 7, 2], [2, 4, 5, 4, 4, 5, 5, 2, 4], [7], [2], [2, 2, 4, 2, 2, 2], [6], [2, 8, 5, 6, 4], [6, 2], [2], [8, 2, 4], [2], [2, 4, 2, 2, 8], [2], [2, 2, 2, 2], [7, 2, 2, 2], [2, 4], [2, 4, 2, 2, 4], [2, 2, 4, 6, 6, 2, 2, 2, 2, 2, 4], [2, 5, 2], [4, 2, 5, 2, 4], [2, 2], [2, 2, 5, 2, 5, 3], [2, 2], [2, 5, 3, 5, 2], [2], [2, 2], [2], [2, 2], [2], [2, 5, 4, 8], [2, 5, 3, 8], [2, 8, 2], [2, 6, 4, 5], [2, 7], [7, 5, 2, 5, 3, 2], [4, 2, 2, 2, 2, 4, 6, 2, 2, 4, 2, 2], [4, 2, 3, 2, 2], [3, 4, 3, 8, 5, 4, 2, 2, 5, 2, 2, 5, 2, 8], [6], [2], [3, 8, 2], [4, 6, 4, 6], [2, 2], [2, 4, 2, 6, 2, 2, 2, 2, 2, 4, 3, 2, 2], [4, 2, 8, 2, 2, 2, 5, 3, 2], [6], [4, 2, 4, 2, 5, 2, 3], [2, 4, 2], [6, 6], [6], [4, 8, 2, 2, 5, 2, 5, 2, 7], [2, 2, 4, 5, 2], [2, 4, 2, 4, 4, 5], [2], [2, 2, 8], [2, 4], [2], [2], [2], [2, 2, 2, 2, 2, 2, 2], [2], [2, 2, 4, 2, 7], [2, 6, 6], [2, 2, 2, 2, 2, 2], [2, 8], [2], [4, 4], [2], [7, 2, 5, 2], [2], [2], [2], [2, 4, 2, 2, 7, 5, 2, 2], [2], [2, 2, 2], [2], [2, 2, 6], [3], [2], [2, 5, 2, 5, 2, 2], [8], [2, 5, 4, 4, 5, 4, 2], [2, 2, 2, 6, 2], [2, 6], [6, 6], [6, 6], [2, 2, 2, 2], [2], [2, 2, 2, 5, 2, 2], [2], [2, 2, 5, 2], [6], [2, 2, 3, 2], [6, 6], [2], [6], [6], [6, 5, 2, 5, 2], [2, 2], [2], [2, 5, 2, 7], [6], [3, 4, 3, 5, 6, 2, 5, 2, 2, 5, 2, 4], [2], [2], [2, 8, 2, 2, 2, 2, 2], [2, 2, 8, 2], [2, 3], [2, 8], [6, 2], [6], [4, 2, 2, 3], [2, 2, 2], [3, 8], [4, 3, 3, 2], [6], [2, 2, 2, 2, 2, 2], [2], [4, 2, 2, 2, 2, 2], [4, 2, 2, 6], [6, 7], [6, 5, 2, 2], [2, 3, 2, 2, 5, 3], [2, 5, 6, 5, 2], [2], [6], [2], [3, 5, 2, 3, 6], [8, 2], [2], [2], [8, 3], [2, 8, 4, 2, 2, 2, 4, 3], [2], [4, 4, 2, 6, 2, 2, 5, 3, 2], [2], [6, 8, 3], [4, 2, 2, 2], [2], [2], [2], [2, 2, 8, 2, 5, 2], [2, 4], [6], [2], [2, 2], [5], [8, 2, 4], [2, 4], [6, 2, 2], [2, 2, 2], [2, 5, 2], [2], [6], [3], [2, 5, 2, 2], [6], [2, 5, 2, 5, 2], [2, 4, 2, 2], [2, 4], [2], [2, 2, 2, 2], [2, 6], [2], [2], [6], [2], [7], [6, 6, 5, 2, 2, 2, 6], [6], [4, 2, 5, 2], [6, 5, 8, 5, 8, 8, 2, 2, 2, 4], [2], [7, 2, 8, 2], [2, 4, 2, 4, 4, 2, 2, 2, 2], [3, 2], [2], [2], [2], [2], [2, 2, 4, 2, 2], [5], [2], [2, 2], [2], [2], [2], [6], [2, 5, 2, 5, 2], [6, 2], [5, 2, 2, 2, 2, 5, 6, 2, 2, 5, 2, 5, 2, 5], [2, 2, 2, 2, 5, 6, 2, 2, 2, 2], [2, 2, 2, 2, 2, 5, 2, 5, 8, 2, 8, 2, 5, 2], [2], [8, 2, 5, 6, 4, 3, 3, 2], [6, 6], [2, 2, 2, 8, 2], [2, 2, 4, 5, 2], [6, 6, 2, 2, 5, 2], [2], [4, 2], [3, 2], [4, 2, 2, 2, 2, 2, 3, 2, 8], [2], [4, 2, 2, 2, 2, 2, 2], [6, 6], [4, 2, 7], [2], [4, 2, 2, 2, 2], [2], [2], [2], [2], [2, 2, 5, 2], [2, 4, 8], [6], [2, 2, 2, 5, 4, 2], [6, 4, 8], [6, 8], [2, 2, 2, 5, 4, 2, 2, 2, 4, 2], [6, 6], [4, 2], [2, 5, 2, 2, 2, 2, 2], [2], [4], [3, 2, 5, 2, 8], [2, 2, 2, 6, 2, 2, 6, 8], [2], [4, 2], [2, 5, 2, 5, 2, 5, 2, 2], [2], [2], [4, 8, 5, 6, 8], [6, 2, 2], [6, 5], [8, 2, 8], [6], [2], [2], [3, 4], [2, 8], [2, 6, 8, 2], [2], [4, 2, 2, 5, 2, 2, 4, 2, 2, 2, 2, 2], [2, 2, 2, 5, 2, 5, 2, 4, 2], [2], [2], [2, 5, 2], [4, 2, 2], [6, 5, 4, 2, 2, 2], [6, 6], [2], [6, 6, 5, 3], [2, 8, 2, 4, 2], [8, 2, 2], [2, 4, 2, 2], [3, 4], [4, 2, 2, 2, 2], [2, 2, 2, 6], [2], [2, 2], [3], [2], [2], [2], [6, 2, 5, 4, 2, 4, 5, 6], [2, 5, 6], [2, 2, 2, 2, 2, 5, 3, 5, 2], [2], [4, 2, 2, 2, 4, 2, 2, 8], [6, 8, 6, 5, 6, 2, 5, 3, 2, 2, 6, 5, 2, 5, 2], [2, 2, 4, 2], [2, 5, 2], [2, 2, 2, 2, 4, 2], [6, 8], [2, 8, 5, 4, 2, 4], [2, 4], [2, 3, 3, 8], [6], [2, 2, 2, 6, 2, 4], [4, 2, 2, 4], [2, 4], [4, 8, 2, 2], [6, 6], [2, 5, 2, 2], [6, 2, 5, 6, 6], [2], [2], [8, 2, 2, 3, 2, 2, 4], [2, 2, 6, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4], [8], [6, 2], [2], [6, 8, 5, 4, 2], [2, 2, 4, 2, 4], [6, 5, 8, 2, 2, 5, 7, 5, 8, 5, 2, 5, 7], [2, 2, 2, 2], [6], [2, 5, 2, 2, 4, 2, 2, 7, 5, 2, 2, 4, 2, 2], [2], [2, 2], [2], [8, 2, 2, 3], [2], [4, 5, 2, 4, 2, 4, 5, 2, 8, 2, 2, 2], [2, 2, 2], [2, 2], [6, 2], [6], [6, 2, 6], [2], [3, 5, 2, 2, 2, 2], [2, 2, 2, 2], [6], [2], [2, 2, 2, 6], [2, 2, 2, 2, 2], [6], [2, 2, 2], [6, 2], [2], [2], [6], [2, 5, 2, 5, 2], [2, 2, 5, 2], [2], [2, 5, 2], [4, 6, 8, 2], [6], [2, 2], [3, 2], [2, 4], [2, 2, 2, 2, 2, 5, 2, 2], [2], [4, 2, 2, 4], [2], [2, 4, 2, 6, 2, 4, 2, 2, 2, 2, 2], [2, 5, 4, 2, 2, 2, 6, 2, 2, 4, 2], [2], [3, 4, 4], [2, 3, 8, 2], [2], [2, 4, 7], [4, 5, 4, 4, 7, 5, 2, 2, 2, 2, 5, 2, 2, 2], [6], [3, 2, 2, 5, 2, 2, 5, 2, 2], [2], [2, 6, 5, 2], [2, 2], [6, 3], [2, 2, 4, 6, 4, 7], [4, 2, 8], [6], [4, 2], [2, 2, 2, 4], [6], [8, 2, 7, 2, 2, 2, 3, 2, 2, 4, 2, 2, 2, 8, 2, 2, 6, 4, 2, 7, 2, 7, 2, 2, 2], [6, 8], [3, 5, 3, 5, 3], [2], [2, 6], [6, 2], [2, 7, 5, 2], [2], [4, 4, 2, 2, 2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 6, 2, 2], [2, 2, 2], [2], [8, 8, 8], [2], [2, 2, 5, 2, 2, 2, 8, 5, 2, 2, 8, 5, 2, 2, 5, 2], [6, 5, 2], [2, 5, 2, 2], [6, 5, 2, 5, 2], [2], [6, 6, 5, 2, 2, 2, 2, 4, 2], [2, 5, 3], [2, 4, 2], [2, 4, 2], [6], [6, 5, 6], [2, 2, 2], [4, 2, 2, 2, 4, 5, 2], [2, 6], [2, 2, 2, 8, 2, 2], [2, 2], [4, 2, 2, 6, 5, 6], [2], [2], [2, 5, 2, 2], [2, 4, 2, 2, 2, 2, 2], [2], [4, 7, 2], [6], [4, 2, 4, 2, 2, 4, 2, 2, 2], [6, 2, 2], [2], [2], [2, 2, 2], [6, 8], [8], [4, 4, 2, 2], [2, 2, 3], [2, 2, 2, 3, 2, 2], [2], [2], [2], [5, 2, 2], [2, 5, 2], [6], [4, 2, 2, 5, 4, 2, 2, 2], [2], [2], [2, 2, 8, 2, 2], [2, 2, 4, 4, 2, 2], [6], [3, 2, 2], [2, 5, 8, 2, 2], [4, 4, 4, 2, 2, 2, 8, 2], [6, 6], [6], [2], [2, 5, 6, 5, 2], [6, 6, 8], [2, 2, 2, 2, 2], [2, 5, 7, 5, 2], [6], [2, 2, 2], [2, 8, 5, 2, 4], [2], [6], [6], [2, 2, 5, 4, 2], [2, 2, 2, 2, 5, 4, 2, 2, 2], [6], [2], [2], [2, 4, 2, 2], [2], [2, 2, 2, 2, 2], [2, 5, 2, 4, 2], [8, 2], [2, 2, 2, 2, 2], [2, 2, 6, 7], [2], [6], [2, 8], [4, 2, 2, 2, 2], [2, 2, 5, 4, 2, 5, 2], [6], [2, 2], [2, 3], [8, 2, 2], [2], [6], [6, 5, 6, 6], [2, 8, 5, 2], [4, 2, 2, 2, 2], [6], [6, 5, 2, 2, 2, 5, 3], [6], [2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2, 5, 2], [6, 2, 2, 2, 2, 2, 4], [6], [2, 2, 5, 2, 2], [2, 3, 6], [6], [2, 2], [2, 6, 2, 2, 2, 4, 5, 2, 4, 2, 2], [2, 2, 5, 4, 4, 2, 2, 5, 4, 3], [6, 5, 8, 6], [3, 2], [6], [2, 5, 2], [2, 4, 2, 6, 5], [8, 7, 5, 2, 2, 5, 6, 8, 5, 2, 2, 2, 2, 5, 8, 2, 8, 5, 4, 2, 5, 6, 6, 2], [3, 5, 6, 6, 2, 2], [4, 2], [4, 2, 2], [2, 4], [6, 6], [2, 5, 4, 2], [6], [2, 5, 3], [2, 2, 5, 2], [2, 4, 2, 2, 4, 6, 5, 2, 4, 5, 2, 2], [6, 8, 2], [2, 2, 5, 2, 2, 5, 3, 2, 4, 5, 3, 5, 4, 2, 2, 4, 3], [2, 2, 5, 2, 2, 4, 2], [2, 2, 8], [6], [8, 6, 6, 5, 3], [2, 2, 2], [6], [2], [3], [6], [4, 3, 5, 3], [2, 2, 5, 6], [6], [2], [2, 5, 4, 2, 2, 8, 8, 5, 2, 2, 8, 7, 5, 2, 4, 2, 4, 2], [2], [2, 4, 2, 2, 8], [2, 2, 7], [3, 2, 2], [2], [2], [2, 5, 6, 8], [2, 2, 4, 6, 6, 4, 4, 5, 4, 2, 2, 2], [5, 2, 5], [2, 4, 2, 2], [4, 3, 3, 2], [2, 2], [2, 2, 6, 8], [2, 6], [2, 2, 3, 2, 2], [2, 4, 2, 2, 4, 2, 2, 4, 2, 5, 2, 4, 2, 4, 2, 2], [3, 4], [2, 2], [4], [2, 2, 2], [2, 2, 4, 2, 5, 2, 8, 2, 2, 7], [2, 5, 2, 5, 6], [6], [4, 2, 4], [2, 4, 2, 4, 2, 4, 2, 4], [2, 5, 2, 4, 7], [2, 4, 3], [6], [2, 2, 6, 2, 2, 2, 2], [2, 2], [6], [3, 8, 5, 2, 5, 2], [2, 2, 2], [2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 8, 2, 2, 2, 2, 2, 4, 2, 2, 3], [2, 2, 2], [2, 6, 2, 2, 8], [4, 2, 2, 4, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2], [2], [2, 2, 2, 2, 2], [2, 4, 2, 2, 2, 8, 2], [8], [2, 5, 2, 8], [8, 6], [2, 2], [2, 2], [2], [4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2], [2, 8], [6], [2], [2], [2, 5, 2, 5, 3, 4], [2], [2, 4, 3, 5, 4, 2, 2, 2], [8, 2, 4, 2, 2, 6, 2], [2, 8, 7, 5, 2, 2], [2], [2, 2, 4], [2, 6, 8], [6, 2, 5, 2, 2], [3, 4, 2, 5, 2, 4], [8, 2, 5, 2, 2], [4, 2, 8, 5, 3, 5, 2, 8], [6, 2, 2, 2, 2], [2, 2, 5, 2, 2, 2, 5, 2], [2, 2, 6, 2, 5, 2, 4, 2, 2, 2], [2], [4, 2], [4, 2, 2, 2, 2, 4], [2, 2, 5, 2, 2], [6], [6], [6], [2, 2, 5, 4, 2, 2], [2, 6], [2, 5, 2, 2, 2], [6, 8, 2, 6, 5, 2, 2, 4], [2, 2, 2, 2, 2, 4, 4, 2, 4, 2], [8], [2], [2], [4, 2, 2, 2], [2], [2, 2, 8], [2], [2, 2], [2], [2, 5, 8, 2, 5, 4, 2, 2], [2, 5, 6], [3], [4, 2, 4, 3, 2, 2, 2, 2], [6, 2, 5, 4, 2], [2, 2, 5, 2], [6, 6], [2], [4, 2, 4, 2, 2, 2, 2, 2, 2, 8, 4, 2, 2, 2, 2, 2], [4, 2, 2, 2], [2], [6], [2, 2, 2], [2], [2, 5, 2, 2], [6], [2, 5, 4, 2, 5, 2, 6, 6, 5, 3], [2], [3, 6], [6], [2, 2], [2, 6], [4, 7, 2], [2], [2], [2, 5, 2, 4, 5, 3, 2, 5, 8, 3], [4, 8, 2, 3, 3, 2], [6], [6, 4, 2, 2], [2, 2, 2, 7, 5, 2, 4, 6, 6, 6], [3], [2, 2, 2, 8, 2, 4, 2, 4, 2, 2, 2, 2, 2, 8, 2, 4, 2, 2, 2, 2, 8, 5, 4, 2], [6], [6], [2, 2, 2], [6, 5, 3, 4, 2], [2], [2, 2, 4, 2], [6, 5, 2], [6], [4, 2, 2, 2, 2, 2, 2], [2, 2, 3, 2, 4, 2, 2, 2, 2], [2], [2], [2], [6, 5, 8, 2, 5, 2], [2, 5, 2], [2, 4], [2, 5, 2, 2], [6], [2, 3, 4, 2, 5, 2, 2], [2, 5, 2], [6, 6, 4, 3], [2, 2, 2], [4, 2, 2, 5, 2], [2], [6, 8], [6], [2], [2, 2, 2], [4, 5, 2], [2, 2, 2, 2, 2, 4], [2], [2, 4, 2, 4, 2, 2, 2], [2, 2, 2, 5, 2], [6, 5, 6], [2, 4, 2, 5, 2], [2, 2, 4, 2], [2, 2, 2, 2, 8, 2, 8], [2, 2, 2], [2], [2], [2], [2], [2, 4, 3, 2, 2], [4, 2], [2], [2, 4, 2, 2, 2, 2], [2, 2, 2, 2, 6], [6, 6], [6], [2, 6, 4, 4], [2, 5, 2, 2, 2, 4, 2, 5, 2], [6, 5, 6], [2], [4, 7, 2], [6, 6], [2], [2], [2, 2, 2], [2, 5, 2, 2, 5, 4, 2, 2], [2, 2, 2, 5, 2, 2, 2], [6], [2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2], [6], [6, 6], [6], [6, 6, 4, 2], [2, 2, 5, 2, 4, 5, 2, 6, 2], [4, 2, 5, 4, 2, 4, 5, 3, 2], [2, 3, 6, 8], [3, 2, 2, 4, 2, 2], [6], [6, 2, 2], [2], [2, 4, 8, 2, 2, 4, 2, 2], [2], [2, 4, 2, 2], [6, 2], [2], [8, 2, 2, 4, 2], [2, 3, 2, 2, 2, 2, 5, 2, 5, 2, 2, 2, 2, 5, 2], [3, 2, 2, 2], [6], [6, 6, 3], [2], [6, 6], [2], [6, 5, 4, 2, 5, 8], [2], [6, 6], [2, 2], [4, 6, 6, 2, 5, 2, 2], [2, 2, 2, 8], [2], [2, 2, 5, 2, 5, 2, 5, 2], [6, 2, 5, 2, 2], [3, 8, 5, 2, 7], [2, 2, 2, 4, 2, 4, 2, 2, 2, 6], [6, 6], [8], [6, 8], [2], [4, 4, 2, 2, 2, 5, 2, 2, 5, 3], [2, 7, 5, 3, 4, 2, 7], [4, 2, 2, 2], [4, 2, 5, 2, 2, 2, 2], [3, 3], [2, 7, 2, 5, 4, 2, 2, 2, 2], [4, 2, 2], [2, 2], [2], [8, 5, 4, 2, 5, 2, 6], [6], [2, 4], [3, 4, 2], [3, 8, 5, 2, 6], [2], [2, 6], [2, 2], [3], [6], [2], [2, 2, 2], [4, 2, 2, 2], [6, 6], [2, 8], [8, 8], [6, 5, 8, 2], [3, 8, 4, 2, 2, 3, 2], [2, 2, 2, 2], [2, 5, 2, 6], [2], [6, 2, 5, 2, 5, 2], [2], [2, 4, 2, 4], [4, 8], [2, 2, 5, 2, 4, 7, 5, 2, 2, 2, 4, 5, 3], [2, 2], [2, 2, 4], [2, 2, 8, 8, 2, 2], [2, 5, 2], [6, 2], [2, 4, 6, 5, 3, 8], [4, 2, 2, 4], [2, 8], [4, 2, 5, 2, 4, 5, 4, 2, 4], [2, 2], [4, 2], [6, 5, 6], [2, 4, 6, 2, 2, 2, 2, 4, 2, 5, 6, 2], [6, 2], [2], [2], [2, 5, 2, 2, 5, 2], [2], [4, 2, 2, 2, 5, 2, 2], [4, 2, 2, 6, 2, 2], [2], [6, 8], [2], [6, 6], [2, 5, 6, 2, 2], [6, 6], [3, 2], [2], [6, 2], [4, 2], [4, 2, 2, 2, 2, 2, 3], [4, 2, 2, 2, 2], [2], [2, 4, 2], [4, 3, 8, 5, 2, 6, 2, 2], [2, 2, 2], [2], [6], [2, 5, 2, 5, 2], [2], [2, 3, 2], [3, 4, 2, 6, 4, 2, 2, 2, 7, 4, 3, 2, 4, 2, 6, 2], [2], [3, 3], [4, 2, 2, 2, 2, 2, 2], [2, 2, 2], [6, 2], [2, 2], [2], [8, 5, 2, 2], [6], [2, 6], [4, 2, 2, 4, 3, 3], [2, 3], [6, 4], [3, 2], [2, 2, 2, 2, 2, 2], [6], [2], [2], [3, 2, 5, 2], [4, 4, 3], [2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 2, 2, 2, 5, 2], [6], [2, 8, 5, 2, 4], [4, 2, 2, 2, 2, 4, 2, 4, 2], [6, 8], [2, 5, 3], [2, 5, 2, 2], [8, 4, 2, 4], [2], [3, 5, 4], [2, 4, 2, 2, 2], [2, 5, 2], [2], [2, 5, 3], [2], [2], [6, 6], [2, 2], [6], [2, 2, 2], [2, 5, 4, 2, 2], [2], [2, 5, 2, 5, 6], [2], [6, 2, 2], [2, 2, 6, 2, 2, 2, 4, 4, 2, 5, 6], [2, 2], [2, 2], [2, 2, 4, 2], [6, 8], [2, 4, 5, 2], [2, 2, 4], [2, 4], [2], [2, 2, 5, 2], [2, 4, 2], [4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [2, 8], [2], [2], [2], [6, 6], [2, 5, 2, 2], [6], [4, 4, 8, 5, 2, 5, 2], [2, 2], [2], [6, 5, 8, 5, 6, 8, 5, 8, 2], [6], [2], [2, 2, 2, 2, 3], [4, 2, 2, 4, 8]]\n",
            "[[0], [0], [1, 0, 0, 0, 0], [0], [0], [3, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 5, 0, 0, 12, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0], [0], [3, 3], [0], [0, 0, 0, 0, 0], [0], [0], [0, 2], [0, 0, 0, 1, 0, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0], [1, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [3, 0, 1, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0], [0], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 13, 13, 0, 0, 2], [2, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0], [2, 0], [0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 1], [0, 0, 0], [0], [0], [0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 1, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0], [8, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1], [0, 0, 0, 0, 0, 0], [1, 1, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 9, 9, 9, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [3, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0], [0], [0], [0, 1], [0], [7, 7, 7, 7], [0, 2, 0, 0], [0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 1, 1], [2, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 0, 0], [0], [3, 3, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [3, 3], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3], [0, 0, 0, 0, 0, 0], [7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 9, 9, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0], [0], [1], [0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [3, 3, 3, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 0, 1], [0, 0, 0, 0, 0], [1, 0], [3, 3, 3, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 2], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0], [0, 0], [0, 0, 1], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [3, 3], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [2, 0, 0, 0], [0], [1, 1], [0, 2, 0, 0, 0], [0, 0], [3, 0, 0], [0], [0, 0, 0, 0], [1], [0], [0], [0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0], [0], [0], [2, 2, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0], [0], [3, 3, 3, 3], [0], [1, 0, 3, 0], [0], [3, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3], [0, 0], [0, 2], [0], [0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 2, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0, 3, 0, 0, 0], [3, 3], [0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [3, 3, 3], [0], [2, 0], [0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [2, 0, 0], [4], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 5], [4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [3, 3], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0], [4, 0, 0], [2], [1, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [1, 1, 0, 0, 0], [0, 0, 0, 2, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3], [3, 0, 0, 7, 7, 7], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [7, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0], [2], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0], [3, 3, 3, 3], [0], [0, 0, 0], [2, 0, 0, 0], [0], [3, 3, 3, 3, 3], [1, 0, 0], [3, 3, 3], [1], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 2], [0], [0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [5, 5, 0, 0], [0, 0, 0], [1, 0, 0, 9, 9, 9], [0, 0], [0, 0], [0, 0, 0], [0], [0], [0], [2, 0, 2, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 3, 0], [0], [0], [1, 1, 1, 1, 0, 0], [0, 0, 0, 0, 0], [0, 2, 0], [0, 0], [0, 0], [1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0], [2, 2, 0, 0, 0, 0, 0, 2], [0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 2, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0], [1], [0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [3, 3], [0], [0], [0, 0, 0, 0, 0], [3, 3], [0], [1], [0], [0, 0], [0], [0], [0, 0], [0, 0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [3, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0], [3, 3], [3, 0, 0, 0, 0, 0], [0, 0, 1], [0], [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1], [3, 0, 0, 0, 0, 0], [3, 3, 3, 3, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0, 0], [0, 0], [4, 4, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2], [1], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [3, 3], [0, 0], [0], [1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 1, 0, 0, 0], [0, 0, 0, 0], [0], [1, 1, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [1, 0, 2], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [12, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0], [1], [0, 0], [0, 0], [0], [3, 3], [0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [1, 0], [0, 0, 0], [0, 0, 0, 2, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0, 0], [0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0], [0, 0, 0, 0, 0], [0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [2], [0], [2, 0, 0], [0, 0], [3, 3], [1, 0], [0], [0], [0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 3, 0, 0], [3, 3], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 2, 0, 0, 4, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [1, 1, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [1], [0], [0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 4], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [3, 3], [0], [0, 0, 0, 0], [0, 0], [2, 0, 2, 0, 0, 0], [0], [0], [0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [1, 0, 1], [0, 0, 0, 0, 0, 0, 0], [2, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 3], [0, 0, 0, 0, 0], [2, 0, 1, 0, 0], [0, 7, 0], [0, 0, 0, 0], [0], [1, 1, 0], [0, 0, 0, 2, 0], [4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 2], [0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 1], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 3, 3, 0, 3], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4], [0], [0, 0], [0, 0, 2], [2, 0, 0, 0], [1, 0, 0, 0], [0], [3, 3, 0, 1, 0, 0, 0], [3, 3, 0], [0], [0, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [1], [0], [0, 0], [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 5, 0, 0], [2, 0, 0], [1, 0, 0, 0], [1], [1, 0], [0], [1, 0, 0, 0, 0], [1], [0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 2, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 7, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 3, 3], [0, 0, 0], [1], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 3, 3, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 1, 0, 0, 0, 0, 1, 0, 4, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [3, 3], [0, 0, 0, 0], [3, 3, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 14, 14, 0, 1, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 0, 1, 0, 1], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 7, 7, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 4, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0], [0, 5, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [3, 0, 0, 0, 0, 0, 0], [1], [0, 0], [0, 0, 2, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0], [0, 0], [2], [0, 0], [0, 0, 0, 0, 0], [1], [7, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [2, 0], [3, 3], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0], [0], [0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0], [1, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0], [3, 3, 0, 0, 0], [1, 1, 1, 0, 4, 0, 4, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 1, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0], [0], [1, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [1, 0, 0, 2, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [1, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [3, 3, 0, 13, 13], [0, 2, 0], [0, 0], [0], [0, 0, 0, 0], [0, 1, 0, 3], [0, 0], [0, 0, 0, 0], [1, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [1], [0], [0], [0, 0, 0], [0], [0, 0], [0], [2, 0, 2, 0], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1], [0, 0], [1, 0], [1], [1, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 3, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [1, 0, 1], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [1, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [1, 0, 0], [3, 3, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0], [0, 3], [0], [0, 0, 0, 0, 0], [0], [3, 0, 0], [0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0], [0, 0, 0, 0], [0, 0], [0, 0], [3, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0], [0], [1, 0], [1], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [1], [0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [9, 9, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 3, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [1, 1], [3, 3], [0, 0, 1, 1, 0], [3, 3, 3, 0, 0, 0, 0], [0], [0, 0, 1, 0, 0, 0], [1], [7], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [1, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [1], [0], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0], [1], [0], [0, 0, 0, 0], [2], [0, 0], [1, 0, 0, 0], [0, 0, 0, 0, 0, 3, 0, 0], [0], [0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0], [3, 3, 3, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0], [1, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0], [3, 3, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3], [3, 0, 3, 0], [1, 1, 1, 1, 0, 0, 0, 0, 0, 3, 3], [0, 0], [3, 0, 0, 0, 0, 4, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0, 0], [7, 7], [0, 0, 0], [1, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [2, 0, 0, 0], [0, 0], [0], [1, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0], [0, 0], [0, 1, 0, 0, 0], [3, 3, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0], [3, 0, 0, 0, 0, 0, 0], [0], [3], [0, 0, 0, 0, 1, 1, 1, 0, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [2, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 0], [1, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0], [3, 0], [0, 0, 0], [0, 0, 0, 0], [6, 6, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 9, 9, 0, 0], [0, 0, 0], [0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0, 0], [3, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0, 0, 1, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 0, 3, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 3, 3], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 2], [0], [0, 0], [0, 0], [0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 3, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 7], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [3, 0, 0], [0], [0], [3, 0, 0], [0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0], [0], [2, 0], [0, 0, 0, 1, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0], [0, 0], [0], [0, 0], [3, 3, 3], [1], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0, 0, 0, 0], [1], [0], [1], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0], [0], [2, 0, 0], [3, 3], [0, 0, 0], [0], [0, 0, 0, 0, 12], [1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 1], [0, 0, 0, 0, 0, 0, 0], [1], [0], [2], [0], [0, 2, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 5], [1], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0], [3, 3], [0], [0], [0, 1, 0, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0], [0], [4, 4, 0], [0, 0], [0], [0], [0], [1], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [3, 3, 0], [3, 3], [1], [0, 0], [0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 2, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [1], [0], [0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 2], [0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 3, 0], [3, 3], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [2], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [1, 0, 0], [1, 1, 1, 1, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [1, 1, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0], [3, 0, 0, 0], [0], [1], [0, 0, 0, 1], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 1], [0], [0], [0], [1, 0, 0, 0, 0], [0], [3, 3, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [3, 3, 3, 0, 3, 3, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [9, 9], [0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 2, 1, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0, 7], [0], [0, 0, 0], [3, 3, 0, 0, 0], [0], [3, 0, 0], [2, 0, 0, 0, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 1], [0, 0], [0], [0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0], [1], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0], [0], [1], [0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [1, 0, 0], [0, 0, 0], [0, 0, 3, 3, 0, 2, 0, 0, 0, 0], [0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 7, 0], [0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2], [0], [0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [3, 3], [0], [0], [2, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [1], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [3, 3, 3], [0, 0, 3, 3, 0, 3, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0], [0], [0, 0], [2], [0], [3, 3, 3], [0, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 2], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [2, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 3, 0], [0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [1], [0, 0, 0, 0, 0, 0, 0, 7, 0, 2, 0, 0, 7, 0], [0], [0], [0, 0, 0], [5, 0, 0, 0], [1], [0, 0, 0], [0, 1, 0, 0], [0], [0, 0], [0], [0], [0], [0], [0, 0, 0, 2], [0], [0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0], [0, 0, 3, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0], [0], [0], [0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 2], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0], [7, 7, 0, 0, 0, 0, 0, 8, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3, 3], [0], [3, 3, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1], [1], [0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 3, 3], [0], [1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [1, 1], [0], [0], [1], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [2, 0, 0, 0, 0], [1], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [3, 3, 0, 0], [0, 0], [0], [3, 3, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 3, 3, 0, 0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0], [0, 0, 1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [3, 3], [0], [0], [0], [1, 1, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [1, 1, 1, 1], [0], [0], [0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 1], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 3, 3], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0, 0, 0, 0], [0, 0], [1], [0], [0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [2, 0, 0], [0, 0], [1, 0, 4, 4, 0], [0], [0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0], [0], [3, 0, 3, 0, 0, 0], [1], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 2, 0, 2, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [3, 3, 0], [0], [0, 0], [0, 0, 0], [2, 0], [3, 0, 0], [0, 0], [2, 0], [0, 0], [0, 0], [1, 1, 0, 2, 0, 0, 0, 0, 0], [1], [3, 3, 3], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [2, 0, 2], [0, 0], [0, 0, 0], [0], [3, 3, 3], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 3, 3, 3], [1, 1, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [7, 0], [0, 0, 0], [0, 0, 0, 0, 0], [2, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 0, 3, 3, 0, 0, 0], [0], [0], [0, 0, 0, 3, 3], [0], [0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [8, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3], [0], [0], [0, 0, 0, 2, 0], [0, 0, 0, 0, 0], [1], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [1], [0, 0, 0, 0], [0], [3, 0, 0, 0, 0], [0, 0], [0], [1], [0], [0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [0], [2, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [3, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [1, 0, 3, 0], [0], [2], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 2, 0], [3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 8, 0], [0], [0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0], [0], [0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [1, 0, 0], [0, 0, 0], [3, 3], [1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0], [1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 3, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 1, 0, 3, 3, 0, 0, 0], [2], [0], [1], [3, 3], [0], [0, 0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [1], [0, 0], [0], [2, 0, 0], [0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [2, 0, 0], [0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 3, 3, 3, 0, 0], [0], [0], [3, 0, 0, 0, 0, 0], [0, 0, 0, 3, 3], [2, 0, 0, 0, 0], [0, 2, 0, 2, 2], [0], [1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0], [1], [0, 0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0], [1], [0, 7], [0], [0, 0, 0, 0, 0, 0], [0, 0], [1, 1, 1, 0], [1], [2, 0], [0, 0], [3, 3, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [0, 0, 0], [2], [0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [2], [0, 0, 0, 0, 0, 0], [0], [7, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [3, 3, 0, 3, 3, 0, 0, 0], [3, 3, 0, 0, 5, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 2, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [1], [0], [3, 3], [2, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0], [0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 1, 1, 0], [0, 0], [0, 0, 0], [0], [0], [1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0], [3, 0], [0, 3, 3, 3], [1], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 1, 0], [0], [0, 0, 2, 1], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0], [0], [0, 0], [0, 0], [1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 1, 1, 0, 0, 1, 0, 1, 0], [3, 3, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [1], [1, 1, 0, 0, 0, 0, 0], [0], [1, 1, 0, 0], [1], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 3, 3, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [5, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0, 0], [1, 0, 0], [0, 0, 0, 0, 0, 0], [0], [1, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0, 0], [0], [2], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 3, 3, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [3], [0], [0, 0, 0, 0, 0, 0], [0], [3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [1, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 3, 3, 0, 0], [0], [0, 0, 0], [1, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 2, 0], [3, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0], [0, 0], [0, 0], [0, 0], [0, 0], [5, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0], [2, 0, 0], [0, 0], [0, 0], [0, 0], [3, 3, 0], [0, 0, 0], [0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 2, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0], [4], [0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2], [0], [0, 0, 0, 0], [5, 0, 3], [0], [0, 0], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [11, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0], [3, 3, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [1], [0], [0, 0, 0], [0], [1, 1, 1, 1, 0, 0], [0], [2, 0, 2], [0, 0, 0, 0], [0, 0], [0], [0, 3], [0], [0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 3, 0, 0], [0], [0, 0], [3, 0, 0, 0, 0, 0], [1], [0], [0, 0, 1, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0], [1, 0, 0], [0], [0, 0, 0, 2, 0, 0, 0, 6, 6, 0, 0, 0, 0], [0, 0], [0], [3, 3], [0, 0], [3, 3], [0], [0, 0, 0], [0, 0, 0], [2], [0, 0], [5, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 3, 3, 0, 0], [0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 3, 0], [0, 0, 0, 0], [0], [1], [0, 0], [0, 0, 1], [3, 3, 3], [0, 0, 0], [0, 0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 7, 7, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0], [0, 0, 0, 0], [0], [0, 3, 3, 3, 0, 0, 0, 0, 0, 0], [2], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 3, 3, 3], [0], [2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 2], [1, 0, 2], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [1, 0, 0], [1], [0, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 2, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [3, 0, 0], [3, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [3, 3, 0], [0], [0, 0, 1], [0, 0, 5, 0, 0], [3, 3], [0], [0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [1], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0], [0, 0, 0, 0], [3, 0, 3], [0], [1, 0, 1], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [1, 0, 1, 0], [3, 0, 0], [0], [0], [0], [0, 1, 0, 0, 0, 0, 0, 0], [0], [0], [0], [3, 3, 0, 0], [2, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 7, 0, 0, 0], [0], [0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0], [0], [3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [3, 0, 0], [0], [1], [1], [0, 0], [0], [0, 0, 0, 0, 0, 0], [3, 3, 3, 0, 2], [0], [0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [2, 0, 0], [0, 0, 0], [0], [0], [0], [1, 1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [1], [1], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 2, 0, 0], [0], [0], [0], [0], [5, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 1, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 2], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [3, 3], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0, 0], [6, 6, 6], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0], [0], [1], [0, 4, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 0], [0, 0], [0, 0, 0], [0, 0, 0, 8, 0, 0, 0], [3, 3, 3], [0], [0, 0], [0, 1, 0, 3, 3, 0, 6, 6, 6], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [2, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [1, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 3, 3], [1, 0, 0, 0, 0], [0, 0, 0, 0, 9, 9, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [1, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 2, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [2, 0, 0], [0], [0], [0, 0, 1], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [1, 1, 0, 0], [0], [0, 0, 0, 0, 1], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 7, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0], [3, 3, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 9, 9], [0], [0, 0, 0], [0, 0, 0, 0], [5, 0, 0], [3, 3, 0, 0], [1, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0], [0, 0], [1, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 3], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], [0, 0, 0, 0, 2], [0], [0, 0, 0, 3, 3], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0], [2], [0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [5, 0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 7, 7, 7], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [11, 11, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0], [2, 1, 0, 0, 0, 0, 0], [0], [0, 0], [2, 0], [0], [3, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [0, 0, 1, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [3, 3], [0, 0, 0, 0, 7], [0, 0, 0, 0, 0], [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 9, 9, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0, 0], [0], [0, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [0], [9, 9, 9, 0, 0], [0], [3, 3, 3, 3, 3, 0, 0, 0], [0, 0, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [1, 0, 1, 0, 1, 0, 1], [3, 3, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0], [0], [0], [0, 0, 0], [1, 0], [0, 0, 0, 0, 0, 0], [4, 0], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 9, 9, 0, 0], [0, 0], [0], [0], [0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3], [3, 3], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 4], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [1, 1, 1, 0], [0, 0, 0], [0, 0, 3, 3], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 3, 3, 0, 0, 0], [0, 0, 0, 0], [0], [0, 3, 3], [0], [2], [0, 0, 0], [0, 0], [0, 0, 0, 2, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3], [0, 2], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0], [0, 0], [0], [0, 0], [0], [1, 0, 0], [0, 0, 0], [0], [0, 0, 0], [1, 1, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0], [0], [3, 3, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0], [3, 0, 0, 1, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 0, 1, 0], [3, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 2, 0, 7, 0, 0, 0, 0], [0, 0], [2], [0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0], [0], [1, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 3, 3], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1], [1], [1, 0, 0], [0], [0], [0], [3, 3, 0, 0, 0, 0], [0, 0], [0, 2, 0, 0, 0, 0], [2], [3, 3, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0], [1, 0, 0, 2, 0, 0, 0], [0, 0], [0], [3, 3], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1], [0, 0, 0, 0], [0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [0], [0, 0], [0], [1, 1], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0], [3, 0, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0], [1, 0, 2], [0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [3, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [0, 0, 0], [0], [0], [2, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 3, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [1, 0, 0, 0, 0], [0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 2, 0], [0], [0, 0, 0, 0], [0], [0], [1, 1, 0, 9, 9, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [2], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 1], [3, 3, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 0, 0, 0, 3, 0, 0, 0, 0, 3], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [3, 3, 0, 0], [0, 0], [0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 7, 7, 0], [0], [0], [0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 1], [0, 0, 3, 0, 0, 0], [0, 0], [3, 3], [2, 0, 0, 0, 0], [0], [0, 0, 0], [1], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [1], [0, 0, 0, 0, 0], [3, 3, 3, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0], [6, 6, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0, 0, 0], [0, 1, 0, 0, 1, 0, 0], [0, 0, 1, 0, 11, 0, 0, 0, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 0, 1], [0], [3, 0, 0], [0, 0], [0, 1], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 0, 0], [2, 0, 2], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 0], [3, 3, 3], [0, 0, 0, 3, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 3], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0], [0], [0], [9, 9, 0], [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 3, 0, 0], [1], [0], [0, 0], [0], [0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [3, 3, 3], [0], [3, 3, 3, 3], [0], [0, 2], [0], [3, 0, 0, 0, 0], [0], [0], [1], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0], [0], [0], [3, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [3, 3, 3], [0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [0, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [0, 7, 7, 7], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0], [0, 0], [0], [2, 0, 2, 0, 2], [1, 0, 8, 0, 0], [0, 0, 0], [0, 0], [0], [0, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [2, 0, 0], [0, 0, 0, 0, 3, 0, 0], [0], [3, 3, 0, 0, 0, 0], [2, 0, 0], [0], [0, 0, 0, 0], [1, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 2, 1, 0, 3, 3, 3], [0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0], [0, 0], [0], [0, 3, 3], [0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [3, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [1], [0, 0, 0, 0, 6, 6, 6, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], [0], [3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [3, 3, 0], [0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3, 0, 1, 0], [0], [0, 0, 0, 0, 0, 0], [0], [1, 1, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [1, 1, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0], [1], [0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0], [0], [5, 0, 0], [2, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0], [0, 0, 0, 0], [0, 3, 3, 0, 13, 13, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0, 3, 0, 0], [0, 0, 0, 0, 0, 3, 3], [0, 0], [0], [0, 3, 3, 3], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 0, 0], [0], [0, 0, 0, 1, 0, 0, 0, 0, 12], [1, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 1], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [3, 3, 0, 2, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 4, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 2], [0, 0], [0], [0], [0, 0, 0, 0], [0], [0, 0], [1, 1, 1, 0, 0, 0, 0, 0], [3, 3, 3], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [6, 6], [3, 0, 0], [0], [0, 0, 0], [1, 0, 0, 0], [1, 0], [3, 3], [0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [1], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [3, 3, 3, 0, 0], [0], [0], [0, 3, 0, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0], [0], [3, 3], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0], [0, 0], [1, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0], [0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [3, 3, 3, 0], [3, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [2, 0, 2], [0], [0], [3, 3], [3, 0, 0], [3, 3, 0, 1], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0], [0], [0], [0, 0, 1, 0, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 2, 0, 0, 0, 2], [2, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [1], [3, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [8, 0, 0, 7, 7, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3], [0], [0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3], [0, 0, 0], [0, 0, 0, 3, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [1], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 1, 0, 2, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0], [3, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0], [0], [1, 0, 1], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 9, 9, 0, 0], [3, 3], [1, 0, 13, 13, 13], [1, 1, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 3, 0], [0, 0, 0], [0, 1, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0], [0], [0], [1, 0, 1], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 2, 0], [0, 0, 0], [0], [0], [0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [2, 0, 2, 0, 0, 0], [0], [3, 3, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0, 0, 4], [0], [1, 0, 3, 3, 3, 0, 0, 17, 2, 0, 0, 0, 0, 0], [0, 0], [0, 2, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [2, 2, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [5, 0, 5, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0], [0], [0, 3, 0, 0], [3, 3], [1, 0, 0, 3, 3], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0], [0], [1, 0], [0, 0], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0], [0], [0, 0], [0, 0, 0, 4, 0, 0, 0, 0], [9, 9], [0], [0, 0, 0, 0], [0], [0], [1, 1, 1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0], [3, 3], [2], [0, 0, 0], [3, 3], [0], [0, 0, 2, 0, 0], [0], [0, 16, 0, 0, 0, 0, 0, 0, 4], [1, 0, 0], [2], [0, 0, 0], [0, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 3, 0, 0, 1], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [1, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [1], [3, 3], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1], [0], [0, 0], [0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 3, 3], [0], [0, 0], [0, 0, 2, 0], [0, 0, 0, 0], [3, 3, 3, 0, 0, 0], [1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [3, 3, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 2], [0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0], [2], [0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [3, 3, 0, 0, 0], [0], [0], [0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0], [0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 0, 0, 3, 3], [0], [1], [3], [0, 0, 0, 0], [3, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0], [0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [1, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 0], [2, 0, 0, 2, 0, 0, 6, 6], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [2, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [5, 0], [0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [3, 3, 3], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 3], [0], [0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 2, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0], [0], [0, 0, 0], [4, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 0], [0], [3, 3, 3, 3], [0, 0, 0, 0], [0, 0], [3, 3], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0], [0], [1, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2], [0, 0, 0, 0, 0], [1, 1], [0, 0, 0], [0, 0, 0, 0, 2], [0], [0, 0, 0], [0], [0], [16, 16, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [3, 0], [0], [3, 3, 3], [0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 3, 3, 0], [0], [3, 0, 3, 3], [3, 3], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3, 3], [0], [0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 2, 0, 0, 0, 2], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0], [0], [0, 0, 0], [0, 0], [2, 0, 0, 2, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 4, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [2], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 3, 3, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 13, 13, 13, 13, 0, 0], [0], [0], [2, 0, 0], [0, 0, 0, 0], [0, 4, 4, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3], [0], [0, 0, 0], [0, 0, 0, 0, 9, 9], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 2, 1], [0], [0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [1], [3, 3, 0, 0, 0], [0, 0], [0], [0], [3, 3, 0, 3, 3], [0, 0, 0], [0, 0, 0], [1, 0, 0], [0], [0, 0, 0], [3, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 2, 0, 0], [0, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 3], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [2, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0], [0], [9, 9, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 4, 0, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0, 4], [1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2], [0, 1, 0, 0, 0, 0, 0], [0, 0], [1, 0, 0], [1, 0, 0], [1], [3], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [1, 0, 3, 3], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0], [0], [0, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0], [0, 0], [0], [3, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 0], [0], [0], [0, 0], [1], [0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3], [2], [3, 3], [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 13, 13, 0, 0, 1], [1], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 5, 0, 0, 0], [0], [0], [0, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7], [1, 0, 0], [0], [0, 2, 0], [3, 3, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [1, 0, 0, 0, 1], [0, 0], [0, 0], [1, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [1, 1], [0, 0], [1, 1, 0, 11, 11, 11], [0, 0, 3, 3], [0], [3, 3, 0, 2], [0, 0, 0], [0], [0, 0, 0], [1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 18, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0], [1, 0, 0, 0], [0, 0], [3, 3], [0], [0], [0], [0, 1, 0, 0, 0, 0, 0, 0, 2], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [3, 0, 3, 3, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [2, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [1, 1, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0], [0], [0, 0, 1], [0, 0, 7], [0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0], [0, 0, 0, 0], [0, 0], [0, 0, 3, 0], [0], [0], [0, 0, 0, 0], [0], [2, 0, 2], [0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 3], [0], [0], [4, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0], [0, 0, 0], [0], [0, 0, 2, 0], [1, 1, 1, 1, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 1], [0], [0, 0], [0, 0], [0], [0, 0], [0], [0], [0], [0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2], [3, 3, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 3, 0, 0], [0, 0, 0, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0], [0], [0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [1], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0], [3, 3, 0, 2], [0, 0, 0, 0, 0, 0, 0], [0], [3, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [2, 0], [1, 0, 3, 0, 0, 0, 0], [0], [0, 2, 0, 0, 0, 0, 0, 5, 0], [0, 0, 0], [0, 0, 0, 2, 0, 2, 0, 0, 2, 2], [1, 1], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 7, 7], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 2, 0], [0], [0, 0], [0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0], [0], [0], [0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 11, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [3, 3, 0], [0, 5], [3, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [5, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0], [3, 3, 3, 0, 0], [0], [0], [0], [0], [0], [0], [0, 0], [0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2], [0, 0, 2, 0], [0, 0, 0, 0, 0], [0], [0], [9, 9, 9, 9, 0, 0], [1], [1], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [1, 1, 1, 0, 0], [1, 0, 0, 1, 0, 0, 0], [0], [3, 0, 3, 3, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 1, 1, 1, 0], [1, 0, 2, 0], [0, 0, 0], [0], [0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [1], [3, 3, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0], [1, 0], [0], [0], [0], [0], [4, 0, 0, 0, 0], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 4, 0, 0], [0], [0, 0, 0], [0, 0, 0], [2, 3, 0, 0, 3, 3], [0, 0, 0, 0, 0], [0, 0, 0, 0, 7, 7], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 3, 3, 3, 0], [1, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 1, 0, 0], [3, 3], [0], [0], [0, 1, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [3, 3, 3], [0, 0], [0], [0, 0, 0], [0], [0], [1, 0, 1, 0, 0], [0, 0, 0], [0], [0], [0], [3, 3], [0, 0, 0, 0], [3, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0], [2], [0], [0, 0], [1, 0, 1], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [3, 3, 0, 1], [0, 0, 0, 0, 0], [0], [0], [3, 3, 0], [0], [0], [0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 5, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 1, 0], [0, 0, 0], [0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [2], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [3, 0, 0, 0], [0, 0, 0, 0], [1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [3, 3, 0], [0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 2, 0, 0, 0, 0, 0], [2, 0, 0], [0], [0], [0, 0, 4, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0], [2, 0, 0], [0], [0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [3, 3], [0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0, 0, 0], [0], [2], [0], [0, 2], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0], [1, 0, 4], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 1], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 1, 0, 2, 0], [0], [0, 0, 0], [0, 1, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [3, 3, 3], [0, 0, 0], [0, 0, 0, 0], [1, 0, 0], [3, 3], [0], [9, 9], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0], [0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0], [1, 0], [0], [3, 0, 0, 0, 0], [0, 1, 0, 0, 0, 1], [4, 0], [0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [2], [0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 0, 0], [3, 3, 0, 3, 0, 0, 0, 0, 3, 0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0], [3, 3], [0], [0], [0, 9, 9], [0, 0, 0], [3, 3], [1, 0, 0, 0, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 0], [0, 0], [0], [0, 0], [0, 2], [0], [0], [0, 0, 0], [0], [3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [2, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [1, 1, 0], [3, 3, 0, 0], [0, 0, 0, 2, 0], [0, 0, 0, 2, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 2, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 1, 0], [0], [0, 0, 3, 3], [0], [0, 0], [0], [0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [4], [0], [0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 0, 0], [0, 0], [3, 3, 0, 0], [3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 0, 0, 5, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [2, 0], [0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [3], [0, 0, 0, 0, 0, 2, 0], [0], [3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [1], [1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0], [1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [1], [3, 3, 3], [0, 0, 0, 0, 1], [9, 9, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [4, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0], [0], [1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 2], [0, 4], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 1, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 2, 5, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0], [1], [0, 0], [0, 0], [4, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [1, 1, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 3], [0, 0, 0, 0], [1, 1, 1, 0], [0, 0], [0], [0], [0, 1], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 5, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 3, 0], [0], [5, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0], [1, 1], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0, 4, 0, 4, 0, 0, 0, 0], [0, 0, 0], [0, 0], [3, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0], [3, 3], [0, 0, 0, 0], [0, 0, 7, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 1], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3], [1, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [1], [0], [1, 0, 0, 3, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 0], [0], [0], [7, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 2, 0], [3, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1, 0, 0], [0, 0, 0, 6, 6, 6, 0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0], [0], [0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 2], [0], [0], [1], [0, 0], [0], [0], [0], [0, 0, 2, 0, 2, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [1], [0, 1, 0], [0, 0, 0, 0, 0, 0], [0], [0], [1, 0, 0, 8, 0, 1, 0, 0, 0, 0, 0], [1, 1, 0, 0], [0], [0, 2, 0], [0], [2], [0], [0], [1, 0, 0, 0, 0, 0, 0], [0], [0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0], [1, 1, 0, 0], [2, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [3, 0], [1, 1, 1, 1], [0, 0, 0, 0, 0], [0], [1, 0, 0, 0, 1], [0], [0, 0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [1, 1, 1, 1], [0], [0, 0], [0], [0, 0, 0, 0, 3], [0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 3, 0, 0, 0, 2, 0, 0, 0, 0], [0, 0], [0], [3, 3, 3], [0], [1, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 10, 10, 0, 0, 0], [0], [3, 3, 0, 3], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1], [0, 0, 0, 0], [2, 0], [0], [0, 0], [0], [3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0], [1, 0, 0, 0], [3, 3], [0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0], [0], [1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [9, 9, 0, 0, 0], [0, 0, 0], [0], [0, 4], [0], [0, 0], [0, 0], [3, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0, 0, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [2, 0, 0], [0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], [0], [0, 0, 3, 3], [0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [3, 3, 0, 0, 0, 0], [1], [3, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0], [1], [2, 0, 0, 0, 2, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 5, 0], [0], [3, 3, 3], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0], [0], [0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 7, 0, 0], [0, 0, 0, 0, 0], [1, 0, 2], [0], [0, 0, 0, 0, 0, 0], [0, 0], [3, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 6, 6], [0, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [1, 0, 3, 3], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 2, 0, 0, 0, 6, 6], [0, 0], [0, 0, 0, 0, 3, 3, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 5], [0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [4], [0, 1, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0], [3, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 7, 7, 7, 0, 0], [0], [0], [7, 0], [2, 1, 1, 1, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0], [3, 3], [2, 0, 0], [1, 0], [0, 0, 0, 0, 9, 9, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0], [3, 3, 3], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [4, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [1, 0, 0], [3, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0], [0], [1, 1, 0, 3, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0], [3, 3], [1], [0], [0, 0], [0, 0, 0], [0], [0], [0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 13, 13, 13, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 3, 3], [0], [3, 3], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0], [0, 0, 0, 0], [1, 0, 0, 0], [3, 3], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 3, 0, 0, 0], [0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0, 0], [3, 3, 0], [0, 0, 0, 0, 0, 3, 3], [0], [0], [0, 0, 0, 0, 2, 0, 0, 0], [0], [0, 0], [3, 3, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0], [0, 0, 2], [0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 1, 1, 0], [3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0], [0, 0], [1], [1], [3, 3], [0], [0, 0, 3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0], [3, 3, 0], [1, 1], [0], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0], [7, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 2], [6, 6, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 3, 0], [5, 0, 0], [3], [0, 0], [0, 0], [0], [0, 0], [0, 9, 9, 9, 0, 0], [3, 0, 0, 0, 0, 0], [0], [0], [2], [0], [0], [2, 0, 0, 0, 0, 0, 0], [0, 0, 0], [1], [3, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0], [2], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [1, 0, 1, 0, 0], [0, 0, 0], [1, 1, 1, 1, 0, 0], [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 3, 3, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 5, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0], [0], [0, 0, 0, 1, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 2], [0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 2, 0], [0], [0, 0, 0, 0], [0, 0, 2, 0, 0], [0], [0], [0], [0], [3, 3, 3, 0, 0], [0, 0, 0], [3, 3, 3], [1, 0], [0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0], [0, 0], [3, 3, 0, 0, 0], [0], [1, 0, 0], [1, 0, 1, 0, 0, 0, 0, 0], [2], [0], [0], [0], [0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 3, 0, 0], [0], [3, 0, 0], [2, 0, 0, 0], [0, 0], [3, 3, 3, 3, 3], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 0, 3, 0, 0], [3, 3, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0], [1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [3, 0, 0, 4, 0], [0], [3, 3], [0], [0], [1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9], [0], [0, 0], [0, 0], [0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 2, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [3, 3], [0, 0], [0, 0, 1, 0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0], [0], [0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 2, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [3, 3, 3, 0, 0], [0, 0, 9, 9, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 1, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0], [3, 3, 0, 1, 1, 0, 0, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1], [6, 6, 0, 0, 0], [0], [3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 1], [1, 0, 0, 4], [0], [0], [0], [0], [0], [0], [0, 0, 0], [0], [0, 0], [0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [3, 0, 0], [1], [0, 0, 2, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 11, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [11, 11, 11, 11, 0, 0, 0, 0, 0], [3, 3, 3, 0], [0, 0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0], [1], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0], [0, 0, 1], [3, 3, 3], [0, 0, 0, 0], [0], [0], [3, 3, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [2, 1, 0, 0, 0], [0], [1], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [1], [0, 0, 0, 0], [1], [0, 0], [0], [0, 0], [2, 0], [0], [0, 0], [0], [0], [3, 3, 3, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0], [3, 0, 0, 0, 0, 0], [1, 0, 3], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 2], [0, 0, 0], [1, 0, 0, 9, 9], [0, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [0], [2, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [1], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5], [4], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0], [0], [0], [3, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1], [3, 3, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 3, 3], [1, 0], [1, 0, 1, 0], [0, 0, 0, 0, 0], [0, 0, 0, 7, 7, 7, 0, 0, 0, 7, 7, 7, 0, 1, 0, 2], [0, 2], [0], [0, 0, 0, 0, 0], [0], [2, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 1, 1, 0, 0], [0, 0, 0, 0], [1, 1, 1, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 2], [0], [0, 0, 2, 0], [3, 3, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [9, 9], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [7, 0, 0], [0, 0, 0, 0], [0, 0, 0], [3, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0], [1, 0, 1, 0, 0, 0], [2, 0, 0, 0, 0], [3, 3, 3, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [1], [0], [0, 0, 0], [0, 0], [1], [3, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 2, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [0, 0, 1], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 4, 0], [0], [1, 1, 1, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [1], [0], [0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 1, 0, 0], [0, 0], [1], [0, 0], [2], [0, 0, 0, 0, 0], [1], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [4], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 10, 10, 10, 10], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [3, 3, 0, 0, 0, 0, 2], [0], [0], [2, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 1, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [1, 0, 1], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0], [1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 4, 0, 3, 0, 0], [0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [1], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 1, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [2, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 3, 3, 3], [0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0], [0, 2, 0], [0, 0], [3, 3, 0], [0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 3, 0, 0, 0], [7, 0, 4, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0], [0], [1, 0], [1, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [1], [0], [0, 0, 0, 0, 6, 6, 0, 1, 0, 0, 0, 0, 0], [0], [0, 3, 0, 0], [0, 0, 0, 0], [2, 0], [0], [0, 0, 0, 0], [0, 0, 0], [0, 0], [1, 0, 0, 0, 0], [3, 3], [0, 0], [3, 3], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [3, 0, 0, 0], [0, 12, 0, 0], [0, 0, 0, 0], [1], [2, 0, 0, 0, 0, 0], [0, 0], [0, 0, 1, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3], [0, 2], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 3, 0, 0], [0, 0, 2, 4, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 2, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0], [2, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 3, 3, 0], [0, 0, 0], [0], [3, 3], [0, 2, 0, 0, 2], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [1, 0, 0], [3, 3, 0, 0], [0], [0], [1, 0, 0, 0], [0], [0], [0, 0, 0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [3, 3], [3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0], [0, 0], [3, 3], [0], [0], [3, 0, 0, 0, 0], [0, 0, 0], [3, 3], [0], [0, 0, 0, 2, 0], [0, 0], [0, 0], [0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0, 0], [3, 3, 3], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 7, 7, 7], [0, 0, 0], [0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 5, 5, 0], [0, 0, 0], [0, 0, 0], [0, 4, 4, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [3], [1, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 6, 6], [0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 2, 0], [0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 1, 0, 0, 0, 0, 0], [2], [1, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 8, 2, 0], [0, 0, 0, 0, 0, 0], [2], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 0], [3, 0, 3, 3, 0], [0], [0, 0, 0], [0, 0], [0], [0], [0], [0], [0], [0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0], [1, 0, 1], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0], [0, 0], [0, 0, 0], [0], [2, 2], [0, 0, 0], [0], [0, 0, 0, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [3, 3, 0, 0], [1, 0, 1, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 6, 6, 6, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [1, 0, 0, 0, 1, 1, 0], [0], [0, 0], [0], [0, 0], [0, 0, 0], [0, 3, 3], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2], [0, 3, 3, 0, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 3], [0, 0, 0, 0], [3, 0, 0], [0], [0], [0, 0, 2, 0, 0, 0, 0], [0, 0], [0, 0, 0], [2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [2, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [16, 16, 0], [3, 0, 0], [0], [0], [2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [3, 3], [0, 0], [4], [0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 6, 6], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0], [3, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [6, 6, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 1, 0, 3, 3, 0, 0, 0, 7], [0], [0], [0, 0, 0, 2, 0, 0, 2], [0], [0], [0, 0, 5, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0], [0, 0, 0], [0, 0], [0, 0], [4], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [1], [3, 3], [3, 0, 0, 0, 0, 0], [1, 1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [0], [0], [1, 1], [3, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 2, 0, 0], [0, 3, 3], [0], [0, 0], [1], [0, 0, 0, 0, 0], [0, 0], [0, 7, 7, 7, 0], [0], [1, 0, 0, 0, 0, 0], [0], [0], [3, 3, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [3, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 5, 0, 0, 0, 0, 0], [3, 3], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 15, 15, 0, 3, 0, 0, 0], [0], [0], [0], [0, 0], [0, 0, 0], [1, 0], [1], [0, 0], [0], [0, 0, 0, 0], [0], [0, 3], [0, 0], [0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [3, 3, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0], [0], [2, 2], [0], [0], [1, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0], [0, 0, 0], [3, 3, 3], [0, 0, 0, 1, 0, 0, 0, 0], [0], [1, 0, 1, 0, 0, 0], [0], [7, 7], [0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 1, 0, 0, 0, 0, 0, 0], [0], [3, 3], [0], [0, 0, 3, 0, 0], [0, 0, 2, 0, 0, 6, 6, 6, 6, 2, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0], [1], [1, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 5, 0, 0, 3, 3, 3], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0], [0], [2, 0, 0], [2, 0, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0], [0], [0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 3, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 3], [0, 0, 0], [1], [3, 0, 0], [0, 0, 0, 0], [0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 7, 7, 0, 0], [0, 0, 0, 0], [0, 0, 0], [3, 3, 0], [3, 3, 3], [0, 1], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 7], [0, 0, 0, 2, 0], [0, 0], [0, 0], [3, 0, 0, 0, 0, 0, 3], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 0], [0], [0], [1, 0, 0], [3, 0, 0, 0, 8, 0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0], [0], [0], [1, 1, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 0], [2], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0], [0], [3, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 7, 0, 3, 3, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0, 0], [0], [3, 3, 3], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [3, 0, 0], [0, 0, 0], [0], [0, 0], [0, 0, 0, 0], [0], [0], [0], [0, 0, 0], [2, 0], [0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0], [0], [0], [3, 0, 0, 0, 0, 0, 0], [2], [3, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0], [0], [0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 9, 9], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0], [1, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 4, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [1, 0, 0, 0, 0], [0, 0, 0], [1, 0, 0, 0, 0, 0, 0], [3, 3, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [0], [0, 0], [3, 3, 0, 0, 0], [0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 1, 0], [0], [0, 0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [1, 0, 0], [0, 0, 0], [0], [0], [1, 1, 0, 2, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0], [0, 0, 0, 0], [3, 0, 0, 0, 3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 2], [3, 3, 0], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 8], [0, 0], [0], [3, 3], [3, 3, 0], [0], [3, 3], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [1, 0, 0, 0, 11, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0], [1, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0], [3, 0, 0, 0, 0], [0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 7, 0, 0, 2, 0, 0, 0], [3, 3, 3], [0, 0, 0, 4, 4, 0], [3, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 2], [0, 0], [0], [3, 3, 7, 0], [0], [0], [0], [3, 3, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 4, 0, 0, 0], [0, 11, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0], [2, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 0], [0, 0], [0], [0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 7, 0, 1, 0, 2, 1, 0], [0, 0, 0, 0, 0, 0, 0], [2, 0, 9, 9, 0], [1, 0], [5, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0], [1, 0, 0, 0, 1], [0, 0, 0], [0], [0], [0], [0], [0, 0, 3, 3, 0, 0, 0], [3, 3, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0], [0], [1, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0], [3, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 0], [0, 2], [3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1], [3, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0], [0], [1, 1, 1], [0], [0, 0, 0, 0, 0], [0], [4, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [2, 0], [0, 0, 0, 0, 0], [0], [0, 0], [0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0], [0], [1, 1, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 9, 9, 0, 0, 0, 4, 4, 5, 0], [0, 0, 3, 0, 1, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [3, 3], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1], [0, 0, 0], [0, 0], [0], [0], [0], [2, 0, 0, 0, 9, 9, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [2, 0, 0, 0, 0, 0], [0, 0], [0], [1, 0], [0], [3, 3, 0, 1], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 2, 0], [0], [0], [0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0], [3, 3, 0, 0], [0], [2, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 5, 0, 0], [0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [3, 3], [0], [3, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 7, 7], [0, 0, 0, 0], [0, 0], [0, 1], [0, 0], [0], [0, 0, 3, 3], [0, 0, 0], [1, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0], [0], [7, 7, 0, 2, 0, 0], [0, 0, 2, 0], [0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [4], [0], [0], [1, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0], [3, 3, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1, 0, 0], [0, 0, 0, 0], [0], [0], [2], [0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 5], [0], [1, 0, 0], [0, 0], [0, 0, 1], [3, 3, 3], [0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [3, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 2, 0], [0, 0], [1], [0], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 8, 0], [1, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0], [0], [0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 2], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0], [3, 3, 3], [0], [3, 3, 3, 0, 0, 0], [0, 0, 0], [1, 1], [3, 3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0], [3, 3, 0, 4, 0], [2, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [2, 0, 2, 0, 2, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0], [0, 2, 0], [0], [0], [0], [0, 0], [3, 3], [3, 3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0], [3, 3, 3, 0, 0, 0, 0, 0, 0], [0], [0], [1, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0], [1, 1, 0, 0], [0, 0, 0, 4, 0], [0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 8, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [1], [0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0], [2, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [1, 1, 1, 0], [0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [0, 0], [3, 0, 0, 0], [0, 1, 0, 1, 0], [0], [0], [1, 0, 3, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 2], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0], [0], [3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [3, 3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0], [0, 0, 0], [0, 0], [1, 0], [0], [0, 0, 0], [0], [1, 0, 0, 0, 0, 0], [7, 0, 0, 0], [0], [1], [0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0], [0], [0], [0], [1, 0, 0, 0, 0], [0, 0, 0, 0], [1], [0, 0, 0], [0, 0, 0, 0], [0], [0, 0], [1, 0], [0, 0], [0, 0, 3, 0, 3, 0, 0, 0], [0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3, 3], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [11, 11, 11, 0, 2, 0, 0, 0, 1], [0], [3, 3, 0, 0], [1, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0], [1, 0, 0, 0], [0], [1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [0, 0], [1, 0, 1, 0, 0], [0], [0, 0], [0, 0], [2, 0, 0, 0], [0], [3, 3, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1], [0], [1, 1, 1], [0], [3, 3, 0, 3, 3, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0], [3, 3, 3, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0], [0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [3, 0, 0, 0], [0, 0, 0, 0, 6, 6, 6], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0], [2, 0, 2], [3, 3], [1], [0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0], [2], [0, 0, 0], [0, 0, 0], [0], [0, 0, 3, 0, 0, 0, 0, 0], [0], [1], [0, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 9, 9], [1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [1, 1], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [2, 0, 0], [0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [9, 9, 0, 0, 0], [2, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0], [0, 0, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0], [0], [3, 3], [0, 0], [3, 3, 3], [0], [0], [0, 0, 0, 0], [3, 3, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0], [2, 1, 0], [0], [0, 0], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [1, 0], [0], [2, 0, 3], [0, 0, 0, 0, 0], [1, 1, 0, 3, 3, 0, 4, 4, 0, 2, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [0, 0], [0, 0], [1, 0, 0, 0], [0], [3, 3, 3], [0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [1], [0], [0], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 1], [0, 0, 0], [3, 3, 0], [0], [2], [3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 0], [3, 3], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1], [3, 3], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 1], [0, 0], [0], [0, 0, 0, 0, 0, 0], [2, 0, 0], [0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 3, 0], [0], [0, 0, 0, 0, 0], [0, 0, 0, 2, 3, 3, 0], [0], [0, 0, 0, 0], [0, 0], [3, 3], [1, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0], [2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 0, 0, 0], [0], [1, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [3, 3, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 15, 15, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2], [0], [0], [0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0], [0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0], [0], [1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 1], [0, 0], [0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [0], [2, 0, 0], [0], [0, 0, 0, 2], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [1], [0, 0], [0, 0], [0, 0, 0], [0], [0], [0, 0, 0, 0, 0, 0, 4, 0, 0, 0], [0, 3, 3, 0, 0, 1], [0], [0, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 0, 0, 0], [1], [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [0], [0, 0, 1], [0, 0, 3, 3, 3], [0], [0, 0, 0, 0], [0, 0, 1], [0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0], [0], [1], [0], [0, 0, 3, 3, 0, 0], [3, 0, 0], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [1, 0, 1], [3, 3, 3, 3], [0, 0, 0], [0, 0, 0, 0, 0], [0], [0, 4], [0], [0], [1, 0, 0], [3, 0, 4], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [2, 0, 0], [0], [0], [0], [0], [0, 0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0, 0], [0, 3, 3, 3, 0], [0, 0], [0], [0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 1], [0], [0, 0, 0], [0, 0], [0], [0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 4, 0], [0], [0, 0], [0], [3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 4], [0, 0, 0, 0, 0, 0], [0], [0, 0, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0], [0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0], [1, 0, 0, 0], [0], [4, 4, 0], [0], [1, 1], [0], [1, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0], [0], [1, 1, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0], [1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [3, 0], [0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0], [0, 0, 0, 0], [1, 0, 0, 2, 0, 0, 4], [0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7], [2, 0], [0], [0, 0, 0, 0, 0, 0, 0], [0], [0, 0], [0, 0, 0], [3, 3, 0, 8, 0], [0], [0, 0], [0, 0], [1], [0], [0], [2, 0, 0], [0, 0, 0, 0], [0, 0], [0, 4], [0, 0], [0, 0, 0, 0], [0, 3, 0, 0, 0, 0, 0], [0, 0, 0, 2], [0, 0, 0, 0], [0], [3, 3, 0, 0, 0, 0], [0], [0, 0, 0, 0], [0, 0], [0, 0, 0, 13, 13, 13, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0, 0], [7, 7, 0, 0, 0, 2], [0, 0, 0], [0, 0], [0, 0, 0, 0, 3, 3], [0, 0, 0, 0], [0, 3], [7, 7, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [0], [0, 0, 0, 0, 0, 0], [1], [0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0], [0, 0], [0], [1, 1], [0, 0, 0, 0, 0], [0, 0], [0, 0], [0], [3, 3], [0, 0], [0, 0, 0, 8, 0, 0, 0], [0, 0, 2, 0, 7], [0], [0, 0, 0], [0, 0, 0, 0, 2, 0, 0, 0], [2, 0, 0], [0], [0], [0, 0, 0, 0, 0], [0], [0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [3, 3], [1, 1, 0, 0, 7, 7, 0], [0, 0, 0], [1, 0], [0, 2], [0], [0, 0, 0, 0], [0], [0, 0], [0, 0, 0, 0, 0, 0], [0, 0], [0, 0], [1, 0], [0, 0, 0, 0, 0, 0], [0], [0], [0], [3, 3, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 6, 6], [0, 0, 0, 0, 0, 0], [0], [3, 3, 0, 0, 0], [0, 0, 6, 6, 0, 0, 0, 0, 0], [0, 0], [3, 3, 3], [0, 0, 0, 0], [0, 0, 0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0], [0], [0, 0, 0], [0], [0], [0, 0], [0, 0], [0], [0, 0, 0], [0, 0, 0, 0, 0], [0], [3, 0, 0, 0, 0], [1], [0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3], [0, 0], [0, 0, 0, 0], [3, 3], [0, 0, 0, 0], [1, 0, 0], [0, 0], [0], [0, 4, 0, 0], [0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0], [0], [2], [1], [0, 0], [0, 0, 0, 0], [0], [0, 0, 0, 0, 3, 0, 0], [0, 0], [1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0], [1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
            "8705\n",
            "8705\n",
            "8705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Domain (w2v using dota2 chat corpus)"
      ],
      "metadata": {
        "id": "OUfV3IdKUJpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from gensim.models import FastText\n",
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "# kaggle download dota2 in-game chat corpus\n",
        "id = '1iWIZ_eC5-QddHVowDmaqjtABkMfRL_q3'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('dota2_chat_messages.csv')\n",
        "download_data = pd.read_csv('dota2_chat_messages.csv')\n",
        "download_data.head()\n",
        "\n",
        "def is_english(sentence):\n",
        "  return all([(ord(c) < 128) for c in sentence])\n",
        "\n",
        "x_download = []\n",
        "for i in download_data['text'].tolist():\n",
        "  if is_english(str(i)):\n",
        "    x_download.append(str(i))\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "ft_model = FastText(sentences=[x_download[i].split() for i in range(len(x_download))], size=250, window=5,min_count=2, workers=4,sg=1)\n",
        "EMBEDDING_DIM = 250\n",
        "import pickle\n",
        "embedding_matrix_domain = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix_domain.append(ft_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix_domain.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix_domain = np.array(embedding_matrix_domain)\n",
        "\n",
        "\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/domain/'\n",
        "\n",
        "\n",
        "\n",
        "f = open(dir+'domain_emb_new.pkl', 'wb')\n",
        "pickle.dump(embedding_matrix_domain, f)\n",
        "f.close()\n",
        "'''\n",
        "import pickle\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/domain/'\n",
        "embedding_matrix_domain = pickle.load(open(dir+'domain_emb_new.pkl', 'rb'))\n"
      ],
      "metadata": {
        "id": "SJf4EY44SfRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Semantic "
      ],
      "metadata": {
        "id": "jq_pdgXCo1mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "import pandas as pd\n",
        "\n",
        "'''\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "!git clone https://github.com/usydnlp/CONDA.git\n",
        "conda_1 = pd.read_csv('/content/CONDA/data/CONDA_test.csv')['utterance'].tolist()\n",
        "conda_2 = pd.read_csv('/content/CONDA/data/CONDA_train.csv')['utterance'].tolist()\n",
        "conda_3 = pd.read_csv('/content/CONDA/data/CONDA_train.csv')['utterance'].tolist()\n",
        "conda = conda_1+conda_2+conda_3\n",
        "for i in range(len(conda)):\n",
        "  conda[i] = str(conda[i])\n",
        "\n",
        "#wv_sg_model = Word2Vec(sentences=[conda[i].split() for i in range(len(conda))], window=1, size = 5,min_count = 0, workers=4,sg=0)\n",
        "ft_model = FastText(sentences=[conda[i].split() for i in range(len(conda))], size=250, window=5,min_count=2, workers=4,sg=1)\n",
        "EMBEDDING_DIM = 250\n",
        "import pickle\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix.append(ft_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "\n",
        "\n",
        "\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/sym/'\n",
        "\n",
        "\n",
        "\n",
        "f = open(dir+'sym_emb.pkl', 'wb')\n",
        "pickle.dump(embedding_matrix, f)\n",
        "f.close()\n",
        "'''\n",
        "import pickle\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/sym/'\n",
        "embedding_matrix = pickle.load(open(dir+'sym_emb.pkl', 'rb'))\n"
      ],
      "metadata": {
        "id": "eWF13E27sa4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "glove 25(ignore, not used.)"
      ],
      "metadata": {
        "id": "RNEmdkgN9eyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import pickle\n",
        "'''\n",
        "word_emb_model = api.load(\"glove-twitter-25\") \n",
        "\n",
        "EMBEDDING_DIM = 25\n",
        "\n",
        "embedding_matrix_baseline = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        embedding_matrix_baseline.append(word_emb_model.wv[word])\n",
        "    except:\n",
        "        embedding_matrix_baseline.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix_baseline = np.array(embedding_matrix_baseline)\n",
        "embedding_matrix_baseline.shape\n",
        "\n",
        "\n",
        "\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/sym/'\n",
        "\n",
        "\n",
        "\n",
        "f = open(dir+'baseline_emb.pkl', 'wb')\n",
        "pickle.dump(embedding_matrix_baseline, f)\n",
        "f.close()\n",
        "'''\n",
        "dir = '/content/drive/MyDrive/Colab Notebooks/5046a2/sym/'\n",
        "embedding_matrix_baseline = pickle.load(open(dir+'baseline_emb.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "45rjRpKb9ZDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_baseline"
      ],
      "metadata": {
        "id": "H_TdpC8NQ1Gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a673ff18-6398-4b9c-c6cf-a545127ba3c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.4452    , -0.14844   ,  0.21890999, ..., -0.2325    ,\n",
              "         0.57489997, -0.1191    ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.011279  ,  0.032927  ,  0.23339   , ...,  0.060032  ,\n",
              "         0.13866   ,  0.089993  ],\n",
              "       ...,\n",
              "       [ 0.26029   ,  0.77099001, -0.2384    , ...,  1.36839998,\n",
              "        -0.66071999,  0.64133   ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bilstm+crf+attention"
      ],
      "metadata": {
        "id": "b6D2Tr88TTB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3 Attention layers"
      ],
      "metadata": {
        "id": "zeVrrQ0BfhCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# DotProduct\n",
        "class DotProductAttention(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "    def forward(self, q, k, v):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1))\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        output = attention.bmm(v)\n",
        "        return output, attention\n",
        "# Cos\n",
        "class CosineAttention(nn.Module):\n",
        "    def __init__(self, eps=1e-10, **kwargs):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        q_norm = q / (q.norm(p=2, dim=-1, keepdim=True) + self.eps) \n",
        "        k_norm = k / (k.norm(p=2, dim=-1, keepdim=True) + self.eps)  \n",
        "        attention = torch.bmm(q_norm, k_norm.permute(0, 2, 1)) \n",
        "\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "        output = attention.bmm(v) \n",
        "        return output, attention\n",
        "\n",
        "# ScaledDot attention\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self,  **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None):\n",
        "        attention = torch.bmm(q, k.permute(0, 2, 1)) \n",
        "        attention *= k.size(-1) ** -0.5\n",
        "\n",
        "        attention = F.softmax(attention, dim=-1)\n",
        "\n",
        "        output = attention.bmm(v)  \n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "i-taxfi6XLGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model(baseline+crf+attn)"
      ],
      "metadata": {
        "id": "OzUctBnVgH8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    #crf #att\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim,syn,sym,baseline,domain,attention,crf,attention_method):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        self.attention = attention\n",
        "        if self.attention:\n",
        "          self.Q = nn.Linear(hidden_dim,hidden_dim)\n",
        "          self.K = nn.Linear(hidden_dim,hidden_dim)\n",
        "          self.V = nn.Linear(hidden_dim,hidden_dim)\n",
        "\n",
        "        if attention_method == 'dot_product':\n",
        "            self.attention_layer = DotProductAttention()\n",
        "        elif attention_method == 'scaled_dot_product':\n",
        "            self.attention_layer = ScaledDotProductAttention()\n",
        "        elif attention_method == 'cos':\n",
        "            self.attention_layer = CosineAttention()\n",
        "        self.crf = crf\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        #---------------------------------------\n",
        "        if baseline:\n",
        "          self.word_embeds_baseline = nn.Embedding(vocab_size, 25)\n",
        "          self.word_embeds_baseline.weight.data.copy_(torch.from_numpy(embedding_matrix_baseline))\n",
        "        if sym:\n",
        "          self.word_embeds = nn.Embedding(vocab_size, 250)\n",
        "          self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        if domain:\n",
        "          self.word_embeds_domain = nn.Embedding(vocab_size, 250)\n",
        "          self.word_embeds_domain.weight.data.copy_(torch.from_numpy(embedding_matrix_domain))\n",
        "        if syn:\n",
        "          self.pos_embeds = nn.Embedding(pos_embedding.shape[0], pos_embedding.shape[0])\n",
        "          self.pos_embeds.weight.data.copy_(torch.from_numpy(pos_embedding))\n",
        "          \n",
        "          self.dep_embeds = nn.Embedding(dep_embedding.shape[0], dep_embedding.shape[0])\n",
        "          self.dep_embeds.weight.data.copy_(torch.from_numpy(dep_embedding))\n",
        "          \n",
        "          self.ent_embeds = nn.Embedding(ent_embedding.shape[0], ent_embedding.shape[0])\n",
        "          self.ent_embeds.weight.data.copy_(torch.from_numpy(ent_embedding))\n",
        "        #---------------------------------------\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=NUM_LAYER, bidirectional=True,dropout=DROPOUT)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2,\n",
        "                            num_layers=NUM_LAYER, bidirectional=True,dropout=DROPOUT)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):#2,1->4,1->6,1 num_layer\n",
        "        return (torch.randn(NUM_LAYER*2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(NUM_LAYER*2, 1, self.hidden_dim // 2).to(device))\n",
        "    def init_hidden2(self):#2,1->4,1->6,1 num_layer\n",
        "        return (torch.randn(NUM_LAYER*2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(NUM_LAYER*2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    # self attention for lstm output\n",
        "    def cal_attention(self, lstm_out):\n",
        "        lstm_out = lstm_out.permute(1,0,2)\n",
        "        q = self.Q(lstm_out)\n",
        "        k = self.K(lstm_out)\n",
        "        v = self.V(lstm_out)\n",
        "        output, attention = self.attention_layer(q,k,v)\n",
        "        return output\n",
        "\n",
        "    def _get_lstm_features(self, sentence,pos,dep,ent,syn,sym,baseline,domain):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = None\n",
        "        #-----------------------------------------bert\n",
        "        \n",
        "        if baseline:\n",
        "          embeds_word_baseline = self.word_embeds_baseline(sentence).view(len(sentence), 1, -1)\n",
        "          if embeds == None:\n",
        "            embeds = embeds_word_baseline\n",
        "          else:\n",
        "            embeds = torch.cat((embeds,embeds_word_baseline),2)\n",
        "        \n",
        "        if domain:\n",
        "          embeds_word_domain = self.word_embeds_domain(sentence).view(len(sentence), 1, -1)\n",
        "          if embeds == None:\n",
        "            embeds = embeds_word_domain\n",
        "          else:\n",
        "            embeds = torch.cat((embeds,embeds_word_domain),2)\n",
        "        #------------------------------------bert\n",
        "\n",
        "        if sym:\n",
        "          embeds_word = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "          if embeds == None:\n",
        "            embeds = embeds_word\n",
        "          else:\n",
        "            embeds = torch.cat((embeds,embeds_word),2)\n",
        "\n",
        "        if syn:\n",
        "\n",
        "          embeds_pos = self.pos_embeds(pos).view(len(pos), 1, -1)\n",
        "          embeds_dep = self.dep_embeds(dep).view(len(dep), 1, -1)\n",
        "          embeds_ent = self.ent_embeds(ent).view(len(ent), 1, -1)\n",
        "          if embeds == None:\n",
        "            #embeds = embeds_pos\n",
        "            embeds = torch.cat((embeds_pos,embeds_dep,embeds_ent),2)\n",
        "          else:\n",
        "            #embeds = torch.cat((embeds,embeds_pos),2)\n",
        "            embeds = torch.cat((embeds,embeds_pos,embeds_dep,embeds_ent),2)\n",
        "  \n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "        if not self.attention:\n",
        "          lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "          lstm_feats = self.hidden2tag(lstm_out)\n",
        "          return lstm_feats\n",
        "\n",
        "        #attention\n",
        "\n",
        "        # two layer, attention position between 2 lstm\n",
        "        if ATTENTION_POSITION_BETWEEN_TWO_LAYER:\n",
        "          attention_out = self.cal_attention(lstm_out)\n",
        "          attention_out = attention_out.view(len(sentence), self.hidden_dim).unsqueeze(1)\n",
        "          self.hidden = self.init_hidden2() \n",
        "          lstm_out, self.hidden = self.lstm2(attention_out, self.hidden)\n",
        "          lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "          lstm_feats = self.hidden2tag(lstm_out) \n",
        "          return lstm_feats\n",
        "        # attention position after lstm\n",
        "        attention_out = self.cal_attention(lstm_out)\n",
        "        attention_out = attention_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(attention_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags,pos,dep,ent,syn,sym,baseline,domain):\n",
        "        feats = self._get_lstm_features(sentence,pos, dep,ent,syn,sym,baseline,domain)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        \n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence,pos,dep,ent,syn,sym,baseline,domain):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence,pos,dep,ent,syn,sym,baseline,domain)\n",
        "        if not self.crf:\n",
        "          tag_seq = torch.max(F.softmax(lstm_feats, dim=1), dim=1).indices.tolist()\n",
        "          return 0, tag_seq\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "metadata": {
        "id": "xKQtWFkfTV6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cal_acc(model, input_index, output_index,pos_index,dep_index,ent_index,syn,sym,baseline,domain):\n",
        "    pred_list=[]\n",
        "    tag_list=[]\n",
        "    for i, idxs in enumerate(input_index):\n",
        "        tags_index = output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index[i], dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index[i], dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index[i], dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        _,pred = model.forward(sentence_in,pos,dep,ent,syn,sym,baseline,domain)\n",
        "        \n",
        "        for i in range(len(pred)):\n",
        "          pred_list.append(pred[i])\n",
        "          tag_list.append(targets[i].cpu().numpy().tolist())\n",
        "    acc = np.mean(np.array(pred_list) == np.array(tag_list))\n",
        "    return pred_list, tag_list, acc"
      ],
      "metadata": {
        "id": "xU5oz6p7rNv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculate Val f1"
      ],
      "metadata": {
        "id": "uP0HUZ4v7GnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def calculate_f1(y_pred,y_true,model_name):\n",
        "\n",
        "  y_pred = np.array(y_pred)\n",
        "  y_true = np.array(y_true)\n",
        "\n",
        "\n",
        "\n",
        "  micro_f1 = classification_report(y_pred,y_true,output_dict=True)['accuracy']\n",
        "  micro_f1_2 = classification_report(y_pred,y_true,output_dict=True)['2']['f1-score']\n",
        "  micro_f1_3 = classification_report(y_pred,y_true,output_dict=True)['3']['f1-score']\n",
        "  micro_f1_4 = classification_report(y_pred,y_true,output_dict=True)['4']['f1-score']\n",
        "  micro_f1_5 = classification_report(y_pred,y_true,output_dict=True)['5']['f1-score']\n",
        "  micro_f1_6 = classification_report(y_pred,y_true,output_dict=True)['6']['f1-score']\n",
        "  micro_f1_7 = classification_report(y_pred,y_true,output_dict=True)['7']['f1-score']\n",
        "  micro_f1_8 = classification_report(y_pred,y_true,output_dict=True)['8']['f1-score']\n",
        "  dic = {\n",
        "      'Model_name':model_name,\n",
        "      'T-F1':micro_f1,\n",
        "      'T-F1(O)':micro_f1_2,\n",
        "      'T-F1(T)':micro_f1_3,\n",
        "      'T-F1(P)':micro_f1_4,\n",
        "      'T-F1(SEPA)':micro_f1_5,\n",
        "      'T-F1(S)':micro_f1_6,\n",
        "      'T-F1(D)':micro_f1_7,\n",
        "      'T-F1(C)':micro_f1_8}\n",
        "\n",
        "  df = pd.DataFrame(dic,index=[0])\n",
        "  print()\n",
        "  return df"
      ],
      "metadata": {
        "id": "Q5PxPZCRJzg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Prediction fun"
      ],
      "metadata": {
        "id": "K9nv6ftO7PTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input_index, pos_index,dep_index,ent_index,syn,sym,baseline,domain,attention,crf):\n",
        "    pred_list=[]\n",
        "    tag_list=[]\n",
        "    for i, idxs in enumerate(input_index):\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index[i], dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index[i], dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index[i], dtype=torch.long).to(device)\n",
        "        # Step 3. Run our forward pass.\n",
        "        _,pred = model(sentence_in,pos,dep,ent,syn,sym,baseline,domain)\n",
        "        \n",
        "        for i in range(len(pred)):\n",
        "          pred_list.append(pred[i])\n",
        "    ix_to_tag = {}\n",
        "    for i in tag_to_ix.keys():\n",
        "      ix_to_tag[tag_to_ix[i]] = i\n",
        "    pred_tag = []\n",
        "    for i in pred_list:\n",
        "      pred_tag.append(ix_to_tag[i])\n",
        "    dic = {'Predicted':pred_tag}\n",
        "    df = pd.DataFrame(dic).reset_index(drop=True)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "zDBmXaqo64MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config and train model"
      ],
      "metadata": {
        "id": "As5CbsfV7Y24"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation study: embedding"
      ],
      "metadata": {
        "id": "8xMFx08nQhFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('max_colwidth',200)\n",
        "Ablation_df = None\n",
        "Model_name_list = []"
      ],
      "metadata": {
        "id": "eTijRgE16ZOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline(Bilstm+crf+glove25)"
      ],
      "metadata": {
        "id": "J93B9Cz4zM_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "# typo SYM means semantic embedding\n",
        "SYM = False\n",
        "DOMAIN = False\n",
        "BASELINE = True\n",
        "\n",
        "Model_name = 'Baseline(Bilstm+crf+glove25)'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "fChw2QBFrOhk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "e8f38404-6145-4ea4-b4c3-2c428026d64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [02:20, 30.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.8767583984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:33, 42.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.2355123046875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [06:43, 43.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.8861234375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20004it [08:51, 35.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.653346728515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24998it [11:02, 39.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.591906787109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:32, 37.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 31799.22, train acc: 0.9676, val loss: 4202.31, val acc: 0.9626, time: 951.82s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [02:12, 32.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.51799169921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9998it [04:25, 41.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.30824345703125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [06:35, 45.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3016852783203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20004it [08:44, 35.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.247519677734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24998it [10:56, 39.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2619974365234375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:25, 38.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 7852.81, train acc: 0.9880, val loss: 2541.61, val acc: 0.9799, time: 948.17s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Model_name      T-F1   T-F1(O)   T-F1(T)   T-F1(P)  \\\n",
              "0  Baseline(Bilstm+crf+glove25)  0.979882  0.983839  0.949341  0.995158   \n",
              "\n",
              "   T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0         1.0  0.972511  0.813049  0.934729  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ce6105c-e935-4c7a-9dd0-99e59ff391e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "      <td>0.983839</td>\n",
              "      <td>0.949341</td>\n",
              "      <td>0.995158</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.972511</td>\n",
              "      <td>0.813049</td>\n",
              "      <td>0.934729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ce6105c-e935-4c7a-9dd0-99e59ff391e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ce6105c-e935-4c7a-9dd0-99e59ff391e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ce6105c-e935-4c7a-9dd0-99e59ff391e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Baseline(Bilstm+crf+glove25)'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "6t_kDkBt5SZE",
        "outputId": "4d2c67a8-b7f1-4b22-cb0e-f0d708e2f483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Model_name      T-F1\n",
              "0  Baseline(Bilstm+crf+glove25)  0.979882"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83192331-09f2-425b-8bcc-d7cdf6f7861f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83192331-09f2-425b-8bcc-d7cdf6f7861f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83192331-09f2-425b-8bcc-d7cdf6f7861f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83192331-09f2-425b-8bcc-d7cdf6f7861f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+glove25+domain_emb"
      ],
      "metadata": {
        "id": "3hipgtyzKv3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = True\n",
        "\n",
        "Model_name = 'Bilstm+crf+glove25+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "qIK3-TeANA0f",
        "outputId": "0f3a4cf1-b4e9-4dd6-a424-6b3a3d980c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4998it [02:16, 29.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.06699951171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:33, 40.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.24892109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14993it [06:47, 38.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2209135009765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20005it [09:01, 33.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.17701180419921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25001it [11:17, 40.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.16522171630859375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:48, 36.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 9544.29, train acc: 0.9950, val loss: 1039.32, val acc: 0.9909, time: 989.67s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4999it [02:15, 29.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10187207641601563\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9997it [04:32, 38.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.04805668334960937\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15003it [06:47, 41.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0519818603515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19997it [09:07, 31.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.049141619873046875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [11:25, 40.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.04280217590332031\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:56, 36.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 1356.33, train acc: 0.9993, val loss: 1054.20, val acc: 0.9900, time: 997.63s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model_name      T-F1   T-F1(O)   T-F1(T)   T-F1(P)  \\\n",
              "0  Bilstm+crf+glove25+domain_emb  0.990046  0.991871  0.961786  0.995693   \n",
              "\n",
              "   T-F1(SEPA)   T-F1(S)   T-F1(D)  T-F1(C)  \n",
              "0    0.999584  0.990632  0.895981  0.98301  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a954b353-95b8-49c0-964c-99d697c59dbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "      <td>0.991871</td>\n",
              "      <td>0.961786</td>\n",
              "      <td>0.995693</td>\n",
              "      <td>0.999584</td>\n",
              "      <td>0.990632</td>\n",
              "      <td>0.895981</td>\n",
              "      <td>0.98301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a954b353-95b8-49c0-964c-99d697c59dbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a954b353-95b8-49c0-964c-99d697c59dbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a954b353-95b8-49c0-964c-99d697c59dbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+glove25+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "hHl82fWSNA23",
        "outputId": "8e442355-0c05-4064-9b19-cd87c6b0c8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model_name      T-F1\n",
              "0   Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0  Bilstm+crf+glove25+domain_emb  0.990046"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41142903-9da5-4657-a200-9c3d848f4c84\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41142903-9da5-4657-a200-9c3d848f4c84')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41142903-9da5-4657-a200-9c3d848f4c84 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41142903-9da5-4657-a200-9c3d848f4c84');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+glove25+syn_emb+sem_emb"
      ],
      "metadata": {
        "id": "e2pN9VItKsGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = True\n",
        "DOMAIN = False\n",
        "BASELINE = True\n",
        "\n",
        "Model_name = 'Bilstm+crf+glove25+syn_emb+sym_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "uEmmRGWOL3bY",
        "outputId": "922fbb3d-7d13-40e5-cec9-08860dfbb1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [02:20, 27.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.21264775390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:42, 38.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3717332275390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14998it [06:59, 40.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.28290693359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20005it [09:17, 33.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.220529638671875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [11:36, 39.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.197838037109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [12:08, 35.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 11626.36, train acc: 0.9959, val loss: 1431.31, val acc: 0.9886, time: 1027.37s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4997it [02:17, 30.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0937372802734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:38, 39.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.032212994384765624\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15003it [06:55, 40.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.028909765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [09:10, 32.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.027925430297851564\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [11:28, 40.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.02425648651123047\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:59, 36.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 860.33, train acc: 0.9996, val loss: 2273.79, val acc: 0.9802, time: 1013.41s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Model_name      T-F1   T-F1(O)   T-F1(T)   T-F1(P)  \\\n",
              "0  Bilstm+crf+glove25+syn_emb+sym_emb  0.980212  0.983735  0.954362  0.972404   \n",
              "\n",
              "   T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0         1.0  0.988791  0.873072  0.950148  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2537d7a9-07de-4187-a23b-6a1e8457ea67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "      <td>0.983735</td>\n",
              "      <td>0.954362</td>\n",
              "      <td>0.972404</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988791</td>\n",
              "      <td>0.873072</td>\n",
              "      <td>0.950148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2537d7a9-07de-4187-a23b-6a1e8457ea67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2537d7a9-07de-4187-a23b-6a1e8457ea67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2537d7a9-07de-4187-a23b-6a1e8457ea67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+glove25+syn_emb+sym_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "VCltn9ngMTY5",
        "outputId": "649c680c-570c-44a7-b352-d7b94c4787bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Model_name      T-F1\n",
              "0        Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0       Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0  Bilstm+crf+glove25+syn_emb+sym_emb  0.980212"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cd87bdd-1372-4e7d-aacc-bea3a33ba8cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cd87bdd-1372-4e7d-aacc-bea3a33ba8cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9cd87bdd-1372-4e7d-aacc-bea3a33ba8cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9cd87bdd-1372-4e7d-aacc-bea3a33ba8cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+glove25+syn_emb+domain_emb"
      ],
      "metadata": {
        "id": "uaw7RGjgKvLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = True\n",
        "\n",
        "Model_name = 'Bilstm+crf+glove25+syn_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "H57NOrzbMlL4",
        "outputId": "60413c86-b227-494f-cc20-8569a1cc0ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [02:16, 31.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.9211451171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:35, 40.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2435121337890625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14998it [06:49, 41.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.209232275390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19998it [09:04, 33.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1745566162109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [11:22, 39.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.16236927490234376\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:53, 36.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 8703.86, train acc: 0.9947, val loss: 1067.02, val acc: 0.9905, time: 1008.26s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5002it [02:16, 30.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10195420532226562\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10005it [04:36, 38.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.05125003662109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [06:50, 43.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.05089415588378906\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19998it [09:05, 31.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.045241598510742186\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [11:23, 39.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.04470038146972656\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:54, 36.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 1351.56, train acc: 0.9990, val loss: 1150.03, val acc: 0.9898, time: 1007.39s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Model_name      T-F1   T-F1(O)   T-F1(T)  \\\n",
              "0  Bilstm+crf+glove25+syn_emb+domain_emb  0.989776  0.992084  0.962085   \n",
              "\n",
              "    T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.997587    0.999723  0.990765  0.849224  0.984078  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e0712cc-522f-4d98-bfe4-9552cff54c0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "      <td>0.992084</td>\n",
              "      <td>0.962085</td>\n",
              "      <td>0.997587</td>\n",
              "      <td>0.999723</td>\n",
              "      <td>0.990765</td>\n",
              "      <td>0.849224</td>\n",
              "      <td>0.984078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e0712cc-522f-4d98-bfe4-9552cff54c0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e0712cc-522f-4d98-bfe4-9552cff54c0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e0712cc-522f-4d98-bfe4-9552cff54c0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+glove25+syn_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "LgvWiR6NMm2b",
        "outputId": "ea5fe712-7205-4775-e8c7-8c94525de088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Model_name      T-F1\n",
              "0           Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0          Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0     Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0  Bilstm+crf+glove25+syn_emb+domain_emb  0.989776"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10832941-c590-41b7-bfa3-ff1f4edce699\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10832941-c590-41b7-bfa3-ff1f4edce699')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10832941-c590-41b7-bfa3-ff1f4edce699 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10832941-c590-41b7-bfa3-ff1f4edce699');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+domain_emb"
      ],
      "metadata": {
        "id": "aosGWutiffUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "i2gz-pgxgM4u",
        "outputId": "8acd8ca6-3f7a-4b1a-950a-787901c9a36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4999it [02:06, 31.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.06751318359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9996it [04:16, 39.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2533486328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [06:24, 30.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.21917783203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20006it [08:34, 35.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1783586181640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24998it [10:42, 40.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.169886181640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:11, 38.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 9595.57, train acc: 0.9947, val loss: 1083.56, val acc: 0.9902, time: 926.34s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4997it [02:05, 34.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10005819702148437\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:12, 42.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.05037345581054688\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14993it [06:15, 40.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0495367919921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [08:19, 32.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0471834228515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24997it [10:25, 38.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.04623373413085938\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [10:53, 39.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 1349.19, train acc: 0.9993, val loss: 1187.59, val acc: 0.9884, time: 906.75s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Model_name      T-F1   T-F1(O)  T-F1(T)  T-F1(P)  T-F1(SEPA)  \\\n",
              "0  Bilstm+crf+domain_emb  0.988397  0.990588  0.95334  0.99759    0.999861   \n",
              "\n",
              "    T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.988845  0.879171  0.975845  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d7ac06d-6a0c-43f2-b746-f7f44ab2c662\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "      <td>0.990588</td>\n",
              "      <td>0.95334</td>\n",
              "      <td>0.99759</td>\n",
              "      <td>0.999861</td>\n",
              "      <td>0.988845</td>\n",
              "      <td>0.879171</td>\n",
              "      <td>0.975845</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d7ac06d-6a0c-43f2-b746-f7f44ab2c662')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d7ac06d-6a0c-43f2-b746-f7f44ab2c662 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d7ac06d-6a0c-43f2-b746-f7f44ab2c662');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "385v9l_0gGL7",
        "outputId": "b8e11364-5eab-44b9-f827-1386d464a83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Model_name      T-F1\n",
              "0           Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0          Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0     Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0  Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                  Bilstm+crf+domain_emb  0.988397"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a39ea3d-7014-480d-a7d0-cdedd4b8e7de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a39ea3d-7014-480d-a7d0-cdedd4b8e7de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a39ea3d-7014-480d-a7d0-cdedd4b8e7de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a39ea3d-7014-480d-a7d0-cdedd4b8e7de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+sym_emb+domain_emb"
      ],
      "metadata": {
        "id": "rqcCu8hnfsIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = True\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+sym_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "wrwz2KeKgTTp",
        "outputId": "3371048f-ac08-4021-9a1f-ebcd19b5fe8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [02:08, 33.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.89101943359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10002it [04:19, 44.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.22989912109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [06:26, 45.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1903878662109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19996it [08:32, 35.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.168429443359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25002it [10:44, 42.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.15486771240234376\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:13, 38.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 8314.58, train acc: 0.9973, val loss: 1009.81, val acc: 0.9911, time: 944.48s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4999it [02:08, 31.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0641677490234375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [04:19, 42.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.023355105590820314\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [06:27, 45.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.02709447021484375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [08:35, 33.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.021002545166015626\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25003it [10:45, 42.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.025457553100585936\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:14, 38.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 677.67, train acc: 0.9996, val loss: 1170.02, val acc: 0.9904, time: 944.95s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model_name      T-F1   T-F1(O)   T-F1(T)   T-F1(P)  \\\n",
              "0  Bilstm+crf+sym_emb+domain_emb  0.990436  0.992095  0.968643  0.992935   \n",
              "\n",
              "   T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0         1.0  0.990321  0.911515  0.983717  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37f73496-6f5b-427d-ba40-8635a03cd847\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "      <td>0.992095</td>\n",
              "      <td>0.968643</td>\n",
              "      <td>0.992935</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.990321</td>\n",
              "      <td>0.911515</td>\n",
              "      <td>0.983717</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37f73496-6f5b-427d-ba40-8635a03cd847')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37f73496-6f5b-427d-ba40-8635a03cd847 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37f73496-6f5b-427d-ba40-8635a03cd847');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+sym_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "H0IdEAS7gG2x",
        "outputId": "626fd2be-3450-41fc-b6c5-ef1dc343f9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Model_name      T-F1\n",
              "0           Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0          Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0     Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0  Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                  Bilstm+crf+domain_emb  0.988397\n",
              "0          Bilstm+crf+sym_emb+domain_emb  0.990436"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd09d3d-2cac-4629-af47-ea44c488f030\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd09d3d-2cac-4629-af47-ea44c488f030')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5dd09d3d-2cac-4629-af47-ea44c488f030 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5dd09d3d-2cac-4629-af47-ea44c488f030');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+syn_emb+domain_emb"
      ],
      "metadata": {
        "id": "KxR2jGovfspe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = False\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+syn_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "6757a50tgZBE",
        "outputId": "7a4b3a65-5ef3-4028-b627-4367b054bbe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [02:12, 25.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.1026751953125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9997it [04:24, 39.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2538625732421875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [06:34, 44.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.223097998046875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20006it [08:44, 35.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1783278076171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24998it [11:06, 29.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.17200400390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:41, 37.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 9809.68, train acc: 0.9944, val loss: 1133.90, val acc: 0.9900, time: 978.40s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [02:11, 33.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10439959716796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9998it [04:23, 42.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.05272037353515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [06:33, 40.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.047475411987304685\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20005it [08:42, 35.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.049917105102539064\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25003it [10:55, 40.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.045713613891601564\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [11:24, 38.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 1376.67, train acc: 0.9994, val loss: 1151.47, val acc: 0.9891, time: 959.47s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Model_name      T-F1   T-F1(O)   T-F1(T)   T-F1(P)  \\\n",
              "0  Bilstm+crf+syn_emb+domain_emb  0.989117  0.991021  0.957022  0.996451   \n",
              "\n",
              "   T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0    0.999723  0.986194  0.903686  0.982937  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1de9da48-d371-4243-93ea-c9fc181747c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "      <td>0.991021</td>\n",
              "      <td>0.957022</td>\n",
              "      <td>0.996451</td>\n",
              "      <td>0.999723</td>\n",
              "      <td>0.986194</td>\n",
              "      <td>0.903686</td>\n",
              "      <td>0.982937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1de9da48-d371-4243-93ea-c9fc181747c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1de9da48-d371-4243-93ea-c9fc181747c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1de9da48-d371-4243-93ea-c9fc181747c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+syn_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "R-8wGpGXgHgv",
        "outputId": "455e9d0a-b8f3-49ad-e967-1529fd4f80ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Model_name      T-F1\n",
              "0           Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0          Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0     Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0  Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                  Bilstm+crf+domain_emb  0.988397\n",
              "0          Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0          Bilstm+crf+syn_emb+domain_emb  0.989117"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05f9dcd6-fb99-4015-87b3-ce87ccc4663f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05f9dcd6-fb99-4015-87b3-ce87ccc4663f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05f9dcd6-fb99-4015-87b3-ce87ccc4663f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05f9dcd6-fb99-4015-87b3-ce87ccc4663f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb"
      ],
      "metadata": {
        "id": "N-q3i-qYzNwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = False\n",
        "DOMAIN = False\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "4NVZBDbL77Zz",
        "outputId": "441c0831-2794-43df-f015-d06e070d4c30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4996it [01:29, 50.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  4.248840625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9997it [03:02, 55.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  3.078301953125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:34, 61.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.837425390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [06:09, 45.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.7671904296875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25006it [07:46, 46.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.79408359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:08, 53.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 81522.29, train acc: 0.7747, val loss: 23657.46, val acc: 0.7732, time: 674.26s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [01:31, 45.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  3.3076328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:05, 56.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.6431353515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:40, 56.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.604862890625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20003it [06:17, 44.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.5856384765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24999it [07:53, 50.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.6616703125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:15, 52.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 68909.58, train acc: 0.7775, val loss: 23062.35, val acc: 0.7749, time: 681.21s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model_name    T-F1   T-F1(O)  T-F1(T)  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.7749  0.835523      0.0   \n",
              "\n",
              "    T-F1(P)  T-F1(SEPA)   T-F1(S)  T-F1(D)   T-F1(C)  \n",
              "0  0.822964    0.980392  0.377567      0.0  0.029206  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee1a9acc-e93a-4fe5-b658-32d7c116af45\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.7749</td>\n",
              "      <td>0.835523</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.822964</td>\n",
              "      <td>0.980392</td>\n",
              "      <td>0.377567</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee1a9acc-e93a-4fe5-b658-32d7c116af45')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ee1a9acc-e93a-4fe5-b658-32d7c116af45 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ee1a9acc-e93a-4fe5-b658-32d7c116af45');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "LCuooKBj79Iq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "253da256-dcdd-4be7-db2d-46f828b225b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model_name      T-F1\n",
              "0                     Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                    Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0               Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0            Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                            Bilstm+crf+domain_emb  0.988397\n",
              "0                    Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                    Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ffc5b5a-2bc4-4cb4-b5cd-37073116043a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ffc5b5a-2bc4-4cb4-b5cd-37073116043a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ffc5b5a-2bc4-4cb4-b5cd-37073116043a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ffc5b5a-2bc4-4cb4-b5cd-37073116043a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+sem_emb"
      ],
      "metadata": {
        "id": "3lPQTJQOzsEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = True\n",
        "DOMAIN = False\n",
        "BASELINE = True\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "z2xcGqcy-NFH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "b9c7db05-257e-4486-d1d0-2023bfe633af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5007it [01:34, 42.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.1526625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [03:09, 58.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.654443408203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14995it [04:40, 56.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.433005419921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20007it [06:14, 46.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3210453125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [07:53, 50.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.285421142578125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:16, 52.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 19483.66, train acc: 0.9902, val loss: 1989.89, val acc: 0.9842, time: 697.27s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [01:38, 43.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.18988521728515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:14, 56.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1108135986328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:48, 60.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.108579150390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20010it [06:21, 53.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.08181817626953125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25002it [07:54, 54.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.07923604125976562\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:15, 52.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2668.42, train acc: 0.9970, val loss: 1712.31, val acc: 0.9862, time: 687.11s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model_name      T-F1   T-F1(O)  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179  0.989061   \n",
              "\n",
              "    T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.968837  0.994162    0.999584  0.972861  0.913992  0.963936  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b037c2c-c8a4-4485-87cc-2cacb3b0282c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "      <td>0.989061</td>\n",
              "      <td>0.968837</td>\n",
              "      <td>0.994162</td>\n",
              "      <td>0.999584</td>\n",
              "      <td>0.972861</td>\n",
              "      <td>0.913992</td>\n",
              "      <td>0.963936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b037c2c-c8a4-4485-87cc-2cacb3b0282c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b037c2c-c8a4-4485-87cc-2cacb3b0282c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b037c2c-c8a4-4485-87cc-2cacb3b0282c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "9atghqz6-Qaq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "c469832f-e619-43fb-c9bb-4b5781c4ba64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        Model_name      T-F1\n",
              "0                     Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                    Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0               Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0            Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                            Bilstm+crf+domain_emb  0.988397\n",
              "0                    Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                    Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a33c25d5-1a84-4ef3-8ef6-eaecccad0e21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a33c25d5-1a84-4ef3-8ef6-eaecccad0e21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a33c25d5-1a84-4ef3-8ef6-eaecccad0e21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a33c25d5-1a84-4ef3-8ef6-eaecccad0e21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb"
      ],
      "metadata": {
        "id": "wTxz2MaNzs69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "eqc2Pq_L_RKt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "8ad56c55-1674-43b4-f0f8-41f1648541a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [01:32, 47.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.8740283203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:08, 55.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.432675537109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15004it [04:44, 55.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.355255517578125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20007it [06:15, 46.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.268726220703125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25002it [07:51, 54.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2392268310546875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:12, 52.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 16102.27, train acc: 0.9896, val loss: 1548.93, val acc: 0.9868, time: 673.39s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4997it [01:28, 49.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.182026513671875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10005it [02:59, 60.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10188599853515624\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15004it [04:29, 53.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10731480712890624\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20002it [06:03, 45.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0981130615234375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25001it [07:41, 54.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09012686767578125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:03, 53.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2747.88, train acc: 0.9971, val loss: 1209.65, val acc: 0.9905, time: 673.47s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Model_name      T-F1   T-F1(O)  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526  0.992309   \n",
              "\n",
              "    T-F1(T)  T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.963905  0.99582    0.999861  0.991217  0.921151  0.975976  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b9c6ee2-a2a8-46e5-a50f-ee2843350f22\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "      <td>0.992309</td>\n",
              "      <td>0.963905</td>\n",
              "      <td>0.99582</td>\n",
              "      <td>0.999861</td>\n",
              "      <td>0.991217</td>\n",
              "      <td>0.921151</td>\n",
              "      <td>0.975976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b9c6ee2-a2a8-46e5-a50f-ee2843350f22')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b9c6ee2-a2a8-46e5-a50f-ee2843350f22 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b9c6ee2-a2a8-46e5-a50f-ee2843350f22');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "H-6edZjb_ROp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "80e90847-5dcd-4dcf-f992-eae7738ffcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Model_name      T-F1\n",
              "0                        Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                       Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0                  Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0               Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                               Bilstm+crf+domain_emb  0.988397\n",
              "0                       Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                       Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900\n",
              "0     Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4657a0a7-66d5-47cb-93b3-0684a65335f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4657a0a7-66d5-47cb-93b3-0684a65335f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4657a0a7-66d5-47cb-93b3-0684a65335f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4657a0a7-66d5-47cb-93b3-0684a65335f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sem_emb"
      ],
      "metadata": {
        "id": "EkWjjXm1ztPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = True\n",
        "DOMAIN = False\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "9bSo5gdd_uSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "1e2876b8-74f0-4845-a457-132d87e15ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4997it [01:33, 49.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.2183611328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10003it [03:08, 53.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.5891126953125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14994it [04:40, 55.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.43344482421875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20003it [06:10, 50.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3237877685546875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [07:45, 53.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.280106982421875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:06, 53.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 19532.69, train acc: 0.9908, val loss: 1769.36, val acc: 0.9865, time: 681.47s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [01:35, 41.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2099327880859375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:11, 58.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10001655883789062\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:42, 60.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09633452758789063\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20003it [06:12, 51.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0952931640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25001it [07:44, 57.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0711631103515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:05, 53.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2656.76, train acc: 0.9973, val loss: 2019.32, val acc: 0.9867, time: 680.68s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Model_name      T-F1  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb  0.986748   \n",
              "\n",
              "    T-F1(O)   T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.989302  0.962401  0.996313         1.0  0.976343  0.906133  0.967544  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f336679-5f19-44ff-b978-3ebcd8247401\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "      <td>0.989302</td>\n",
              "      <td>0.962401</td>\n",
              "      <td>0.996313</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.976343</td>\n",
              "      <td>0.906133</td>\n",
              "      <td>0.967544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f336679-5f19-44ff-b978-3ebcd8247401')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f336679-5f19-44ff-b978-3ebcd8247401 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f336679-5f19-44ff-b978-3ebcd8247401');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "8TMG8-ef_uUO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "a34023ef-97e9-4e2f-e5a6-348a5079b9c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Model_name      T-F1\n",
              "0                             Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                            Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0                       Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0                    Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                                    Bilstm+crf+domain_emb  0.988397\n",
              "0                            Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                            Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900\n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179\n",
              "0       Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb  0.986748"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a12f6197-330c-48de-8aff-c980c9b9792f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a12f6197-330c-48de-8aff-c980c9b9792f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a12f6197-330c-48de-8aff-c980c9b9792f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a12f6197-330c-48de-8aff-c980c9b9792f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb"
      ],
      "metadata": {
        "id": "uBh9DNoHztao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "_JN0mwUk_5BA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "692a62dc-57b2-4080-c461-a2db6eea30c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4998it [01:35, 46.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.733978515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:09, 55.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.40227841796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14997it [04:40, 59.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3253280029296875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20008it [06:13, 48.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2655216552734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [07:47, 53.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.229356201171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:08, 53.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 15013.75, train acc: 0.9903, val loss: 1676.23, val acc: 0.9874, time: 684.46s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5003it [01:32, 45.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1896699462890625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:05, 55.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10210465698242188\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:37, 58.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.102715380859375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20004it [06:07, 50.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09651688232421875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25001it [07:41, 57.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.08858800659179687\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:02, 54.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2742.70, train acc: 0.9971, val loss: 1391.99, val acc: 0.9879, time: 676.00s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Model_name      T-F1  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb  0.987917   \n",
              "\n",
              "    T-F1(O)   T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.990386  0.945165  0.997329    0.999861  0.982823  0.900249  0.981674  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d8fedf7-54b0-47ac-a667-292fcb4e8cf4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "      <td>0.990386</td>\n",
              "      <td>0.945165</td>\n",
              "      <td>0.997329</td>\n",
              "      <td>0.999861</td>\n",
              "      <td>0.982823</td>\n",
              "      <td>0.900249</td>\n",
              "      <td>0.981674</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d8fedf7-54b0-47ac-a667-292fcb4e8cf4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d8fedf7-54b0-47ac-a667-292fcb4e8cf4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d8fedf7-54b0-47ac-a667-292fcb4e8cf4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "luk9dbk7_5C8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "ac7fbfed-fdfa-44b4-d07d-d3b56f0c4338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Model_name      T-F1\n",
              "0                                Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                               Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0                          Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0                       Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                                       Bilstm+crf+domain_emb  0.988397\n",
              "0                               Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                               Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900\n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179\n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526\n",
              "0     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb  0.986748\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb  0.987917"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c465e6df-22c6-4dbe-92ca-200e85b2e6bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c465e6df-22c6-4dbe-92ca-200e85b2e6bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c465e6df-22c6-4dbe-92ca-200e85b2e6bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c465e6df-22c6-4dbe-92ca-200e85b2e6bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+sem_emb+domain_emb"
      ],
      "metadata": {
        "id": "6syKtYlWzt7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = True\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "9KTKf2cEAF3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "31d40fd2-1354-441f-96bb-e48ee6ad0fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [01:32, 44.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.548116796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:08, 57.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3572800048828125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14998it [04:42, 57.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.284611328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19996it [06:15, 48.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2337063720703125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24996it [07:50, 52.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2056137451171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:12, 52.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 13344.33, train acc: 0.9937, val loss: 1367.53, val acc: 0.9881, time: 683.57s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [01:32, 48.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1324294921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:06, 53.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.06588770141601563\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:37, 58.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09024820556640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20002it [06:11, 49.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.06478214721679687\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [07:45, 51.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0542432861328125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:06, 53.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 1902.02, train acc: 0.9985, val loss: 1399.43, val acc: 0.9892, time: 674.28s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Model_name      T-F1  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb  0.989237   \n",
              "\n",
              "    T-F1(O)   T-F1(T)   T-F1(P)  T-F1(SEPA)  T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.991185  0.965283  0.995438         1.0  0.98913  0.912883  0.969189  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a6ae138-e310-4555-b941-7c404f0ba676\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "      <td>0.991185</td>\n",
              "      <td>0.965283</td>\n",
              "      <td>0.995438</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.98913</td>\n",
              "      <td>0.912883</td>\n",
              "      <td>0.969189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a6ae138-e310-4555-b941-7c404f0ba676')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a6ae138-e310-4555-b941-7c404f0ba676 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a6ae138-e310-4555-b941-7c404f0ba676');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "pqZUe7xNAF5P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "54a6bb29-a21c-462c-c274-d92150d50e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Model_name      T-F1\n",
              "0                                Baseline(Bilstm+crf+glove25)  0.979882\n",
              "0                               Bilstm+crf+glove25+domain_emb  0.990046\n",
              "0                          Bilstm+crf+glove25+syn_emb+sym_emb  0.980212\n",
              "0                       Bilstm+crf+glove25+syn_emb+domain_emb  0.989776\n",
              "0                                       Bilstm+crf+domain_emb  0.988397\n",
              "0                               Bilstm+crf+sym_emb+domain_emb  0.990436\n",
              "0                               Bilstm+crf+syn_emb+domain_emb  0.989117\n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb  0.774900\n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb  0.986179\n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526\n",
              "0     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb  0.986748\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb  0.987917\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb  0.989237"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e94b03c-ee55-4f9a-80ef-b8ca648345b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e94b03c-ee55-4f9a-80ef-b8ca648345b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e94b03c-ee55-4f9a-80ef-b8ca648345b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e94b03c-ee55-4f9a-80ef-b8ca648345b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sem_emb+domain_emb"
      ],
      "metadata": {
        "id": "DIRC84Ej84Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = True\n",
        "SYM = True\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "XSnl_VZ6AR17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "9a1a49c5-6a5c-4d31-cad1-d5debac6ea48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [01:37, 43.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.55796416015625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:15, 55.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.363279150390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15004it [04:50, 52.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.295601708984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19997it [06:25, 47.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.224865625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [08:02, 48.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1982087158203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:25, 51.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 13392.69, train acc: 0.9938, val loss: 1321.18, val acc: 0.9898, time: 712.84s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5002it [01:36, 45.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.15166566162109374\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:13, 56.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.06972535400390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14997it [04:48, 57.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.07909921264648437\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20007it [06:24, 47.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.07462854614257812\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25006it [08:00, 49.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.058210540771484375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:22, 51.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2009.10, train acc: 0.9978, val loss: 2169.74, val acc: 0.9857, time: 707.77s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           Model_name  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "\n",
              "       T-F1   T-F1(O)   T-F1(T)  T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)  \\\n",
              "0  0.985729  0.988554  0.950918   0.9918    0.999723  0.988228  0.851305   \n",
              "\n",
              "    T-F1(C)  \n",
              "0  0.970862  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5877222d-a06f-42b4-8c65-2bfc711258f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "      <td>0.988554</td>\n",
              "      <td>0.950918</td>\n",
              "      <td>0.9918</td>\n",
              "      <td>0.999723</td>\n",
              "      <td>0.988228</td>\n",
              "      <td>0.851305</td>\n",
              "      <td>0.970862</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5877222d-a06f-42b4-8c65-2bfc711258f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5877222d-a06f-42b4-8c65-2bfc711258f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5877222d-a06f-42b4-8c65-2bfc711258f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "T-_ECmwjAR32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "e796b06e-54e7-443c-ce1f-a7e7d7fc7b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           Model_name  \\\n",
              "0                                        Baseline(Bilstm+crf+glove25)   \n",
              "0                                       Bilstm+crf+glove25+domain_emb   \n",
              "0                                  Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                               Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                               Bilstm+crf+domain_emb   \n",
              "0                                       Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                       Bilstm+crf+syn_emb+domain_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f14f5f5b-1966-48b6-afc1-00755b08ec5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f14f5f5b-1966-48b6-afc1-00755b08ec5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f14f5f5b-1966-48b6-afc1-00755b08ec5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f14f5f5b-1966-48b6-afc1-00755b08ec5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "g7zD0mrDoSiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl.iloc[7:14,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "k7ei_3PdolOM",
        "outputId": "728173b1-b6d2-4465-e7d4-0fd3be41290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  \\\n",
              "7            7   \n",
              "8            8   \n",
              "9            9   \n",
              "10          10   \n",
              "11          11   \n",
              "12          12   \n",
              "13          13   \n",
              "\n",
              "                                                            Model_name  \\\n",
              "7                      Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "8                      Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "9                   Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "10             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "11          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "12          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "13  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "\n",
              "        T-F1  \n",
              "7   0.774900  \n",
              "8   0.986179  \n",
              "9   0.990526  \n",
              "10  0.986748  \n",
              "11  0.987917  \n",
              "12  0.989237  \n",
              "13  0.985729  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da30e2c8-bca0-4b30-bf02-06259678061f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da30e2c8-bca0-4b30-bf02-06259678061f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da30e2c8-bca0-4b30-bf02-06259678061f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da30e2c8-bca0-4b30-bf02-06259678061f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation study: attention strategy"
      ],
      "metadata": {
        "id": "fte0zcTr1Mn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(dot_product,1layer)+domain_emb"
      ],
      "metadata": {
        "id": "AB_nxVnRQbxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "ATTENTION_METHOD = 'dot_product'\n",
        "#ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(dot_product,1layer)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "Z7uONeFeRQb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "4cc2a7e8-1115-4925-e3b2-302ab4e9d87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [01:28, 50.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.1736966796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9992it [02:56, 53.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.585273583984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14995it [04:23, 60.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.462003515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [05:51, 52.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3924794921875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24998it [07:19, 57.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.36727412109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:39, 56.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 20174.27, train acc: 0.9888, val loss: 1898.27, val acc: 0.9858, time: 631.72s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5006it [01:27, 49.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2713629638671875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10005it [02:56, 60.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1858135498046875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:22, 62.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.160083642578125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [05:49, 53.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1646675048828125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25002it [07:17, 55.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.17830933837890625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:37, 57.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 4741.29, train acc: 0.9952, val loss: 1623.17, val acc: 0.9885, time: 629.67s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Model_name      T-F1   T-F1(O)  \\\n",
              "0  Bilstm+crf+Attention(dot_product,1layer)+domain_emb  0.988517  0.990692   \n",
              "\n",
              "    T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)   T-F1(C)  \n",
              "0  0.946873  0.995689         1.0  0.987178  0.913858  0.979617  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcb88de8-efb5-4c1d-8aa7-fb65d83786f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "      <td>0.990692</td>\n",
              "      <td>0.946873</td>\n",
              "      <td>0.995689</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.987178</td>\n",
              "      <td>0.913858</td>\n",
              "      <td>0.979617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcb88de8-efb5-4c1d-8aa7-fb65d83786f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcb88de8-efb5-4c1d-8aa7-fb65d83786f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcb88de8-efb5-4c1d-8aa7-fb65d83786f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(dot_product,1layer)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "vq45b1MXRQfS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "outputId": "1457a78a-a3cb-4eab-8a3d-1ef61603689d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           Model_name  \\\n",
              "0                                        Baseline(Bilstm+crf+glove25)   \n",
              "0                                       Bilstm+crf+glove25+domain_emb   \n",
              "0                                  Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                               Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                               Bilstm+crf+domain_emb   \n",
              "0                                       Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                       Bilstm+crf+syn_emb+domain_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                 Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa3d19ac-3bbf-4a4c-b635-c9a6dbbfe172\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa3d19ac-3bbf-4a4c-b635-c9a6dbbfe172')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa3d19ac-3bbf-4a4c-b635-c9a6dbbfe172 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa3d19ac-3bbf-4a4c-b635-c9a6dbbfe172');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(cos,1layer)+domain_emb"
      ],
      "metadata": {
        "id": "fxtnD4HdQcNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "#ATTENTION_METHOD = 'scaled_dot_product'\n",
        "ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(cos,1layer)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "Q1vPd3KiTi7Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "6b462339-d5cd-428a-a305-b38fdcea0d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4999it [01:27, 49.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.0882322265625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10001it [02:55, 60.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.660576953125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:22, 62.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.506692333984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20004it [05:49, 52.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.4003522216796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [07:17, 54.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.370787744140625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:37, 57.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 20474.05, train acc: 0.9855, val loss: 2486.12, val acc: 0.9829, time: 630.00s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [01:26, 50.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.336263916015625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10001it [02:54, 59.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.23251552734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:21, 62.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.201837109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [05:47, 52.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1763650634765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24996it [07:15, 54.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2060179931640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:34, 57.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 5574.95, train acc: 0.9938, val loss: 1465.88, val acc: 0.9897, time: 627.08s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Model_name      T-F1   T-F1(O)  T-F1(T)  \\\n",
              "0  Bilstm+crf+Attention(cos,1layer)+domain_emb  0.989746  0.991705  0.96304   \n",
              "\n",
              "    T-F1(P)  T-F1(SEPA)   T-F1(S)  T-F1(D)   T-F1(C)  \n",
              "0  0.995801    0.999723  0.987696     0.91  0.977669  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9565b03a-91e2-46ff-ad82-eff59f5f2071\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "      <td>0.991705</td>\n",
              "      <td>0.96304</td>\n",
              "      <td>0.995801</td>\n",
              "      <td>0.999723</td>\n",
              "      <td>0.987696</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.977669</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9565b03a-91e2-46ff-ad82-eff59f5f2071')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9565b03a-91e2-46ff-ad82-eff59f5f2071 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9565b03a-91e2-46ff-ad82-eff59f5f2071');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl.iloc[7:14,:]"
      ],
      "metadata": {
        "id": "RizdBnv0pIYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(cos,1layer)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "WV9ee2tKTi9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "8f94fd9d-ba09-460c-fa66-63e079056e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                           Model_name  \\\n",
              "0                                        Baseline(Bilstm+crf+glove25)   \n",
              "0                                       Bilstm+crf+glove25+domain_emb   \n",
              "0                                  Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                               Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                               Bilstm+crf+domain_emb   \n",
              "0                                       Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                       Bilstm+crf+syn_emb+domain_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                     Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                 Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "0                         Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  \n",
              "0  0.989746  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64c14bca-3cd6-4d58-9fdf-a390b64d1e52\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64c14bca-3cd6-4d58-9fdf-a390b64d1e52')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-64c14bca-3cd6-4d58-9fdf-a390b64d1e52 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-64c14bca-3cd6-4d58-9fdf-a390b64d1e52');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "le98MXafpGAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl.iloc[[9,14,15],:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "fKja8CZypVao",
        "outputId": "60a62908-e587-4771-b929-95167ea2c954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                           Model_name      T-F1\n",
              "9            9   Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526\n",
              "14          14  Bilstm+crf+Attention(dot_product,1layer)+domain_emb  0.988517\n",
              "15          15          Bilstm+crf+Attention(cos,1layer)+domain_emb  0.989746"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc1049ba-4973-48aa-8e05-f95a271ea675\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc1049ba-4973-48aa-8e05-f95a271ea675')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc1049ba-4973-48aa-8e05-f95a271ea675 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc1049ba-4973-48aa-8e05-f95a271ea675');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation study: stacked layer numbers and attention position"
      ],
      "metadata": {
        "id": "h56O__z4UWt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb"
      ],
      "metadata": {
        "id": "KtNBKwobQcoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 2\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "STuYP_h8boc_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "11ef6255-ffd5-4f84-8f5f-bbbac6361276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5000it [01:32, 45.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.2945841796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10005it [03:05, 56.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.42791904296875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15004it [04:37, 52.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.349712255859375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20009it [06:08, 49.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2573936767578125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [07:41, 52.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2454275634765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:02, 54.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 18120.22, train acc: 0.9914, val loss: 1488.30, val acc: 0.9882, time: 662.49s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5001it [01:31, 46.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.18229527587890626\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:05, 56.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10651627197265626\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14995it [04:37, 52.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1035560546875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [06:08, 49.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.104638330078125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24996it [07:42, 53.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09379010009765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:03, 53.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2808.45, train acc: 0.9967, val loss: 1275.20, val acc: 0.9895, time: 665.10s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                           Model_name  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "\n",
              "       T-F1   T-F1(O)   T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)  \\\n",
              "0  0.989507  0.992235  0.954499  0.996308         1.0  0.988072  0.902975   \n",
              "\n",
              "    T-F1(C)  \n",
              "0  0.973596  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5bf9a9c-abf3-4ae4-836e-26489e4db3d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "      <td>0.992235</td>\n",
              "      <td>0.954499</td>\n",
              "      <td>0.996308</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988072</td>\n",
              "      <td>0.902975</td>\n",
              "      <td>0.973596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5bf9a9c-abf3-4ae4-836e-26489e4db3d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5bf9a9c-abf3-4ae4-836e-26489e4db3d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5bf9a9c-abf3-4ae4-836e-26489e4db3d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "MfFfTrRIbofB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "2699bf88-46bf-4a8e-96be-f2d24ccddce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                           Model_name  \\\n",
              "0                                                        Baseline(Bilstm+crf+glove25)   \n",
              "0                                                       Bilstm+crf+glove25+domain_emb   \n",
              "0                                                  Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                                               Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                                               Bilstm+crf+domain_emb   \n",
              "0                                                       Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                                       Bilstm+crf+syn_emb+domain_emb   \n",
              "0                                     Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                                     Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                                  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0                             Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0                          Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0                          Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0                  Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                                 Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "0                                         Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  \n",
              "0  0.989746  \n",
              "0  0.989507  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-067c58eb-d9b2-405d-87c7-4fb935308c8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-067c58eb-d9b2-405d-87c7-4fb935308c8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-067c58eb-d9b2-405d-87c7-4fb935308c8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-067c58eb-d9b2-405d-87c7-4fb935308c8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb"
      ],
      "metadata": {
        "id": "49V2k0LfmsJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = True\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "w4dwY_esmzLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "15d46049-f96b-43a7-f349-cdebcc3db904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5002it [01:36, 45.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.7791\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:13, 56.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.64238583984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:47, 57.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.442314306640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20003it [06:22, 51.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.3151566650390625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [07:59, 53.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2850303955078125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:22, 51.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 22607.98, train acc: 0.9885, val loss: 1752.01, val acc: 0.9858, time: 695.72s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5005it [01:36, 45.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.24704677734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10001it [03:13, 55.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.14284945068359375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15000it [04:48, 57.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1645341552734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20003it [06:23, 50.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.13509078369140626\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25001it [08:00, 56.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1308053466796875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:22, 51.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 3950.28, train acc: 0.9947, val loss: 1542.10, val acc: 0.9884, time: 698.36s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             Model_name  \\\n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "\n",
              "       T-F1   T-F1(O)   T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)  \\\n",
              "0  0.988367  0.991399  0.956194  0.996571    0.999723  0.985928  0.844933   \n",
              "\n",
              "    T-F1(C)  \n",
              "0  0.977873  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3b77262-73a6-4f0a-b60b-fd097bcee7ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "      <td>0.991399</td>\n",
              "      <td>0.956194</td>\n",
              "      <td>0.996571</td>\n",
              "      <td>0.999723</td>\n",
              "      <td>0.985928</td>\n",
              "      <td>0.844933</td>\n",
              "      <td>0.977873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3b77262-73a6-4f0a-b60b-fd097bcee7ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3b77262-73a6-4f0a-b60b-fd097bcee7ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3b77262-73a6-4f0a-b60b-fd097bcee7ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "CPwsVbSEm0bZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "d47f457a-5039-452e-b3f4-c66e760ef64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             Model_name  \\\n",
              "0                                                          Baseline(Bilstm+crf+glove25)   \n",
              "0                                                         Bilstm+crf+glove25+domain_emb   \n",
              "0                                                    Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                                                 Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                                                 Bilstm+crf+domain_emb   \n",
              "0                                                         Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                                         Bilstm+crf+syn_emb+domain_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                                    Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0                               Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0                    Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                                   Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "0                                           Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "0    Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  \n",
              "0  0.989746  \n",
              "0  0.989507  \n",
              "0  0.988367  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83c3b23c-1d68-42c1-aff3-fb8caef50daf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83c3b23c-1d68-42c1-aff3-fb8caef50daf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83c3b23c-1d68-42c1-aff3-fb8caef50daf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83c3b23c-1d68-42c1-aff3-fb8caef50daf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb"
      ],
      "metadata": {
        "id": "gcn6CUwsnFTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 3\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "id": "TiWrsHfunO_S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "5e2893c0-23a6-42c7-cbb6-df3e4749a70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4998it [01:39, 43.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  2.6926287109375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10000it [03:20, 54.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.5474263671875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15003it [04:58, 50.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.412040478515625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [06:36, 46.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.299031884765625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [08:19, 41.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2867138427734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:43, 49.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 21485.72, train acc: 0.9863, val loss: 2092.62, val acc: 0.9835, time: 716.39s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4998it [01:41, 42.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.2449040283203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9997it [03:22, 49.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1409899658203125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14998it [04:59, 49.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.13998779296875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "19999it [06:37, 45.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.1192095458984375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25004it [08:20, 47.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.13054808349609376\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [08:43, 49.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 3735.36, train acc: 0.9938, val loss: 1626.87, val acc: 0.9864, time: 724.54s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                            Model_name  \\\n",
              "0  BBilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb   \n",
              "\n",
              "       T-F1   T-F1(O)  T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)  \\\n",
              "0  0.986418  0.990751  0.95498  0.994251    0.999722  0.974937  0.847368   \n",
              "\n",
              "    T-F1(C)  \n",
              "0  0.972366  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8466845-eb01-4b80-be1a-3dcf9371417a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BBilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb</td>\n",
              "      <td>0.986418</td>\n",
              "      <td>0.990751</td>\n",
              "      <td>0.95498</td>\n",
              "      <td>0.994251</td>\n",
              "      <td>0.999722</td>\n",
              "      <td>0.974937</td>\n",
              "      <td>0.847368</td>\n",
              "      <td>0.972366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8466845-eb01-4b80-be1a-3dcf9371417a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8466845-eb01-4b80-be1a-3dcf9371417a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8466845-eb01-4b80-be1a-3dcf9371417a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "id": "IQ4HXfemnU3X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "outputId": "25b438f8-fdd8-43cf-feeb-72420858aee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             Model_name  \\\n",
              "0                                                          Baseline(Bilstm+crf+glove25)   \n",
              "0                                                         Bilstm+crf+glove25+domain_emb   \n",
              "0                                                    Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                                                 Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                                                 Bilstm+crf+domain_emb   \n",
              "0                                                         Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                                         Bilstm+crf+syn_emb+domain_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                                    Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0                               Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0                    Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                                   Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "0                                           Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "0    Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "0    Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  \n",
              "0  0.989746  \n",
              "0  0.989507  \n",
              "0  0.988367  \n",
              "0  0.986418  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68dbd1ee-d50d-4c11-99c8-51467f30c026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb</td>\n",
              "      <td>0.986418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68dbd1ee-d50d-4c11-99c8-51467f30c026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68dbd1ee-d50d-4c11-99c8-51467f30c026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68dbd1ee-d50d-4c11-99c8-51467f30c026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "GkcJ9APyrgZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl.iloc[[9,16,17,18],:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ZSbaZn1erijo",
        "outputId": "0c11883e-34f1-423f-87db-a264cecf7e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  \\\n",
              "9            9   \n",
              "16          16   \n",
              "17          17   \n",
              "18          18   \n",
              "\n",
              "                                                                              Model_name  \\\n",
              "9                                     Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "16    Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "17  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "18    Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb   \n",
              "\n",
              "        T-F1  \n",
              "9   0.990526  \n",
              "16  0.989507  \n",
              "17  0.988367  \n",
              "18  0.986418  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a97ab6e8-4f20-43cd-8ab8-07278dd834c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb</td>\n",
              "      <td>0.986418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a97ab6e8-4f20-43cd-8ab8-07278dd834c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a97ab6e8-4f20-43cd-8ab8-07278dd834c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a97ab6e8-4f20-43cd-8ab8-07278dd834c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation study: with/without CRF"
      ],
      "metadata": {
        "id": "QuNV7NUUUgjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bilstm+Attention(scaled-d-a,1layer)+domain_emb"
      ],
      "metadata": {
        "id": "99LE9JPX-BeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2 to have 2 layer LSTM, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = False\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Bilstm+Attention(scaled-d-a,1layer)+domain_emb'\n",
        "Model_name_list.append(Model_name)\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
        "\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Train and valid\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\"\"\"Each epoch will take about 1-2 minutes\"\"\"\n",
        "torch.manual_seed(1)\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "loss_mean_view = 0\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    #if epoch == 1:\n",
        "    #  optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4)\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index)):\n",
        "        j+=1\n",
        "        tags_index = train_output_index[i]\n",
        "        ent_index = train_ent_index[i]\n",
        "        dep_index = train_dep_index[i]\n",
        "        pos_index = train_pos_index[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          \n",
        "          print('Mean 5000 sample Loss: ',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    # Call the cal_acc functions you implemented as required\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index,train_pos_index,train_dep_index,train_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "    val_pred, val_true, val_acc = cal_acc(model,val_input_index,val_output_index,val_pos_index,val_dep_index,val_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        ent_index = val_ent_index[i]\n",
        "        dep_index = val_dep_index[i]\n",
        "        pos_index = val_pos_index[i]\n",
        "\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets,pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "    print('='*150)\n",
        "\n",
        "df_eval = calculate_f1(val_pred,val_true,Model_name)\n",
        "df_eval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "df_eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "G8ueAkc1aEya",
        "outputId": "e116afb7-c4ea-4277-eb5f-f3605674a0a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5004it [01:35, 49.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  1.7969640625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10004it [03:06, 57.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.418040576171875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14995it [04:34, 59.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.330938671875\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20004it [06:03, 53.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.252335302734375\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24996it [07:32, 54.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.227056689453125\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:53, 55.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1, Training loss: 15339.90, train acc: 0.9901, val loss: 1427.92, val acc: 0.9869, time: 575.09s\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5003it [01:28, 49.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.16752420654296876\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10005it [02:59, 61.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.10094646606445312\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15002it [04:27, 61.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.09243887329101562\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20001it [05:55, 52.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.0912418212890625\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "24996it [07:27, 51.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss:  0.07289392700195313\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "26078it [07:49, 55.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2, Training loss: 2469.69, train acc: 0.9965, val loss: 1400.91, val acc: 0.9875, time: 573.13s\n",
            "======================================================================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       Model_name      T-F1   T-F1(O)  \\\n",
              "0  Bilstm+Attention(scaled-d-a,1layer)+domain_emb  0.987528  0.989915   \n",
              "\n",
              "    T-F1(T)   T-F1(P)  T-F1(SEPA)   T-F1(S)   T-F1(D)  T-F1(C)  \n",
              "0  0.946417  0.996944    0.999861  0.988335  0.859091  0.98063  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6119e45-3a7f-4c4c-b2ed-dd22c5cae505\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "      <th>T-F1(O)</th>\n",
              "      <th>T-F1(T)</th>\n",
              "      <th>T-F1(P)</th>\n",
              "      <th>T-F1(SEPA)</th>\n",
              "      <th>T-F1(S)</th>\n",
              "      <th>T-F1(D)</th>\n",
              "      <th>T-F1(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.987528</td>\n",
              "      <td>0.989915</td>\n",
              "      <td>0.946417</td>\n",
              "      <td>0.996944</td>\n",
              "      <td>0.999861</td>\n",
              "      <td>0.988335</td>\n",
              "      <td>0.859091</td>\n",
              "      <td>0.98063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6119e45-3a7f-4c4c-b2ed-dd22c5cae505')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6119e45-3a7f-4c4c-b2ed-dd22c5cae505 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6119e45-3a7f-4c4c-b2ed-dd22c5cae505');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'Bilstm+Attention(scaled-d-a,1layer)+domain_emb'\n",
        "df_eval = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_eval.csv\")\n",
        "Ablation_df = pd.concat([Ablation_df,df_eval.iloc[[0],1:3]],0)\n",
        "Ablation_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "3TUZN_4paE8f",
        "outputId": "23828b6c-0e98-48cd-87e2-83b07136ccde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                             Model_name  \\\n",
              "0                                                          Baseline(Bilstm+crf+glove25)   \n",
              "0                                                         Bilstm+crf+glove25+domain_emb   \n",
              "0                                                    Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "0                                                 Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "0                                                                 Bilstm+crf+domain_emb   \n",
              "0                                                         Bilstm+crf+sym_emb+domain_emb   \n",
              "0                                                         Bilstm+crf+syn_emb+domain_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "0                                       Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "0                                    Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "0                               Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "0                            Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "0                    Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "0                                   Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "0                                           Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "0    Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "0  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "0    Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb   \n",
              "0                                        Bilstm+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "\n",
              "       T-F1  \n",
              "0  0.979882  \n",
              "0  0.990046  \n",
              "0  0.980212  \n",
              "0  0.989776  \n",
              "0  0.988397  \n",
              "0  0.990436  \n",
              "0  0.989117  \n",
              "0  0.774900  \n",
              "0  0.986179  \n",
              "0  0.990526  \n",
              "0  0.986748  \n",
              "0  0.987917  \n",
              "0  0.989237  \n",
              "0  0.985729  \n",
              "0  0.988517  \n",
              "0  0.989746  \n",
              "0  0.989507  \n",
              "0  0.988367  \n",
              "0  0.986418  \n",
              "0  0.987528  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c54ac79b-06f9-4ae3-96cf-2226eed2879a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb</td>\n",
              "      <td>0.986418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bilstm+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.987528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c54ac79b-06f9-4ae3-96cf-2226eed2879a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c54ac79b-06f9-4ae3-96cf-2226eed2879a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c54ac79b-06f9-4ae3-96cf-2226eed2879a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "a8LQLoj5sEbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl.iloc[[9,19],:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zDSspSQrsGPE",
        "outputId": "a4c9c4c9-187d-4f79-ab05-96c2caaf16e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0                                          Model_name      T-F1\n",
              "9            9  Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb  0.990526\n",
              "19          19      Bilstm+Attention(scaled-d-a,1layer)+domain_emb  0.987528"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d35f0c-cf4a-4b4e-877e-5be97b03eeef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Bilstm+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.987528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d35f0c-cf4a-4b4e-877e-5be97b03eeef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d35f0c-cf4a-4b4e-877e-5be97b03eeef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d35f0c-cf4a-4b4e-877e-5be97b03eeef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_abl = Ablation_df.reset_index(drop=True)\n",
        "final_abl.to_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')"
      ],
      "metadata": {
        "id": "MTkjbkCAafeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_abl = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/5046a2/ablation.csv')\n",
        "final_abl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "oscfQPFmhxh1",
        "outputId": "2cbd5619-b545-4c3a-dfdc-9fd7aad49632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Unnamed: 0  \\\n",
              "0            0   \n",
              "1            1   \n",
              "2            2   \n",
              "3            3   \n",
              "4            4   \n",
              "5            5   \n",
              "6            6   \n",
              "7            7   \n",
              "8            8   \n",
              "9            9   \n",
              "10          10   \n",
              "11          11   \n",
              "12          12   \n",
              "13          13   \n",
              "14          14   \n",
              "15          15   \n",
              "16          16   \n",
              "17          17   \n",
              "18          18   \n",
              "19          19   \n",
              "\n",
              "                                                                              Model_name  \\\n",
              "0                                                           Baseline(Bilstm+crf+glove25)   \n",
              "1                                                          Bilstm+crf+glove25+domain_emb   \n",
              "2                                                     Bilstm+crf+glove25+syn_emb+sym_emb   \n",
              "3                                                  Bilstm+crf+glove25+syn_emb+domain_emb   \n",
              "4                                                                  Bilstm+crf+domain_emb   \n",
              "5                                                          Bilstm+crf+sym_emb+domain_emb   \n",
              "6                                                          Bilstm+crf+syn_emb+domain_emb   \n",
              "7                                        Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb   \n",
              "8                                        Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb   \n",
              "9                                     Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "10                               Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb   \n",
              "11                            Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb   \n",
              "12                            Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb   \n",
              "13                    Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb   \n",
              "14                                   Bilstm+crf+Attention(dot_product,1layer)+domain_emb   \n",
              "15                                           Bilstm+crf+Attention(cos,1layer)+domain_emb   \n",
              "16    Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb   \n",
              "17  Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb   \n",
              "18    Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb   \n",
              "19                                        Bilstm+Attention(scaled-d-a,1layer)+domain_emb   \n",
              "\n",
              "        T-F1  \n",
              "0   0.979882  \n",
              "1   0.990046  \n",
              "2   0.980212  \n",
              "3   0.989776  \n",
              "4   0.988397  \n",
              "5   0.990436  \n",
              "6   0.989117  \n",
              "7   0.774900  \n",
              "8   0.986179  \n",
              "9   0.990526  \n",
              "10  0.986748  \n",
              "11  0.987917  \n",
              "12  0.989237  \n",
              "13  0.985729  \n",
              "14  0.988517  \n",
              "15  0.989746  \n",
              "16  0.989507  \n",
              "17  0.988367  \n",
              "18  0.986418  \n",
              "19  0.987528  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4f634d7-7ce0-4e18-9ac0-4866cd845080\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Model_name</th>\n",
              "      <th>T-F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Baseline(Bilstm+crf+glove25)</td>\n",
              "      <td>0.979882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Bilstm+crf+glove25+domain_emb</td>\n",
              "      <td>0.990046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+sym_emb</td>\n",
              "      <td>0.980212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Bilstm+crf+glove25+syn_emb+domain_emb</td>\n",
              "      <td>0.989776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Bilstm+crf+domain_emb</td>\n",
              "      <td>0.988397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Bilstm+crf+sym_emb+domain_emb</td>\n",
              "      <td>0.990436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Bilstm+crf+syn_emb+domain_emb</td>\n",
              "      <td>0.989117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb</td>\n",
              "      <td>0.774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb</td>\n",
              "      <td>0.986179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.990526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb</td>\n",
              "      <td>0.986748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+domain_emb</td>\n",
              "      <td>0.987917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+sym_emb+domain_emb</td>\n",
              "      <td>0.989237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,1layer)+syn_emb+sym_emb+domain_emb</td>\n",
              "      <td>0.985729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>Bilstm+crf+Attention(dot_product,1layer)+domain_emb</td>\n",
              "      <td>0.988517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>Bilstm+crf+Attention(cos,1layer)+domain_emb</td>\n",
              "      <td>0.989746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position after 2 lstm)+domain_emb</td>\n",
              "      <td>0.989507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,2layer,attention position between 2 lstm)+domain_emb</td>\n",
              "      <td>0.988367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>Bilstm+crf+Attention(scaled-d-a,3layer,attention position after 3 lstm)+domain_emb</td>\n",
              "      <td>0.986418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Bilstm+Attention(scaled-d-a,1layer)+domain_emb</td>\n",
              "      <td>0.987528</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4f634d7-7ce0-4e18-9ac0-4866cd845080')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4f634d7-7ce0-4e18-9ac0-4866cd845080 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4f634d7-7ce0-4e18-9ac0-4866cd845080');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best model for prediction"
      ],
      "metadata": {
        "id": "FH_gqpN19CIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "# Config\n",
        "#-----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "HIDDEN_DIM = 250\n",
        "learning_rate = 0.0005\n",
        "DROPOUT = 0\n",
        "NUM_LAYER = 1\n",
        "\n",
        "ATTENTION = True\n",
        "# only available when NUM_LAYER=1, then class can automatically activate LSTM2, and automatically add attention between two LSTM layers.\n",
        "ATTENTION_POSITION_BETWEEN_TWO_LAYER = False\n",
        "CRF = True\n",
        "\n",
        "#ATTENTION_METHOD = 'dot_product'\n",
        "ATTENTION_METHOD = 'scaled_dot_product'\n",
        "#ATTENTION_METHOD == 'cos'\n",
        "\n",
        "SYN = False\n",
        "SYM = False\n",
        "DOMAIN = True\n",
        "BASELINE = False\n",
        "\n",
        "Model_name = 'Best_model:Bilstm+crf+Attention(scaled-d-a,1layer)+domain_emb'\n",
        "#(48+45+19)\n",
        "EMBEDDING_DIM = (48+45+19)*SYN+(250)*SYM+(250)*DOMAIN+25*BASELINE\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
        "#optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)"
      ],
      "metadata": {
        "id": "jtFKxCe54U2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After getting the F1 evaluation result of validation data for report, train this validation data combine training data to improve model\n",
        "# reset model\n",
        "\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF,attention_method=ATTENTION_METHOD).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "loss_mean_view = 0\n",
        "\n",
        "for epoch in range(2):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "    model.train()\n",
        "    j = 0\n",
        "    for i, idxs in tqdm(enumerate(train_input_index+val_input_index)):\n",
        "        j+=1\n",
        "        tags_index = (train_output_index+val_output_index)[i]\n",
        "        ent_index = (train_ent_index+val_ent_index)[i]\n",
        "        dep_index = (train_dep_index+val_dep_index)[i]\n",
        "        pos_index = (train_pos_index+val_pos_index)[i]\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        ent = torch.tensor(ent_index, dtype=torch.long).to(device)\n",
        "        dep = torch.tensor(dep_index, dtype=torch.long).to(device)\n",
        "        pos = torch.tensor(pos_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets, pos,dep,ent,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN)\n",
        "        loss_mean_view+=loss\n",
        "        if j % 5000 == 0:\n",
        "          print('\\n')\n",
        "          print('Mean 5000 sample Loss:',loss_mean_view.cpu().detach().numpy()[0]/5000)\n",
        "          print('\\n')\n",
        "          print('-'*150)\n",
        "          loss_mean_view=0\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('='*150)\n",
        "    print(\"Epoch:%d\" %(epoch+1))\n",
        "    print('='*150)"
      ],
      "metadata": {
        "id": "HmEw0tC08tCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959e7509-f943-498b-b80e-67870d86cfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5001it [02:32, 26.90it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 1.7854345703125\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10003it [04:58, 35.80it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.433616162109375\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14998it [07:21, 39.51it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.344727978515625\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20005it [09:47, 31.78it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.26478076171875\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "25002it [12:14, 37.24it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.242056201171875\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29997it [14:38, 37.66it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.18580111083984374\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "34783it [16:57, 34.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:1\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5004it [02:24, 28.92it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.2751015380859375\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10003it [04:51, 36.33it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.09200323486328126\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "15003it [07:13, 39.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.08422568969726563\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "20000it [09:35, 29.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.07881895141601562\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "25000it [12:00, 39.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.08126123046875\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "30002it [14:24, 38.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Mean 5000 sample Loss: 0.0574939697265625\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "34783it [16:43, 34.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Epoch:2\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate prediction result"
      ],
      "metadata": {
        "id": "P49VMm7jf7qM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = predict(model,test_input_index,test_pos_index,test_dep_index,test_ent_index,syn=SYN,sym=SYM,baseline=BASELINE,domain=DOMAIN,attention=ATTENTION,crf=CRF)\n",
        "df_pred.to_csv(\"/content/drive/MyDrive/Colab Notebooks/5046a2/\"+Model_name+\"_predict.csv\",index_label=\"Id\")"
      ],
      "metadata": {
        "id": "4LpHlQ0y6mHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred.head()"
      ],
      "metadata": {
        "id": "8w_jbcfu8OyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "87367af4-5928-4394-8ff9-97d5d6ab5fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Predicted\n",
              "0         T\n",
              "1         O\n",
              "2         S\n",
              "3         O\n",
              "4         O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6689b8a-650e-45b8-843f-18aaa938a88e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6689b8a-650e-45b8-843f-18aaa938a88e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6689b8a-650e-45b8-843f-18aaa938a88e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6689b8a-650e-45b8-843f-18aaa938a88e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7oLWS5beh-Li"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}